
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Crawling Website &#8212; My sample book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Ekstraksi Ringkasan Dokumen" href="ekstraksi.html" />
    <link rel="prev" title="Welcome to your Jupyter Book" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">My sample book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Crawling Website
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ekstraksi.html">
   Ekstraksi Ringkasan Dokumen
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble.html">
   Ensemble Learning (Bagging, Stacking, dan Random Forest Classification) dan Grid Search
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="klasifikasi.html">
   Klasifikasi &amp; Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="modelling.html">
   Topik Modelling Dengan Latent Semantic Indexing (LSI) atau Latent Semantic Analysis (LSA) menggunakan Scikit-Learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="UTS.html">
   UTS WEB Mining
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markdown.html">
   Markdown Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks.html">
   Content with notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markdown-notebooks.html">
   Notebooks with MyST Markdown
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/crawling.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fcrawling.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/crawling.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Crawling Website
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#installasi-scrapy">
     <strong>
      Installasi Scrapy
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#crawling-abstrak">
     <strong>
      Crawling Abstrak
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#buang-baris-kosong">
     <strong>
      Buang Baris Kosong
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#baca-hasil-crawling">
     <strong>
      Baca Hasil Crawling
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kesimpulan">
     <strong>
      Kesimpulan
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#klasifikasi-clustering">
   Klasifikasi &amp; Clustering
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#praprepocessing-text">
     <strong>
      Praprepocessing Text
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#crawling-tweeter">
       Crawling Tweeter
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#installasi-twint">
         Installasi Twint
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#scraping-data-tweeter">
         Scraping Data Tweeter
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#ambil-tweet">
         Ambil Tweet
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#upload-data-tweet">
       Upload Data Tweet
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prepocessing-text">
     <strong>
      Prepocessing Text
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#case-folding">
       Case Folding
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#merubah-huruf-kecil-semua">
         Merubah Huruf Kecil Semua
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#menghapus-karakter-spesial">
         Menghapus Karakter Spesial
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#menghapus-angka">
         Menghapus Angka
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#menghapus-tanda-baca">
         Menghapus Tanda Baca
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#menghapus-spasi">
         Menghapus Spasi
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#menghapus-huruf">
         Menghapus Huruf
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tokenizing">
       Tokenizing
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#filtering-stopword">
       Filtering(Stopword)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stemming">
       Stemming
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#labelling-dataset">
     <strong>
      Labelling Dataset
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nilai-polarity">
       Nilai Polarity
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#ambil-nilai-polarity">
       Ambil Nilai Polarity
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#menentukan-kelas-label-dengan-nilai-polarity">
       Menentukan Kelas/Label dengan Nilai Polarity
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#term-frequncy-tf">
     <strong>
      Term Frequncy(TF)
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#matrik-vsm-visual-space-model">
       Matrik VSM(Visual Space Model)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nilai-term-dokumen">
       Nilai Term Dokumen
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mengambil-data-label">
       Mengambil Data label
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#split-data">
       Split Data
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#data-training">
         Data Training
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#data-testing">
         Data Testing
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#information-gain">
     <strong>
      Information Gain
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sorting-information-gain">
       Sorting Information Gain
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#membuat-grafik-information-gain">
       Membuat Grafik Information Gain
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pilih-fitur-penting">
       Pilih Fitur Penting
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#klasifikasi-data">
     <strong>
      Klasifikasi Data
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#knn-k-nearest-neighbor">
       KNN (K-Nearest Neighbor)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#naive-bayes">
       Naive Bayes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#svm-support-vector-machine">
       SVM(Support Vector Machine)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#klustering-data">
     <strong>
      Klustering Data
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#k-means-clustering">
       K-Means Clustering
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hasil-clustering">
       Hasil Clustering
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     <strong>
      Kesimpulan
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ekstraksi-ringkasan-dokumen">
   Ekstraksi Ringkasan Dokumen
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mengambil-dokumen">
     <strong>
      Mengambil Dokumen
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#membaca-dokumen">
     <strong>
      Membaca Dokumen
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#convert-file-csv-ke-pdf">
       Convert File CSV ke PDF
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#baca-dokumen">
       Baca Dokumen
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#memecah-dokumen">
     <strong>
      Memecah Dokumen
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#memecah-kalimat">
       Memecah Kalimat
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#memecah-kata">
       Memecah Kata
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#membuat-matrik-tf-idf">
     <strong>
      Membuat Matrik TF-IDF
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#membuat-graph">
     <strong>
      Membuat Graph
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#menghitung-pagerank">
     <strong>
      Menghitung PageRank
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#memilih-kalimat">
     <strong>
      Memilih Kalimat
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     <strong>
      Kesimpulan
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#uts-web-mining">
   UTS WEB Mining
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clustering-tragedi-kanjuruhan">
     <strong>
      1. Clustering Tragedi Kanjuruhan
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       <strong>
        Praprepocessing Text
       </strong>
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id4">
         Crawling Tweeter
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id5">
         Installasi Twint
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id6">
         Scraping Data Tweeter
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id7">
         Ambil Tweet
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id8">
         Upload Data Tweet
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id9">
       Prepocessing Text
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id10">
         Case Folding
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id11">
           Merubah Huruf Kecil Semua
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id12">
           Menghapus Karakter Spesial
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id13">
           Menghapus Angka
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id14">
           Menghapus Tanda Baca
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id15">
           Menghapus Spasi
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id16">
           Menghapus Huruf
          </a>
         </li>
        </ul>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id17">
         Tokenizing
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id18">
         Filtering(Stopword)
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id19">
         Stemming
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id20">
       Term Frequncy(TF)
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id21">
         Matrik VSM(Visual Space Model)
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id22">
       Klustering Data
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id23">
         K-Means Clustering
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id24">
         Hasil Clustering
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id25">
       Kesimpulan
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ringkasan-berita-dengan-pagerank">
     <strong>
      2. Ringkasan Berita dengan PageRank
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id26">
       Mengambil Dokumen
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id27">
       Membaca Dokumen
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id28">
         Convert File CSV ke PDF
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id29">
         Baca Dokumen
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id30">
       Memecah Dokumen
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id31">
         Memecah Kalimat
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id32">
         Memecah Kata
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id33">
       Membuat Matrik TF-IDF
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id34">
       Membuat Graph
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id35">
       Menghitung PageRank
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id36">
       Memilih Kalimat
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id37">
       Kesimpulan
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#topik-modelling-dengan-latent-semantic-indexing-lsi-atau-latent-semantic-analysis-lsa-menggunakan-scikit-learn">
   Topik Modelling Dengan Latent Semantic Indexing (LSI) atau Latent Semantic Analysis (LSA) menggunakan Scikit-Learn
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#topik-modelling">
     <strong>
      Topik Modelling
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#latent-semantic-indexing-lsi-atau-latent-semantic-analysis-lsa">
     <strong>
      Latent Semantic Indexing (LSI) atau Latent Semantic Analysis (LSA)
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id38">
     <strong>
      Mengambil Dokumen
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#meload-dokumen">
     <strong>
      Meload Dokumen
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#membuat-fitur-tf-idf">
     <strong>
      Membuat Fitur TF-IDF
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#membuat-matrik-svd">
     <strong>
      Membuat Matrik SVD
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ekstrak-topik-dan-istilah">
     <strong>
      Ekstrak topik dan istilah
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id39">
     <strong>
      Kesimpulan
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ensemble-learning-bagging-stacking-dan-random-forest-classification-dan-grid-search">
   Ensemble Learning (Bagging, Stacking, dan Random Forest Classification) dan Grid Search
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id40">
     <strong>
      Praprepocessing Text
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id41">
       Crawling Tweeter
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id42">
         Installasi Twint
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id43">
         Scraping Data Tweeter
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id44">
         Ambil Tweet
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id45">
       Upload Data Tweet
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id46">
     <strong>
      Prepocessing Text
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id47">
       Case Folding
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id48">
         Merubah Huruf Kecil Semua
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id49">
         Menghapus Karakter Spesial
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id50">
         Menghapus Angka
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id51">
         Menghapus Tanda Baca
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id52">
         Menghapus Spasi
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id53">
         Menghapus Huruf
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id54">
       Tokenizing
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id55">
       Filtering(Stopword)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id56">
       Stemming
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id57">
     <strong>
      Labelling Dataset
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id58">
       Nilai Polarity
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id59">
       Ambil Nilai Polarity
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id60">
       Menentukan Kelas/Label dengan Nilai Polarity
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id61">
     <strong>
      Term Frequncy(TF)
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id62">
       Matrik VSM(Visual Space Model)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id63">
       Nilai Term Dokumen
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id64">
       Mengambil Data label
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id65">
       Split Data
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id66">
         Data Training
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id67">
         Data Testing
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bagging-classification">
     <strong>
      Bagging Classification
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stacking-classification">
     <strong>
      Stacking Classification
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-forest-classification">
     <strong>
      Random Forest Classification
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grid-search">
     <strong>
      Grid Search
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bagging-classification-dengan-menggunakan-grid-search">
       Bagging Classification dengan menggunakan Grid Search
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#random-forest-classification-dengan-menggunakan-grid-search">
       Random Forest Classification dengan menggunakan Grid Search
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id68">
     <strong>
      Kesimpulan
     </strong>
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Crawling Website</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Crawling Website
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#installasi-scrapy">
     <strong>
      Installasi Scrapy
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#crawling-abstrak">
     <strong>
      Crawling Abstrak
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#buang-baris-kosong">
     <strong>
      Buang Baris Kosong
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#baca-hasil-crawling">
     <strong>
      Baca Hasil Crawling
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kesimpulan">
     <strong>
      Kesimpulan
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#klasifikasi-clustering">
   Klasifikasi &amp; Clustering
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#praprepocessing-text">
     <strong>
      Praprepocessing Text
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#crawling-tweeter">
       Crawling Tweeter
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#installasi-twint">
         Installasi Twint
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#scraping-data-tweeter">
         Scraping Data Tweeter
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#ambil-tweet">
         Ambil Tweet
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#upload-data-tweet">
       Upload Data Tweet
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prepocessing-text">
     <strong>
      Prepocessing Text
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#case-folding">
       Case Folding
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#merubah-huruf-kecil-semua">
         Merubah Huruf Kecil Semua
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#menghapus-karakter-spesial">
         Menghapus Karakter Spesial
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#menghapus-angka">
         Menghapus Angka
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#menghapus-tanda-baca">
         Menghapus Tanda Baca
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#menghapus-spasi">
         Menghapus Spasi
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#menghapus-huruf">
         Menghapus Huruf
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tokenizing">
       Tokenizing
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#filtering-stopword">
       Filtering(Stopword)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stemming">
       Stemming
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#labelling-dataset">
     <strong>
      Labelling Dataset
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nilai-polarity">
       Nilai Polarity
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#ambil-nilai-polarity">
       Ambil Nilai Polarity
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#menentukan-kelas-label-dengan-nilai-polarity">
       Menentukan Kelas/Label dengan Nilai Polarity
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#term-frequncy-tf">
     <strong>
      Term Frequncy(TF)
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#matrik-vsm-visual-space-model">
       Matrik VSM(Visual Space Model)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nilai-term-dokumen">
       Nilai Term Dokumen
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mengambil-data-label">
       Mengambil Data label
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#split-data">
       Split Data
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#data-training">
         Data Training
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#data-testing">
         Data Testing
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#information-gain">
     <strong>
      Information Gain
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sorting-information-gain">
       Sorting Information Gain
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#membuat-grafik-information-gain">
       Membuat Grafik Information Gain
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pilih-fitur-penting">
       Pilih Fitur Penting
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#klasifikasi-data">
     <strong>
      Klasifikasi Data
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#knn-k-nearest-neighbor">
       KNN (K-Nearest Neighbor)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#naive-bayes">
       Naive Bayes
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#svm-support-vector-machine">
       SVM(Support Vector Machine)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#klustering-data">
     <strong>
      Klustering Data
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#k-means-clustering">
       K-Means Clustering
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hasil-clustering">
       Hasil Clustering
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     <strong>
      Kesimpulan
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ekstraksi-ringkasan-dokumen">
   Ekstraksi Ringkasan Dokumen
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mengambil-dokumen">
     <strong>
      Mengambil Dokumen
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#membaca-dokumen">
     <strong>
      Membaca Dokumen
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#convert-file-csv-ke-pdf">
       Convert File CSV ke PDF
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#baca-dokumen">
       Baca Dokumen
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#memecah-dokumen">
     <strong>
      Memecah Dokumen
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#memecah-kalimat">
       Memecah Kalimat
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#memecah-kata">
       Memecah Kata
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#membuat-matrik-tf-idf">
     <strong>
      Membuat Matrik TF-IDF
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#membuat-graph">
     <strong>
      Membuat Graph
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#menghitung-pagerank">
     <strong>
      Menghitung PageRank
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#memilih-kalimat">
     <strong>
      Memilih Kalimat
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     <strong>
      Kesimpulan
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#uts-web-mining">
   UTS WEB Mining
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clustering-tragedi-kanjuruhan">
     <strong>
      1. Clustering Tragedi Kanjuruhan
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       <strong>
        Praprepocessing Text
       </strong>
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id4">
         Crawling Tweeter
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id5">
         Installasi Twint
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id6">
         Scraping Data Tweeter
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id7">
         Ambil Tweet
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id8">
         Upload Data Tweet
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id9">
       Prepocessing Text
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id10">
         Case Folding
        </a>
        <ul class="nav section-nav flex-column">
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id11">
           Merubah Huruf Kecil Semua
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id12">
           Menghapus Karakter Spesial
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id13">
           Menghapus Angka
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id14">
           Menghapus Tanda Baca
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id15">
           Menghapus Spasi
          </a>
         </li>
         <li class="toc-h5 nav-item toc-entry">
          <a class="reference internal nav-link" href="#id16">
           Menghapus Huruf
          </a>
         </li>
        </ul>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id17">
         Tokenizing
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id18">
         Filtering(Stopword)
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id19">
         Stemming
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id20">
       Term Frequncy(TF)
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id21">
         Matrik VSM(Visual Space Model)
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id22">
       Klustering Data
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id23">
         K-Means Clustering
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id24">
         Hasil Clustering
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id25">
       Kesimpulan
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ringkasan-berita-dengan-pagerank">
     <strong>
      2. Ringkasan Berita dengan PageRank
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id26">
       Mengambil Dokumen
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id27">
       Membaca Dokumen
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id28">
         Convert File CSV ke PDF
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id29">
         Baca Dokumen
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id30">
       Memecah Dokumen
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id31">
         Memecah Kalimat
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id32">
         Memecah Kata
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id33">
       Membuat Matrik TF-IDF
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id34">
       Membuat Graph
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id35">
       Menghitung PageRank
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id36">
       Memilih Kalimat
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id37">
       Kesimpulan
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#topik-modelling-dengan-latent-semantic-indexing-lsi-atau-latent-semantic-analysis-lsa-menggunakan-scikit-learn">
   Topik Modelling Dengan Latent Semantic Indexing (LSI) atau Latent Semantic Analysis (LSA) menggunakan Scikit-Learn
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#topik-modelling">
     <strong>
      Topik Modelling
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#latent-semantic-indexing-lsi-atau-latent-semantic-analysis-lsa">
     <strong>
      Latent Semantic Indexing (LSI) atau Latent Semantic Analysis (LSA)
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id38">
     <strong>
      Mengambil Dokumen
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#meload-dokumen">
     <strong>
      Meload Dokumen
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#membuat-fitur-tf-idf">
     <strong>
      Membuat Fitur TF-IDF
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#membuat-matrik-svd">
     <strong>
      Membuat Matrik SVD
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ekstrak-topik-dan-istilah">
     <strong>
      Ekstrak topik dan istilah
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id39">
     <strong>
      Kesimpulan
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ensemble-learning-bagging-stacking-dan-random-forest-classification-dan-grid-search">
   Ensemble Learning (Bagging, Stacking, dan Random Forest Classification) dan Grid Search
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id40">
     <strong>
      Praprepocessing Text
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id41">
       Crawling Tweeter
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id42">
         Installasi Twint
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id43">
         Scraping Data Tweeter
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id44">
         Ambil Tweet
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id45">
       Upload Data Tweet
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id46">
     <strong>
      Prepocessing Text
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id47">
       Case Folding
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id48">
         Merubah Huruf Kecil Semua
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id49">
         Menghapus Karakter Spesial
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id50">
         Menghapus Angka
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id51">
         Menghapus Tanda Baca
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id52">
         Menghapus Spasi
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id53">
         Menghapus Huruf
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id54">
       Tokenizing
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id55">
       Filtering(Stopword)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id56">
       Stemming
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id57">
     <strong>
      Labelling Dataset
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id58">
       Nilai Polarity
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id59">
       Ambil Nilai Polarity
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id60">
       Menentukan Kelas/Label dengan Nilai Polarity
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id61">
     <strong>
      Term Frequncy(TF)
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id62">
       Matrik VSM(Visual Space Model)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id63">
       Nilai Term Dokumen
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id64">
       Mengambil Data label
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id65">
       Split Data
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id66">
         Data Training
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id67">
         Data Testing
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bagging-classification">
     <strong>
      Bagging Classification
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stacking-classification">
     <strong>
      Stacking Classification
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-forest-classification">
     <strong>
      Random Forest Classification
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grid-search">
     <strong>
      Grid Search
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bagging-classification-dengan-menggunakan-grid-search">
       Bagging Classification dengan menggunakan Grid Search
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#random-forest-classification-dengan-menggunakan-grid-search">
       Random Forest Classification dengan menggunakan Grid Search
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id68">
     <strong>
      Kesimpulan
     </strong>
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="crawling-website">
<h1>Crawling Website<a class="headerlink" href="#crawling-website" title="Permalink to this headline">#</a></h1>
<p>Crawling merupakan suatu proses pengambilan data dengan menggunakan mesin yang dilakukan secara online. Proses ini dilakukan untuk mengimpor data yang ditemukan kedalam file lokal komputer. Untuk dapat melakukan crawling dengan menggunakan python kita dapat menggunakan scrapy.</p>
<section id="installasi-scrapy">
<h2><strong>Installasi Scrapy</strong><a class="headerlink" href="#installasi-scrapy" title="Permalink to this headline">#</a></h2>
<p>Scrapy adalah kerangka kerja aplikasi untuk crawling web site dan mengekstraksi data terstruktur yang dapat digunakan untuk berbagai aplikasi yang bermanfaat, seperti data mining, pemrosesan informasi atau arsip sejarah. Meskipun Scrapy awalnya dirancang untuk web scraping, namu scrapy juga dapat digunakan untuk mengekstrak data menggunakan API (seperti Amazon Associates Web Services) atau sebagai web crawl.<br>
Untuk menggunakan scrapy terlebih dahulu install scrapy dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install scrapy
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: scrapy in /usr/local/lib/python3.7/dist-packages (2.7.1)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from scrapy) (21.3)
Requirement already satisfied: cryptography&gt;=3.3 in /usr/local/lib/python3.7/dist-packages (from scrapy) (38.0.4)
Requirement already satisfied: PyDispatcher&gt;=2.0.5 in /usr/local/lib/python3.7/dist-packages (from scrapy) (2.0.6)
Requirement already satisfied: parsel&gt;=1.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.7.0)
Requirement already satisfied: pyOpenSSL&gt;=21.0.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (22.1.0)
Requirement already satisfied: service-identity&gt;=18.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (21.1.0)
Requirement already satisfied: Twisted&gt;=18.9.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (22.10.0)
Requirement already satisfied: queuelib&gt;=1.4.2 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.6.2)
Requirement already satisfied: itemloaders&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.0.6)
Requirement already satisfied: w3lib&gt;=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (2.1.1)
Requirement already satisfied: zope.interface&gt;=5.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (5.5.2)
Requirement already satisfied: protego&gt;=0.1.15 in /usr/local/lib/python3.7/dist-packages (from scrapy) (0.2.1)
Requirement already satisfied: tldextract in /usr/local/lib/python3.7/dist-packages (from scrapy) (3.4.0)
Requirement already satisfied: lxml&gt;=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (4.9.1)
Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from scrapy) (57.4.0)
Requirement already satisfied: cssselect&gt;=0.9.1 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.2.0)
Requirement already satisfied: itemadapter&gt;=0.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (0.7.0)
Requirement already satisfied: cffi&gt;=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography&gt;=3.3-&gt;scrapy) (1.15.1)
Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi&gt;=1.12-&gt;cryptography&gt;=3.3-&gt;scrapy) (2.21)
Requirement already satisfied: jmespath&gt;=0.9.5 in /usr/local/lib/python3.7/dist-packages (from itemloaders&gt;=1.0.1-&gt;scrapy) (1.0.1)
Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from protego&gt;=0.1.15-&gt;scrapy) (1.15.0)
Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity&gt;=18.1.0-&gt;scrapy) (0.2.8)
Requirement already satisfied: attrs&gt;=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity&gt;=18.1.0-&gt;scrapy) (21.4.0)
Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity&gt;=18.1.0-&gt;scrapy) (0.4.8)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: incremental&gt;=21.3.0 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=18.9.0-&gt;scrapy) (22.10.0)
Requirement already satisfied: hyperlink&gt;=17.1.1 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=18.9.0-&gt;scrapy) (21.0.0)
Requirement already satisfied: constantly&gt;=15.1 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=18.9.0-&gt;scrapy) (15.1.0)
Requirement already satisfied: typing-extensions&gt;=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=18.9.0-&gt;scrapy) (4.1.1)
Requirement already satisfied: Automat&gt;=0.8.0 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=18.9.0-&gt;scrapy) (22.10.0)
Requirement already satisfied: idna&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink&gt;=17.1.1-&gt;Twisted&gt;=18.9.0-&gt;scrapy) (2.10)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;scrapy) (3.0.9)
Requirement already satisfied: requests&gt;=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract-&gt;scrapy) (2.28.1)
Requirement already satisfied: filelock&gt;=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract-&gt;scrapy) (3.8.0)
Requirement already satisfied: requests-file&gt;=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract-&gt;scrapy) (1.5.1)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.1.0-&gt;tldextract-&gt;scrapy) (1.26.13)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.1.0-&gt;tldextract-&gt;scrapy) (2022.9.24)
Requirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.1.0-&gt;tldextract-&gt;scrapy) (2.1.1)
</pre></div>
</div>
</div>
</div>
</section>
<section id="crawling-abstrak">
<h2><strong>Crawling Abstrak</strong><a class="headerlink" href="#crawling-abstrak" title="Permalink to this headline">#</a></h2>
<p>Setelah berhasil menginstall scrapy, selanjutnya kita dapat melakukan proses crawling data abstrak dari pta.trunojoyo menggunakan library scrapy dengan menggunakan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">scrapy.crawler</span> <span class="kn">import</span> <span class="n">CrawlerProcess</span>


<span class="k">class</span> <span class="nc">AbstracToCsv</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
  <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;Abstrac To CSV&#39;</span>
  <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="mi">100000</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">75</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">+=</span><span class="mi">1</span>
            <span class="n">urls</span> <span class="o">=</span> <span class="p">[</span>
                <span class="s1">&#39;https://pta.trunojoyo.ac.id/welcome/detail/130411&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
                <span class="s1">&#39;https://pta.trunojoyo.ac.id/welcome/detail/140411&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
                <span class="s1">&#39;https://pta.trunojoyo.ac.id/welcome/detail/150411&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
                <span class="s1">&#39;https://pta.trunojoyo.ac.id/welcome/detail/160411&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
                <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

  <span class="n">custom_settings</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s1">&#39;FEED_FORMAT&#39;</span><span class="p">:</span> <span class="s1">&#39;csv&#39;</span><span class="p">,</span>
      <span class="s1">&#39;FEED_URI&#39;</span><span class="p">:</span> <span class="s1">&#39;Abstraksi.csv&#39;</span>
  <span class="p">}</span>

  <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">yield</span> <span class="p">{</span>
            <span class="s1">&#39;Abstrak&#39;</span><span class="p">:</span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;#content_journal &gt; ul &gt; li &gt; div:nth-child(4) &gt; div:nth-child(2) &gt; p::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
              <span class="p">}</span>

<span class="n">process</span> <span class="o">=</span> <span class="n">CrawlerProcess</span><span class="p">()</span>
<span class="n">process</span><span class="o">.</span><span class="n">crawl</span><span class="p">(</span><span class="n">AbstracToCsv</span><span class="p">)</span>
<span class="n">process</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.utils.log:Scrapy 2.7.1 started (bot: scrapybot)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:18 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: scrapybot)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.utils.log:Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.1, Twisted 22.10.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:18 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.7.0, w3lib 2.1.1, Twisted 22.10.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 38.0.4, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.crawler:Overridden settings:
{}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:18 [scrapy.crawler] INFO: Overridden settings:
{}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/scrapy/utils/request.py:231: ScrapyDeprecationWarning: &#39;2.6&#39; is a deprecated value for the &#39;REQUEST_FINGERPRINTER_IMPLEMENTATION&#39; setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the &#39;REQUEST_FINGERPRINTER_IMPLEMENTATION&#39; setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the &#39;REQUEST_FINGERPRINTER_IMPLEMENTATION&#39; setting for information on how to handle this deprecation.
  return cls(crawler)
DEBUG:scrapy.utils.log:Using reactor: twisted.internet.epollreactor.EPollReactor
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.extensions.telnet:Telnet Password: a81aa86b4a19cf28
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:18 [scrapy.extensions.telnet] INFO: Telnet Password: a81aa86b4a19cf28
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/scrapy/extensions/feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)
INFO:scrapy.middleware:Enabled extensions:
[&#39;scrapy.extensions.corestats.CoreStats&#39;,
 &#39;scrapy.extensions.telnet.TelnetConsole&#39;,
 &#39;scrapy.extensions.memusage.MemoryUsage&#39;,
 &#39;scrapy.extensions.feedexport.FeedExporter&#39;,
 &#39;scrapy.extensions.logstats.LogStats&#39;]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:18 [scrapy.middleware] INFO: Enabled extensions:
[&#39;scrapy.extensions.corestats.CoreStats&#39;,
 &#39;scrapy.extensions.telnet.TelnetConsole&#39;,
 &#39;scrapy.extensions.memusage.MemoryUsage&#39;,
 &#39;scrapy.extensions.feedexport.FeedExporter&#39;,
 &#39;scrapy.extensions.logstats.LogStats&#39;]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.middleware:Enabled downloader middlewares:
[&#39;scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.retry.RetryMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.redirect.RedirectMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.cookies.CookiesMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.stats.DownloaderStats&#39;]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
[&#39;scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.retry.RetryMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.redirect.RedirectMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.cookies.CookiesMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.stats.DownloaderStats&#39;]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.middleware:Enabled spider middlewares:
[&#39;scrapy.spidermiddlewares.httperror.HttpErrorMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.referer.RefererMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.urllength.UrlLengthMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.depth.DepthMiddleware&#39;]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:18 [scrapy.middleware] INFO: Enabled spider middlewares:
[&#39;scrapy.spidermiddlewares.httperror.HttpErrorMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.referer.RefererMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.urllength.UrlLengthMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.depth.DepthMiddleware&#39;]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.middleware:Enabled item pipelines:
[]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:18 [scrapy.middleware] INFO: Enabled item pipelines:
[]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.core.engine:Spider opened
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:18 [scrapy.core.engine] INFO: Spider opened
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.extensions.logstats:Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.extensions.telnet:Telnet console listening on 127.0.0.1:6023
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:filelock:Attempting to acquire lock 139802756929488 on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [filelock] DEBUG: Attempting to acquire lock 139802756929488 on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:filelock:Lock 139802756929488 acquired on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [filelock] DEBUG: Lock 139802756929488 acquired on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:filelock:Attempting to release lock 139802756929488 on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [filelock] DEBUG: Attempting to release lock 139802756929488 on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:filelock:Lock 139802756929488 released on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [filelock] DEBUG: Lock 139802756929488 released on /root/.cache/python-tldextract/3.7.15.final__usr__7d8fdf__tldextract-3.4.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100001&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100001&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100002&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100002&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100002&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100002&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100002&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100002&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100001&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100001&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100002&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100002&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100002&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100002&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100002&gt;
{&#39;Abstrak&#39;: &#39;Pemberian reward bagi perawat yang telah bekerja dengan baik merupakan langkah untuk mendorong semangat kerja perawat sehingga dapat meningkatkan keberhasilan suatu instansi tempatnya bekerja. Proses penilaian kinerja perawat yang selama ini masih dilakukan secara manual dan lebih mengandalkan intuisi personal dari pimpinan, manajer keperawatan, dan Human Resources Departement (HRD) Rumah Sakit. Pada penelitian ini akan dibuat sistem pendukung keputusan pemberian reward perawat terbaik menggunakan metode Analitycal Hierarchy Process (AHP). AHP merupakan metode pengambilan keputusan menggunakan perbandingan berpasangan (Pairwise Comparison) untuk menjelaskan faktor berbobot dalam kondisi multi faktor. Pada proses perhitungan metode ini menggunakan delapan kriteria. Nilai akurasi yang didapat pada implementasi metode AHP ini adalah sebesar 72,36% dengan jumlah data yang digunakan adalah 152.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100002&gt;
{&#39;Abstrak&#39;: &#39;Pemberian reward bagi perawat yang telah bekerja dengan baik merupakan langkah untuk mendorong semangat kerja perawat sehingga dapat meningkatkan keberhasilan suatu instansi tempatnya bekerja. Proses penilaian kinerja perawat yang selama ini masih dilakukan secara manual dan lebih mengandalkan intuisi personal dari pimpinan, manajer keperawatan, dan Human Resources Departement (HRD) Rumah Sakit. Pada penelitian ini akan dibuat sistem pendukung keputusan pemberian reward perawat terbaik menggunakan metode Analitycal Hierarchy Process (AHP). AHP merupakan metode pengambilan keputusan menggunakan perbandingan berpasangan (Pairwise Comparison) untuk menjelaskan faktor berbobot dalam kondisi multi faktor. Pada proses perhitungan metode ini menggunakan delapan kriteria. Nilai akurasi yang didapat pada implementasi metode AHP ini adalah sebesar 72,36% dengan jumlah data yang digunakan adalah 152.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100001&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100001&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100001&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100001&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100001&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100001&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100001&gt;
{&#39;Abstrak&#39;: &quot;Sparsity merupakan suatu masalah yang umum terjadi dalam sistem rekomendasi. Masalah ini berkaitan dengan sedikitnya nilai atau informasi yang telah terisi dari sebagian besar dataset yang ada. Oleh karena itu, nilai data atau informasi data berupa rating efektif digunakan dalam rekomendasi, sehingga mengatasi data sparsity perlu diterapkan. Tujuan penelitian ini adalah menggunakan metode berbasis Non-negative Matrix Factorization dengan Optimasi Discounted Cumulative Gain (DNMF) untuk mengatasi masalah sparsity tersebut. Algoritma DNMF mempertahankan efek positif dari data pada matrix dekomposisi dan membuat suatu prediksi yang lebih baik dari data asli yang dikarenakan dimensi data yang sangat besar serta terdapat optimasi. DNMF menawarkan solusi berdasarkan pengurangan dimensi di mana faktor-faktor yang berguna untuk memilih yang optimal dimensi (optimal &#39;k&#39;) yang diambil dari data matriks sampai pendekatan yang tepat memperoleh data asli dari peringkat &#39;k&#39; matriks. Dengan demikian, model yang disajikan tidak hanya memilih faktor terbaik dari data asli, tetapi  merekomendasikan nilai yang sesuai untuk peringkat yang hilang dan mengatasi masalah sparsity. Pada penelitian ini telah dilakukan beberapa skenario percobaan untuk mengetahui hasil evaluasi dalam mengatasi masalah data sparsity dan hasil skenario percobaan menghasilkan nilai AP@10=0,069382 dan NDCG@10=0,250328. Metode DNMF menunjukkan hasil yang lebih baik dibandingkan metode standart NMF dengan rata-rata kenaikan akurasi AP=25,90%, maksimal AP=38,58%, dan minimal AP=6,06% sedangkan rata-rata kenaikan NDCG=7,74%, maksimal NDCG=10,58% dan minimal NDCG=-0,35%.&quot;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:20 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100001&gt;
{&#39;Abstrak&#39;: &quot;Sparsity merupakan suatu masalah yang umum terjadi dalam sistem rekomendasi. Masalah ini berkaitan dengan sedikitnya nilai atau informasi yang telah terisi dari sebagian besar dataset yang ada. Oleh karena itu, nilai data atau informasi data berupa rating efektif digunakan dalam rekomendasi, sehingga mengatasi data sparsity perlu diterapkan. Tujuan penelitian ini adalah menggunakan metode berbasis Non-negative Matrix Factorization dengan Optimasi Discounted Cumulative Gain (DNMF) untuk mengatasi masalah sparsity tersebut. Algoritma DNMF mempertahankan efek positif dari data pada matrix dekomposisi dan membuat suatu prediksi yang lebih baik dari data asli yang dikarenakan dimensi data yang sangat besar serta terdapat optimasi. DNMF menawarkan solusi berdasarkan pengurangan dimensi di mana faktor-faktor yang berguna untuk memilih yang optimal dimensi (optimal &#39;k&#39;) yang diambil dari data matriks sampai pendekatan yang tepat memperoleh data asli dari peringkat &#39;k&#39; matriks. Dengan demikian, model yang disajikan tidak hanya memilih faktor terbaik dari data asli, tetapi  merekomendasikan nilai yang sesuai untuk peringkat yang hilang dan mengatasi masalah sparsity. Pada penelitian ini telah dilakukan beberapa skenario percobaan untuk mengetahui hasil evaluasi dalam mengatasi masalah data sparsity dan hasil skenario percobaan menghasilkan nilai AP@10=0,069382 dan NDCG@10=0,250328. Metode DNMF menunjukkan hasil yang lebih baik dibandingkan metode standart NMF dengan rata-rata kenaikan akurasi AP=25,90%, maksimal AP=38,58%, dan minimal AP=6,06% sedangkan rata-rata kenaikan NDCG=7,74%, maksimal NDCG=10,58% dan minimal NDCG=-0,35%.&quot;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100003&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100003&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100003&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100003&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100003&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100003&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100003&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100003&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100003&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100003&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100003&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100003&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100003&gt;
{&#39;Abstrak&#39;: &#39;Pada era teknologi seperti saat ini, setiap perusahaan dituntut untuk terus meningkatkan efektivitas dan efisiensi dalam melakukan proses optimasi produksi agar dapat bersaing dengan memaksimalkan keuntungan dengan penggunaan sumber daya serta menekan biaya produksi. Hal tersebut juga tidak dapat dihindari oleh UKM Kerupuk Dahri, perusahaan ini bergerak dibidang produksi kerupuk yang berada di Desa Tragah, Kec.Trgah Kabupaten Bangkalan. Pada proses produksi pasti terdapat biaya yang dikeluarkan oleh perusahaan, namun saat ini perusahaan dalam menentukan biaya produksi masih menggunakan sistem yang manual dengan membuat perkiraan dalam memproduksi kerupuk. Maka dirancang suatu sistem optimasi produksi yang secara otomatis sehingga membantu sistem perusahaan kedepannya. Agar proses optimasi produksi dan pengolahan data seperti bahan baku, tenaga kerja, biaya operasional mudah di kelola di butuhkan aplikasi yang dapat digunakan proses pengembangan menggunakan  model waterfall. Pemilihan penggunaan linear programming metode simpleks ini bertujuan agar perusahaan dapat menghitung semua unsur biaya produksi yang terdiri dari bahan baku, tenaga kerja dan biaya operasional. Dari hasil pengujian aplikasi 80% dari user beranggapan bahwa penilaian program secara keseluruhan sangat baik, sedangkan 20% dari user lainnya beranggapan bahwa penilaian program secara keseluruhan baik.\nKata Kunci : UKM Kerupuk, Optimasi, Linear Proggramming, Metode Simpleks, Hypertext Preprocessor (PHP), CodeIgniter.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100003&gt;
{&#39;Abstrak&#39;: &#39;Pada era teknologi seperti saat ini, setiap perusahaan dituntut untuk terus meningkatkan efektivitas dan efisiensi dalam melakukan proses optimasi produksi agar dapat bersaing dengan memaksimalkan keuntungan dengan penggunaan sumber daya serta menekan biaya produksi. Hal tersebut juga tidak dapat dihindari oleh UKM Kerupuk Dahri, perusahaan ini bergerak dibidang produksi kerupuk yang berada di Desa Tragah, Kec.Trgah Kabupaten Bangkalan. Pada proses produksi pasti terdapat biaya yang dikeluarkan oleh perusahaan, namun saat ini perusahaan dalam menentukan biaya produksi masih menggunakan sistem yang manual dengan membuat perkiraan dalam memproduksi kerupuk. Maka dirancang suatu sistem optimasi produksi yang secara otomatis sehingga membantu sistem perusahaan kedepannya. Agar proses optimasi produksi dan pengolahan data seperti bahan baku, tenaga kerja, biaya operasional mudah di kelola di butuhkan aplikasi yang dapat digunakan proses pengembangan menggunakan  model waterfall. Pemilihan penggunaan linear programming metode simpleks ini bertujuan agar perusahaan dapat menghitung semua unsur biaya produksi yang terdiri dari bahan baku, tenaga kerja dan biaya operasional. Dari hasil pengujian aplikasi 80% dari user beranggapan bahwa penilaian program secara keseluruhan sangat baik, sedangkan 20% dari user lainnya beranggapan bahwa penilaian program secara keseluruhan baik.\nKata Kunci : UKM Kerupuk, Optimasi, Linear Proggramming, Metode Simpleks, Hypertext Preprocessor (PHP), CodeIgniter.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100003&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100003&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100004&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100004&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100004&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100004&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100004&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100004&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100001&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100001&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100004&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100004&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100001&gt;
{&#39;Abstrak&#39;: &#39;Bola voli dapat dikatakan sebagai salah satu olahraga yang mempunyai gerakan–gerakan kompleks. Seorang pemain voli harus bekerja keras untuk meningkatkan kemampuannya dengan salah satunya pada kondisi fisik. Dalam menentukan kondisi fisik dapat memanfaatkan komputer sains dalam memberikan solusi dan pendukung keputusan terhadap pemain voli. Dengan menerapkan metode learning vector quzntization dapat mengklasifikasi kondisi fisik seorang pemain voli. Metode learning vector quantization sendiri merupakan metode klasifikasi Supervised Learning. Dengan adanya sistem ini dapat membantu pelatih untuk mengetahui dan memberikan porsi latihan terhadap pemain yang mempunyai kondisi fisik yang dibagi beberapa kategori yaitu baik sekali, baik, cukup, kurang, dan kurang sekali sehingga penentuan kondisi fisik pemain lebih cepat. Hasil akurasi yang diperoleh klasifikasi kondisi fisik pada pemain bola voli menggunakan metode learning vector quantization yaitu 95% dengan alpha 0,1 sampai 0,5 dan epoch 5 sampai 40 yang didapatkan dari hasil perbandingan perhitungan manual dengan hasil klasifikasi sistem.\nKata kunci : Klasifikasi, Kondisi Fisik, Learning Vector Quantization.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100001&gt;
{&#39;Abstrak&#39;: &#39;Bola voli dapat dikatakan sebagai salah satu olahraga yang mempunyai gerakan–gerakan kompleks. Seorang pemain voli harus bekerja keras untuk meningkatkan kemampuannya dengan salah satunya pada kondisi fisik. Dalam menentukan kondisi fisik dapat memanfaatkan komputer sains dalam memberikan solusi dan pendukung keputusan terhadap pemain voli. Dengan menerapkan metode learning vector quzntization dapat mengklasifikasi kondisi fisik seorang pemain voli. Metode learning vector quantization sendiri merupakan metode klasifikasi Supervised Learning. Dengan adanya sistem ini dapat membantu pelatih untuk mengetahui dan memberikan porsi latihan terhadap pemain yang mempunyai kondisi fisik yang dibagi beberapa kategori yaitu baik sekali, baik, cukup, kurang, dan kurang sekali sehingga penentuan kondisi fisik pemain lebih cepat. Hasil akurasi yang diperoleh klasifikasi kondisi fisik pada pemain bola voli menggunakan metode learning vector quantization yaitu 95% dengan alpha 0,1 sampai 0,5 dan epoch 5 sampai 40 yang didapatkan dari hasil perbandingan perhitungan manual dengan hasil klasifikasi sistem.\nKata kunci : Klasifikasi, Kondisi Fisik, Learning Vector Quantization.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100004&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100004&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100004&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100004&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100004&gt;
{&#39;Abstrak&#39;: &#39;Permasalahan yang dihadapi oleh instansi pemerintahan dalam lingkup desa salah satunya adalah proses pembuatan surat menyurat yang masih membutuhkan waktu yang lama, hal ini berdampak terhadap pelayanan yang kurang efektif bagi masyarakat. Pekerjaan masyarakat di desa Waru Barat rata-rata merantau ke luar kota dan tidak sedikit pula yang menjadi TKI (Tenaga Kerja Indonesia). Oleh sebab itu jika mereka sedang membutuhkan surat yang harus diurus di kantor balai desa Waru Barat seperti tanda tangan kepala desa dan stempel desa, mereka akan sangat kesulitan karena harus pulang kampung sedangkan perjalanan dari luar negeri ke desa Waru Barat tidaklah sebentar dan juga membutuhkan biaya transportasi yang cukup mahal, sehingga di butuhkan aplikasi e-surat yang menggunakan tanda tangan digital berupa Quick Respon Code atau sering di sebut QR Code. Dengan memanfaatkan QR Code, tanda tangan kepala desa dan stempel desa dapat di simpan dalam bentuk gambar QR Code. Berdasarkan Hasil Penelitian yang dilakukan maka penggunaan aplikasi e-surat terhadap pelayanan surat-menyurat lebih efisien dengan rata-rata 95% sedangkan hasil pengujian dengan menggunakan kuisioner perangkat desa dan masyarakat didapatkan nilai 5 dengan kategori sangat setuju. Dengan begitu sistem dapat dikatakan sangat efektif untuk membantu pelayanan surat-menyurat.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:21 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100004&gt;
{&#39;Abstrak&#39;: &#39;Permasalahan yang dihadapi oleh instansi pemerintahan dalam lingkup desa salah satunya adalah proses pembuatan surat menyurat yang masih membutuhkan waktu yang lama, hal ini berdampak terhadap pelayanan yang kurang efektif bagi masyarakat. Pekerjaan masyarakat di desa Waru Barat rata-rata merantau ke luar kota dan tidak sedikit pula yang menjadi TKI (Tenaga Kerja Indonesia). Oleh sebab itu jika mereka sedang membutuhkan surat yang harus diurus di kantor balai desa Waru Barat seperti tanda tangan kepala desa dan stempel desa, mereka akan sangat kesulitan karena harus pulang kampung sedangkan perjalanan dari luar negeri ke desa Waru Barat tidaklah sebentar dan juga membutuhkan biaya transportasi yang cukup mahal, sehingga di butuhkan aplikasi e-surat yang menggunakan tanda tangan digital berupa Quick Respon Code atau sering di sebut QR Code. Dengan memanfaatkan QR Code, tanda tangan kepala desa dan stempel desa dapat di simpan dalam bentuk gambar QR Code. Berdasarkan Hasil Penelitian yang dilakukan maka penggunaan aplikasi e-surat terhadap pelayanan surat-menyurat lebih efisien dengan rata-rata 95% sedangkan hasil pengujian dengan menggunakan kuisioner perangkat desa dan masyarakat didapatkan nilai 5 dengan kategori sangat setuju. Dengan begitu sistem dapat dikatakan sangat efektif untuk membantu pelayanan surat-menyurat.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100004&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100004&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100005&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100005&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100005&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100005&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100005&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100005&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100005&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100005&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100005&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100005&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100005&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100005&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100005&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100005&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100005&gt;
{&#39;Abstrak&#39;: &#39;Kesehatan gigi dan mulut merupakan hal yang penting bagi manusia. Tanda klinis awal gangguan kesehatan\nseseorang biasanya pertama kali terlihat di rongga mulut. Jika kesehatan gigi dan mulut tidak dijaga, dapat menimbulkan penyakit lain\nyang mungkin bisa menyerang organ tubuh lainnya. Akan tetapi, masih banyak masyarakat yang tidak tahu akan betapa pentingnya\nkesehatan gigi dan mulut. Oleh sebab itu, peneliti ingin membangun sebuah aplikasi sistem pakar untuk mendiagnosis awal penyakit gigi\ndan mulut seseorang. Aplikasi ini diharapkan dapat membantu masyarakat agar segera memeriksakan penyakit gigi dan mulut mereka\nketika terasa sakit. Aplikasi sistem pakar ini dibangun menggunakan metode Certainty Factor dan menggunakan gejala user sebagai\nmasukan awal yang kemudian akan mendiagnosis sesuai dengan gejala yang dimasukkan. Setiap gejala yang dimasukkan oleh user akan\nmemiliki nilai yang akan dihitung menggunakan rumus Certainty Factordan menghasilkan kemungkinan penyakit yang diderita user.\nMetode Certainty Factor dipilih karena metode ini cocok dalam proses penentuan identifikasi penyakit gigi dan mulut, dan hasil dari\npenerapan metode ini adalah persentase. Penetuan persentase dipengaruhi oleh nilai bobot kepercayaan yang didapat dari penilaian seorang\npakar. Outputpada aplikasi ini adalah berupa penyakit yang diderita oleh user, nilai kepastiannya serta solusi dari penyakit tersebut. Hasil\npengujian menunjukkan aplikasi mampu mendiagnosis penyakit user dengan tingkat akurasi yang mendekati hasil diagnosis yang\ndilakukan langsung oleh pakar kepada pasien. Penelitian ini menggunakan sebanyak 100 data sebagai pengujiannya dan dari data tersebut\ndiperoleh nilai akurasi sebesar 86%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100005&gt;
{&#39;Abstrak&#39;: &#39;Kesehatan gigi dan mulut merupakan hal yang penting bagi manusia. Tanda klinis awal gangguan kesehatan\nseseorang biasanya pertama kali terlihat di rongga mulut. Jika kesehatan gigi dan mulut tidak dijaga, dapat menimbulkan penyakit lain\nyang mungkin bisa menyerang organ tubuh lainnya. Akan tetapi, masih banyak masyarakat yang tidak tahu akan betapa pentingnya\nkesehatan gigi dan mulut. Oleh sebab itu, peneliti ingin membangun sebuah aplikasi sistem pakar untuk mendiagnosis awal penyakit gigi\ndan mulut seseorang. Aplikasi ini diharapkan dapat membantu masyarakat agar segera memeriksakan penyakit gigi dan mulut mereka\nketika terasa sakit. Aplikasi sistem pakar ini dibangun menggunakan metode Certainty Factor dan menggunakan gejala user sebagai\nmasukan awal yang kemudian akan mendiagnosis sesuai dengan gejala yang dimasukkan. Setiap gejala yang dimasukkan oleh user akan\nmemiliki nilai yang akan dihitung menggunakan rumus Certainty Factordan menghasilkan kemungkinan penyakit yang diderita user.\nMetode Certainty Factor dipilih karena metode ini cocok dalam proses penentuan identifikasi penyakit gigi dan mulut, dan hasil dari\npenerapan metode ini adalah persentase. Penetuan persentase dipengaruhi oleh nilai bobot kepercayaan yang didapat dari penilaian seorang\npakar. Outputpada aplikasi ini adalah berupa penyakit yang diderita oleh user, nilai kepastiannya serta solusi dari penyakit tersebut. Hasil\npengujian menunjukkan aplikasi mampu mendiagnosis penyakit user dengan tingkat akurasi yang mendekati hasil diagnosis yang\ndilakukan langsung oleh pakar kepada pasien. Penelitian ini menggunakan sebanyak 100 data sebagai pengujiannya dan dari data tersebut\ndiperoleh nilai akurasi sebesar 86%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100006&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100006&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100006&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100006&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100006&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100006&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100006&gt;
{&#39;Abstrak&#39;: &#39;Bisnis pakaian di era modern ini berkembang seiring dengan perkembangan teknologi, terlihat dari banyaknya pusat perbelanjaan yang dimana di dalamnya terdapat beberapa toko pakaian. Banyaknya toko pakaian yang ada, membuat para pemilik toko bersaing memberikan inovasi yang bisa menarik minat calon pembeli untuk membeli produk mereka misalkan memberikan promo atau potongan harga agar calon pembeli tertarik. Semakin banyak calon pembeli yang tertarik dan berkunjung untuk mencoba pakaian, bisa menyebabkan antrian pada ruang ganti yang biasanya dalam jumlah terbatas. Oleh karena itu, teknologi pada sensor Kinect dan Augmented Reality menjadi salah satu solusi tepat untuk mengatasi permasalahan tersebut. Dengan penggunaan sensor Kinect dapat diukur estimasi ukuran lebar punggung manusia yang dapat dijadikan acuan dalam memilih ukuran baju yang sesuai. Sedangkan melalui teknologi Augmented Reality, pakaian direpresentasikan menjadi obyek virtual yang dapat ditambahkan ke tubuh pengguna tanpa harus mencoba pakaian secara langsung. Dari hasil penelitian ini, akurasi rata-rata dari sistem untuk merekomendasikan pakaian sebesar 75 %, sedangkan sistem akan optimal dalam memberikan rekomendasi sebesar 86 % pada ketinggian Kinect 75 cm dan jarak Kinect dengan user 200 cm, 225 cm dan 250 cm. Survei User Experience dengan Skala Likert berada pada angka 83,9 % yang menunjukkan bahwa pengguna puas dengan hasil dari penelitian ini. &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100006&gt;
{&#39;Abstrak&#39;: &#39;Bisnis pakaian di era modern ini berkembang seiring dengan perkembangan teknologi, terlihat dari banyaknya pusat perbelanjaan yang dimana di dalamnya terdapat beberapa toko pakaian. Banyaknya toko pakaian yang ada, membuat para pemilik toko bersaing memberikan inovasi yang bisa menarik minat calon pembeli untuk membeli produk mereka misalkan memberikan promo atau potongan harga agar calon pembeli tertarik. Semakin banyak calon pembeli yang tertarik dan berkunjung untuk mencoba pakaian, bisa menyebabkan antrian pada ruang ganti yang biasanya dalam jumlah terbatas. Oleh karena itu, teknologi pada sensor Kinect dan Augmented Reality menjadi salah satu solusi tepat untuk mengatasi permasalahan tersebut. Dengan penggunaan sensor Kinect dapat diukur estimasi ukuran lebar punggung manusia yang dapat dijadikan acuan dalam memilih ukuran baju yang sesuai. Sedangkan melalui teknologi Augmented Reality, pakaian direpresentasikan menjadi obyek virtual yang dapat ditambahkan ke tubuh pengguna tanpa harus mencoba pakaian secara langsung. Dari hasil penelitian ini, akurasi rata-rata dari sistem untuk merekomendasikan pakaian sebesar 75 %, sedangkan sistem akan optimal dalam memberikan rekomendasi sebesar 86 % pada ketinggian Kinect 75 cm dan jarak Kinect dengan user 200 cm, 225 cm dan 250 cm. Survei User Experience dengan Skala Likert berada pada angka 83,9 % yang menunjukkan bahwa pengguna puas dengan hasil dari penelitian ini. &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100006&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100006&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100002&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100002&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100006&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100006&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100002&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100002&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100006&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100006&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100007&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100007&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100007&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100007&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100006&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:22 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100006&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100007&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100007&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100007&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100007&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100007&gt;
{&#39;Abstrak&#39;: &#39;Pada Proses identifikasi Leukemia ada beberapa masalah yang terjadi yaitu lamanya proses atau prosedure dimana memakan waktu yang lama sehingga membuat proses identifikasi tidak efisien. Dengan adanya permasalahan tersebut maka akan diselesaikan menggunakan metode Naive Bayes sebagai proses klasifikasi. Algoritma pengolahan citra yang digunakan adalah contras stretching dengan menggunakan metode Fuzzy c-means (FCM) sebagai proses segmentasi dan ekstraksi ciri menggunakan Gray Level Cooccurence Matrix (GLCM) dengan menggunakan 6 fitur GLCM berdasarkan sudut 0°, 45°, 90° dan 135°. Tujuan dari penelitian ini adalah mengimplementasikan Algoritma Naive Bayes sebagai klasifikasi leukemia apakah termasuk ALL_positif atau ALL_negatif dan mengetahui hasil akurasi dari sistem yang dibuat.\nPada proses pengujian digunakan 260 citra yaitu 130 ALL-Positif dan 130 ALL-Negatif. Hasil penelitian menunjukkan bahwa klasifikasi berdasarkan ekstraksi fitur GLCM mendapat akurasi sebesar 78% dalam mengklasifikasi sel darah putih.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100007&gt;
{&#39;Abstrak&#39;: &#39;Pada Proses identifikasi Leukemia ada beberapa masalah yang terjadi yaitu lamanya proses atau prosedure dimana memakan waktu yang lama sehingga membuat proses identifikasi tidak efisien. Dengan adanya permasalahan tersebut maka akan diselesaikan menggunakan metode Naive Bayes sebagai proses klasifikasi. Algoritma pengolahan citra yang digunakan adalah contras stretching dengan menggunakan metode Fuzzy c-means (FCM) sebagai proses segmentasi dan ekstraksi ciri menggunakan Gray Level Cooccurence Matrix (GLCM) dengan menggunakan 6 fitur GLCM berdasarkan sudut 0°, 45°, 90° dan 135°. Tujuan dari penelitian ini adalah mengimplementasikan Algoritma Naive Bayes sebagai klasifikasi leukemia apakah termasuk ALL_positif atau ALL_negatif dan mengetahui hasil akurasi dari sistem yang dibuat.\nPada proses pengujian digunakan 260 citra yaitu 130 ALL-Positif dan 130 ALL-Negatif. Hasil penelitian menunjukkan bahwa klasifikasi berdasarkan ekstraksi fitur GLCM mendapat akurasi sebesar 78% dalam mengklasifikasi sel darah putih.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100007&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100007&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100007&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100007&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100008&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100008&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100008&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100008&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100007&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100007&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100008&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100008&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100008&gt;
{&#39;Abstrak&#39;: &#39;Pelayanan administrasi kependudukan di Kantor Kecamatan Kamal saat ini masih menggunakan cara manual. Hal ini menyebabkan proses pelayanan administrasi yang ada di Kantor Kecamatan Kamal belum bisa berjalan secara efisien. Oleh karena itu, dibutuhkan sebuah aplikasi Sistem Pelayanan Administrasi Kependudukan berbasis web yang dibangun dengan arsitektur Model View Controller menggunakan Framework Codeigniter. Dengan menggunakan arsitektur MVC ada beberapa keuntungan diantarannya pengembangan perangkat lunak mudah untuk dilakukan perbaikan. Dengan menggunakan arsitektur MVC dapat membawa perubahan yakni mempermudah pada proses pelayanan kependudukan dikecamatan Kamal, dan juga dapat mempersingkat  waktu proses pelayanan sehingga dapat mengurangi penumpukan antrian selain itu juga dapat mempermudah admin di kantor kecamatan pada proses pencarian data penduduk yang bertempat tinggal di kecamatan Kamal. Hasil penelitian menunjukkan bahwa implementasi MVC pada aplikasi sistem pelayanan administrasi kependudukan dapat mudah digunakan dan dikembangkan kembali.\nKata Kunci : Sistem Informasi, Administrasi Kependudukan, Aplikasi Berbasis Web, MVC, Codeigniter\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100008&gt;
{&#39;Abstrak&#39;: &#39;Pelayanan administrasi kependudukan di Kantor Kecamatan Kamal saat ini masih menggunakan cara manual. Hal ini menyebabkan proses pelayanan administrasi yang ada di Kantor Kecamatan Kamal belum bisa berjalan secara efisien. Oleh karena itu, dibutuhkan sebuah aplikasi Sistem Pelayanan Administrasi Kependudukan berbasis web yang dibangun dengan arsitektur Model View Controller menggunakan Framework Codeigniter. Dengan menggunakan arsitektur MVC ada beberapa keuntungan diantarannya pengembangan perangkat lunak mudah untuk dilakukan perbaikan. Dengan menggunakan arsitektur MVC dapat membawa perubahan yakni mempermudah pada proses pelayanan kependudukan dikecamatan Kamal, dan juga dapat mempersingkat  waktu proses pelayanan sehingga dapat mengurangi penumpukan antrian selain itu juga dapat mempermudah admin di kantor kecamatan pada proses pencarian data penduduk yang bertempat tinggal di kecamatan Kamal. Hasil penelitian menunjukkan bahwa implementasi MVC pada aplikasi sistem pelayanan administrasi kependudukan dapat mudah digunakan dan dikembangkan kembali.\nKata Kunci : Sistem Informasi, Administrasi Kependudukan, Aplikasi Berbasis Web, MVC, Codeigniter\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100008&gt;
{&#39;Abstrak&#39;: &#39;Penginputan dan pengolahan data anggota Jaminan Kesehatan Daerah (JAMKESDA) Rumah Sakit Bangkalan saat ini masih dilakukan secara manual dan tersimpan dalam bentuk berkas (hardcopy) serta disimpan dalam rak. Hal ini menyulitkan admin ketika melakukan pencarian data anggota dan membutuhkan waktu yang lama. Untuk pendaftaran Kartu Indonesia Sehat (KIS) saat ini masih daftar di Rumah Sakit sehingga pasien harus datang ke tempat dan mengisi formulir. Selain itu, kelemahan lainnya adalah apabila rekap data hilang atau berkas mudah rusak maka akan merugikan Jaminan Kesehatan Daerah (Jamkesda) serta admin harus melakukan penginputan serta pengolahan data kembali. Untuk mengurangi kendala tersebut, maka diberilah solusi dengan menerapkan sistem informasi berbasis web. Seiring dengan perkembangan teknologi web yang semakin pesat, muncullah istilah Framework. Framework adalah kerangka kerja yang dapat membantu pengembangan aplikasi dalam menangani berbagai masalah - masalah pemrograman seperti koneksi ke database serta pemanggilan variabel dan file, sehingga developer lebih fokus dan lebih cepat untuk membangun aplikasi.Salah satu contoh Framework yang dapat digunakan yaitu laravel.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100008&gt;
{&#39;Abstrak&#39;: &#39;Penginputan dan pengolahan data anggota Jaminan Kesehatan Daerah (JAMKESDA) Rumah Sakit Bangkalan saat ini masih dilakukan secara manual dan tersimpan dalam bentuk berkas (hardcopy) serta disimpan dalam rak. Hal ini menyulitkan admin ketika melakukan pencarian data anggota dan membutuhkan waktu yang lama. Untuk pendaftaran Kartu Indonesia Sehat (KIS) saat ini masih daftar di Rumah Sakit sehingga pasien harus datang ke tempat dan mengisi formulir. Selain itu, kelemahan lainnya adalah apabila rekap data hilang atau berkas mudah rusak maka akan merugikan Jaminan Kesehatan Daerah (Jamkesda) serta admin harus melakukan penginputan serta pengolahan data kembali. Untuk mengurangi kendala tersebut, maka diberilah solusi dengan menerapkan sistem informasi berbasis web. Seiring dengan perkembangan teknologi web yang semakin pesat, muncullah istilah Framework. Framework adalah kerangka kerja yang dapat membantu pengembangan aplikasi dalam menangani berbagai masalah - masalah pemrograman seperti koneksi ke database serta pemanggilan variabel dan file, sehingga developer lebih fokus dan lebih cepat untuk membangun aplikasi.Salah satu contoh Framework yang dapat digunakan yaitu laravel.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100008&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100008&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100008&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100008&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100009&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100009&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100009&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100009&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100008&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100008&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100009&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100009&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100009&gt;
{&#39;Abstrak&#39;: &#39;Kegiatan pencatatan data administrasi penduduk oleh pemerintahan desa sering dihadapi masalah seperti, hilangnya data, pengisian data yang salah, dan sulitnya proses pencarian data. Hal ini dikarenakan proses pencatatanya dibagi dalam lima buku yaitu, buku Induk Penduduk, buku Mutasi Penduduk Desa, buku Rekapitulasi Jumlah Penduduk, buku Penduduk Sementara; dan buku Kartu Tanda Penduduk dan buku Kartu Keluarga, serta dalam pengelolaanya selama ini, masih menggunakan cara manual. Untuk mengatasi masalah tersebut, diperlukan sebuah aplikasi yang dapat mengatasi permasalahan dan kerumitan dalam proses pencatatan administrasi penduduk. Teknologi/konsep Hierarchical Model View Controller dipilih, karena mempermudah dalam pengembangan aplikasi dan penyatuan dari beberapa buku administrasi penduduk, berdasarkan PERMENDAGRI No. 47 Tahun 2016. Penerapan HMVC tersusun dari beberapa modul MVC. Pada administrasi penduduk konsep Hierarchical diterapakan pada setiap sub buku administrasi penduduk, dimana dalam sub terdapat konsep MVC. Dari ujicoba aplikasi pengelolaan administrasi penduduk, berbasis HMVC didapat kesimpulan, bahwa aplikasi ini, sesuai dengan permendagri no. 47 tahun 2016 dalam penerapan konsep HMVC. Sehingga, mempermudah proses administrasi penduduk dan pengembangan aplikasi kedepannya.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100009&gt;
{&#39;Abstrak&#39;: &#39;Kegiatan pencatatan data administrasi penduduk oleh pemerintahan desa sering dihadapi masalah seperti, hilangnya data, pengisian data yang salah, dan sulitnya proses pencarian data. Hal ini dikarenakan proses pencatatanya dibagi dalam lima buku yaitu, buku Induk Penduduk, buku Mutasi Penduduk Desa, buku Rekapitulasi Jumlah Penduduk, buku Penduduk Sementara; dan buku Kartu Tanda Penduduk dan buku Kartu Keluarga, serta dalam pengelolaanya selama ini, masih menggunakan cara manual. Untuk mengatasi masalah tersebut, diperlukan sebuah aplikasi yang dapat mengatasi permasalahan dan kerumitan dalam proses pencatatan administrasi penduduk. Teknologi/konsep Hierarchical Model View Controller dipilih, karena mempermudah dalam pengembangan aplikasi dan penyatuan dari beberapa buku administrasi penduduk, berdasarkan PERMENDAGRI No. 47 Tahun 2016. Penerapan HMVC tersusun dari beberapa modul MVC. Pada administrasi penduduk konsep Hierarchical diterapakan pada setiap sub buku administrasi penduduk, dimana dalam sub terdapat konsep MVC. Dari ujicoba aplikasi pengelolaan administrasi penduduk, berbasis HMVC didapat kesimpulan, bahwa aplikasi ini, sesuai dengan permendagri no. 47 tahun 2016 dalam penerapan konsep HMVC. Sehingga, mempermudah proses administrasi penduduk dan pengembangan aplikasi kedepannya.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100009&gt;
{&#39;Abstrak&#39;: &#39;Pada saat ini proses sistem pencatatan serta pembuatan laporan keuangan pada UKM masih dilakukan secara manual. Pembuatan laporan keuangan yang dilakukan secara m anual memiliki resiko kesalahan perhitungan yang tinggi dalam perhitungan laba rugi dan neraca. Oleh karenanya di butuhkan bantuan teknologi berupa Sistem Akuntansi pada UKM yang dapat mengatasi kesalahan perhitungan tersebut. Semakin berkembangnya teknologi pada saat ini, telah banyak teknologi yang telah di kembangkan baik hardware maupun software. Meskipun banyak teknologi yang sudah canggih, masalah performa masih sering ditemukan. Salah satu contoh teknologi yang sering ditemukannya masalah performa adalah website. Performa pada website dapat berpengaruh pada pengunjung website itu sendiri. Apabila performa website kurang baik dapat memunculkan pendapat kurang baik oleh pengunjung. Maka dari itu membandingkan sebuah teknologi yang terbaru dapat menjadi solusi untuk mengetahui teknologi mana yang paling tepat untuk membangun sebuah website dengan performa yang baik. Teknologi yang digunakan untuk perbandingan yaitu PHP berarsitektur MVC dan PHP tidak berarsitektur. Dimana PHP tidak berarsitektur merupakan teknologi lama dan PHP berarsitektur MVC merupakan penerapan teknologi baru. Dari hasil pengujian yang telah dilakukan dapat disimpulkan bahwa arsitektur PHP tidak berasitektur MVC memiliki performa lebih baik dan penggunaan memori yang lebih kecil. \nKeyword : Performa Sistem, PHP Native, PHP MVC, Apache Benchmark, Sistem Akuntansi.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100009&gt;
{&#39;Abstrak&#39;: &#39;Pada saat ini proses sistem pencatatan serta pembuatan laporan keuangan pada UKM masih dilakukan secara manual. Pembuatan laporan keuangan yang dilakukan secara m anual memiliki resiko kesalahan perhitungan yang tinggi dalam perhitungan laba rugi dan neraca. Oleh karenanya di butuhkan bantuan teknologi berupa Sistem Akuntansi pada UKM yang dapat mengatasi kesalahan perhitungan tersebut. Semakin berkembangnya teknologi pada saat ini, telah banyak teknologi yang telah di kembangkan baik hardware maupun software. Meskipun banyak teknologi yang sudah canggih, masalah performa masih sering ditemukan. Salah satu contoh teknologi yang sering ditemukannya masalah performa adalah website. Performa pada website dapat berpengaruh pada pengunjung website itu sendiri. Apabila performa website kurang baik dapat memunculkan pendapat kurang baik oleh pengunjung. Maka dari itu membandingkan sebuah teknologi yang terbaru dapat menjadi solusi untuk mengetahui teknologi mana yang paling tepat untuk membangun sebuah website dengan performa yang baik. Teknologi yang digunakan untuk perbandingan yaitu PHP berarsitektur MVC dan PHP tidak berarsitektur. Dimana PHP tidak berarsitektur merupakan teknologi lama dan PHP berarsitektur MVC merupakan penerapan teknologi baru. Dari hasil pengujian yang telah dilakukan dapat disimpulkan bahwa arsitektur PHP tidak berasitektur MVC memiliki performa lebih baik dan penggunaan memori yang lebih kecil. \nKeyword : Performa Sistem, PHP Native, PHP MVC, Apache Benchmark, Sistem Akuntansi.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100009&gt;
{&#39;Abstrak&#39;: &#39;Bayangan sangat mempengaruhi dalam pengenalan objek pada citra. Dalam pengambilan sebuah gambar di bawah cahaya akan menghasilkan bayangan.  Suatu bayangan terjadi ketika objek yang secara persial atau secara total mengarah terhadap cahaya dari suatu sumber penerangan. Bayangan yang terdapat pada suatu gambar dapat mengurangi daya tarik visual secara keseluruhan. Oleh karena itu, penghapusan bayangan penting diimplementasikan untuk mengenali suatu objek pada gambar. Pada penelitian ini diusulkan metode Fuzzy C-Means yang di optimasikan dengan Particle Swarm Optimization untuk menentukan pusat cluster yang lebih baik. Metode yang diusulkan akan diterapkan dalam proses clustering daerah bayangan dan non-bayangan pada citra bayangan. Proses clustering akan menghasilkan cluster image yang akan diubah menjadi citra biner sebagai hasil deteksi bayangan. Untuk hasil deteksi bayangan daerah bayangan berwarna putih dan non-bayangan berwarna hitam. Untuk menghilangkan bayangan yang sudah terdeteksi dengan menambahkan gamma correction pada daerah bayangan yang digunakan untuk meningkatkan pencahayaan pada daerah bayangan, sehingga warna daerah bayangan akan sama dengan daerah non-bayangan. Dari penelitian ini menunjukkan nilai RMSE yang dihasilkan dari penggunaan Fuzzy C-Means terkecil sebesar 0.67612, sedangkan penggunaan Fuzzy C-Means dan Particle Swarm Optimization untuk proses segmentasi menghasilkan nilai RMSE terkecil sebesar 0.59410.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:23 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100009&gt;
{&#39;Abstrak&#39;: &#39;Bayangan sangat mempengaruhi dalam pengenalan objek pada citra. Dalam pengambilan sebuah gambar di bawah cahaya akan menghasilkan bayangan.  Suatu bayangan terjadi ketika objek yang secara persial atau secara total mengarah terhadap cahaya dari suatu sumber penerangan. Bayangan yang terdapat pada suatu gambar dapat mengurangi daya tarik visual secara keseluruhan. Oleh karena itu, penghapusan bayangan penting diimplementasikan untuk mengenali suatu objek pada gambar. Pada penelitian ini diusulkan metode Fuzzy C-Means yang di optimasikan dengan Particle Swarm Optimization untuk menentukan pusat cluster yang lebih baik. Metode yang diusulkan akan diterapkan dalam proses clustering daerah bayangan dan non-bayangan pada citra bayangan. Proses clustering akan menghasilkan cluster image yang akan diubah menjadi citra biner sebagai hasil deteksi bayangan. Untuk hasil deteksi bayangan daerah bayangan berwarna putih dan non-bayangan berwarna hitam. Untuk menghilangkan bayangan yang sudah terdeteksi dengan menambahkan gamma correction pada daerah bayangan yang digunakan untuk meningkatkan pencahayaan pada daerah bayangan, sehingga warna daerah bayangan akan sama dengan daerah non-bayangan. Dari penelitian ini menunjukkan nilai RMSE yang dihasilkan dari penggunaan Fuzzy C-Means terkecil sebesar 0.67612, sedangkan penggunaan Fuzzy C-Means dan Particle Swarm Optimization untuk proses segmentasi menghasilkan nilai RMSE terkecil sebesar 0.59410.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100009&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100009&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100010&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100010&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100010&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100010&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100009&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100009&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100010&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100010&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100010&gt;
{&#39;Abstrak&#39;: &#39;Di Dinas Koperasi dan UMKM  kabupaten Bangkalan mempunyai banyak data diantaranya data aset, data omset, jumlah tenaga kerja,jenis kegiatan usaha,nama pemilik  usaha, dan tahun berdiri usaha tersebut dengan nilai yang berbeda. Dari permsalahan tersebut untuk memperoleh hasil pengelompokkan data usaha  mikro yang tepat maka di perlukan adanya sebuah clustering dengan menggunakan metode Fuzzy C-Means,tujuan dari penelitian ini adalah mengelompokkan data usaha mikro berdasarkan data aset, omset dan jumlah tenaga kerja.Pada proses pengujian digunakan 300 data usaha mikro. Hasil dari penelitian menunjukkan bahwa clustering berdasarkan metode Fuzzy C-Means mendapatkan 8 cluster dengan nilai sillhoutte 0,4314\nKata kunci :  Clustering , Fuzzy C-Mean Clustering , Usaha Mikro\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100010&gt;
{&#39;Abstrak&#39;: &#39;Di Dinas Koperasi dan UMKM  kabupaten Bangkalan mempunyai banyak data diantaranya data aset, data omset, jumlah tenaga kerja,jenis kegiatan usaha,nama pemilik  usaha, dan tahun berdiri usaha tersebut dengan nilai yang berbeda. Dari permsalahan tersebut untuk memperoleh hasil pengelompokkan data usaha  mikro yang tepat maka di perlukan adanya sebuah clustering dengan menggunakan metode Fuzzy C-Means,tujuan dari penelitian ini adalah mengelompokkan data usaha mikro berdasarkan data aset, omset dan jumlah tenaga kerja.Pada proses pengujian digunakan 300 data usaha mikro. Hasil dari penelitian menunjukkan bahwa clustering berdasarkan metode Fuzzy C-Means mendapatkan 8 cluster dengan nilai sillhoutte 0,4314\nKata kunci :  Clustering , Fuzzy C-Mean Clustering , Usaha Mikro\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100010&gt;
{&#39;Abstrak&#39;: &#39;Sistem rekomendasi adalah sistem yang digunakan untuk merekomendasikan sesuatu item, misalnya merekomendasikan film. Banyaknya informasi film di internet membuat kita kesulitan dalam memilih film yang sesuai dengan selera. Untuk itu sistem rekomendasi film ini dibutuhkan oleh masyarakat. Sistem rekomendasi ini membutuhkan data  rating dari movielens. Pemilihan metode sangat mempengaruhi keberhasilan sistem. Semakin akurat sistem yang dibuat maka semakin bagus. Metode yang populer saat ini adalah collaborative filtering khususnya metode collaborative filtering tradisional. Namun metode ini memiliki masalah skalabilitas sehingga untuk mengatasinya perlu ditambahkan metode clustering. Pada penelitian  sebelumnya ada yang menggunakan metode k-means clustering dan user-based collaborative filtering. Collaborative filtering terdiri dari user-based dan item-based collaborative filtering. Pada penelitian lain menyebutkan bahwa metode item-based lebih akurat daripada metode  user-based collaborative filtering. Untuk itu pada penelitian ini menggunakan metode k-means clustering dan item-based collaborative filtering. Hasil dari uji coba yang dilakukan menunjukkan bahwa metode pada penelitin ini lebih akurat daripada user-based dan item-based collaborative filtering. Presentase kenaikan akurasi metode yang diteliti dengan user-based adalah 113% sedangkan bila dibandingkan dengan item-based collaborative filtering kenaikan akurasinya adalah 168%. Metode yang diteliti juga lebih  akurat dibandingkan metode gabungan user clustering dan user-based collaborative filtering dengan kenaikan akurasi sebesar 27%.\nKata kunci: Film, Sistem Rekomendasi, Item Clustering, Item-Based Collaborative Filtering.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100010&gt;
{&#39;Abstrak&#39;: &#39;Sistem rekomendasi adalah sistem yang digunakan untuk merekomendasikan sesuatu item, misalnya merekomendasikan film. Banyaknya informasi film di internet membuat kita kesulitan dalam memilih film yang sesuai dengan selera. Untuk itu sistem rekomendasi film ini dibutuhkan oleh masyarakat. Sistem rekomendasi ini membutuhkan data  rating dari movielens. Pemilihan metode sangat mempengaruhi keberhasilan sistem. Semakin akurat sistem yang dibuat maka semakin bagus. Metode yang populer saat ini adalah collaborative filtering khususnya metode collaborative filtering tradisional. Namun metode ini memiliki masalah skalabilitas sehingga untuk mengatasinya perlu ditambahkan metode clustering. Pada penelitian  sebelumnya ada yang menggunakan metode k-means clustering dan user-based collaborative filtering. Collaborative filtering terdiri dari user-based dan item-based collaborative filtering. Pada penelitian lain menyebutkan bahwa metode item-based lebih akurat daripada metode  user-based collaborative filtering. Untuk itu pada penelitian ini menggunakan metode k-means clustering dan item-based collaborative filtering. Hasil dari uji coba yang dilakukan menunjukkan bahwa metode pada penelitin ini lebih akurat daripada user-based dan item-based collaborative filtering. Presentase kenaikan akurasi metode yang diteliti dengan user-based adalah 113% sedangkan bila dibandingkan dengan item-based collaborative filtering kenaikan akurasinya adalah 168%. Metode yang diteliti juga lebih  akurat dibandingkan metode gabungan user clustering dan user-based collaborative filtering dengan kenaikan akurasi sebesar 27%.\nKata kunci: Film, Sistem Rekomendasi, Item Clustering, Item-Based Collaborative Filtering.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100010&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100010&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100010&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100010&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100011&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100011&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100011&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100011&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100010&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100010&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100011&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100011&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100011&gt;
{&#39;Abstrak&#39;: &#39;Image merupakan suatu media yang memberikan informasi lebih banyak dari pada informasi yang disajikan dalam bentuk tulisan. Oleh karena itu maka diperlukan aplikasi untuk mengamankan sebuah image sehingga image tidak dapat dilihat oleh yang tidak berhak melihat. Salah satu aplikasi pengamanan tersebut yaitu menggunakan kriptografi dengan metode RC6. Inputan berupa digital image, kemudian image dienkripsi dan didekripsi menggunakan algoritma RC6 biasa, dan selanjutnya dilakukan proses enkripsi dan dekripsi sebagai pembanding dengan menggunakan algoritma RC6 dengan kunci yang telah dimodifikasi. Kunci yang dimodifikasi yakni kunci yang difungsikan dengan Blum Blum Shub. Algoritma RC6 dengan menggunakan kunci biasa memiliki performansi yang baik, terlihat dari nilai Avalanche Effect sebesar antara 49.9167 % dan nilai Avalanche Effect dari modifikasi kunci RC6 yaitu 50.0808 %. Rata-rata waktu enkripsi-dekripsi pada kunci biasa RC6 sebesar 0.8086542 dan 0.7348798 detik dan rata-rata waktu enkripsi-dekripsi modifikasi kunci RC6 yaitu 0.695695 detik dan 0.6764988 detik. Sedangkan  rata-rata PSNR kunci biasa RC6 yang dihasilkan yaitu 8.24174 dan PSNR modifikasi kunci RC6 yaitu 8.08961. Secara umum bahwa Avalanche Effect dan waktu enkripsi dan dekripsi pada modifikasi kunci RC6 lebih baik dari RC6 biasa sebesar 0.1641 % dan  enkripsi-dekripsi 0.1129592 detik dan 0.058381 detik .Sedangkan performa PSNR lebih baik menggunakan kunci RC6 biasa.\nKata kunci: Image, kriptografi, RC6, Blum Blum Shub, lama waktu proses, Avalanche Effect, PSNR\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100011&gt;
{&#39;Abstrak&#39;: &#39;Image merupakan suatu media yang memberikan informasi lebih banyak dari pada informasi yang disajikan dalam bentuk tulisan. Oleh karena itu maka diperlukan aplikasi untuk mengamankan sebuah image sehingga image tidak dapat dilihat oleh yang tidak berhak melihat. Salah satu aplikasi pengamanan tersebut yaitu menggunakan kriptografi dengan metode RC6. Inputan berupa digital image, kemudian image dienkripsi dan didekripsi menggunakan algoritma RC6 biasa, dan selanjutnya dilakukan proses enkripsi dan dekripsi sebagai pembanding dengan menggunakan algoritma RC6 dengan kunci yang telah dimodifikasi. Kunci yang dimodifikasi yakni kunci yang difungsikan dengan Blum Blum Shub. Algoritma RC6 dengan menggunakan kunci biasa memiliki performansi yang baik, terlihat dari nilai Avalanche Effect sebesar antara 49.9167 % dan nilai Avalanche Effect dari modifikasi kunci RC6 yaitu 50.0808 %. Rata-rata waktu enkripsi-dekripsi pada kunci biasa RC6 sebesar 0.8086542 dan 0.7348798 detik dan rata-rata waktu enkripsi-dekripsi modifikasi kunci RC6 yaitu 0.695695 detik dan 0.6764988 detik. Sedangkan  rata-rata PSNR kunci biasa RC6 yang dihasilkan yaitu 8.24174 dan PSNR modifikasi kunci RC6 yaitu 8.08961. Secara umum bahwa Avalanche Effect dan waktu enkripsi dan dekripsi pada modifikasi kunci RC6 lebih baik dari RC6 biasa sebesar 0.1641 % dan  enkripsi-dekripsi 0.1129592 detik dan 0.058381 detik .Sedangkan performa PSNR lebih baik menggunakan kunci RC6 biasa.\nKata kunci: Image, kriptografi, RC6, Blum Blum Shub, lama waktu proses, Avalanche Effect, PSNR\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100011&gt;
{&#39;Abstrak&#39;: &#39;Pegawai adalah aset yang sangat penting dalam suatu organisasi. Guna memberi penghargaan dan sebagai motivasi kepada pegawai yang ada, maka dibuatlah sebuah sistem rekomendasi kenaikan jabatan terhadap Jabatan Fungsional Pengawas Dinas Inspektorat Kabupaten Bangkalan. Sistem ini dibuat menggunakan metode perhitungan AHP(Analytical Hierarchy Process). AHP menghasilkan sebuah rangking yang didapat dari membandingkan setiap kriteria dan juga alternatif dalam hal ini bakal calon yang akan diberikan kenaikan jabatan. AHP merupakan suatu metode dengan melakukan perbandingan berpasangan antara kriteria pilihan dan juga perbandingan berpasangan antara pilihan yang ada. Permasalahan pengambilan keputusan dengan AHP umumnya dikomposisikan menjadi kriteria, dan alternative pilihan. Hasil dari implementasi metode AHP dalam memberikan rekomendasi kenaikan jenjang jabatan, setelah dilakukan 4 kali uji rekomendasi maka didapat hasil rata-rata akurasi sebesar 86,25 %. Dengan demikian implementasi metode AHP dalam rekomendasi kenaikan jabatan menunjukkan bahwa hasil rekomendasi adalah “baik”.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100011&gt;
{&#39;Abstrak&#39;: &#39;Pegawai adalah aset yang sangat penting dalam suatu organisasi. Guna memberi penghargaan dan sebagai motivasi kepada pegawai yang ada, maka dibuatlah sebuah sistem rekomendasi kenaikan jabatan terhadap Jabatan Fungsional Pengawas Dinas Inspektorat Kabupaten Bangkalan. Sistem ini dibuat menggunakan metode perhitungan AHP(Analytical Hierarchy Process). AHP menghasilkan sebuah rangking yang didapat dari membandingkan setiap kriteria dan juga alternatif dalam hal ini bakal calon yang akan diberikan kenaikan jabatan. AHP merupakan suatu metode dengan melakukan perbandingan berpasangan antara kriteria pilihan dan juga perbandingan berpasangan antara pilihan yang ada. Permasalahan pengambilan keputusan dengan AHP umumnya dikomposisikan menjadi kriteria, dan alternative pilihan. Hasil dari implementasi metode AHP dalam memberikan rekomendasi kenaikan jenjang jabatan, setelah dilakukan 4 kali uji rekomendasi maka didapat hasil rata-rata akurasi sebesar 86,25 %. Dengan demikian implementasi metode AHP dalam rekomendasi kenaikan jabatan menunjukkan bahwa hasil rekomendasi adalah “baik”.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100011&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100011&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100011&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100011&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100012&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100012&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100012&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100012&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100011&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100011&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100012&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:24 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100012&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100012&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100012&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100012&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100012&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100012&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100012&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100012&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100012&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100013&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100013&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100012&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100012&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100013&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100013&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100013&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100013&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100013&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100013&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100013&gt;
{&#39;Abstrak&#39;: &#39;Sistem rekomendasi merupakan sebuah sistem yang dibuat dengan tujuan memberikan sebuah rekomendasi item kepada user. Salah satu model pendekatan sistem rekomendasi yang sering digunakan adalah Collaborative Filtering (CF), dengan pendekatan item-based. Model ini memberikan hasil rekomendasi yang cukup baik, namun item-based CF tidak memanfaatkan atribut item dalam perhitungan rekomendasinya. Penerapan atribut item dapat dilakukan dengan dua cara, yaitu dengan satu tahap permodelan dan dua tahap permodelan. Satu tahap permodelan menghasilkan kualitas rekomendasi tidak terlalu signifikan (kurang baik). Cara yang kedua adalah dua tahap permodelan, candidate rekomendasi dan tahap re-ordering. Misal, tahap candidate rekomendasi menggunakan pendekatan collaborative filtering, dan re ordering dilakukan content-basedatau naïve bayes. Pada penelitian sebelumnya sudah dilakukan penerapan candidate rekomendasi menggunakan collaborative filtering, dan re ordering dengan naive bayes pada data tagging menghasikan rekomendasi yang baik. Oleh sebab itu pada penelitian ini penulis mencoba menerapkan dua tahap permodelan candidate ranking dengan collaborative filtering, dan re-ordering menggunakan nave bayes. dengan study kasus movie atribut genre pada data explicit (2 dimensi) . Dari hasil percobaan mendapatkan nilai yang cukup baik, dengan kenaikan nilai akurasi yang dihasilkan metode evaluasi NDCG sebesar 40.94486%.\nKata kunci: Sistem Rekomendasi, Item-Based Collaborative Filtering, Naive Bayes, NDCG, Probabilistic Ranking. &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100013&gt;
{&#39;Abstrak&#39;: &#39;Sistem rekomendasi merupakan sebuah sistem yang dibuat dengan tujuan memberikan sebuah rekomendasi item kepada user. Salah satu model pendekatan sistem rekomendasi yang sering digunakan adalah Collaborative Filtering (CF), dengan pendekatan item-based. Model ini memberikan hasil rekomendasi yang cukup baik, namun item-based CF tidak memanfaatkan atribut item dalam perhitungan rekomendasinya. Penerapan atribut item dapat dilakukan dengan dua cara, yaitu dengan satu tahap permodelan dan dua tahap permodelan. Satu tahap permodelan menghasilkan kualitas rekomendasi tidak terlalu signifikan (kurang baik). Cara yang kedua adalah dua tahap permodelan, candidate rekomendasi dan tahap re-ordering. Misal, tahap candidate rekomendasi menggunakan pendekatan collaborative filtering, dan re ordering dilakukan content-basedatau naïve bayes. Pada penelitian sebelumnya sudah dilakukan penerapan candidate rekomendasi menggunakan collaborative filtering, dan re ordering dengan naive bayes pada data tagging menghasikan rekomendasi yang baik. Oleh sebab itu pada penelitian ini penulis mencoba menerapkan dua tahap permodelan candidate ranking dengan collaborative filtering, dan re-ordering menggunakan nave bayes. dengan study kasus movie atribut genre pada data explicit (2 dimensi) . Dari hasil percobaan mendapatkan nilai yang cukup baik, dengan kenaikan nilai akurasi yang dihasilkan metode evaluasi NDCG sebesar 40.94486%.\nKata kunci: Sistem Rekomendasi, Item-Based Collaborative Filtering, Naive Bayes, NDCG, Probabilistic Ranking. &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100013&gt;
{&#39;Abstrak&#39;: &#39;Leasing merupakan kegiatan pembiayaan dalam bentuk penyediaan modal berupa dana yang digunakan dalam jangka waktu tertentu berdasarkan pembayaran secara berkala. Sedangkan perusahaan leasing sendiri merupakan perusahaan yang bergerak dibidang jasa leasing atau pemberian pinjaman kepada nasabah (lessee). Banyak perusahaan leasing memiliki kesulitan dalam memilih calon nasabahnya dikarenakan proses persetujuan pemberian pinjaman memerlukan waktu yang lama dan banyak tahapan prosedur laporan yang masih dilakukan secara manual. Penelitian ini bertujuan untuk membantu perusahaan dalam menyeleksi calon nasabah yang layak mendapatkan pinjaman sehingga dapat mengefisiankan waktu dan kinerja karyawan. Penelitian ini menghasilan sebuah sistem pendukung keputusan kelayakan pemberian pinjaman dengan metode AHP (Analytical Hirarchy Process) dimana terdapat 7 kriteria penilaian  dengan 14 kali pengujian yang dibagi berdasarkan bulan pendaftaran dimulai november 2017 hingga desember 2018  terhadap 200 calon nasabah dengan hasil tingkat kesesuaian  sebesar  92%. Dengan hasil tersebut pendekatan ini dapat membantu perusahaan leasing dalam mementukan calon nasabah yang layak menerima pinjaman secara efektif.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100013&gt;
{&#39;Abstrak&#39;: &#39;Leasing merupakan kegiatan pembiayaan dalam bentuk penyediaan modal berupa dana yang digunakan dalam jangka waktu tertentu berdasarkan pembayaran secara berkala. Sedangkan perusahaan leasing sendiri merupakan perusahaan yang bergerak dibidang jasa leasing atau pemberian pinjaman kepada nasabah (lessee). Banyak perusahaan leasing memiliki kesulitan dalam memilih calon nasabahnya dikarenakan proses persetujuan pemberian pinjaman memerlukan waktu yang lama dan banyak tahapan prosedur laporan yang masih dilakukan secara manual. Penelitian ini bertujuan untuk membantu perusahaan dalam menyeleksi calon nasabah yang layak mendapatkan pinjaman sehingga dapat mengefisiankan waktu dan kinerja karyawan. Penelitian ini menghasilan sebuah sistem pendukung keputusan kelayakan pemberian pinjaman dengan metode AHP (Analytical Hirarchy Process) dimana terdapat 7 kriteria penilaian  dengan 14 kali pengujian yang dibagi berdasarkan bulan pendaftaran dimulai november 2017 hingga desember 2018  terhadap 200 calon nasabah dengan hasil tingkat kesesuaian  sebesar  92%. Dengan hasil tersebut pendekatan ini dapat membantu perusahaan leasing dalam mementukan calon nasabah yang layak menerima pinjaman secara efektif.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100013&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100013&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100014&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100014&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100013&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100013&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100014&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100014&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100014&gt;
{&#39;Abstrak&#39;: &#39;Aplikasi penerjemah bahasa bilingual Indonesia Madura berbasis web telah tersedia di madura.web.id. Tidak cukup pada web tersebut perlu adanya sebuah sistem penerjemah Bahasa billingual Madura Indonesia yang dapat berjalan pada semua platform dan dapat digunakan oleh pengembang-pengembang aplikasi lain untuk menggunakan sistem terjemahan ini sehingga pembelajaran Bahasa Madura bisa menjadi lebih berkembang.  Salah satunya adalah aplikasi penerjemah pada perangkat android karena paltform android paling banyak digunakan oleh pengguna smartphone. Untuk membangun sistem penerjemah yang bisa digunakan oleh semua platform termasuk android adalah dengan membuat web service. Web service adalah standar dan sebuah metode pemrograman untuk membagikan data antar beberapa aplikasi. Arsitektur yang sangat baik digunakan adalah RESTful Web Service karena lebih ringan dan cepat. Sedangkan untuk format teks yang digunakan untuk pertukaran data adalah format JSON yang lebih mudah di encoding maupun di decoding oleh perangkat mobile. Berdasarkan hasil pengujian, waktu response untuk penerjemah bahasa bilingual Madura dan Indonesia pada perangkat android, penggunaan web service lebih cepat dibandingkan dengan sistem penerjemah  pada website yang telah ada, berdasarkan hasil pengujian pada jaringan 2G rata-rata waktu response web service lebih cepat 31% dibanding dengan website, pada jaringan 3G lebih cepat 77% dan pada jaringan 4G lebih cepat 73%.\nKata Kunci : RESTful API, web service, JSON, Terjemahan Madura Indonesia&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100014&gt;
{&#39;Abstrak&#39;: &#39;Aplikasi penerjemah bahasa bilingual Indonesia Madura berbasis web telah tersedia di madura.web.id. Tidak cukup pada web tersebut perlu adanya sebuah sistem penerjemah Bahasa billingual Madura Indonesia yang dapat berjalan pada semua platform dan dapat digunakan oleh pengembang-pengembang aplikasi lain untuk menggunakan sistem terjemahan ini sehingga pembelajaran Bahasa Madura bisa menjadi lebih berkembang.  Salah satunya adalah aplikasi penerjemah pada perangkat android karena paltform android paling banyak digunakan oleh pengguna smartphone. Untuk membangun sistem penerjemah yang bisa digunakan oleh semua platform termasuk android adalah dengan membuat web service. Web service adalah standar dan sebuah metode pemrograman untuk membagikan data antar beberapa aplikasi. Arsitektur yang sangat baik digunakan adalah RESTful Web Service karena lebih ringan dan cepat. Sedangkan untuk format teks yang digunakan untuk pertukaran data adalah format JSON yang lebih mudah di encoding maupun di decoding oleh perangkat mobile. Berdasarkan hasil pengujian, waktu response untuk penerjemah bahasa bilingual Madura dan Indonesia pada perangkat android, penggunaan web service lebih cepat dibandingkan dengan sistem penerjemah  pada website yang telah ada, berdasarkan hasil pengujian pada jaringan 2G rata-rata waktu response web service lebih cepat 31% dibanding dengan website, pada jaringan 3G lebih cepat 77% dan pada jaringan 4G lebih cepat 73%.\nKata Kunci : RESTful API, web service, JSON, Terjemahan Madura Indonesia&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100014&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100014&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100014&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100014&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100014&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100014&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100014&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:25 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100014&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100014&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100014&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100015&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100015&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100015&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100015&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100015&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100015&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100015&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100015&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100015&gt;
{&#39;Abstrak&#39;: &#39;      Sistem pengendalian persediaan barang  (inventory logistic) merupakan suatu sistem untuk mengetahui stock opname persediaan barang pada suatu tempat. Karena terdapat beberapa masalah, yaitu adanya kesulitan dalam mengetahui informasi permintaan, penerimaan, pemakaian, dan stok barang habis pakai (BHP) . Hal ini disebabkan data belum tersimpan dalam file yang baik dan pengelolaan data persediaan BHP masih dilakukan secara manual (kartu persediaan barang), dalam proses persedian barang di gudang menjadi single user dalam melakukan stock opname persediaan BHP tidak dapat digunakan untuk multiusers sehingga bagian pelayanan dan Kepala Logistik tidak dapat langsung bisa mengakses laporan stock opname BHP. Permasalahan seperti ini memerlukan sebuah sistem yang terkomputerisasi dan berbasis web. \n\n     Metodologi pengembangan sistem yang digunakan dalam penelitian ini adalah dengan metode waterfall (Siklus Air Terjun) yang meliputi, analisa dan rekayasa sistem, analisis kebutuhan, perancangan, pemrograman, pengujian dan pemeliharaan. Sistem Manajemen Inventory Logistic telah dirasa tepat hal ini dapat dilihat pada kepuasan pengguna dengan nilai survei rata-rata adalah sebesar 7,88 dan uji coba sistem yang dapat berjalan dengan baik. Aplikasi ini secara signifikan dapat menyederhanakan alur kerja distribusi barang dan pembuatan laporan distribusi barang di lingkungan RSUD. dr. H. Slamet Martodirdjo. \nKata Kunci : Inventory, Stock Opname, BHP (Barang Habis Pakai)\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100015&gt;
{&#39;Abstrak&#39;: &#39;      Sistem pengendalian persediaan barang  (inventory logistic) merupakan suatu sistem untuk mengetahui stock opname persediaan barang pada suatu tempat. Karena terdapat beberapa masalah, yaitu adanya kesulitan dalam mengetahui informasi permintaan, penerimaan, pemakaian, dan stok barang habis pakai (BHP) . Hal ini disebabkan data belum tersimpan dalam file yang baik dan pengelolaan data persediaan BHP masih dilakukan secara manual (kartu persediaan barang), dalam proses persedian barang di gudang menjadi single user dalam melakukan stock opname persediaan BHP tidak dapat digunakan untuk multiusers sehingga bagian pelayanan dan Kepala Logistik tidak dapat langsung bisa mengakses laporan stock opname BHP. Permasalahan seperti ini memerlukan sebuah sistem yang terkomputerisasi dan berbasis web. \n\n     Metodologi pengembangan sistem yang digunakan dalam penelitian ini adalah dengan metode waterfall (Siklus Air Terjun) yang meliputi, analisa dan rekayasa sistem, analisis kebutuhan, perancangan, pemrograman, pengujian dan pemeliharaan. Sistem Manajemen Inventory Logistic telah dirasa tepat hal ini dapat dilihat pada kepuasan pengguna dengan nilai survei rata-rata adalah sebesar 7,88 dan uji coba sistem yang dapat berjalan dengan baik. Aplikasi ini secara signifikan dapat menyederhanakan alur kerja distribusi barang dan pembuatan laporan distribusi barang di lingkungan RSUD. dr. H. Slamet Martodirdjo. \nKata Kunci : Inventory, Stock Opname, BHP (Barang Habis Pakai)\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100015&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100015&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100015&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100015&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100015&gt;
{&#39;Abstrak&#39;: &#39;Tembakau merupakan salah satu hasil produk pertanian yang diproses dari bagian daun tanaman tembakau. Masyarakat secara umum hanya mengetahui bahwa tembakau merupakan bahan baku utama rokok, akan tetapi pada kenyataannya ada manfaat lain dari daun tembakau, mulai dari melepaskan gigitan lintah hingga sebagai obat HIV/AIDS dan sebagai biofuel. Pada umumnya ada dua faktor yang mempengaruhi kualitas tanaman pada daun tembakau yaitu hama dan penyakit. Untuk meminimalisir penurunan kualitas tanaman pada daun tembakau, dibutuhkan suatu metode yang mampu mendeteksi penyakit daun tembakau sebagai bentuk dari pengembangan teknologi digital (pengolahan citra). Metode yang digunakan pada penelitian ini yaitu Color Moment (CM), dimana metode ini digunakan untuk ekstraksi fitur warna. Sedangkan untuk ekstraksi fitur tekstur, metode yang digunakan adalah metode Grey Level Run Length Matrix (GLRLM). Klasifikasi dilakukan berdasarkan fitur yang telah diekstraksi sebelumnya. Penelitian ini menggunakan algoritma klasifikasi K-Nearest Neighbors (KNN). Hasil penelitian didapat nilai akurasi untuk ekstraksi fitur warna mencapai 57.33%, untuk ekstraksi fitur tekstur nilai akurasi mencapai 40.00% , dan untuk ekstraksi fitur hybrid nilai akurasi mencapai 40.33% .&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100015&gt;
{&#39;Abstrak&#39;: &#39;Tembakau merupakan salah satu hasil produk pertanian yang diproses dari bagian daun tanaman tembakau. Masyarakat secara umum hanya mengetahui bahwa tembakau merupakan bahan baku utama rokok, akan tetapi pada kenyataannya ada manfaat lain dari daun tembakau, mulai dari melepaskan gigitan lintah hingga sebagai obat HIV/AIDS dan sebagai biofuel. Pada umumnya ada dua faktor yang mempengaruhi kualitas tanaman pada daun tembakau yaitu hama dan penyakit. Untuk meminimalisir penurunan kualitas tanaman pada daun tembakau, dibutuhkan suatu metode yang mampu mendeteksi penyakit daun tembakau sebagai bentuk dari pengembangan teknologi digital (pengolahan citra). Metode yang digunakan pada penelitian ini yaitu Color Moment (CM), dimana metode ini digunakan untuk ekstraksi fitur warna. Sedangkan untuk ekstraksi fitur tekstur, metode yang digunakan adalah metode Grey Level Run Length Matrix (GLRLM). Klasifikasi dilakukan berdasarkan fitur yang telah diekstraksi sebelumnya. Penelitian ini menggunakan algoritma klasifikasi K-Nearest Neighbors (KNN). Hasil penelitian didapat nilai akurasi untuk ekstraksi fitur warna mencapai 57.33%, untuk ekstraksi fitur tekstur nilai akurasi mencapai 40.00% , dan untuk ekstraksi fitur hybrid nilai akurasi mencapai 40.33% .&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100016&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100016&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100016&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100016&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100016&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100016&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100016&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100016&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100016&gt;
{&#39;Abstrak&#39;: &#39;Padi merupakan tanaman pangan yang diamati oleh Dinas Pertanian dan paling banyak terserang penyakit. Dalam penanganannya terdapat beberapa kendala diantaranya keberadaan organisme pengganggu tanaman (OPT) yang semakin meningkat. Keberadaan OPT seperti penggerek batang, tikus, penyakit blas, dsb, dapat menyebabkan kerusakan mutlak dan kerusakan tidak mutlak. Namun untuk mengetahui intensitas kerusakan mutlak dan kerusakan tidak mutlak yang diamati, petugas lapangan melakukan perhitungan dengan cara tradisional tanpa adanya system dan belum adanya pemetaan yang digunakan sebagai alat pendukung pengendalian serangan OPT. Oleh karena itu, perlu dibuatkan sistem pemetaan intensitas kerusakan berdasarkan serangan OPT. Dari hasil penelitian yang telah dilakukan dapat diketahui bahwa sistem ini dapat membantu pihak petugas lapangan untuk mengetahui intensitas kerusakanan dan mengetahui pemetaan intensitas kerusakan sebagai media informasi untuk memberikan kebijakan pengendalian serangan OPT. Berdasarkan hasil uji coba sistem dengan melakukan kuisioner untuk mengetahui kelayakan sistem, maka didapat hasil kuisioner kelayakan bagi petugas dan admin sebesar 82%, sedangkan hasil kuisioner kelayakan bagi masyarakat (umum) sebesar 83%. Sehingga dapat disimpulkan bahwa hasil dari kedua kuisioner memiliki tingkat kelayakan dalam mengetahui hasil intensitas kerusakan dan pemetaan intensitas kerusakan.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100016&gt;
{&#39;Abstrak&#39;: &#39;Padi merupakan tanaman pangan yang diamati oleh Dinas Pertanian dan paling banyak terserang penyakit. Dalam penanganannya terdapat beberapa kendala diantaranya keberadaan organisme pengganggu tanaman (OPT) yang semakin meningkat. Keberadaan OPT seperti penggerek batang, tikus, penyakit blas, dsb, dapat menyebabkan kerusakan mutlak dan kerusakan tidak mutlak. Namun untuk mengetahui intensitas kerusakan mutlak dan kerusakan tidak mutlak yang diamati, petugas lapangan melakukan perhitungan dengan cara tradisional tanpa adanya system dan belum adanya pemetaan yang digunakan sebagai alat pendukung pengendalian serangan OPT. Oleh karena itu, perlu dibuatkan sistem pemetaan intensitas kerusakan berdasarkan serangan OPT. Dari hasil penelitian yang telah dilakukan dapat diketahui bahwa sistem ini dapat membantu pihak petugas lapangan untuk mengetahui intensitas kerusakanan dan mengetahui pemetaan intensitas kerusakan sebagai media informasi untuk memberikan kebijakan pengendalian serangan OPT. Berdasarkan hasil uji coba sistem dengan melakukan kuisioner untuk mengetahui kelayakan sistem, maka didapat hasil kuisioner kelayakan bagi petugas dan admin sebesar 82%, sedangkan hasil kuisioner kelayakan bagi masyarakat (umum) sebesar 83%. Sehingga dapat disimpulkan bahwa hasil dari kedua kuisioner memiliki tingkat kelayakan dalam mengetahui hasil intensitas kerusakan dan pemetaan intensitas kerusakan.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100016&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100016&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100016&gt;
{&#39;Abstrak&#39;: &#39;Machine Learning  telah diaplikasikan untuk permainan sederhana sejak beberapa tahun lalu. Metode ini menunjukkan bagaimana sebuah komputer belajar memainkan video game Atari 2600 dengan mengamati piksel layar dan menerima hadiah saat skor game meningkat. Convolutional Neural Network merupakan sebuah pembelajaran Deep Learning yang beberapa tahun terakhir ini menjadi sangat populer ketika mencapai hasil yang sangat mengesankan dalam pengenalan gambar, pada bidang computer vision. Agen belajar memainkan permainan ular berdasarkan snapshot dari layar. Convolutional Neural Network digunakan untuk memilih tindakan terbaik berdasarkan pengamatan dari lingkungan dan pengetahuan sebelum dipelajari. Selain itu Convolutional Neural Network tidak perlu melakukan feature extraction karena metode ini memiliki kemampuan feature learning pada saat proses konvolusi dilakukan. Serangkaian empat screenshot dari layar digunakan sebagai input jaringan. Oleh karena itu, jaringan dapat menangkap informasi game termasuk arah dan posisi, dan kemudian output yang dihasilkan berupa sebuah tindakan. Berdasarkan percobaan yang telah dilakukan, terdapat 3 model yang masing-masing memiliki jumlah dataset yang berbeda-beda, dilakukan 3 perbandingan performa, yakni rata-rata skor tertinggi, rata-rata skor total dan rata-rata jumlah tabrakan yang dilakukan dalam durasi waktu tertentu yakni 3 menit, 5 menit dan 7 menit. Perolehan akurasi tertinggi yakni 47,93% untuk 105.000 data (model 3), 40,66% untuk 55.000 data (model 2) dan 26,30% untuk 15.000 data (model 1). Akurasi tersebut mempengaruhi hasil prediksi arah saat agen bermain. Dalam pencapaian skor, model 3 lebih unggul daripada kedua model lainnya dan dalam jumlah tabrakan model 3 memiliki jumlah tabrakan terendah dibandingkan model 1 yang memiliki jumlah tabrakan terbanyak.\n\nKata kunci : Machine Learning, Snake Game, Convolutional Neural Network (CNN)&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100016&gt;
{&#39;Abstrak&#39;: &#39;Machine Learning  telah diaplikasikan untuk permainan sederhana sejak beberapa tahun lalu. Metode ini menunjukkan bagaimana sebuah komputer belajar memainkan video game Atari 2600 dengan mengamati piksel layar dan menerima hadiah saat skor game meningkat. Convolutional Neural Network merupakan sebuah pembelajaran Deep Learning yang beberapa tahun terakhir ini menjadi sangat populer ketika mencapai hasil yang sangat mengesankan dalam pengenalan gambar, pada bidang computer vision. Agen belajar memainkan permainan ular berdasarkan snapshot dari layar. Convolutional Neural Network digunakan untuk memilih tindakan terbaik berdasarkan pengamatan dari lingkungan dan pengetahuan sebelum dipelajari. Selain itu Convolutional Neural Network tidak perlu melakukan feature extraction karena metode ini memiliki kemampuan feature learning pada saat proses konvolusi dilakukan. Serangkaian empat screenshot dari layar digunakan sebagai input jaringan. Oleh karena itu, jaringan dapat menangkap informasi game termasuk arah dan posisi, dan kemudian output yang dihasilkan berupa sebuah tindakan. Berdasarkan percobaan yang telah dilakukan, terdapat 3 model yang masing-masing memiliki jumlah dataset yang berbeda-beda, dilakukan 3 perbandingan performa, yakni rata-rata skor tertinggi, rata-rata skor total dan rata-rata jumlah tabrakan yang dilakukan dalam durasi waktu tertentu yakni 3 menit, 5 menit dan 7 menit. Perolehan akurasi tertinggi yakni 47,93% untuk 105.000 data (model 3), 40,66% untuk 55.000 data (model 2) dan 26,30% untuk 15.000 data (model 1). Akurasi tersebut mempengaruhi hasil prediksi arah saat agen bermain. Dalam pencapaian skor, model 3 lebih unggul daripada kedua model lainnya dan dalam jumlah tabrakan model 3 memiliki jumlah tabrakan terendah dibandingkan model 1 yang memiliki jumlah tabrakan terbanyak.\n\nKata kunci : Machine Learning, Snake Game, Convolutional Neural Network (CNN)&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100016&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100016&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100017&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:26 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100017&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100017&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100017&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100017&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100017&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100017&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100017&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100017&gt;
{&#39;Abstrak&#39;: &#39;Universitas Trunojoyo Madura merupakan salah satu universitas negeri yang banyak diminati mahasiswa untuk melanjutkan studi mereka ke tahap sarjana. Kebanyakan mahasiswa baru berasal dari luar kota, sehingga belum mengenal daerah sekitar Universitas Trunojoyo Madura. Seiring bertambahnya mahasiswa pendatang baru tersebut menyebabkan kebutuhan rumah kost meningkat, oleh karena itu dibutuhkannya sebuah sistem rekomendasi rumah kost untuk mempermudah mahasiswa dalam menentukan pilihan sesuai kebutuhan mereka. Sistem rekomendasi yang akan diusulkan pada penelitian ini ialah menggunakan metode k-means clustering untuk mengelompokkan data menjadi beberapa kelompok yang berbeda. Selain menggunakan metode k-means clustering, sistem rekomendasi menyediakan sistem berbasis mobile yang didukung dengan google maps untuk mempermudah mahasiswa pendatang baru mengetahui lokasi sekitar Universitas Trunojoyo Madura. Penelitan ini diharapkan dapat merekomendasikan beberapa item kepada mahasiswa yaitu item rumah kost dengan beberapa parameter seperti harga kost, jenis kost, kamar mandi dalam, kamar mandi luar, kulkas, dapur, tv, kipas angina, gratis wi-fi, gratis listrik dan jarak kost ke Universitas Trunojoyo Madura. Berdasarkan hasil implementasi metode K-means Clustering untuk rekomendasi rumah kost diperoleh akurasi persentase pengujian system(P) didapatkan 81.67%, sedangkan persentase pengujian akurasi(Q) didapatkan 79.53 %. Dengan begitu metode k-means clustering telah memberikan tingkat akurasi yang cukup tinggi dan layak untuk diaplikasikan.\n\nKata kunci: Rumah Kost, Sistem Rekomendasi, K-means Clustering, Mobile\n \n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100017&gt;
{&#39;Abstrak&#39;: &#39;Universitas Trunojoyo Madura merupakan salah satu universitas negeri yang banyak diminati mahasiswa untuk melanjutkan studi mereka ke tahap sarjana. Kebanyakan mahasiswa baru berasal dari luar kota, sehingga belum mengenal daerah sekitar Universitas Trunojoyo Madura. Seiring bertambahnya mahasiswa pendatang baru tersebut menyebabkan kebutuhan rumah kost meningkat, oleh karena itu dibutuhkannya sebuah sistem rekomendasi rumah kost untuk mempermudah mahasiswa dalam menentukan pilihan sesuai kebutuhan mereka. Sistem rekomendasi yang akan diusulkan pada penelitian ini ialah menggunakan metode k-means clustering untuk mengelompokkan data menjadi beberapa kelompok yang berbeda. Selain menggunakan metode k-means clustering, sistem rekomendasi menyediakan sistem berbasis mobile yang didukung dengan google maps untuk mempermudah mahasiswa pendatang baru mengetahui lokasi sekitar Universitas Trunojoyo Madura. Penelitan ini diharapkan dapat merekomendasikan beberapa item kepada mahasiswa yaitu item rumah kost dengan beberapa parameter seperti harga kost, jenis kost, kamar mandi dalam, kamar mandi luar, kulkas, dapur, tv, kipas angina, gratis wi-fi, gratis listrik dan jarak kost ke Universitas Trunojoyo Madura. Berdasarkan hasil implementasi metode K-means Clustering untuk rekomendasi rumah kost diperoleh akurasi persentase pengujian system(P) didapatkan 81.67%, sedangkan persentase pengujian akurasi(Q) didapatkan 79.53 %. Dengan begitu metode k-means clustering telah memberikan tingkat akurasi yang cukup tinggi dan layak untuk diaplikasikan.\n\nKata kunci: Rumah Kost, Sistem Rekomendasi, K-means Clustering, Mobile\n \n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100017&gt;
{&#39;Abstrak&#39;: &#39;Kesehatan merupakan hal penting bagi kehidupan, terutama bagi manusia. Banyak penyakit yang menyerang manusia, salah satunya yaitu penyakit stroke. Penyakit stroke merupakan suatu gangguan fungsi sistem saraf yang dapat terjadi secara mendadak, disebabkan oleh gangguan pembuluh darah di otak. Banyaknya orang yang terkena stroke membuat dokter kesusahan untuk mendiagnosis pasien yang konsultasi maupun yang terkena stroke. Klasifikasi penyakit stroke secara cepat dan tepat dapat membantu dokter untuk mendiagnosis penyakit stroke. Klasifikasi penyakit stroke akan memprediksi penyakit yang diderita oleh pasien secara efektif dan efisien. Pada penelitian ini menggunakan model klasifikasi K-Nearest Neighbor(KNN) dengan seleksi fitur Gain Ratio. Metode KNN digunakan untuk klasifikasi penyakit stroke berdasarkan nilai k tetangga yang mana akan dihitung jarak antara data latih dan data uji, sedangkan Gain Ratio digunakan untuk meningkatkan akurasi dari metode KNN dengan cara mereduksi dimensi pada fitur. Data set yang digunakan yaitu data penyakit stroke dari situs https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data dengan jumlah data 43400 yang mana terdiri 10 fitur. Data dipencah menggunakan K-fold Cross Validation dengan menggunakan k=10. Hasil yang didapatkan dengan menggunakan metode seleksi fitur Gain Ratio dan model klasifikasi KNN yaitu dengan jumlah fitur = 1 dan KNN(k=3) yang menghasilkan akurasi 1, recall 1, precision 1, error 0, dan waktu komputasi selama 228 detik.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100017&gt;
{&#39;Abstrak&#39;: &#39;Kesehatan merupakan hal penting bagi kehidupan, terutama bagi manusia. Banyak penyakit yang menyerang manusia, salah satunya yaitu penyakit stroke. Penyakit stroke merupakan suatu gangguan fungsi sistem saraf yang dapat terjadi secara mendadak, disebabkan oleh gangguan pembuluh darah di otak. Banyaknya orang yang terkena stroke membuat dokter kesusahan untuk mendiagnosis pasien yang konsultasi maupun yang terkena stroke. Klasifikasi penyakit stroke secara cepat dan tepat dapat membantu dokter untuk mendiagnosis penyakit stroke. Klasifikasi penyakit stroke akan memprediksi penyakit yang diderita oleh pasien secara efektif dan efisien. Pada penelitian ini menggunakan model klasifikasi K-Nearest Neighbor(KNN) dengan seleksi fitur Gain Ratio. Metode KNN digunakan untuk klasifikasi penyakit stroke berdasarkan nilai k tetangga yang mana akan dihitung jarak antara data latih dan data uji, sedangkan Gain Ratio digunakan untuk meningkatkan akurasi dari metode KNN dengan cara mereduksi dimensi pada fitur. Data set yang digunakan yaitu data penyakit stroke dari situs https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data dengan jumlah data 43400 yang mana terdiri 10 fitur. Data dipencah menggunakan K-fold Cross Validation dengan menggunakan k=10. Hasil yang didapatkan dengan menggunakan metode seleksi fitur Gain Ratio dan model klasifikasi KNN yaitu dengan jumlah fitur = 1 dan KNN(k=3) yang menghasilkan akurasi 1, recall 1, precision 1, error 0, dan waktu komputasi selama 228 detik.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100017&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100017&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100017&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100017&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100018&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100018&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100018&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100018&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100018&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100018&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100018&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100018&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100018&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100018&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100018&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100018&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100018&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100018&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100018&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100018&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100019&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100019&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100019&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100019&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100019&gt;
{&#39;Abstrak&#39;: &#39;Proses monitoring kegiatan yang ada di asrama pada saat ini masih manual. Dari proses manual tersebut ketika pengelola meminta data – data  kegiatan yang sudah dilaksanakan di asrama kepada musahhil, maka musahhil harus mencari data sehingga membutuhkan waktu yang cukup lama.  Oleh karena itu dibutuhkan suatu aplikasi yang dapat mengatasi permasalahan - permasalahan tersebut. Aplikasi yang akan digunakan adalah dengan  menerapkan konsep  MVC (Model, View Controller) menggunakan Framework Codeigniter. MVC adalah suatu konsep dimana untuk mengembangkan suatu aplikasi website yang  memisahkan  presentasi logic dengan tampilannya yang diatur  oleh controller. Diharapkan dengan adanya aplikasi monitoring kegiatan asrama dengan konsep MVC (Model, View, Controller)  ini seluruh kegiatan asrama dapat terpantau dengan baik dan mudah. Selain itu berdasarkan hasil kuisioner yang telah dilakukan di asrama  menunjukkan persentase kesesuaian dan penilaian aplikasi sebesar 100% dapat disimpulkan bahwa aplikasi monitoring kegiatan asrama masuk dalam kategori baik dan layak untuk diimplementasikan.  \n\nKata Kunci : Monitoring, Asrama Mahasiswa, Framework Codeigniter MVC (Model, View, Controller).\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100019&gt;
{&#39;Abstrak&#39;: &#39;Proses monitoring kegiatan yang ada di asrama pada saat ini masih manual. Dari proses manual tersebut ketika pengelola meminta data – data  kegiatan yang sudah dilaksanakan di asrama kepada musahhil, maka musahhil harus mencari data sehingga membutuhkan waktu yang cukup lama.  Oleh karena itu dibutuhkan suatu aplikasi yang dapat mengatasi permasalahan - permasalahan tersebut. Aplikasi yang akan digunakan adalah dengan  menerapkan konsep  MVC (Model, View Controller) menggunakan Framework Codeigniter. MVC adalah suatu konsep dimana untuk mengembangkan suatu aplikasi website yang  memisahkan  presentasi logic dengan tampilannya yang diatur  oleh controller. Diharapkan dengan adanya aplikasi monitoring kegiatan asrama dengan konsep MVC (Model, View, Controller)  ini seluruh kegiatan asrama dapat terpantau dengan baik dan mudah. Selain itu berdasarkan hasil kuisioner yang telah dilakukan di asrama  menunjukkan persentase kesesuaian dan penilaian aplikasi sebesar 100% dapat disimpulkan bahwa aplikasi monitoring kegiatan asrama masuk dalam kategori baik dan layak untuk diimplementasikan.  \n\nKata Kunci : Monitoring, Asrama Mahasiswa, Framework Codeigniter MVC (Model, View, Controller).\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100019&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100019&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100019&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100019&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100019&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:27 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100019&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100019&gt;
{&#39;Abstrak&#39;: &#39;Di dalam permainan sepak bola seorang pelatih akan menentukan posisi pemain yang tepat dalam permainan dengan melihat data pemain tersebut. Terkadang posisi pemain tidak sesuai dengan kemampuan yang dimilikinya. Hal seperti inilah yang membuat pelatih kesulitan dalam membuat keputusan yang tepat dengan menilai pemain secara obyektif dan tidak hanya menggunakan insting saja dalam menentukan posisi pemain, terutama pemain bertahan yang menjadi benteng pertahanan bagi sebuah tim. Terkadang hasil penilaian yang tidak efektif  karena adanya penggunaan cara penilaian yang tidak sesuai dengan aturan yang ada. Sehingga untuk menyelesaikan permasalahan tersebut diperlukan suatu sistem pendukung keputusan yang membantu pelatih dalam menentukan posisi bertahan dalam sepakbola. Pada penelitian sebelumnya, metode pendukung keputusan telah mampu menentukan posisi pemain sepakbola, namun yang didapat akurasinya kurang tinggi. Oleh karena itu, pada penentuan posisi bertahan yang digunakan adalah metode Simple Multi Attribute Rating Technique (SMART). Pengujian dilakukan kepada 20 pemain Persebaya U-14 dengan menggunakan 23 kriteria. Hasil akhir dari metode SMART menghasilkan akurasi sebesar 69.23%. dari hasil rekomendasi sistem dengan uji coba di lapangan.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100019&gt;
{&#39;Abstrak&#39;: &#39;Di dalam permainan sepak bola seorang pelatih akan menentukan posisi pemain yang tepat dalam permainan dengan melihat data pemain tersebut. Terkadang posisi pemain tidak sesuai dengan kemampuan yang dimilikinya. Hal seperti inilah yang membuat pelatih kesulitan dalam membuat keputusan yang tepat dengan menilai pemain secara obyektif dan tidak hanya menggunakan insting saja dalam menentukan posisi pemain, terutama pemain bertahan yang menjadi benteng pertahanan bagi sebuah tim. Terkadang hasil penilaian yang tidak efektif  karena adanya penggunaan cara penilaian yang tidak sesuai dengan aturan yang ada. Sehingga untuk menyelesaikan permasalahan tersebut diperlukan suatu sistem pendukung keputusan yang membantu pelatih dalam menentukan posisi bertahan dalam sepakbola. Pada penelitian sebelumnya, metode pendukung keputusan telah mampu menentukan posisi pemain sepakbola, namun yang didapat akurasinya kurang tinggi. Oleh karena itu, pada penentuan posisi bertahan yang digunakan adalah metode Simple Multi Attribute Rating Technique (SMART). Pengujian dilakukan kepada 20 pemain Persebaya U-14 dengan menggunakan 23 kriteria. Hasil akhir dari metode SMART menghasilkan akurasi sebesar 69.23%. dari hasil rekomendasi sistem dengan uji coba di lapangan.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100019&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100019&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100020&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100020&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100020&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100020&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100020&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100020&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100020&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100020&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100020&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100020&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100020&gt;
{&#39;Abstrak&#39;: &#39;Bahan baku merupakan hal utama didalam perusahaan, terutama perusahaan industri, karena bahan baku merupakan bagian dari suatu proses produksi yang harus ada dan tidak dapat diabaikan keberadaannya. UD. Budi Jaya adalah perusahaan makanan khususnya cemilan yang bahan baku utamanya adalah buah salak. Di lokasi  terdapat perkebunan salak milik perusahaan danmenjadi sumber bahan baku yang dimana pohon berbuah hanya pada musimnya. Tetapi, saat pohon tidak dalam masa panenmenyebabkan  perusahaan harus membeli buah salak pada penyedia lain yang dimana perusahaan mengeluarkan modal  lebih untuk membeli bahan baku. Oleh karena itu, Penelitian ini bertujuan untuk dapat mengendalikan bahan baku, dengan menerapkan metode Economic Order Quantity yang dimana metode tersebut membantu perusahaan untuk memanajemen bahan baku salak. Dan Metode Single Exponential Smoothing untuk mendukung perhitungan Eqonomic Order Qunatity. Berdasarkan hasil penelitian yang dilakukan di UD.Budi Jaya, bahwa dengen menggunakan metode Economic Order Quantity menghasilkan kebutuhan bahan baku yang lebih efisien.Pada tahun 2014, perusahaan bisa meminimalisir bahan baku salak sebesar 662,2 kg, tahun 2015 sebesar 351,6 kg, tahun 2016 sebesar 628,3 kg, dan tahun 2017 sebesar 589,3 kg. biaya pembelian bahan baku dapat diminimalisir Pada tahun 2014 sebesar Rp. 1.409.618, tahun 2015 sebesar Rp. 2.312.449, tahun 2016 sebesar Rp. 2.596.150, dan tahun 2017 sebesar Rp. 2.496.757.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100020&gt;
{&#39;Abstrak&#39;: &#39;Bahan baku merupakan hal utama didalam perusahaan, terutama perusahaan industri, karena bahan baku merupakan bagian dari suatu proses produksi yang harus ada dan tidak dapat diabaikan keberadaannya. UD. Budi Jaya adalah perusahaan makanan khususnya cemilan yang bahan baku utamanya adalah buah salak. Di lokasi  terdapat perkebunan salak milik perusahaan danmenjadi sumber bahan baku yang dimana pohon berbuah hanya pada musimnya. Tetapi, saat pohon tidak dalam masa panenmenyebabkan  perusahaan harus membeli buah salak pada penyedia lain yang dimana perusahaan mengeluarkan modal  lebih untuk membeli bahan baku. Oleh karena itu, Penelitian ini bertujuan untuk dapat mengendalikan bahan baku, dengan menerapkan metode Economic Order Quantity yang dimana metode tersebut membantu perusahaan untuk memanajemen bahan baku salak. Dan Metode Single Exponential Smoothing untuk mendukung perhitungan Eqonomic Order Qunatity. Berdasarkan hasil penelitian yang dilakukan di UD.Budi Jaya, bahwa dengen menggunakan metode Economic Order Quantity menghasilkan kebutuhan bahan baku yang lebih efisien.Pada tahun 2014, perusahaan bisa meminimalisir bahan baku salak sebesar 662,2 kg, tahun 2015 sebesar 351,6 kg, tahun 2016 sebesar 628,3 kg, dan tahun 2017 sebesar 589,3 kg. biaya pembelian bahan baku dapat diminimalisir Pada tahun 2014 sebesar Rp. 1.409.618, tahun 2015 sebesar Rp. 2.312.449, tahun 2016 sebesar Rp. 2.596.150, dan tahun 2017 sebesar Rp. 2.496.757.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100020&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100020&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100020&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100020&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100021&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100021&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100021&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100021&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100021&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100021&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100021&gt;
{&#39;Abstrak&#39;: &#39;Proses registrasi Asrama saat ini membutuhkan waktu dan tenaga yang banyak serta proses rekap data yang belum terorganisir dengan baik. Aplikasi registrasi asrama dibuat untuk mengatasi masalah tersebut. Aplikasi ini dibangun dengan menerapkan konsep Model View Controller (MVC) yang memisahkan antara desain, data dan proses. Hasil penelitian ini menunjukkan bahwa  penerapan konsep MVC pada  aplikasi registrasi asrama dapat memudahkan developer dalam pembangunan aplikasi. Selain itu berdasarkan hasil perhitungan kuisioner yang telah dilakukan dari 6 jenis responden, dapat disimpulkan bahwa rata-rata presentase ketercapaian sistem yaitu sebesar 99.57%  menyatakan sesuai dan 0.42%  menyatakan tidak sesuai.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100021&gt;
{&#39;Abstrak&#39;: &#39;Proses registrasi Asrama saat ini membutuhkan waktu dan tenaga yang banyak serta proses rekap data yang belum terorganisir dengan baik. Aplikasi registrasi asrama dibuat untuk mengatasi masalah tersebut. Aplikasi ini dibangun dengan menerapkan konsep Model View Controller (MVC) yang memisahkan antara desain, data dan proses. Hasil penelitian ini menunjukkan bahwa  penerapan konsep MVC pada  aplikasi registrasi asrama dapat memudahkan developer dalam pembangunan aplikasi. Selain itu berdasarkan hasil perhitungan kuisioner yang telah dilakukan dari 6 jenis responden, dapat disimpulkan bahwa rata-rata presentase ketercapaian sistem yaitu sebesar 99.57%  menyatakan sesuai dan 0.42%  menyatakan tidak sesuai.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100021&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100021&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100021&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100021&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100021&gt;
{&#39;Abstrak&#39;: &#39;Cold-start merupakan sebuah masalah yang terjadi pada sistem rekomendasi yang menggunakan pendekatan memory based. Cold-start terjadi pada user baru yang belum memiliki riwayat apapun pada sistem. Kondisi tersebut membuat proses rekomendasi menjadi tidak akurat. Rekomendasi pada user baru sangat efektif untuk membantu user baru memilih item. Oleh karena itu, mengatasi masalah coldstart perlu diterapkan. Tujuan penelitian ini adalah menerapkan metode Clustering k-modes, Fuzzy C Means dan Teknik Popularitas item untuk mengatasi cold-start. Algoritma K-modes dapat megelompokkan pengguna berdasarkan atribut non numerik. Seperti jenis kelamin dan pekerjaan. Dengan menggunakan atribut-atribut tersebut, user dapat dikelompokkan walaupun tanpa riwayat apapun. Kemudian, Item akan di kelompokkan berdasarkan rating menggunakan metode Fuzzy C Means Clustering. proses untuk menghasilkan Top-N akan menggunakan Teknik Popularitas item. Dengan kombinasi metode tersebut, diharapkan mampu mengetahui selera user baru sesuai kelompoknya dan mendapatkan rekomendasi yang lebih akurat dalam keadaan cold-start. Dari hasil percobaan yang telah dilakukan, kombinasi metode usulan mampu mendapatkan akurasi lebih baik dari pendekatan memory based (Item-based). Dengan rata-rata persentase kenaikan sebesar 489.55 %, Kenaikan maksimal sebesar 2358.70 %, dan kenaikan minimal sebesar 124.25 % pada metrik evaluasi Precision. Sedangkan pada metrik evaluasi Discounted Comulative Gain (DCG), didapatkan nilai rata-rata kenaikan sebesar 571.36 %,  kenaikan maksimal sebesar 2358.70 % dan kenaikan minimal sebesar 163.59 %.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100021&gt;
{&#39;Abstrak&#39;: &#39;Cold-start merupakan sebuah masalah yang terjadi pada sistem rekomendasi yang menggunakan pendekatan memory based. Cold-start terjadi pada user baru yang belum memiliki riwayat apapun pada sistem. Kondisi tersebut membuat proses rekomendasi menjadi tidak akurat. Rekomendasi pada user baru sangat efektif untuk membantu user baru memilih item. Oleh karena itu, mengatasi masalah coldstart perlu diterapkan. Tujuan penelitian ini adalah menerapkan metode Clustering k-modes, Fuzzy C Means dan Teknik Popularitas item untuk mengatasi cold-start. Algoritma K-modes dapat megelompokkan pengguna berdasarkan atribut non numerik. Seperti jenis kelamin dan pekerjaan. Dengan menggunakan atribut-atribut tersebut, user dapat dikelompokkan walaupun tanpa riwayat apapun. Kemudian, Item akan di kelompokkan berdasarkan rating menggunakan metode Fuzzy C Means Clustering. proses untuk menghasilkan Top-N akan menggunakan Teknik Popularitas item. Dengan kombinasi metode tersebut, diharapkan mampu mengetahui selera user baru sesuai kelompoknya dan mendapatkan rekomendasi yang lebih akurat dalam keadaan cold-start. Dari hasil percobaan yang telah dilakukan, kombinasi metode usulan mampu mendapatkan akurasi lebih baik dari pendekatan memory based (Item-based). Dengan rata-rata persentase kenaikan sebesar 489.55 %, Kenaikan maksimal sebesar 2358.70 %, dan kenaikan minimal sebesar 124.25 % pada metrik evaluasi Precision. Sedangkan pada metrik evaluasi Discounted Comulative Gain (DCG), didapatkan nilai rata-rata kenaikan sebesar 571.36 %,  kenaikan maksimal sebesar 2358.70 % dan kenaikan minimal sebesar 163.59 %.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100021&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:28 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100021&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100022&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100022&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100022&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100022&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100022&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100022&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100022&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100022&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100022&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100022&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100022&gt;
{&#39;Abstrak&#39;: &#39;Demam Berdarah Dengue (DBD) merupakan penyakit yang dapat membuat suhu tubuh penderita menjadi sangat tinggi dan pada umumnya disertai tanda gejala seperti sakit kepala, nyeri sendi, otot, dan tulang, serta nyeri di bagian belakang mata. Penyakit Demam Berdarah Dengue disebabkan oleh virus dengue yang penyebarannya terjadi melalui gigitan nyamuk Aedes aegypti dan Aedes albopictus. Dalam hal ini, untuk diagnosis dibutuhkan analisa yang akurat untuk meminimalisir kesalahan diagnosis yang membuat keterlambatan penanganan. Pada penelitian ini dibuatkan sistem pakar berbasis android untuk mendiagnosis penyakit DBD yang bertujuan sebagai pencegahan lebih awal. Sistem pakar tersebut akan memberikan pilihan gejala-gejala demam berdarah untuk dipilih oleh pengguna. Gejalagejala yang sudah dipilih oleh pengguna akan dihitung menggunakan metode Certainty Factor dan Naive Bayes. Dengan adanya sistem ini diharapkan dapat membantu masyarakat luas dalam melakukan diagnosis demam berdarah lebih cepat. Pengujian sistem dilakukan menggunakan metode K-fold cross validation dengan nilai k = 3. Berdasarkan uji coba menggunakan metode K-fold cross validation menunjukkan bahwa metode Naive Bayes mampu melakukan diagnosis lebih akurat dibandingkan Certainty Factor dengan hasil pengujian sebesar 76,5625 % dan 70,83333333 %. &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100022&gt;
{&#39;Abstrak&#39;: &#39;Demam Berdarah Dengue (DBD) merupakan penyakit yang dapat membuat suhu tubuh penderita menjadi sangat tinggi dan pada umumnya disertai tanda gejala seperti sakit kepala, nyeri sendi, otot, dan tulang, serta nyeri di bagian belakang mata. Penyakit Demam Berdarah Dengue disebabkan oleh virus dengue yang penyebarannya terjadi melalui gigitan nyamuk Aedes aegypti dan Aedes albopictus. Dalam hal ini, untuk diagnosis dibutuhkan analisa yang akurat untuk meminimalisir kesalahan diagnosis yang membuat keterlambatan penanganan. Pada penelitian ini dibuatkan sistem pakar berbasis android untuk mendiagnosis penyakit DBD yang bertujuan sebagai pencegahan lebih awal. Sistem pakar tersebut akan memberikan pilihan gejala-gejala demam berdarah untuk dipilih oleh pengguna. Gejalagejala yang sudah dipilih oleh pengguna akan dihitung menggunakan metode Certainty Factor dan Naive Bayes. Dengan adanya sistem ini diharapkan dapat membantu masyarakat luas dalam melakukan diagnosis demam berdarah lebih cepat. Pengujian sistem dilakukan menggunakan metode K-fold cross validation dengan nilai k = 3. Berdasarkan uji coba menggunakan metode K-fold cross validation menunjukkan bahwa metode Naive Bayes mampu melakukan diagnosis lebih akurat dibandingkan Certainty Factor dengan hasil pengujian sebesar 76,5625 % dan 70,83333333 %. &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100022&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100022&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100022&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100022&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100023&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100023&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100023&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100023&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100023&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100023&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100023&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100023&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100023&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100023&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100023&gt;
{&#39;Abstrak&#39;: &#39;Fashion merupakan kebutuhan pokok bagi setiap orang. Semakin berkembangnya fashion saat ini dipengaruhi oleh banyaknya inovasi-inovasi yang diberikan toko dalam menjual pakaian untuk menarik minat pelanggan. Salah satunya adalah memberikan fasilitas kamar ganti kepada pelanggan, agar pelanggan dapat mencoba pakaian yang akan dibelinya. Namun, ternyata ada beberapa permasalahan yang terjadi yang dikeluhkan pelanggan, semisal : antrian kamar ganti yang panjang, keterbatasan tempat dan membautuhkan waktu lama jika pelanggan harus mencoba 2 atau 3 baju dengan model baju yang sama hanya untuk menentukan ukuran baju yang pas.\nDari permasalahan tersebut munculah teknologi tentang kamar ganti virtual yang banyak dikembangkan oleh beberapa perusahaan fashion. Dalam penelitian ini membahas tentang salah satu metode untuk mengimplementasikan teknologi kamar ganti virtual yang akan menggunakan hardware kinect dan  teknologi Augmented Reality. Pemanfaatan fitur yang didapat dari kinect (yaitu : data skeleton user) untuk mendapatkan lebar badan pelanggan yang digunakan sebagai penentuan ukuran pakaian. Metode yang digunakan dalam penelitian ini untuk menghitung lebar badan pelanggan adalah menggunakan  Euclidean distance. Hasil eksperimen tehadap 20 pengguna menunjukan bahwa tingkat akurasi sistem mencapai kami 80% dalam memberikan rekomendasi ukuran pakaian yang sesuai dengan ukuran yang sebenarnya dari pelanggan.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100023&gt;
{&#39;Abstrak&#39;: &#39;Fashion merupakan kebutuhan pokok bagi setiap orang. Semakin berkembangnya fashion saat ini dipengaruhi oleh banyaknya inovasi-inovasi yang diberikan toko dalam menjual pakaian untuk menarik minat pelanggan. Salah satunya adalah memberikan fasilitas kamar ganti kepada pelanggan, agar pelanggan dapat mencoba pakaian yang akan dibelinya. Namun, ternyata ada beberapa permasalahan yang terjadi yang dikeluhkan pelanggan, semisal : antrian kamar ganti yang panjang, keterbatasan tempat dan membautuhkan waktu lama jika pelanggan harus mencoba 2 atau 3 baju dengan model baju yang sama hanya untuk menentukan ukuran baju yang pas.\nDari permasalahan tersebut munculah teknologi tentang kamar ganti virtual yang banyak dikembangkan oleh beberapa perusahaan fashion. Dalam penelitian ini membahas tentang salah satu metode untuk mengimplementasikan teknologi kamar ganti virtual yang akan menggunakan hardware kinect dan  teknologi Augmented Reality. Pemanfaatan fitur yang didapat dari kinect (yaitu : data skeleton user) untuk mendapatkan lebar badan pelanggan yang digunakan sebagai penentuan ukuran pakaian. Metode yang digunakan dalam penelitian ini untuk menghitung lebar badan pelanggan adalah menggunakan  Euclidean distance. Hasil eksperimen tehadap 20 pengguna menunjukan bahwa tingkat akurasi sistem mencapai kami 80% dalam memberikan rekomendasi ukuran pakaian yang sesuai dengan ukuran yang sebenarnya dari pelanggan.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100023&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100023&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100024&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100024&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100023&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100023&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100024&gt;
{&#39;Abstrak&#39;: &#39;Dalam pengelolaan administrasi umum masih ditemui beberapa masalah seperti hilangnya data, ketika input data, dan sulitnya ketika melakukan pencarian data. Hal ini di karenakan pencatatan datanya masih menggunakan cara manual. Dari masalah-masalah yang ada di administrasi umum, perlu adanya aplikasi agar masalah tersebut dapat teratasi.  Untuk mempermudah pengembangan dan penggabungan buku-buku dalam administrasi umum, aplikasi ini menggunakan konsep Hierarchical Model View Controller. Penerapan HMVC membuat aplikasi menjadi lebih modular karena tersusun dari modul-modul MVC untuk setiap buku. Dari hasil ujicoba aplikasi pengelolaan administrasi umum dengan menggunakan HMVC didapat kesimpulan, bahwa aplikasi ini sesuai dengan standart user dan standart developer. Sehingga, aplikasi ini mempermudah pengelolaan administrasi umum dan dengan HMVC mempermudah pengembangan aplikasi.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100024&gt;
{&#39;Abstrak&#39;: &#39;Dalam pengelolaan administrasi umum masih ditemui beberapa masalah seperti hilangnya data, ketika input data, dan sulitnya ketika melakukan pencarian data. Hal ini di karenakan pencatatan datanya masih menggunakan cara manual. Dari masalah-masalah yang ada di administrasi umum, perlu adanya aplikasi agar masalah tersebut dapat teratasi.  Untuk mempermudah pengembangan dan penggabungan buku-buku dalam administrasi umum, aplikasi ini menggunakan konsep Hierarchical Model View Controller. Penerapan HMVC membuat aplikasi menjadi lebih modular karena tersusun dari modul-modul MVC untuk setiap buku. Dari hasil ujicoba aplikasi pengelolaan administrasi umum dengan menggunakan HMVC didapat kesimpulan, bahwa aplikasi ini sesuai dengan standart user dan standart developer. Sehingga, aplikasi ini mempermudah pengelolaan administrasi umum dan dengan HMVC mempermudah pengembangan aplikasi.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100024&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100024&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100024&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100024&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100024&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100024&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100024&gt;
{&#39;Abstrak&#39;: &#39;Garam merupakan komoditas strategis, Provinsi Jawa Timur salah satu pemasok terbesar garam nasional yang sentra produksinya berada di Madura. Madura adalah daerah yang mempunyai potensi untuk produksi garam sehingga dari dulu madura dikenal sebagai pulau garam. Namun tambak garam sebagai lahan untuk  menghasilkan garam tidak semuanya memiliki potensi yang bagus karena memiliki perbedaan dari aspek teknis yang mempengaruhi produktivitas tambak garam,  Untuk mengetahui kelompok tambak garam yang memiliki kesamaan dari aspek teknis. Dilakukan pengelompokan dengan menggunakan analisis cluster. Analsisis cluster adalah pengelompokan suatu objek kedalam kelompok yang lebih kecil dimana masing-masing kelompok memiliki objek kemiripan satu sama lain. proses pengelompokan dilakukan untuk tambak garam yang ada di Jawa Timur dengan menggunakan metode Single Linkage. Metode Single Linkage adalah suatu metode Hierarki yang mengelompokkan suatu objek yang memiliki jarak terdekat terlebih dahulu atau kemiripan yang paling besar. Hal ini dipengaruhi oleh perhitungan jarak menggunakan Euclidian Distance dan  pemetaan memanfaatkan teknologi Sistem Informasi Geografis pada data spasial tambak garam. Clustering Menggunakan Single Linkage dapat diukur menggunakan metode Silhouette Coefficient. Hasil dari penelitian ini menunjukkan nilai Silhouette Coefficient 0.9361 dalam cluster tambak garam di Provinsi Jawa Timur dengan nilai akurasi  93.61% dan dikategorikan strong structure \n\nKata kunci : Pemetaan,  Tambak Garam, Single Linkage, Provinsi Jawa Timur\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:29 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100024&gt;
{&#39;Abstrak&#39;: &#39;Garam merupakan komoditas strategis, Provinsi Jawa Timur salah satu pemasok terbesar garam nasional yang sentra produksinya berada di Madura. Madura adalah daerah yang mempunyai potensi untuk produksi garam sehingga dari dulu madura dikenal sebagai pulau garam. Namun tambak garam sebagai lahan untuk  menghasilkan garam tidak semuanya memiliki potensi yang bagus karena memiliki perbedaan dari aspek teknis yang mempengaruhi produktivitas tambak garam,  Untuk mengetahui kelompok tambak garam yang memiliki kesamaan dari aspek teknis. Dilakukan pengelompokan dengan menggunakan analisis cluster. Analsisis cluster adalah pengelompokan suatu objek kedalam kelompok yang lebih kecil dimana masing-masing kelompok memiliki objek kemiripan satu sama lain. proses pengelompokan dilakukan untuk tambak garam yang ada di Jawa Timur dengan menggunakan metode Single Linkage. Metode Single Linkage adalah suatu metode Hierarki yang mengelompokkan suatu objek yang memiliki jarak terdekat terlebih dahulu atau kemiripan yang paling besar. Hal ini dipengaruhi oleh perhitungan jarak menggunakan Euclidian Distance dan  pemetaan memanfaatkan teknologi Sistem Informasi Geografis pada data spasial tambak garam. Clustering Menggunakan Single Linkage dapat diukur menggunakan metode Silhouette Coefficient. Hasil dari penelitian ini menunjukkan nilai Silhouette Coefficient 0.9361 dalam cluster tambak garam di Provinsi Jawa Timur dengan nilai akurasi  93.61% dan dikategorikan strong structure \n\nKata kunci : Pemetaan,  Tambak Garam, Single Linkage, Provinsi Jawa Timur\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100024&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100024&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100025&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100025&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100024&gt;
{&#39;Abstrak&#39;: &#39;Perkembangan penyakit tuberkulosis menurut World Health Organization (WHO) pada tahun 2014 menyatakan bahwa diperkirakan terjadi pada 9,6 juta orang dan 12% diantaranya adalah HIV-positif. Tuberkulosis adalah penyakit menular secara langsung yang disebabkan oleh kuman tuberkulosis (Mycobacterium Tuberculosis). Bakteri tuberkulosis dapat ditularkan melalui kontak fisik, udara, dahak penderita dan lain sebagainya. Saat ini banyak masyarakat yang tidak mengetahui gejala awal dan bahaya penyakit tuberkulosis, sehingga diperlukan sistem pakar dalam mendiagnosis dini penyakit tuberkulosis dan memberi rekomendasi pola makan yang dapat membantu mempercepat penanganan pasien. Pada sistem pakar diagnosis penyakit ini menggunakan metode Fuzzy Sugeno yang menghasilkan keputusan dengan menjawab pertanyaan berupa gejala-gejala. Selain itu  agar penderita memiliki status gizi yang baik maka dibutuhkan rekomendasi pola makan dengan menggunakan metode Naive Bayes agar mampu memberikan pola makan sesuai dengan status gizi yang dibutuhkan oleh seorang penderita tuberkulosis. Dengan menggunakan metode Fuzzy Sugeno untuk  menentukan diagnosis penyakit menghasilkan tingkat akurasi yaitu sebesar 85.35 % dan metode Naive Bayes untuk  menentukan rekomendasi pola makan menghasilkan tingkat akurasi tertinggi yaitu sebesar 89.28 % pada fold 3 dan  dengan perhitungan rata-rata nilai akurasi dari semua fold sebesar 78.57 %.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100024&gt;
{&#39;Abstrak&#39;: &#39;Perkembangan penyakit tuberkulosis menurut World Health Organization (WHO) pada tahun 2014 menyatakan bahwa diperkirakan terjadi pada 9,6 juta orang dan 12% diantaranya adalah HIV-positif. Tuberkulosis adalah penyakit menular secara langsung yang disebabkan oleh kuman tuberkulosis (Mycobacterium Tuberculosis). Bakteri tuberkulosis dapat ditularkan melalui kontak fisik, udara, dahak penderita dan lain sebagainya. Saat ini banyak masyarakat yang tidak mengetahui gejala awal dan bahaya penyakit tuberkulosis, sehingga diperlukan sistem pakar dalam mendiagnosis dini penyakit tuberkulosis dan memberi rekomendasi pola makan yang dapat membantu mempercepat penanganan pasien. Pada sistem pakar diagnosis penyakit ini menggunakan metode Fuzzy Sugeno yang menghasilkan keputusan dengan menjawab pertanyaan berupa gejala-gejala. Selain itu  agar penderita memiliki status gizi yang baik maka dibutuhkan rekomendasi pola makan dengan menggunakan metode Naive Bayes agar mampu memberikan pola makan sesuai dengan status gizi yang dibutuhkan oleh seorang penderita tuberkulosis. Dengan menggunakan metode Fuzzy Sugeno untuk  menentukan diagnosis penyakit menghasilkan tingkat akurasi yaitu sebesar 85.35 % dan metode Naive Bayes untuk  menentukan rekomendasi pola makan menghasilkan tingkat akurasi tertinggi yaitu sebesar 89.28 % pada fold 3 dan  dengan perhitungan rata-rata nilai akurasi dari semua fold sebesar 78.57 %.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100025&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100025&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100025&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100025&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100025&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100025&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100025&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100025&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100025&gt;
{&#39;Abstrak&#39;: &#39;Demam berdarah merupakan penyakit berbahaya yang menimbulkan syok yang berujung kematian dalam waktu singkat bila tidak mendapat penanganan dengan cepat. Dalam hal ini, untuk mendiagnosa dibutuhkan analisa yang akurat untuk meminimalisir terhadap kesalahan diagnosa yang membuat lambatnya penanganan terhadap pasien. Dengan demikian dibuatkan suatu sistem pakar deteksi dini penyakit demam berdarah dengue(DBD) metode iterative dichotomiser three( id3) yang dapat membantu calon dokter muda untuk mendiagnosa secara dini penyakit demam berdarah dengue(DBD). Sistem pakar tersebut terdapat pilihan gejala penyakit demam berdarah dengue(DBD) yang bisa dipilih oleh pengguna sesuai dengan yang dirasakan penderita. Setelah itu dari gejala-gejala yang telah dipilih akan dilakukan proses perhitungan menggunakan metode iterative dichotomiser three( id3). Dari proses perhitungan tersebut akan mendapatkan hasil diagnosa berdasarkan tingkat keparahan dari gejala yang telah dipilih. Berdasarkan Hasil Penelitian yang dilakukan dalam pembuatan aplikasi ini, dengan hasil kuisioner yang telah disebar terhadap 20 calon dokter muda diperoleh rata-rata sebanyak 78% yang artinya sistem ini efektif untuk membantu calon dokter muda dalam mendiagnosa penyakit  demam berdarah dengue (dbd) secara dini.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100025&gt;
{&#39;Abstrak&#39;: &#39;Demam berdarah merupakan penyakit berbahaya yang menimbulkan syok yang berujung kematian dalam waktu singkat bila tidak mendapat penanganan dengan cepat. Dalam hal ini, untuk mendiagnosa dibutuhkan analisa yang akurat untuk meminimalisir terhadap kesalahan diagnosa yang membuat lambatnya penanganan terhadap pasien. Dengan demikian dibuatkan suatu sistem pakar deteksi dini penyakit demam berdarah dengue(DBD) metode iterative dichotomiser three( id3) yang dapat membantu calon dokter muda untuk mendiagnosa secara dini penyakit demam berdarah dengue(DBD). Sistem pakar tersebut terdapat pilihan gejala penyakit demam berdarah dengue(DBD) yang bisa dipilih oleh pengguna sesuai dengan yang dirasakan penderita. Setelah itu dari gejala-gejala yang telah dipilih akan dilakukan proses perhitungan menggunakan metode iterative dichotomiser three( id3). Dari proses perhitungan tersebut akan mendapatkan hasil diagnosa berdasarkan tingkat keparahan dari gejala yang telah dipilih. Berdasarkan Hasil Penelitian yang dilakukan dalam pembuatan aplikasi ini, dengan hasil kuisioner yang telah disebar terhadap 20 calon dokter muda diperoleh rata-rata sebanyak 78% yang artinya sistem ini efektif untuk membantu calon dokter muda dalam mendiagnosa penyakit  demam berdarah dengue (dbd) secara dini.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100025&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100025&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100026&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100026&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100025&gt;
{&#39;Abstrak&#39;: &#39;Ekspresi wajah merupakan suatu hal yang penting dalam proses komunikasi antar manusia. Pada pengenalan ekspresi wajah manusia, terdapat dua hal yang harus dilakukan, yaitu pengekstraksian ciri dari suatu citra inputan dan pengklasifikasian citra tersebut ke dalam kelas ekspresi tertentu. Cara yang tepat untuk mendapatkan kombinasi ekstrasi fitur dan klasifikasi citra merupakan hal yang penting dalam pengenalan ekspresi wajah. Oleh karena itu, Principal Component Analysis (PCA) digunakan sebagai teknik ekstraksi fitur untuk pengenalan ekspresi wajah manusia. PCA memilih fitur yang bisa merepresentasikan ekspresi pada citra wajah manusia secara tepat . Untuk klasifikasi, dipilih metode jaringan syaraf tiruan Learning Vector Quantization (LVQ), dan algoritma diuji pada database JAFFE (Japanese Female Facial Expressions). Dari penelitian ini menunjukkan tingkat performa (akurasi) rata-rata yang dihasilkan dari penggunaan PCA (Principal Component Analysis) untuk ekstraksi fitur dan Jaringan Syaraf Tiruan LVQ (Learning Vector Quantization) dalam pengenalan ekspresi wajah adalah sebesar 48%, dengan akurasi tertinggi yang dicapai adalah 60% untuk penggunaan 20 fitur PCA.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100025&gt;
{&#39;Abstrak&#39;: &#39;Ekspresi wajah merupakan suatu hal yang penting dalam proses komunikasi antar manusia. Pada pengenalan ekspresi wajah manusia, terdapat dua hal yang harus dilakukan, yaitu pengekstraksian ciri dari suatu citra inputan dan pengklasifikasian citra tersebut ke dalam kelas ekspresi tertentu. Cara yang tepat untuk mendapatkan kombinasi ekstrasi fitur dan klasifikasi citra merupakan hal yang penting dalam pengenalan ekspresi wajah. Oleh karena itu, Principal Component Analysis (PCA) digunakan sebagai teknik ekstraksi fitur untuk pengenalan ekspresi wajah manusia. PCA memilih fitur yang bisa merepresentasikan ekspresi pada citra wajah manusia secara tepat . Untuk klasifikasi, dipilih metode jaringan syaraf tiruan Learning Vector Quantization (LVQ), dan algoritma diuji pada database JAFFE (Japanese Female Facial Expressions). Dari penelitian ini menunjukkan tingkat performa (akurasi) rata-rata yang dihasilkan dari penggunaan PCA (Principal Component Analysis) untuk ekstraksi fitur dan Jaringan Syaraf Tiruan LVQ (Learning Vector Quantization) dalam pengenalan ekspresi wajah adalah sebesar 48%, dengan akurasi tertinggi yang dicapai adalah 60% untuk penggunaan 20 fitur PCA.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100026&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100026&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100026&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100026&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100026&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100026&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100026&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100026&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100026&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100026&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100026&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100026&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100027&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100027&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100026&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100026&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100027&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:30 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100027&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100027&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100027&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100027&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100027&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100027&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100027&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100027&gt;
{&#39;Abstrak&#39;: &#39;Perusahaan harus mampu menyeimbangan produksi gula sesuai dengan permintaan pasar. Karena, jika produksi gula melebihi permintaan pasar akan menyebabkan penumpukkan dan biaya pengeluaran yang melebihi batas. Namun, jika produksi gula terlalu sedikit perusahaan tidak mampu memenuhi permintaan pasar sehingga dapat mengurangi kesempatan perusahaan untuk mendapatkan keuntungan. Untuk itu diperlukan sebuah sistem yang nantinya dapat mempermudah proses peramalan produksi gula. Sistem yang dibangun menggunakan perbandingan 2 metode, yaitu metode Single Exponential Smoothing dan metode Backpropagation. Tujuan dari penelitian ini untuk mengetahui hasil akurasi terbaik menggunakan metode Single Exponential Smoothing dan metode Backpropagation pada peramalan produksi gula. Metode Single  Exponential Smoothing dan Backpropagation digunakan untuk meramalkan jumlah produksi gula untuk satu bulan kedepan berdasarkan data produksi 5 bulan sebelumnya. Dari hasil pengujian yang telah dilakukan, dapat diketahui bahwa metode Backpropagation menghasilkan MSE dan MAPE terkecil, yaitu sebesar 57187817,49 dan MAPE sebesar 1,019593892% dibandingkan metode Single Exponential Smoothing dengan MSE sebesar 83602989,43 dan MAPE  sebesar 1,46412926%. Sehingga metode yang peling tepat untuk peramalan produksi gula yaitu metode Backpropagation.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100027&gt;
{&#39;Abstrak&#39;: &#39;Perusahaan harus mampu menyeimbangan produksi gula sesuai dengan permintaan pasar. Karena, jika produksi gula melebihi permintaan pasar akan menyebabkan penumpukkan dan biaya pengeluaran yang melebihi batas. Namun, jika produksi gula terlalu sedikit perusahaan tidak mampu memenuhi permintaan pasar sehingga dapat mengurangi kesempatan perusahaan untuk mendapatkan keuntungan. Untuk itu diperlukan sebuah sistem yang nantinya dapat mempermudah proses peramalan produksi gula. Sistem yang dibangun menggunakan perbandingan 2 metode, yaitu metode Single Exponential Smoothing dan metode Backpropagation. Tujuan dari penelitian ini untuk mengetahui hasil akurasi terbaik menggunakan metode Single Exponential Smoothing dan metode Backpropagation pada peramalan produksi gula. Metode Single  Exponential Smoothing dan Backpropagation digunakan untuk meramalkan jumlah produksi gula untuk satu bulan kedepan berdasarkan data produksi 5 bulan sebelumnya. Dari hasil pengujian yang telah dilakukan, dapat diketahui bahwa metode Backpropagation menghasilkan MSE dan MAPE terkecil, yaitu sebesar 57187817,49 dan MAPE sebesar 1,019593892% dibandingkan metode Single Exponential Smoothing dengan MSE sebesar 83602989,43 dan MAPE  sebesar 1,46412926%. Sehingga metode yang peling tepat untuk peramalan produksi gula yaitu metode Backpropagation.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100027&gt;
{&#39;Abstrak&#39;: &#39;Proses pencarian dokumen yang sangat banyak, tentunya memerlukan sebuah teknik khusus dalam mengambil / mencari dokumen yang relevan dengan permintaan pengguna. Pada proses pencarian dokumen dapat dilakukan dengan menggunakan sebuah query. Query adalah sebuah kata kunci yang digunakan untuk menampilkan data dari database kemudian akan diolah lebih lanjut. Data tersebut diambil dari tabel-tabel dalam database yang memudahkan pengguna dalam mengolah banyak data. Permasalahan dari penggunaan query secara umum adalah dari sudut pandang pengguna atau user. Pengguna memiliki karakter yang berbeda- beda. Query yang terlalu singkat dapat diselesaikan dengan cara Query Expansion. Query Expasion adalah proses merancang kembali query awal untuk meningkatkan kinerja sistem dalam proses pengambilan informasi. Dalam penelitian ini query expansion akan menggunakan metode pseudo relevance feedback dengan dataset Wikipedia bahasa Indonesia. Untuk melakukan perhitungan persamaan dokumen, digunakanlah metode cosine similarity dan pembobotan menggunakan TF-IDF. Bahasa Indonesia memiliki banyak sekali kata-kata yang ambigu, sehingga wikipedia bahasa Indonesia perlu digunakan sebagai acuan agar kata-kata yang ambigu atau kata yang mengandung istilah dapat memiliki suatu makna tertentu. Dalam penelitian ini, memiliki hasil rata-rata presisi dalam penelitian menggunakan\n100 artikel pariwisata Madura tanpa query expansion adalah 75,5%, sedangkan dengan query expansion hanya 36,67%. Jika menggunakan 75  artikel pariwisata Madura tanpa query expansion adalah 70,5%, sedangkan dengan query expansion hanya 31,67%. Hal ini terjadi karena hasil dari query expansion tidak berpusat pada pariwisata di Madura. Sebab abstrak wikipedia bahasa Indonesia yang digunakan tidak berfokus pada pariwisata di Madura, melainkan abstrak artikel wikipedia bahasa Indonesia secara umum\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100027&gt;
{&#39;Abstrak&#39;: &#39;Proses pencarian dokumen yang sangat banyak, tentunya memerlukan sebuah teknik khusus dalam mengambil / mencari dokumen yang relevan dengan permintaan pengguna. Pada proses pencarian dokumen dapat dilakukan dengan menggunakan sebuah query. Query adalah sebuah kata kunci yang digunakan untuk menampilkan data dari database kemudian akan diolah lebih lanjut. Data tersebut diambil dari tabel-tabel dalam database yang memudahkan pengguna dalam mengolah banyak data. Permasalahan dari penggunaan query secara umum adalah dari sudut pandang pengguna atau user. Pengguna memiliki karakter yang berbeda- beda. Query yang terlalu singkat dapat diselesaikan dengan cara Query Expansion. Query Expasion adalah proses merancang kembali query awal untuk meningkatkan kinerja sistem dalam proses pengambilan informasi. Dalam penelitian ini query expansion akan menggunakan metode pseudo relevance feedback dengan dataset Wikipedia bahasa Indonesia. Untuk melakukan perhitungan persamaan dokumen, digunakanlah metode cosine similarity dan pembobotan menggunakan TF-IDF. Bahasa Indonesia memiliki banyak sekali kata-kata yang ambigu, sehingga wikipedia bahasa Indonesia perlu digunakan sebagai acuan agar kata-kata yang ambigu atau kata yang mengandung istilah dapat memiliki suatu makna tertentu. Dalam penelitian ini, memiliki hasil rata-rata presisi dalam penelitian menggunakan\n100 artikel pariwisata Madura tanpa query expansion adalah 75,5%, sedangkan dengan query expansion hanya 36,67%. Jika menggunakan 75  artikel pariwisata Madura tanpa query expansion adalah 70,5%, sedangkan dengan query expansion hanya 31,67%. Hal ini terjadi karena hasil dari query expansion tidak berpusat pada pariwisata di Madura. Sebab abstrak wikipedia bahasa Indonesia yang digunakan tidak berfokus pada pariwisata di Madura, melainkan abstrak artikel wikipedia bahasa Indonesia secara umum\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100028&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100028&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100027&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100027&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100028&gt;
{&#39;Abstrak&#39;: &#39;-&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100028&gt;
{&#39;Abstrak&#39;: &#39;-&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100028&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100028&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100028&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100028&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100028&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100028&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100029&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100029&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100028&gt;
{&#39;Abstrak&#39;: &#39;Penyakit gigi dan mulut merupakan salah satu masalah kesehatan yang banyak diderita oleh masyarakat Indonesia. Minimnya pengetahuan serta terbatasnya sumber informasi mengenai kesehatan gigi dan mulut menyebabkan kesadaran masyarakat untuk menjaga kesehatan gigi dan mulut masih rendah. Untuk itulah dibutuhkannya sistem indentifikasi penyakit gigi dan mulut dengan mempertimbangkan faktor-faktor tersebut perlu dilakukan. Tujuan dari laporan ini adalah untuk memperoleh sistem identifikasi penyakit gigi dan mulut, dengan menggunakan metode fuzzy c – means.  Pada tahap uji coba penulis membagi data menjadi training dan testing menggunkan k-fold validation. Dari hasil perhitungan akurasi yang menggunakan k-fold cross validation dengan nilai k=5, jumlah iterasi 10, target error 0,0001 serta error awal (P0) 0, pembagian data latih dan data uji menggunakan 5 fold menghasilkan rata-rata akurasi 83.666%&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100028&gt;
{&#39;Abstrak&#39;: &#39;Penyakit gigi dan mulut merupakan salah satu masalah kesehatan yang banyak diderita oleh masyarakat Indonesia. Minimnya pengetahuan serta terbatasnya sumber informasi mengenai kesehatan gigi dan mulut menyebabkan kesadaran masyarakat untuk menjaga kesehatan gigi dan mulut masih rendah. Untuk itulah dibutuhkannya sistem indentifikasi penyakit gigi dan mulut dengan mempertimbangkan faktor-faktor tersebut perlu dilakukan. Tujuan dari laporan ini adalah untuk memperoleh sistem identifikasi penyakit gigi dan mulut, dengan menggunakan metode fuzzy c – means.  Pada tahap uji coba penulis membagi data menjadi training dan testing menggunkan k-fold validation. Dari hasil perhitungan akurasi yang menggunakan k-fold cross validation dengan nilai k=5, jumlah iterasi 10, target error 0,0001 serta error awal (P0) 0, pembagian data latih dan data uji menggunakan 5 fold menghasilkan rata-rata akurasi 83.666%&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100028&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100028&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100028&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100028&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100029&gt;
{&#39;Abstrak&#39;: &#39;Deteksi outlier merupakan salah satu penelitian yang penting dengan tujuan mencari data yang memiliki karakteristik yang berbeda dengan kebanyakan data lainya. Data outlier yang ada di  dataset akan mempengaruhi terhadap hasil dari proses selanjutnya seperti clustering dan klasifikasi dan terkadang outlier juga menyimpan informasi yang penting. Penelitian ini dimulai dengan pemotongan daerah penting pada citra yang dilakukan secara manual. Setelah mendapatkan citra dari proses sebelumnya, kemudian dilakukan ektraksi fitur warna dengan perhitungan statistik orde pertama yaitu mean, standard deviation, kurtosis dan skewness dan ektraksi fitur tekstur menggunakan algoritma Grey Level Co-Occurrence Matrix (GLCM) dengan jarak 1 dan sudut 0o dengan fitur yang  digunakan yaitu Angular Second Moment, Contras, Inverse Different Moment, Cluster Shade, dan Cluster Prominence. Setelah didapatkan fitur-fitur setiap citra kemudian dilakukan clustering dengan menggunakan Algoritma Clustering Large Applications Based on Randomized Search (CLARANS). Setelah proses clustering kemudian dilakukan deteksi outlier dengan menggunakan Algoritma unweighted-CBLOF. Dataset yang digunakan pada penelitian  ini adalah dataset Supermarket Produce dengan jumlah 2633 citra sebagai data normal dan data outlier sebanyak 50 diambil dari dataset Fruit Images. Hasil dari penelitian ini didapatkan fitur yang terbaik untuk deteksi outlier yaitu menggunakan fitur tekstur Grey Level Co-Occurrence Matrix (GLCM) dengan nilai akurasi sebesar 85,612 % dan penentuan jumlah kelas pada  Clustering Large Applications Based on Randomized Search (CLARANS) yang semakin meningkat belum tentu meningkatkan nilai akurasi, sehingga perlu dilakukan uji coba dengan beberapa jumlah kelas untuk mencari nilai akurasi yang paling tinggi.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100029&gt;
{&#39;Abstrak&#39;: &#39;Deteksi outlier merupakan salah satu penelitian yang penting dengan tujuan mencari data yang memiliki karakteristik yang berbeda dengan kebanyakan data lainya. Data outlier yang ada di  dataset akan mempengaruhi terhadap hasil dari proses selanjutnya seperti clustering dan klasifikasi dan terkadang outlier juga menyimpan informasi yang penting. Penelitian ini dimulai dengan pemotongan daerah penting pada citra yang dilakukan secara manual. Setelah mendapatkan citra dari proses sebelumnya, kemudian dilakukan ektraksi fitur warna dengan perhitungan statistik orde pertama yaitu mean, standard deviation, kurtosis dan skewness dan ektraksi fitur tekstur menggunakan algoritma Grey Level Co-Occurrence Matrix (GLCM) dengan jarak 1 dan sudut 0o dengan fitur yang  digunakan yaitu Angular Second Moment, Contras, Inverse Different Moment, Cluster Shade, dan Cluster Prominence. Setelah didapatkan fitur-fitur setiap citra kemudian dilakukan clustering dengan menggunakan Algoritma Clustering Large Applications Based on Randomized Search (CLARANS). Setelah proses clustering kemudian dilakukan deteksi outlier dengan menggunakan Algoritma unweighted-CBLOF. Dataset yang digunakan pada penelitian  ini adalah dataset Supermarket Produce dengan jumlah 2633 citra sebagai data normal dan data outlier sebanyak 50 diambil dari dataset Fruit Images. Hasil dari penelitian ini didapatkan fitur yang terbaik untuk deteksi outlier yaitu menggunakan fitur tekstur Grey Level Co-Occurrence Matrix (GLCM) dengan nilai akurasi sebesar 85,612 % dan penentuan jumlah kelas pada  Clustering Large Applications Based on Randomized Search (CLARANS) yang semakin meningkat belum tentu meningkatkan nilai akurasi, sehingga perlu dilakukan uji coba dengan beberapa jumlah kelas untuk mencari nilai akurasi yang paling tinggi.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100029&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100029&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100029&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:31 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100029&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100030&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100030&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100029&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100029&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100029&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100029&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100029&gt;
{&#39;Abstrak&#39;: &#39;Information retrieval merupakan kegiatan memperoleh data informasi yang relevan, pencarian informasi dapat didasarkan pada teks lengkap atau pengindeksan berbasis konten lainya. Information retrieval terdiri dari tiga komponen utama, yaitu masukan (input), pemroses (processor), dan keluaran (output). Plagiarisme merupakan pelanggaran utama  akademik, namun sebagian dari institusi perguruan tinggi yang telah berkembang dengan baik sudah menerapkan kebijakan dan prosedur untuk menangani masalah tersebut. Selain itu, plagiarisme juga digambarkan sebagai tindakan pencurian karya orang lain dan membuat pekerjaan tersebut adalah pekerjaan sendiri. Pendeteksian plagiarisme di Indonesia hanya menggunakan cara sederhana pra-pemrosesan teks seperti menghilangkan spasi, dan karakter yang tidak dibutuhkan. Metode semacam ini hanya bisa mendeteksi plagiarisme dengan cara sederhana tetapi tidak dapat mendeteksi bentuk yang lebih kompleks. Metode Enhanced Confix Stripping merupakan pengembangan algoritma terdahulunya dengan beberapa perbaikan kesalahan pada metode sebelumnya dan metode Rabin-Karp sebagai tahap membandingkan nilai hash antara string masukan dan substring dalam teks. Berdasarkan hasil pengujian sistem menggunakan metode Rabin-Karp dikombinasikan dengan Enhanced Confix Stripping Stemmer dengan akurasi rata-rata 24.71% dan tanpa menggunakan Stemming dengan akurasi rata-rata 26.28%. \n\nKata Kunci: Information retrieval, kemiripan dokumen, Enhanced Confix Stripping, Rabin-Karp, Stemming\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100029&gt;
{&#39;Abstrak&#39;: &#39;Information retrieval merupakan kegiatan memperoleh data informasi yang relevan, pencarian informasi dapat didasarkan pada teks lengkap atau pengindeksan berbasis konten lainya. Information retrieval terdiri dari tiga komponen utama, yaitu masukan (input), pemroses (processor), dan keluaran (output). Plagiarisme merupakan pelanggaran utama  akademik, namun sebagian dari institusi perguruan tinggi yang telah berkembang dengan baik sudah menerapkan kebijakan dan prosedur untuk menangani masalah tersebut. Selain itu, plagiarisme juga digambarkan sebagai tindakan pencurian karya orang lain dan membuat pekerjaan tersebut adalah pekerjaan sendiri. Pendeteksian plagiarisme di Indonesia hanya menggunakan cara sederhana pra-pemrosesan teks seperti menghilangkan spasi, dan karakter yang tidak dibutuhkan. Metode semacam ini hanya bisa mendeteksi plagiarisme dengan cara sederhana tetapi tidak dapat mendeteksi bentuk yang lebih kompleks. Metode Enhanced Confix Stripping merupakan pengembangan algoritma terdahulunya dengan beberapa perbaikan kesalahan pada metode sebelumnya dan metode Rabin-Karp sebagai tahap membandingkan nilai hash antara string masukan dan substring dalam teks. Berdasarkan hasil pengujian sistem menggunakan metode Rabin-Karp dikombinasikan dengan Enhanced Confix Stripping Stemmer dengan akurasi rata-rata 24.71% dan tanpa menggunakan Stemming dengan akurasi rata-rata 26.28%. \n\nKata Kunci: Information retrieval, kemiripan dokumen, Enhanced Confix Stripping, Rabin-Karp, Stemming\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100030&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100030&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100029&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100029&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100030&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100030&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100030&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100030&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100030&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100030&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100030&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100030&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100031&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100031&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100030&gt;
{&#39;Abstrak&#39;: &#39;Otak merupakan salah satu organ penting yang ada pada tubuh manusia sebagai sistem saraf pusat. Salah satu penyakit yang dapat menyerang pada otak adalah Tumor otak. Tumor otak merupakan salah satu penyakit mematikan yang menyerang bagian glioma dan berasal dari sel-sel glial dalam  otak. Untuk dapat mengidentifikasi penyakit tersebut pasien diharuskan melakukan pemeriksaan secara rutin menggunakan CT (Computed Tomography) Scan. Citra MRI yang diapatkan dalam bentuk 3 Dimensi tersebut akan diperiksa oleh dokter secara manual yang bersifat subjektif dan selanjutnya dilakukan evaluasi oleh dokter. Perhitungan secara manual tersebut dapat menyebabkan resiko kesalahan manusia menjadi lebih besar, dan membutuhkan waktu yang lama. Pada citra MRI juga memiliki permasalahan yaitu, rentang intensitas pada citra MRI yang berbeda menyebabkan dibutuhkannya pembelajaran fitur perlu yang detail  untuk dapat mengidentifikasi tumor otak. Oleh karena itu, dibutuhkannya perhitungan semi otomatis atau otomatis untuk dapat melakukan segmentasi tumor otak tersebut dengan menggunakan CNN (Convolutional Neural Network) dengan menggunakan ukuran kernel konvolusi layer yang kecil untuk mendapatkan model informasi fitur secara detail. Dalam mengolah citra MRI diperlukan tahapan pre-processing dengan menggunakan normalisasi intensitas, dan patch extraction. Citra yang telah dilakukan pre-processing akan diproses oleh metode CNN. Pada penelitian ini, dilakukan beberapa skenario percobaan untuk mengetahui jumlah kernel pada lapisan konvolusi terhadap kinerja CNN. Hasil dari uji coba yang dilakukan, tiga model CNN dengan jumlah kernel pada lapisan konvolusi tiga, lima, dan tujuh memperoleh f1 score secara berturut-turut sebesar 0.87, 0.88, dan 0.84.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100030&gt;
{&#39;Abstrak&#39;: &#39;Otak merupakan salah satu organ penting yang ada pada tubuh manusia sebagai sistem saraf pusat. Salah satu penyakit yang dapat menyerang pada otak adalah Tumor otak. Tumor otak merupakan salah satu penyakit mematikan yang menyerang bagian glioma dan berasal dari sel-sel glial dalam  otak. Untuk dapat mengidentifikasi penyakit tersebut pasien diharuskan melakukan pemeriksaan secara rutin menggunakan CT (Computed Tomography) Scan. Citra MRI yang diapatkan dalam bentuk 3 Dimensi tersebut akan diperiksa oleh dokter secara manual yang bersifat subjektif dan selanjutnya dilakukan evaluasi oleh dokter. Perhitungan secara manual tersebut dapat menyebabkan resiko kesalahan manusia menjadi lebih besar, dan membutuhkan waktu yang lama. Pada citra MRI juga memiliki permasalahan yaitu, rentang intensitas pada citra MRI yang berbeda menyebabkan dibutuhkannya pembelajaran fitur perlu yang detail  untuk dapat mengidentifikasi tumor otak. Oleh karena itu, dibutuhkannya perhitungan semi otomatis atau otomatis untuk dapat melakukan segmentasi tumor otak tersebut dengan menggunakan CNN (Convolutional Neural Network) dengan menggunakan ukuran kernel konvolusi layer yang kecil untuk mendapatkan model informasi fitur secara detail. Dalam mengolah citra MRI diperlukan tahapan pre-processing dengan menggunakan normalisasi intensitas, dan patch extraction. Citra yang telah dilakukan pre-processing akan diproses oleh metode CNN. Pada penelitian ini, dilakukan beberapa skenario percobaan untuk mengetahui jumlah kernel pada lapisan konvolusi terhadap kinerja CNN. Hasil dari uji coba yang dilakukan, tiga model CNN dengan jumlah kernel pada lapisan konvolusi tiga, lima, dan tujuh memperoleh f1 score secara berturut-turut sebesar 0.87, 0.88, dan 0.84.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100030&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100030&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100031&gt;
{&#39;Abstrak&#39;: &#39;Epilepsi atau ayan adalah sebuah penyakit neurologi yaitu penyakit yang menyerang saraf otak. Penyakit ini menyebkan neuron pada otak mengeluarkan listrik yang berlebihan sehingga mengganggu saraf motorik. Dengan memanfaatkan data dari Elektroensefalogram (EEG) yang merupakan teknik untuk mengukur aktivitas kelistrikan pada otak dengan memasang elektoda disekitar kulit kepala, maka dapat membantu dalam mendiagnosa penderita epilepsi.\nPenelitian ini bertujuan untuk mengklasifikasi hasil dari proses perekaman sinyal EEG untuk mendeteksi epilepsi. metode yang digunakan adalah time and frequency domain untuk proses ekstraksi fitur, Particle Swarm Optimization untuk ekstraksi fitur dan mahalonubis untuk klasifikasi. Data yang digunakan didapat dari Bern-Barcelona EEG database dengan jumlah keseluruhan data 3750 percobaan untuk 5 individu. Hasil dari penelitian ini didapatkan akurasi sebesar 78.67% dengan menggunakan 60% data sebagai data pelatihan dan menggunakan metode PSO untuk seleksi fitur.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100031&gt;
{&#39;Abstrak&#39;: &#39;Epilepsi atau ayan adalah sebuah penyakit neurologi yaitu penyakit yang menyerang saraf otak. Penyakit ini menyebkan neuron pada otak mengeluarkan listrik yang berlebihan sehingga mengganggu saraf motorik. Dengan memanfaatkan data dari Elektroensefalogram (EEG) yang merupakan teknik untuk mengukur aktivitas kelistrikan pada otak dengan memasang elektoda disekitar kulit kepala, maka dapat membantu dalam mendiagnosa penderita epilepsi.\nPenelitian ini bertujuan untuk mengklasifikasi hasil dari proses perekaman sinyal EEG untuk mendeteksi epilepsi. metode yang digunakan adalah time and frequency domain untuk proses ekstraksi fitur, Particle Swarm Optimization untuk ekstraksi fitur dan mahalonubis untuk klasifikasi. Data yang digunakan didapat dari Bern-Barcelona EEG database dengan jumlah keseluruhan data 3750 percobaan untuk 5 individu. Hasil dari penelitian ini didapatkan akurasi sebesar 78.67% dengan menggunakan 60% data sebagai data pelatihan dan menggunakan metode PSO untuk seleksi fitur.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100031&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100031&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100031&gt;
{&#39;Abstrak&#39;: &#39;Saat ini perkiraan persediaan air kurang optimal, dimana kadang jumlah air yang diproduksi lebih besar atau lebih kecil dari permintaan. Hal ini tentunya akan menyebabkan terjadinya pemborosan air oleh PDAM Bangkalan ataupun kekurangan air yang dialami oleh konsumen. Kedua permasalahan ini tidak lepas dari kondisi yang ada yaitu terjadinya kehilangan air dan tambahan kompensasi. Untuk itulah dibutuhkannya sistem peramalan ketersediaan air dengan mempertimbangkan faktor-faktor tersebut perlu dilakukan. Tujuan dari laporan ini adalah untuk memperoleh sistem peramalan yang akurat yang dapat membantu produksi air di masa depan agar tidak terjadi pemborosan dan kekurangan air. Metode penelitian yang digunakan untuk peramalan adalah metode Jaringan Syaraf Tiruan Backpropagation. Pada tahap uji coba dilakukan pengujian untuk mendapatkan jumlah iterasi, learning rate, data latih dan data uji, dan maksimal error yang optimal. Berdasarkan hasil penelitian ini didapatkan bahwa Peramalan Produksi Air PDAM Bangkalan dengan metode Backpropagation menghasilkan akurasi yang cukup tinggi dengan menggunakan variabel jumlah pelanggan, volume distribusi air, volume air terjual, volume kehilangan air dan volume produksi air. Akurasi tertinggi yang diperoleh adalah 98% dengan parameter terbaik adalah learning rate (alpha) 0,9 , jumlah iterasi 10000, max error 0,0001 dan pembagian data latih dan data uji menggunakan 5 Fold Cross Validation menghasilkan rata-rata akurasi 83%.\nKata kunci : Produksi Air, Peramalan,  Jaringan Syaraf Tiruan (JST), Backpropagation.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100031&gt;
{&#39;Abstrak&#39;: &#39;Saat ini perkiraan persediaan air kurang optimal, dimana kadang jumlah air yang diproduksi lebih besar atau lebih kecil dari permintaan. Hal ini tentunya akan menyebabkan terjadinya pemborosan air oleh PDAM Bangkalan ataupun kekurangan air yang dialami oleh konsumen. Kedua permasalahan ini tidak lepas dari kondisi yang ada yaitu terjadinya kehilangan air dan tambahan kompensasi. Untuk itulah dibutuhkannya sistem peramalan ketersediaan air dengan mempertimbangkan faktor-faktor tersebut perlu dilakukan. Tujuan dari laporan ini adalah untuk memperoleh sistem peramalan yang akurat yang dapat membantu produksi air di masa depan agar tidak terjadi pemborosan dan kekurangan air. Metode penelitian yang digunakan untuk peramalan adalah metode Jaringan Syaraf Tiruan Backpropagation. Pada tahap uji coba dilakukan pengujian untuk mendapatkan jumlah iterasi, learning rate, data latih dan data uji, dan maksimal error yang optimal. Berdasarkan hasil penelitian ini didapatkan bahwa Peramalan Produksi Air PDAM Bangkalan dengan metode Backpropagation menghasilkan akurasi yang cukup tinggi dengan menggunakan variabel jumlah pelanggan, volume distribusi air, volume air terjual, volume kehilangan air dan volume produksi air. Akurasi tertinggi yang diperoleh adalah 98% dengan parameter terbaik adalah learning rate (alpha) 0,9 , jumlah iterasi 10000, max error 0,0001 dan pembagian data latih dan data uji menggunakan 5 Fold Cross Validation menghasilkan rata-rata akurasi 83%.\nKata kunci : Produksi Air, Peramalan,  Jaringan Syaraf Tiruan (JST), Backpropagation.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100031&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100031&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100031&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100031&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100032&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100032&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100031&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100031&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100031&gt;
{&#39;Abstrak&#39;: &#39;Di zaman yang semakin modern ini, peranan teknologi informasi sangat dibutuhkan untuk menunjang kegiatan sehari-hari. Dalam dunia kesehatan pun telah menggunakan suatu sistem dengan kemampuan yang dapat menirukan keahlian seorang pakar dalam hal ini adalah dokter. Seringkali dokter memiliki kekurangan dalam hal efisiensi waktu sedangkan diagnosis yang cepat dan tepat dibutuhkan oleh pasien agar dapat segera dilakukan penanganan sesuai dengan penyakit yang diderita. Sistem pakar diagnosis penyakit asma dibentuk untuk meringankan tugas dari seorang dokter serta untuk mengefisienkan waktu pasien dalam pemeriksaan. Dalam penelitian diagnosis penyakit asma ini menggunakan metode forward chainingberbasis web. Metode forward chaining dijalankan dengan mengumpulkan fakta-fakta yang ada untuk menarik kesimpulan. Dengan kata lain, prosesnya dimulai dari facts (fakta-fakta yang ada) melalui proses interface fact (penalaran fakta-fakta) menuju suatu goal (suatu tujuan). Metode ini juga disebut menggunakan aturan IF–THEN dimana premis (IF) menuju konklusi (THEN). Hasil dari penelitian ini memiliki tingkat akurasi sebesar 100%&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100031&gt;
{&#39;Abstrak&#39;: &#39;Di zaman yang semakin modern ini, peranan teknologi informasi sangat dibutuhkan untuk menunjang kegiatan sehari-hari. Dalam dunia kesehatan pun telah menggunakan suatu sistem dengan kemampuan yang dapat menirukan keahlian seorang pakar dalam hal ini adalah dokter. Seringkali dokter memiliki kekurangan dalam hal efisiensi waktu sedangkan diagnosis yang cepat dan tepat dibutuhkan oleh pasien agar dapat segera dilakukan penanganan sesuai dengan penyakit yang diderita. Sistem pakar diagnosis penyakit asma dibentuk untuk meringankan tugas dari seorang dokter serta untuk mengefisienkan waktu pasien dalam pemeriksaan. Dalam penelitian diagnosis penyakit asma ini menggunakan metode forward chainingberbasis web. Metode forward chaining dijalankan dengan mengumpulkan fakta-fakta yang ada untuk menarik kesimpulan. Dengan kata lain, prosesnya dimulai dari facts (fakta-fakta yang ada) melalui proses interface fact (penalaran fakta-fakta) menuju suatu goal (suatu tujuan). Metode ini juga disebut menggunakan aturan IF–THEN dimana premis (IF) menuju konklusi (THEN). Hasil dari penelitian ini memiliki tingkat akurasi sebesar 100%&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100032&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:32 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100032&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100032&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100032&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100032&gt;
{&#39;Abstrak&#39;: &#39;Penyakit pada gigi dan mulut merupakan suatu masalah kesehatan yang sering dialami oleh masyarakat Indonesia dari yang tua maupun muda. Minimnya pengetahuan serta terbatasnya sumber informasi mengenai penyakit gigi dan mulut masih rendah. Hal ini diperoleh dari besarnya angka penyakit gigi dan mulut di Nusantara ini yang semakin meningkat. Untuk mengobati sakit gigi tentu tidak bisa di obati dengan sembarangan, harus dengan yang ahli yaitu Dokter Gigi. Seiring terjadinya masalah pada gigi, ini akan berdampak juga kepada para dokter gigi, dikarenakan masalah ini bisa menyebabkan meningkatnya jumlah pasien, berangkat dari hal masalah ini,maka penulis membuat sesuatu Sistem Pendukung Keputusan Gejala Penyakit Gigi dan Mulut untuk mendapatkan hasil diagnosa awal penyakit gigi dan mulut berbasis website. Sistem pendukung keputusan ini bertujuan bukan untuk menggantikan profesi dari Dokter Gigi ini sendiri, dikarenakan hasil dari sistem pendukung keputusan ini  hanya sebagai  rekomendasi, Pada penelitian ini mengimplementasikan metode Simple Additive Weighting  dengan menggunakan 40 data yang didapatkan dari Pos Kesehatan yang bertempat di Bangkalan, dan sistem ini  menghasilkan nilai akurasi kecocokan rata-rata sebesar 77,5% . &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100032&gt;
{&#39;Abstrak&#39;: &#39;Penyakit pada gigi dan mulut merupakan suatu masalah kesehatan yang sering dialami oleh masyarakat Indonesia dari yang tua maupun muda. Minimnya pengetahuan serta terbatasnya sumber informasi mengenai penyakit gigi dan mulut masih rendah. Hal ini diperoleh dari besarnya angka penyakit gigi dan mulut di Nusantara ini yang semakin meningkat. Untuk mengobati sakit gigi tentu tidak bisa di obati dengan sembarangan, harus dengan yang ahli yaitu Dokter Gigi. Seiring terjadinya masalah pada gigi, ini akan berdampak juga kepada para dokter gigi, dikarenakan masalah ini bisa menyebabkan meningkatnya jumlah pasien, berangkat dari hal masalah ini,maka penulis membuat sesuatu Sistem Pendukung Keputusan Gejala Penyakit Gigi dan Mulut untuk mendapatkan hasil diagnosa awal penyakit gigi dan mulut berbasis website. Sistem pendukung keputusan ini bertujuan bukan untuk menggantikan profesi dari Dokter Gigi ini sendiri, dikarenakan hasil dari sistem pendukung keputusan ini  hanya sebagai  rekomendasi, Pada penelitian ini mengimplementasikan metode Simple Additive Weighting  dengan menggunakan 40 data yang didapatkan dari Pos Kesehatan yang bertempat di Bangkalan, dan sistem ini  menghasilkan nilai akurasi kecocokan rata-rata sebesar 77,5% . &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100032&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100032&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100032&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100032&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100033&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100033&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100032&gt;
{&#39;Abstrak&#39;: &#39;Investasi saham selama ini memiliki resiko kerugian yang sangat besar dikarenakan\npergerakan harga saham sangat tidak menentu, dalam meminimalkan resiko kerugian\ndiperlukan pengetahuan dalam membaca pergerakan harga saham. Dengan\nperkembangan teknologi kecerdasan buatan dan pemrosesan perdiksisaat ini, pergerakan\nharga saham dapat di identifikasi dengan cara otomatis secara perhitungan matematis\nyang sangat kompleks. Perhitungan ini adalah Deep Learning yang merupakan salah\nsatu teknologi kecerdasan buatan yang memiliki akurasi pengenalan yang tinggi dengan\ndata yang banyak. Penelitihan ini menggunakan teknik Deep learning, Recurrent Neural\nNetworks (RNN) modul pemrosesan Long-Short Term Memory (LSTM) untuk\nmelakukan prediksi harga saham. Fitur yang digunakan dalam pemrosesan prediksi yaitu\nData harga penutupan saham (harga closing) PT Semen Indonesia (Persero) Tbk, dari\ntanggal (09/01/2014) sampai (09/01/2020), sebanyak 1500 data. Dengan adanya gerbang\n- gerbang didalam metode Neural Network algoritma LSTM ini dapat menyeleksi data\nyang perlu diingat ataupun dilupakan dalam proses perhitungannya. Berdasarkan hasil\nprediksi harga saham menghasilkan keakuratan yang sangat bagus dengan 100 proses\npelatihan dari 13 proses uji coba dengan berbagai nilai parameter learning rate yang\nberbeda - beda dan mendapatkan rata-rata akurasi 94,92 %. Dan yang menghasilkan hasil\nterbaik adalah skenario ke tiga dengan parameter epoch 50, learning rate 0.2 dan\nmenghasilkan MSE 0.51 dan MAPE 0.38%, akurasinya 99.62%&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100032&gt;
{&#39;Abstrak&#39;: &#39;Investasi saham selama ini memiliki resiko kerugian yang sangat besar dikarenakan\npergerakan harga saham sangat tidak menentu, dalam meminimalkan resiko kerugian\ndiperlukan pengetahuan dalam membaca pergerakan harga saham. Dengan\nperkembangan teknologi kecerdasan buatan dan pemrosesan perdiksisaat ini, pergerakan\nharga saham dapat di identifikasi dengan cara otomatis secara perhitungan matematis\nyang sangat kompleks. Perhitungan ini adalah Deep Learning yang merupakan salah\nsatu teknologi kecerdasan buatan yang memiliki akurasi pengenalan yang tinggi dengan\ndata yang banyak. Penelitihan ini menggunakan teknik Deep learning, Recurrent Neural\nNetworks (RNN) modul pemrosesan Long-Short Term Memory (LSTM) untuk\nmelakukan prediksi harga saham. Fitur yang digunakan dalam pemrosesan prediksi yaitu\nData harga penutupan saham (harga closing) PT Semen Indonesia (Persero) Tbk, dari\ntanggal (09/01/2014) sampai (09/01/2020), sebanyak 1500 data. Dengan adanya gerbang\n- gerbang didalam metode Neural Network algoritma LSTM ini dapat menyeleksi data\nyang perlu diingat ataupun dilupakan dalam proses perhitungannya. Berdasarkan hasil\nprediksi harga saham menghasilkan keakuratan yang sangat bagus dengan 100 proses\npelatihan dari 13 proses uji coba dengan berbagai nilai parameter learning rate yang\nberbeda - beda dan mendapatkan rata-rata akurasi 94,92 %. Dan yang menghasilkan hasil\nterbaik adalah skenario ke tiga dengan parameter epoch 50, learning rate 0.2 dan\nmenghasilkan MSE 0.51 dan MAPE 0.38%, akurasinya 99.62%&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100032&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100032&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100033&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100033&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100033&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100033&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100033&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100033&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100033&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100033&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100034&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100034&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100033&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100033&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100033&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100033&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100034&gt;
{&#39;Abstrak&#39;: &#39;Diabetes Mellitus (DM) adalah penyakit yang berlangsung lama atau kronis serta ditandai dengan kadar gula (glukosa) darah yang tinggi atau di atas nilai normal. Glukosa yang menumpuk di dalam darah akibat tidak diserap sel tubuh dengan baik dapat menimbulkan berbagai gangguan organ tubuh. Jika diabetes tidak dikontrol dengan baik, dapat timbul berbagai komplikasi yang membahayakan nyawa penderita.  Kurangnya kesadaran masyarakat akan pola hidup sehat serta keterlambatan masyarakat menyadari gejala-gejala awal indikasi risiko penyakit DM sehingga tidak cepat ditangani. Dari permasalahan tersebut maka dibutuhkan sebuah langkah untuk membangun sistem klasifikasi untuk mendiagnosis penyakit DM. Sistem klasifikasi penyakit dapat dibangun dengan menggunakan metode K-Nearest Neighbor (KNN).  Metode KNN mampu mengklasifikasikan penyakit DM berdasarkan kedekatan pada data latih. Dari hasil pengujian penerapan metode K-Nearest Neighbor dalam mengklasifikasi penyakit diabetes mellitus didapatkan hasil akurasi sebesar 98%. hasil ini didapat dari perhitungan akurasi dengan menggunakan metode Confusion Matrix. &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100034&gt;
{&#39;Abstrak&#39;: &#39;Diabetes Mellitus (DM) adalah penyakit yang berlangsung lama atau kronis serta ditandai dengan kadar gula (glukosa) darah yang tinggi atau di atas nilai normal. Glukosa yang menumpuk di dalam darah akibat tidak diserap sel tubuh dengan baik dapat menimbulkan berbagai gangguan organ tubuh. Jika diabetes tidak dikontrol dengan baik, dapat timbul berbagai komplikasi yang membahayakan nyawa penderita.  Kurangnya kesadaran masyarakat akan pola hidup sehat serta keterlambatan masyarakat menyadari gejala-gejala awal indikasi risiko penyakit DM sehingga tidak cepat ditangani. Dari permasalahan tersebut maka dibutuhkan sebuah langkah untuk membangun sistem klasifikasi untuk mendiagnosis penyakit DM. Sistem klasifikasi penyakit dapat dibangun dengan menggunakan metode K-Nearest Neighbor (KNN).  Metode KNN mampu mengklasifikasikan penyakit DM berdasarkan kedekatan pada data latih. Dari hasil pengujian penerapan metode K-Nearest Neighbor dalam mengklasifikasi penyakit diabetes mellitus didapatkan hasil akurasi sebesar 98%. hasil ini didapat dari perhitungan akurasi dengan menggunakan metode Confusion Matrix. &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100033&gt;
{&#39;Abstrak&#39;: &#39;Cross-Language Information Retrieval (CLIR) merupakan subbidang Temu Kembali Informasi yang berkaitan dengan pengambilan informasi yang disimpan dalam bahasa yang berbeda dari bahasa permintaan yang diberikan pengguna. Pada CLIR terdapat berbagai metode terjemahan, diantaranya adalah Dictionary-based, Parallel corpora based, Comparable corpora based, Machine translator based, Ontology based, dan Transitive based. Langkah-langkah menerjemahkan query ke dalam bahasa target meliputi stemming, kemudian perhitungan kemiripan dokumen. permasalahannya terdapat pada efisiensi waktu dan akurasi dalam penerjemahan query dari banyaknya metode di CLIR pada Bahasa Indonesia dan Inggris. Pada tahap stemming mempunyai metode masing-masing dari kedua Bahasa tersebut. Untuk stemming bahasa Indonesia terdapat kata dasar dan kata imbuhan. Ada variasi imbuhan termasuk prefix, suffix, infiks, dan confixes, sedangkan stemming bahasa Inggris hanya kata imbuhan suffix. Pada pemrosesan stemming membutuhkan waktu yang lebih lama. Untuk mengatasi masalah tersebut, di usulkan menggunakan Google Translate API dalam penerjemahan query dan menggunakan satu stemming bahasa Inggris dengan algoritma Porter Stemmer yang merupakan metode stemming terbaik dari beberapa penelitian dengan akurasi terbaik. Untuk perhitungan kemiripan menggunakan Cosine Similarity. penelitian ini diharapkan dapat menghasilkan sistem yang lebih akurat serta dapat mempercepat waktu dalam proses dan pencarian dokumen lintas bahasa Indonesia dan Inggris.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100033&gt;
{&#39;Abstrak&#39;: &#39;Cross-Language Information Retrieval (CLIR) merupakan subbidang Temu Kembali Informasi yang berkaitan dengan pengambilan informasi yang disimpan dalam bahasa yang berbeda dari bahasa permintaan yang diberikan pengguna. Pada CLIR terdapat berbagai metode terjemahan, diantaranya adalah Dictionary-based, Parallel corpora based, Comparable corpora based, Machine translator based, Ontology based, dan Transitive based. Langkah-langkah menerjemahkan query ke dalam bahasa target meliputi stemming, kemudian perhitungan kemiripan dokumen. permasalahannya terdapat pada efisiensi waktu dan akurasi dalam penerjemahan query dari banyaknya metode di CLIR pada Bahasa Indonesia dan Inggris. Pada tahap stemming mempunyai metode masing-masing dari kedua Bahasa tersebut. Untuk stemming bahasa Indonesia terdapat kata dasar dan kata imbuhan. Ada variasi imbuhan termasuk prefix, suffix, infiks, dan confixes, sedangkan stemming bahasa Inggris hanya kata imbuhan suffix. Pada pemrosesan stemming membutuhkan waktu yang lebih lama. Untuk mengatasi masalah tersebut, di usulkan menggunakan Google Translate API dalam penerjemahan query dan menggunakan satu stemming bahasa Inggris dengan algoritma Porter Stemmer yang merupakan metode stemming terbaik dari beberapa penelitian dengan akurasi terbaik. Untuk perhitungan kemiripan menggunakan Cosine Similarity. penelitian ini diharapkan dapat menghasilkan sistem yang lebih akurat serta dapat mempercepat waktu dalam proses dan pencarian dokumen lintas bahasa Indonesia dan Inggris.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100034&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100034&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100034&gt;
{&#39;Abstrak&#39;: &#39;\n Segmentasi citra merupakan tahapan terpenting dalam memperbaiki pengenalan pola, dimana segmentasi digunakan untuk mengenali objek dari suatu citra. Segmentasi gambar bertujuan untuk membagi prosedur citra menjadi beberapa bagian pokok penyusun citra. Sehingga penelitian segmentasi ini hanya akan membagi dua bagian dari citra yakni bagian objek foreground dan background. Dimana algoritma pengolahan citra digital yang digunakan yaitu contras stretching dengan Segmentasi menggunakan metode K-means clustering yang digunakan untuk proses segmentasi dan pengurangan noise background dimana untuk menghasilkan tingkat keakuratan yang lebih baik dalam mengidentifikasi objek utama dengan background dinamis.  Pada proses pengujian digunakan 100 citra dataset fish, hasil akurasi tertinggi dari penggabungan kedua metode menghasilkan akurasi paling tinggi yaitu 99.38 %.\n\n\nKata kunci: contrast stretchhing, K-means Clustering, Segmentasi citra \n\n\n\n\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100034&gt;
{&#39;Abstrak&#39;: &#39;\n Segmentasi citra merupakan tahapan terpenting dalam memperbaiki pengenalan pola, dimana segmentasi digunakan untuk mengenali objek dari suatu citra. Segmentasi gambar bertujuan untuk membagi prosedur citra menjadi beberapa bagian pokok penyusun citra. Sehingga penelitian segmentasi ini hanya akan membagi dua bagian dari citra yakni bagian objek foreground dan background. Dimana algoritma pengolahan citra digital yang digunakan yaitu contras stretching dengan Segmentasi menggunakan metode K-means clustering yang digunakan untuk proses segmentasi dan pengurangan noise background dimana untuk menghasilkan tingkat keakuratan yang lebih baik dalam mengidentifikasi objek utama dengan background dinamis.  Pada proses pengujian digunakan 100 citra dataset fish, hasil akurasi tertinggi dari penggabungan kedua metode menghasilkan akurasi paling tinggi yaitu 99.38 %.\n\n\nKata kunci: contrast stretchhing, K-means Clustering, Segmentasi citra \n\n\n\n\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100034&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100034&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100035&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100035&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100034&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:33 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100034&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100034&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100034&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100035&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100035&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100034&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100034&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100035&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100035&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100035&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100035&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100035&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100035&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100035&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100035&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100036&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100036&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100035&gt;
{&#39;Abstrak&#39;: &#39;Jagung merupakan sumber karbohidrat dan protein yang dikonsumsi sebagai makanan pokok selain beras. Banyaknya jenis hama dan penyakit yang menyerang tanaman jagung membuat petani kesulitan dalam menentukan cara pengendalian yang tepat, sehingga menyebabkan tingkat produktifitas petani menurun. Oleh karena itu, dibutuhkan sebuah sistem pakar yang dapat mendiagnosa hama dan penyakit tanaman jagung beserta cara pengendalian yang tepat, sehingga tingkat produktifitas petani meningkat. Pada penelitian sebelumnya sebagian besar peneliti hanya memanfaatkan satu metode saja untuk mendiagnosa hama dan penyakit tanaman jagung, sehingga sistem yang dihasilkan memiliki tingkat akurasi yang kurang maksimal. Pada penelitian ini akan dilakukan penggabungan dua metode yaitu metode fuzzy mamdani dan certainty factor. Metode fuzzy mamdani digunakan untuk menentukan nilai measure of belief (mb) atau nilai kepercayaan dan nilai measure of disbelief (md) atau nilai ketidakpercayaan gejala terhadap suatu penyakit. Sedangkan metode certainty factor digunakan untuk menentukan nilai kepastian (cf) pada masing-masing penyakit. Penelitian ini bertujuan untuk mengukur tingkat akurasi dari pengintegrasian metode fuzzy mamdani dan certainty factor. Hasil pengujian tingkat akurasi dari penggabungan metode fuzzy mamdani dan certainty factor didapatkan tingkat akurasi sebesar 40%. Nilai akurasi ini diperoleh dengan cara membandingkan hasil diagnosa sistem dengan hasil diagnosa pakar dari 50 kasus pengujian.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100035&gt;
{&#39;Abstrak&#39;: &#39;Jagung merupakan sumber karbohidrat dan protein yang dikonsumsi sebagai makanan pokok selain beras. Banyaknya jenis hama dan penyakit yang menyerang tanaman jagung membuat petani kesulitan dalam menentukan cara pengendalian yang tepat, sehingga menyebabkan tingkat produktifitas petani menurun. Oleh karena itu, dibutuhkan sebuah sistem pakar yang dapat mendiagnosa hama dan penyakit tanaman jagung beserta cara pengendalian yang tepat, sehingga tingkat produktifitas petani meningkat. Pada penelitian sebelumnya sebagian besar peneliti hanya memanfaatkan satu metode saja untuk mendiagnosa hama dan penyakit tanaman jagung, sehingga sistem yang dihasilkan memiliki tingkat akurasi yang kurang maksimal. Pada penelitian ini akan dilakukan penggabungan dua metode yaitu metode fuzzy mamdani dan certainty factor. Metode fuzzy mamdani digunakan untuk menentukan nilai measure of belief (mb) atau nilai kepercayaan dan nilai measure of disbelief (md) atau nilai ketidakpercayaan gejala terhadap suatu penyakit. Sedangkan metode certainty factor digunakan untuk menentukan nilai kepastian (cf) pada masing-masing penyakit. Penelitian ini bertujuan untuk mengukur tingkat akurasi dari pengintegrasian metode fuzzy mamdani dan certainty factor. Hasil pengujian tingkat akurasi dari penggabungan metode fuzzy mamdani dan certainty factor didapatkan tingkat akurasi sebesar 40%. Nilai akurasi ini diperoleh dengan cara membandingkan hasil diagnosa sistem dengan hasil diagnosa pakar dari 50 kasus pengujian.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100035&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100035&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100036&gt;
{&#39;Abstrak&#39;: &#39;Skripsi merupakan hal yang penting dan selalu ada di sebuah universitas. Skripsi juga sebagai wujud hasil karya tulis ilmiah mahasiswa yang tercatat dan tersusun rapi sesuai dengan kaidah yang ditentukan. Saat ini permasalahan yang timbul dari proses pengajaun skripsi di lingkungan Universitas Trunojoyo Madura secara umum adalah proses pencarian serta penentuan sebuah judul skripsi yang tepat untuk diajukan mahasiswa dan tidak tersedianya data hasil skripsi mahasiswa yang tersusun secara sistematis dan komputerisasi, sehingga dalam pembuatan skripsi terdapat banyak kesamaan baik berupa judul maupun metode yang sering digunakan oleh mahasiswa, hal ini berdampak ketidak beragaman hasil skripsi buatan mahasiswa.\nDengan adanya pengembangan aplikasi manajemen skripsi menggunakan framework codeigniter dan cosine similarity diharapkan bisa mengevaluasi, memonitoring, serta memperbaiki kinerja sistem yang manual menjadi sistem terkomputasi sekaligus meminimalisir kesamaan dan plagiatisme serta dapat meningkatkan pelayanan kepada mahasiswa yang mengajukan skripsi dengan mudah sesuai dengan aturan yang berlaku di lingkungan Universitas Trunojoyo Madura.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100036&gt;
{&#39;Abstrak&#39;: &#39;Skripsi merupakan hal yang penting dan selalu ada di sebuah universitas. Skripsi juga sebagai wujud hasil karya tulis ilmiah mahasiswa yang tercatat dan tersusun rapi sesuai dengan kaidah yang ditentukan. Saat ini permasalahan yang timbul dari proses pengajaun skripsi di lingkungan Universitas Trunojoyo Madura secara umum adalah proses pencarian serta penentuan sebuah judul skripsi yang tepat untuk diajukan mahasiswa dan tidak tersedianya data hasil skripsi mahasiswa yang tersusun secara sistematis dan komputerisasi, sehingga dalam pembuatan skripsi terdapat banyak kesamaan baik berupa judul maupun metode yang sering digunakan oleh mahasiswa, hal ini berdampak ketidak beragaman hasil skripsi buatan mahasiswa.\nDengan adanya pengembangan aplikasi manajemen skripsi menggunakan framework codeigniter dan cosine similarity diharapkan bisa mengevaluasi, memonitoring, serta memperbaiki kinerja sistem yang manual menjadi sistem terkomputasi sekaligus meminimalisir kesamaan dan plagiatisme serta dapat meningkatkan pelayanan kepada mahasiswa yang mengajukan skripsi dengan mudah sesuai dengan aturan yang berlaku di lingkungan Universitas Trunojoyo Madura.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100036&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100036&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100036&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100036&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100036&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100036&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100036&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100036&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100037&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100037&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100036&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100036&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100036&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100036&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100037&gt;
{&#39;Abstrak&#39;: &#39;Dalam usaha mencapai prestasi yang baik dalam olahraga permainan bola voli, pemain bukan hanya ditekankan pada penguasaan teknik dan taktik saja, tetapi dituntut kondisi fisik yang baik, karena merupakan syarat-syarat penting dalam penguasaan keterampilan dalam permainan bola voli. Seorang pemain membutuhkan kondisi fisik yang baik untuk meningkatkan kualitas teknik. Dalam hal ini pelatih ingin tahu sejauh mana kondisi fisik pemain dari masing-masing individu, dengan mengoreksi kondisi fisik pemain bola voli yang baik. Untuk mempermudah dalam mengetahui kondisi fisik pemain maka diperlukan sistem pendukung keputusan yang dapat mengklasifikasi kondisi fisik pemain. Metode yang digunakan dalam sistem pendukung keputusan adalah naive bayes. Naive bayes merupakan salah satu metode di dalam data mining untuk mengklasifikasikan data. Metode ini dapat membantu pelatih dalam mengklasifikasi kondisi fisik setiap pemain bola voli dimana terdapat lima kategori yaitu baik sekali, baik, cukup, kurang dan kurang sekali. Dari hasil perhitungan metode naive bayes menghasilkan akurasi sebesar 85,71% dimana nilai yang didapat dari perbandingan antara perhitungan sistem dengan hasil perhitungan manual.\n\nKata Kunci : Kondisi Fisik, Naïve Bayess, Bola Voli&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100037&gt;
{&#39;Abstrak&#39;: &#39;Dalam usaha mencapai prestasi yang baik dalam olahraga permainan bola voli, pemain bukan hanya ditekankan pada penguasaan teknik dan taktik saja, tetapi dituntut kondisi fisik yang baik, karena merupakan syarat-syarat penting dalam penguasaan keterampilan dalam permainan bola voli. Seorang pemain membutuhkan kondisi fisik yang baik untuk meningkatkan kualitas teknik. Dalam hal ini pelatih ingin tahu sejauh mana kondisi fisik pemain dari masing-masing individu, dengan mengoreksi kondisi fisik pemain bola voli yang baik. Untuk mempermudah dalam mengetahui kondisi fisik pemain maka diperlukan sistem pendukung keputusan yang dapat mengklasifikasi kondisi fisik pemain. Metode yang digunakan dalam sistem pendukung keputusan adalah naive bayes. Naive bayes merupakan salah satu metode di dalam data mining untuk mengklasifikasikan data. Metode ini dapat membantu pelatih dalam mengklasifikasi kondisi fisik setiap pemain bola voli dimana terdapat lima kategori yaitu baik sekali, baik, cukup, kurang dan kurang sekali. Dari hasil perhitungan metode naive bayes menghasilkan akurasi sebesar 85,71% dimana nilai yang didapat dari perbandingan antara perhitungan sistem dengan hasil perhitungan manual.\n\nKata Kunci : Kondisi Fisik, Naïve Bayess, Bola Voli&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100037&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:34 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100037&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100037&gt;
{&#39;Abstrak&#39;: &#39;Bagi manusia, pengenalan obyek pada citra merupakan hal yang sangat mudah. Akan tetapi, untuk pengenalan obyek citra menggunakan mesin, tidaklah mudah. Mesin harus membaca setiap nilai pixel dari citra masukan dan menghasilkan sebuah nilai untuk menentukan kelas citra tersebut. Penelitian ini menggunakan metode Convolutional Neural Network (CNN) untuk pengenalan obyek pada citra. Metode ini tidak memerlukan feature engineering. Pada CNN terdapat beberapa layer seperti, Convolution Layer, Pooling Layer dan Fully Connected.  Dataset yang digunakan untuk pelatihan adalah dataset citra CIFAR10. Dataset CIFAR10 memiliki citra sebanyak 60000 terdiri dari 10 kelas. Untuk mempermudah pembuatan aplikasi menggunakan framework deep learning theano. Penelitian bertujuan untuk mengetahui dampak dari ukuran filter dan kedalaman layer pada CNN. Hasil yang didapat pada penelitian ini adalah dengan ukuran filter lebih besar, dapat menambah tingkat akurasi. Akurasi tertinggi untuk penelitian ini adalah 62.23%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100037&gt;
{&#39;Abstrak&#39;: &#39;Bagi manusia, pengenalan obyek pada citra merupakan hal yang sangat mudah. Akan tetapi, untuk pengenalan obyek citra menggunakan mesin, tidaklah mudah. Mesin harus membaca setiap nilai pixel dari citra masukan dan menghasilkan sebuah nilai untuk menentukan kelas citra tersebut. Penelitian ini menggunakan metode Convolutional Neural Network (CNN) untuk pengenalan obyek pada citra. Metode ini tidak memerlukan feature engineering. Pada CNN terdapat beberapa layer seperti, Convolution Layer, Pooling Layer dan Fully Connected.  Dataset yang digunakan untuk pelatihan adalah dataset citra CIFAR10. Dataset CIFAR10 memiliki citra sebanyak 60000 terdiri dari 10 kelas. Untuk mempermudah pembuatan aplikasi menggunakan framework deep learning theano. Penelitian bertujuan untuk mengetahui dampak dari ukuran filter dan kedalaman layer pada CNN. Hasil yang didapat pada penelitian ini adalah dengan ukuran filter lebih besar, dapat menambah tingkat akurasi. Akurasi tertinggi untuk penelitian ini adalah 62.23%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100037&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100037&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100037&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100037&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100038&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100038&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100037&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100037&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100037&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100037&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100038&gt;
{&#39;Abstrak&#39;: &#39;Epilepsi adalah penyakit kelainan saraf pada otak. Menyerang manusia tanpa ada tanda – tanda akan terjadinya serangan epilepsi pada penderita. Epilepsi adalah penyakit yang bisa diturunkan oleh gen. factor pembawa epilepsi bisa berasal dari orangtua. Penyebab dari epilepsi masih belum diketahui\n Epilepsi dapat dicegah semenjak dini mulai dari perawatan yang mahal ataupun murah di bidang medis. Jika epilepsi tidak bisa ditangani melalui pengobatan medis, maka operasi atau neurostimulation lah solusi terakhir. Dengan adanya penelitian ini, bertujuan untuk meng-identifikasi seseorang apakah teridentifikasi sebagai penderita atau tidak. Electroencephalogram(EEG) adalah metode untuk merekam informasi aktifitas otak pada manusia. Digunakan 3750 sampel yang akan dilakukan ekstraksi fitur menggunakan Haar Wavelet. Dilakukan proses untuk menguraikan sinyal kedalam 3 level yang disebut Decompose Level. Selanjutnya dilakukan proses klasifikasi dengan menggunakan metode Euclidean Distance untuk mendapatkan klasifikasi data. Proses selanjutnya akan dicari nilai akurasi penelitian menggunakan Haar Wavelet dengan tiap Decompose Level menggunakan Confusion Matrix.\n Penelitian menghasilkan jangkauan nilai akurasi dari 78.80% - 78.97% dan menyimpulkan bahwa pengaruh decompose level terdapat pada waktu komputasi yang diperlukan\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100038&gt;
{&#39;Abstrak&#39;: &#39;Epilepsi adalah penyakit kelainan saraf pada otak. Menyerang manusia tanpa ada tanda – tanda akan terjadinya serangan epilepsi pada penderita. Epilepsi adalah penyakit yang bisa diturunkan oleh gen. factor pembawa epilepsi bisa berasal dari orangtua. Penyebab dari epilepsi masih belum diketahui\n Epilepsi dapat dicegah semenjak dini mulai dari perawatan yang mahal ataupun murah di bidang medis. Jika epilepsi tidak bisa ditangani melalui pengobatan medis, maka operasi atau neurostimulation lah solusi terakhir. Dengan adanya penelitian ini, bertujuan untuk meng-identifikasi seseorang apakah teridentifikasi sebagai penderita atau tidak. Electroencephalogram(EEG) adalah metode untuk merekam informasi aktifitas otak pada manusia. Digunakan 3750 sampel yang akan dilakukan ekstraksi fitur menggunakan Haar Wavelet. Dilakukan proses untuk menguraikan sinyal kedalam 3 level yang disebut Decompose Level. Selanjutnya dilakukan proses klasifikasi dengan menggunakan metode Euclidean Distance untuk mendapatkan klasifikasi data. Proses selanjutnya akan dicari nilai akurasi penelitian menggunakan Haar Wavelet dengan tiap Decompose Level menggunakan Confusion Matrix.\n Penelitian menghasilkan jangkauan nilai akurasi dari 78.80% - 78.97% dan menyimpulkan bahwa pengaruh decompose level terdapat pada waktu komputasi yang diperlukan\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100039&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100039&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100038&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100038&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100039&gt;
{&#39;Abstrak&#39;: &#39;Electroencephalogram (EEG) merupakan teknik perekaman gelombang otak manusia melalui elektroda yang dipasang pada kulit kepala manusia. Hasil dari data sinyal yang didapat dapat digunakan sebagai identifikasi penderita epilepsi. Data yang digunakan dalam penelitian ini adalah data The Bern-Barcelona EEG database dengan 2 jenis data yaitu 5 subjek data focal dan 5 subjek data non-focal. Setiap subjek direkam dengan menggunakan 64 channel (penangkap sinyal) dan direkam dengan sampel 1024 Hz. Pada penelitian ini terdapat tiga tahap yang dilakukan. Tahap pertama ekstrasi fitur menggunakan Time and Frequency Distribution. Tahap kedua seleksi fitur menggunakan Genetic Algorithm. Dan tahap ketiga klasifikasi menggunakan Naïve Bayes. Hasil yang didapat dari percobaan adalah seleksi fitur memiliki pengaruh dalam sistem yaitu menambah tingkat akurasi dengan akurasi tertinggi mencapai 87.6 %.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100039&gt;
{&#39;Abstrak&#39;: &#39;Electroencephalogram (EEG) merupakan teknik perekaman gelombang otak manusia melalui elektroda yang dipasang pada kulit kepala manusia. Hasil dari data sinyal yang didapat dapat digunakan sebagai identifikasi penderita epilepsi. Data yang digunakan dalam penelitian ini adalah data The Bern-Barcelona EEG database dengan 2 jenis data yaitu 5 subjek data focal dan 5 subjek data non-focal. Setiap subjek direkam dengan menggunakan 64 channel (penangkap sinyal) dan direkam dengan sampel 1024 Hz. Pada penelitian ini terdapat tiga tahap yang dilakukan. Tahap pertama ekstrasi fitur menggunakan Time and Frequency Distribution. Tahap kedua seleksi fitur menggunakan Genetic Algorithm. Dan tahap ketiga klasifikasi menggunakan Naïve Bayes. Hasil yang didapat dari percobaan adalah seleksi fitur memiliki pengaruh dalam sistem yaitu menambah tingkat akurasi dengan akurasi tertinggi mencapai 87.6 %.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100038&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100038&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100038&gt;
{&#39;Abstrak&#39;: &#39;Perguruan Tinggi merupakan salah satu jenjang pendidikan setelah Sekolah Menengah Atas (SMA) yang menyeleksi penerimaan mahasiswa baru berdasarkan jalur prestasi, SNMPTN, SBMPTN dan jalur mandiri. penerimaan jalur SNMPTN dilakukan berdasarkan prestasi akademik atau Raport. Perguruan tinggi memiliki kriteria masing-masing bagi calon mahasiswanya untuk bisa melanjutkan menuntut ilmu di perguruan tinggi tersebut. Hal tersebut memicu persaingan antar mahasiswa baru dikarenakan perguruan tinggi mengadakan seleksi bagi calon mahasiswa. Siswa yang berprestasi tinggi secara konsisten menunjukkan prestasinya tersebut layak mendapatkan kesempatan untuk menjadi calon mahasiswa melalui SNMPTN. Masalah utama dalam menyeleksi mahasiswa SNMPTN yaitu saat proses meranking mahasiswa secara maksimal serta pembobotan dari setiap masing-masing prodi. MultiCriteria Decision Making (MCDM) merupakan salah satu metode pengambilan keputusan untuk menyeleksi alternatif terbaik dari sejumlah alternatif berdasarkan kriteria tertentu. Banyaknya kriteria dalam menentukan penerimaan mahasiswa baru, sehingga di butuhkan metode untuk meentukan pembobotan kriteria dan perangkingan alternatif jurusan. Berdasarkan hasil pengujian menunjukkan bahwa metode ANP-ELECTRE yang diterapkan pada seleksi penilaian di Fakultas Teknik, didapatkan akurasi tertinggi pada jurusan Teknik Elektro dengan akurasi 86,36%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100038&gt;
{&#39;Abstrak&#39;: &#39;Perguruan Tinggi merupakan salah satu jenjang pendidikan setelah Sekolah Menengah Atas (SMA) yang menyeleksi penerimaan mahasiswa baru berdasarkan jalur prestasi, SNMPTN, SBMPTN dan jalur mandiri. penerimaan jalur SNMPTN dilakukan berdasarkan prestasi akademik atau Raport. Perguruan tinggi memiliki kriteria masing-masing bagi calon mahasiswanya untuk bisa melanjutkan menuntut ilmu di perguruan tinggi tersebut. Hal tersebut memicu persaingan antar mahasiswa baru dikarenakan perguruan tinggi mengadakan seleksi bagi calon mahasiswa. Siswa yang berprestasi tinggi secara konsisten menunjukkan prestasinya tersebut layak mendapatkan kesempatan untuk menjadi calon mahasiswa melalui SNMPTN. Masalah utama dalam menyeleksi mahasiswa SNMPTN yaitu saat proses meranking mahasiswa secara maksimal serta pembobotan dari setiap masing-masing prodi. MultiCriteria Decision Making (MCDM) merupakan salah satu metode pengambilan keputusan untuk menyeleksi alternatif terbaik dari sejumlah alternatif berdasarkan kriteria tertentu. Banyaknya kriteria dalam menentukan penerimaan mahasiswa baru, sehingga di butuhkan metode untuk meentukan pembobotan kriteria dan perangkingan alternatif jurusan. Berdasarkan hasil pengujian menunjukkan bahwa metode ANP-ELECTRE yang diterapkan pada seleksi penilaian di Fakultas Teknik, didapatkan akurasi tertinggi pada jurusan Teknik Elektro dengan akurasi 86,36%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100038&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100038&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100039&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100039&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100039&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100039&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100039&gt;
{&#39;Abstrak&#39;: &#39;Menurut World Health Organization penyakit ginjal berada pada urutan 18 dunia sebagai penyakit yang mematikan pada tahun 2000 dan meningkat pada urutan 12 pada tahun 2015. Di Indonesia penyakit ginjal kronis tercatat sebagai ranking kedua sebagai pembiayaan terbesar oleh BPJS setelah penyakit jantung. Penyakit ginjal kronis merupakan masalah kesehatan dunia yang sangat serius. Prevalensi dan kejadian penyakit ginjal kronis kian hari kian meningkat. Pasalnya 1 dari 10 orang di dunia cenderung memiliki penyakit ginjal kronis dengan stadium tertentu. Seorang lansia cenderung memiliki penyakit ginjal kronis, lebih dari setengah dari orang yang berumur 75 tahun memiliki tingkat gagal ginjal kronis tertentu. Terdapat 24 atribut untuk mengetahui seseorang terserang penyakit gunjal kronis. Kemudian data berupa atribut tersebut diproses menggunakan seleksi fitur dengan metode Information Gain. Hasil dari seleksi fitur dengan Information Gain tersebut dirangking dan dilakukan proses klasifikasi dengan menggunakan metode Regresi Logistik. Dengan menggunakan metode ini menghasilkan hasil tertinggi dalam kategori akurasi dengan nilai 96.0%yaitu pada percobaan ke 7, hasil tertinggi dalam kategori recall dengan nilai 80.0% yaitu pada percobaan ke 2 dan hasil tertinggi dalam kategori precision dengan nilai 80.0% yaitu pada percobaan ke 15. Hal ini menunjukkan bahwa penelitian ini memiliki akurasi yang lumayan tinggi.\n\nKata kunci : seleksi fitur, klasifikasi, Regresi Logistik, Information Gain\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100039&gt;
{&#39;Abstrak&#39;: &#39;Menurut World Health Organization penyakit ginjal berada pada urutan 18 dunia sebagai penyakit yang mematikan pada tahun 2000 dan meningkat pada urutan 12 pada tahun 2015. Di Indonesia penyakit ginjal kronis tercatat sebagai ranking kedua sebagai pembiayaan terbesar oleh BPJS setelah penyakit jantung. Penyakit ginjal kronis merupakan masalah kesehatan dunia yang sangat serius. Prevalensi dan kejadian penyakit ginjal kronis kian hari kian meningkat. Pasalnya 1 dari 10 orang di dunia cenderung memiliki penyakit ginjal kronis dengan stadium tertentu. Seorang lansia cenderung memiliki penyakit ginjal kronis, lebih dari setengah dari orang yang berumur 75 tahun memiliki tingkat gagal ginjal kronis tertentu. Terdapat 24 atribut untuk mengetahui seseorang terserang penyakit gunjal kronis. Kemudian data berupa atribut tersebut diproses menggunakan seleksi fitur dengan metode Information Gain. Hasil dari seleksi fitur dengan Information Gain tersebut dirangking dan dilakukan proses klasifikasi dengan menggunakan metode Regresi Logistik. Dengan menggunakan metode ini menghasilkan hasil tertinggi dalam kategori akurasi dengan nilai 96.0%yaitu pada percobaan ke 7, hasil tertinggi dalam kategori recall dengan nilai 80.0% yaitu pada percobaan ke 2 dan hasil tertinggi dalam kategori precision dengan nilai 80.0% yaitu pada percobaan ke 15. Hal ini menunjukkan bahwa penelitian ini memiliki akurasi yang lumayan tinggi.\n\nKata kunci : seleksi fitur, klasifikasi, Regresi Logistik, Information Gain\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100039&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100039&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100039&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100039&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100040&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:35 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100040&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100039&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100039&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100040&gt;
{&#39;Abstrak&#39;: &#39;Alcoholism adalah kondisi seseorang dimana orang tersebut mengkonsumsi dan kecanduan terhadap minuman keras (alkohol). Salah satu cara mengetahui seseorang termasuk alcoholic (pecandu alkohol) atau tidak dengan cara merekam aktifitas yang terjadi di otak dengan cara menempelkan elektroda logam dan media konduktif pada kulit kepala atau bisa disebut dengan Electroencephalography (EEG). Dalam penelitian ini, sinyal EEG akan diklasifikasikan ke dalam dua kategori yaitu pecandu alkohol dan normal. Penelitian ini diawali dengan preprocessing menggunakan Independent Component Analysis (ICA), dimana pada proses preprocessing sinyal – sinyal EEG dibersihkan dari noise. Setelah sinyal bersih dari noise kemudian dilakukan ektraksi fitur menggunakan Discrete Wavelet Transform (DWT). Setelah didapatkan fitur dari sinyal EEG, kemudian dilakukan proses seleksi fitur menggunakan Genetic Algortihm (GA) guna mencari fitur – fitur terbaik dari sinyal EEG. Setelah fitur – fitur terbaik didapatkan barulah dilakukan proses klasifikasi menggunakan jaringan saraf tiruan Counterpropagation Network (CPN). Penelitian ini menghasilkan akurasi tertinggi yaitu 78,7% yang terjadi pada scenario 4. Jadi, dalam kasus ini metode CounterPropagation Network (CPN) kurang cocok digunakan untuk proses klasifikasi sinyal EEG.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100040&gt;
{&#39;Abstrak&#39;: &#39;Alcoholism adalah kondisi seseorang dimana orang tersebut mengkonsumsi dan kecanduan terhadap minuman keras (alkohol). Salah satu cara mengetahui seseorang termasuk alcoholic (pecandu alkohol) atau tidak dengan cara merekam aktifitas yang terjadi di otak dengan cara menempelkan elektroda logam dan media konduktif pada kulit kepala atau bisa disebut dengan Electroencephalography (EEG). Dalam penelitian ini, sinyal EEG akan diklasifikasikan ke dalam dua kategori yaitu pecandu alkohol dan normal. Penelitian ini diawali dengan preprocessing menggunakan Independent Component Analysis (ICA), dimana pada proses preprocessing sinyal – sinyal EEG dibersihkan dari noise. Setelah sinyal bersih dari noise kemudian dilakukan ektraksi fitur menggunakan Discrete Wavelet Transform (DWT). Setelah didapatkan fitur dari sinyal EEG, kemudian dilakukan proses seleksi fitur menggunakan Genetic Algortihm (GA) guna mencari fitur – fitur terbaik dari sinyal EEG. Setelah fitur – fitur terbaik didapatkan barulah dilakukan proses klasifikasi menggunakan jaringan saraf tiruan Counterpropagation Network (CPN). Penelitian ini menghasilkan akurasi tertinggi yaitu 78,7% yang terjadi pada scenario 4. Jadi, dalam kasus ini metode CounterPropagation Network (CPN) kurang cocok digunakan untuk proses klasifikasi sinyal EEG.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100038&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100038&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100040&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100040&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100040&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100040&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100038&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100038&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100040&gt;
{&#39;Abstrak&#39;: &#39;Peningkatan kualitas citra merupakan proses awal dalam sebuah pengolahan citra (image processing). Peningkatan kualitas citra sangat dibutuhkan karena suatu yang dijadikan obyek pembahasan mengalami kualitas citra yang buruk. Contohnya citra yang terlalu gelap membuat tampilan citra kurang jelas. Citra tersebut terjadi pada saat pengambilan citra intensitas pencahayaannya yang rendah atau gelap. Salah satu cara meningkatkan kualitas citra dengan meningkatkan kontras dari citra, dibutuhkan suatu sistem yang mampu meningkatkan kualitas citra tersebut. Penelitian ini ditujukan untuk meningkatkan kualitas citra yang ada pada citra. Metode yang diusulkan dalam metode penelitian ini adalah histogram equalization yang dioptimasi menggunakan algoritma Particle Swarm Optimization (PSO) untuk menangani kontras citra yang berlebih. Pada penelitian ini dilakukan beberapa scenario pengujian untuk mengetahui seberapa optimal pengaruh algoritma PSO dalam proses optimasi peningkatan kualitas citra dengan menangani kontras citra berlebih dengan menggunakan dataset ExDark. Hasil Dari uji coba yang dilakukan dengan membandingkan rata-rata nilai PSNR dari metode Histogram Equalization dan Histogram Equalization dengan penerapan algoritma PSO diperoleh rata-rata untuk metode Histogram Equalization dari 3 channel untuk Red sebesar 9.941dB, Green sebesar 9.734dB dan Blue sebesar 10.423dB. Sedangkan Histogram Equalization dengan penerapan algoritma PSO dari 3 channel untuk Red sebesar 13.919dB, Green sebesar 13.919dB dan Blue sebesar 14.448dB. Dapat disimpulkan dari hasil yang diperoleh yaitu metode Histogram Equalization dengan penerapan algoritma PSO akurasinya lebih besar dibandingkan dengan metode Histogram Equalization biasa.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100040&gt;
{&#39;Abstrak&#39;: &#39;Peningkatan kualitas citra merupakan proses awal dalam sebuah pengolahan citra (image processing). Peningkatan kualitas citra sangat dibutuhkan karena suatu yang dijadikan obyek pembahasan mengalami kualitas citra yang buruk. Contohnya citra yang terlalu gelap membuat tampilan citra kurang jelas. Citra tersebut terjadi pada saat pengambilan citra intensitas pencahayaannya yang rendah atau gelap. Salah satu cara meningkatkan kualitas citra dengan meningkatkan kontras dari citra, dibutuhkan suatu sistem yang mampu meningkatkan kualitas citra tersebut. Penelitian ini ditujukan untuk meningkatkan kualitas citra yang ada pada citra. Metode yang diusulkan dalam metode penelitian ini adalah histogram equalization yang dioptimasi menggunakan algoritma Particle Swarm Optimization (PSO) untuk menangani kontras citra yang berlebih. Pada penelitian ini dilakukan beberapa scenario pengujian untuk mengetahui seberapa optimal pengaruh algoritma PSO dalam proses optimasi peningkatan kualitas citra dengan menangani kontras citra berlebih dengan menggunakan dataset ExDark. Hasil Dari uji coba yang dilakukan dengan membandingkan rata-rata nilai PSNR dari metode Histogram Equalization dan Histogram Equalization dengan penerapan algoritma PSO diperoleh rata-rata untuk metode Histogram Equalization dari 3 channel untuk Red sebesar 9.941dB, Green sebesar 9.734dB dan Blue sebesar 10.423dB. Sedangkan Histogram Equalization dengan penerapan algoritma PSO dari 3 channel untuk Red sebesar 13.919dB, Green sebesar 13.919dB dan Blue sebesar 14.448dB. Dapat disimpulkan dari hasil yang diperoleh yaitu metode Histogram Equalization dengan penerapan algoritma PSO akurasinya lebih besar dibandingkan dengan metode Histogram Equalization biasa.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100040&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100040&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100040&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100040&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100040&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100040&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100041&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100041&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100041&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100041&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100041&gt;
{&#39;Abstrak&#39;: &#39;Smart city semakin marak diperbincangkan guna menjadi solusi dalam memecahkan permasalahan yang timbul akibat dari dinamika kota yang semakin maju dan modern. Tujuan dari penerapan konsep smart city yakni untuk meningkatkan rasa aman, dan nyaman bagi warganya, membuat kota semakin efektif dan efisien serta meningkatkan daya saing dan pertumbuhan ekonomi serta pemerataan penghasilan. Madura merupakan sebuah pulau yang terletak disebelah utara pulau Jawa.  Pulau yang dijuluki tanah garam ini cukup dikenal dalam bidang kesenian kerapan sapi dan kerajinan batik, khususnya di Kabupaten Bangkalan. Kabupaten Bangkalan merupakan kota berkembang yang tepat untuk penerapan konsep smart city. Salah satu cara yang dapat dilakukan adalah memanfaatkan peluang kebutuhan pasar pecinta batik dengan memberikan kemudahan akses lokasi. Memanfaatkan teknologi pencarian lokasi Google maps dengan Metode Kartesius pada perangkat elektronik smartphone, konsumen akan dipermudah dalam hal pencarian informasi maupun lokasi pengrajin batik yang tersebar diseluruh wilayah Kabupaten Bangkalan.\nKata Kunci : Smart City,  Batik, Google Maps, Metode Kartesius, Smartphone Android.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100041&gt;
{&#39;Abstrak&#39;: &#39;Smart city semakin marak diperbincangkan guna menjadi solusi dalam memecahkan permasalahan yang timbul akibat dari dinamika kota yang semakin maju dan modern. Tujuan dari penerapan konsep smart city yakni untuk meningkatkan rasa aman, dan nyaman bagi warganya, membuat kota semakin efektif dan efisien serta meningkatkan daya saing dan pertumbuhan ekonomi serta pemerataan penghasilan. Madura merupakan sebuah pulau yang terletak disebelah utara pulau Jawa.  Pulau yang dijuluki tanah garam ini cukup dikenal dalam bidang kesenian kerapan sapi dan kerajinan batik, khususnya di Kabupaten Bangkalan. Kabupaten Bangkalan merupakan kota berkembang yang tepat untuk penerapan konsep smart city. Salah satu cara yang dapat dilakukan adalah memanfaatkan peluang kebutuhan pasar pecinta batik dengan memberikan kemudahan akses lokasi. Memanfaatkan teknologi pencarian lokasi Google maps dengan Metode Kartesius pada perangkat elektronik smartphone, konsumen akan dipermudah dalam hal pencarian informasi maupun lokasi pengrajin batik yang tersebar diseluruh wilayah Kabupaten Bangkalan.\nKata Kunci : Smart City,  Batik, Google Maps, Metode Kartesius, Smartphone Android.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100041&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100041&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100041&gt;
{&#39;Abstrak&#39;: &#39;Deteksi teks adalah proses mendeteksi teks yang ada dalam gambar, diikuti dengan mengelilinginya dengan kotak pembatas persegi panjang. Deteksi teks dapat dilakukan menggunakan teknik berbasis gambar atau teknik berbasis frekuensi. Banyak aplikasi membutuhkan deteksi teks pada gambar mulai dari deteksi otomatis rambu-rambu lalu lintas yang membantu dalam system transportasi, membantu orang tunanetra dan lain-lain. Pada penelitian ini data yang digunakan merupakan dataset focused Scene Text dengan gambar yang digunakan ukuran 640 x 480 pixel dengan format .jpg. Metode yang digunakan untuk mendeteksi teks pada gambar adalah Fast Fourier Transform (FFT) penggunaan metode fast fourier transform bertujuan meminimalkan kebutuhan memori pada citra digital, dan sejauh mana tingkat penurunan kualitas sebuah citra digital dan ukuran filenya jika dikenakan sebuah proses kompresi menggunakan metode FFT. Hasil rata-rata penelitian ini adalah precision adalah 0.44, recall 0.95 dan f1 score 0.55.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100041&gt;
{&#39;Abstrak&#39;: &#39;Deteksi teks adalah proses mendeteksi teks yang ada dalam gambar, diikuti dengan mengelilinginya dengan kotak pembatas persegi panjang. Deteksi teks dapat dilakukan menggunakan teknik berbasis gambar atau teknik berbasis frekuensi. Banyak aplikasi membutuhkan deteksi teks pada gambar mulai dari deteksi otomatis rambu-rambu lalu lintas yang membantu dalam system transportasi, membantu orang tunanetra dan lain-lain. Pada penelitian ini data yang digunakan merupakan dataset focused Scene Text dengan gambar yang digunakan ukuran 640 x 480 pixel dengan format .jpg. Metode yang digunakan untuk mendeteksi teks pada gambar adalah Fast Fourier Transform (FFT) penggunaan metode fast fourier transform bertujuan meminimalkan kebutuhan memori pada citra digital, dan sejauh mana tingkat penurunan kualitas sebuah citra digital dan ukuran filenya jika dikenakan sebuah proses kompresi menggunakan metode FFT. Hasil rata-rata penelitian ini adalah precision adalah 0.44, recall 0.95 dan f1 score 0.55.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100041&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100041&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100041&gt;
{&#39;Abstrak&#39;: &#39;Pengenalan wajah merupakan teknologi yang telah banyak dikembangkan oleh peneliti dibidang Computer Vision misalnya pada penggunaan mesin absensi atau akses kontrol. Selama ini, tahapan preprocessing pengenalan wajah telah mengalami perkembangan, namun masih memiliki kekurangan. Salah satu permasalahan yang ada mengenai preprocessing yaitu kurang optimalnya proses mendapatkan vektor proyeksi citra wajah menggunakan citra diagonal sehingga menyebabkan hilangnya beberapa informasi diskriminan yang terdapat pada citra wajah. Pada penelitian ini preprocessing dilakukan menggunakan metode image fusion. Metode yang digunakan untuk ekstraksi fitur yaitu Modified Two Dimensional Linear Discriminant Analysis. Data set yang digunakan adalah citra wajah Olivetti Research Laboratory (ORL) dengan jumlah 400 data yang terdiri dari 40 orang dan masing - masing terdiri dari 10 pose. Pada tahapan klasifikasi, metode yang digunakan yaitu Euclidean Distance. Terdapat 4 skenario pengujian yang dilakukan menggunakan semua kombinasi 4 pose hingga 7 pose data pelatihan, sehingga pengujian dapat dilakukan secara objektif dan meyeluruh. Akurasi tertinggi dan rata-rata akurasi pengenalan wajah yang diperoleh menggunakan citra original lebih tinggi sekitar 1% - 2% dibandingkan pengujian menggunakan citra image fusion.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100041&gt;
{&#39;Abstrak&#39;: &#39;Pengenalan wajah merupakan teknologi yang telah banyak dikembangkan oleh peneliti dibidang Computer Vision misalnya pada penggunaan mesin absensi atau akses kontrol. Selama ini, tahapan preprocessing pengenalan wajah telah mengalami perkembangan, namun masih memiliki kekurangan. Salah satu permasalahan yang ada mengenai preprocessing yaitu kurang optimalnya proses mendapatkan vektor proyeksi citra wajah menggunakan citra diagonal sehingga menyebabkan hilangnya beberapa informasi diskriminan yang terdapat pada citra wajah. Pada penelitian ini preprocessing dilakukan menggunakan metode image fusion. Metode yang digunakan untuk ekstraksi fitur yaitu Modified Two Dimensional Linear Discriminant Analysis. Data set yang digunakan adalah citra wajah Olivetti Research Laboratory (ORL) dengan jumlah 400 data yang terdiri dari 40 orang dan masing - masing terdiri dari 10 pose. Pada tahapan klasifikasi, metode yang digunakan yaitu Euclidean Distance. Terdapat 4 skenario pengujian yang dilakukan menggunakan semua kombinasi 4 pose hingga 7 pose data pelatihan, sehingga pengujian dapat dilakukan secara objektif dan meyeluruh. Akurasi tertinggi dan rata-rata akurasi pengenalan wajah yang diperoleh menggunakan citra original lebih tinggi sekitar 1% - 2% dibandingkan pengujian menggunakan citra image fusion.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100041&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100041&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100042&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100042&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100042&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:36 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100042&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100042&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100042&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100042&gt;
{&#39;Abstrak&#39;: &#39;Sistem pendukung keputusan merupakan suatu sistem informasi berbasis komputer yang bertujuan untuk membantu dalam proses pengambilan keputusan. Banyak metode yang dapat digunakan dalam sistem pendukung keputusan misalnya Fuzzy Mamdani dan Fuzzy Tsukamoto, yang mana dalam sebuah penelitian disebutkan bahwa metode Fuzzy Mamdani memiliki tingkat keakuratan sebesar 87% dan Fuzzy Tsukamoto menghasilkan nilai keakuratan sebesar 0,9512 sehingga dapat disimpulkan bahwa metode Fuzzy Mamdani dan Fuzzy Tsukamoto menghasilkan hasil yang sama baik. Sehingga berdasarkan permasalahan diatas dibuat sistem pendukung keputusan pemilihan sepeda motor dengan membandingkan metode Fuzzy Mamdani dan Fuzzy Tsukamoto. Hasil dari penelitian metode Fuzzy Mamdani dan Fuzzy Tsukamoto akan dibandingkan untuk mengetahui kecepatan waktu eksekusi dan ketepatan metode dalam memberikan keputusan. Dari pengujian yang telah dilakukan didapatkan hasil metode Fuzzy Tsukamoto memiliki kecepatan waktu eksekusi 0.013265 detik dari pada metode Fuzzy Mamdani yaitu 0.01256 detik. Sedangkan untuk hasil ketepatan dalam memberikan keputusan, metode Fuzzy Tsukamoto memiliki tingkat akurasi sebesar 85% dan Fuzzy Mamdani sebesar 75%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100042&gt;
{&#39;Abstrak&#39;: &#39;Sistem pendukung keputusan merupakan suatu sistem informasi berbasis komputer yang bertujuan untuk membantu dalam proses pengambilan keputusan. Banyak metode yang dapat digunakan dalam sistem pendukung keputusan misalnya Fuzzy Mamdani dan Fuzzy Tsukamoto, yang mana dalam sebuah penelitian disebutkan bahwa metode Fuzzy Mamdani memiliki tingkat keakuratan sebesar 87% dan Fuzzy Tsukamoto menghasilkan nilai keakuratan sebesar 0,9512 sehingga dapat disimpulkan bahwa metode Fuzzy Mamdani dan Fuzzy Tsukamoto menghasilkan hasil yang sama baik. Sehingga berdasarkan permasalahan diatas dibuat sistem pendukung keputusan pemilihan sepeda motor dengan membandingkan metode Fuzzy Mamdani dan Fuzzy Tsukamoto. Hasil dari penelitian metode Fuzzy Mamdani dan Fuzzy Tsukamoto akan dibandingkan untuk mengetahui kecepatan waktu eksekusi dan ketepatan metode dalam memberikan keputusan. Dari pengujian yang telah dilakukan didapatkan hasil metode Fuzzy Tsukamoto memiliki kecepatan waktu eksekusi 0.013265 detik dari pada metode Fuzzy Mamdani yaitu 0.01256 detik. Sedangkan untuk hasil ketepatan dalam memberikan keputusan, metode Fuzzy Tsukamoto memiliki tingkat akurasi sebesar 85% dan Fuzzy Mamdani sebesar 75%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100042&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100042&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100042&gt;
{&#39;Abstrak&#39;: &#39;Salah satu dampak negatif dari perkembangan teknologi adalah aksi plagiarisme yang dilakukan oleh orang-orang tidak bertanggung jawab. Plagiarisme adalah tindakan yang disengaja atau tidak disengaja dengan menggunakan atau berusaha untuk mendapatkan pengakuan atau nilai untuk studi ilmiah. Hal ini dapat terjadi dengan mengutip sebagian atau keseluruhan dari karya orang lain tanpa menyertakan sumber aslinya. Mendeteksi plagiarisme sangatlah penting dalam dunia pendidikan, karena kredibilitas lembaga ini sebagian besar didasarkan pada orisinalitas. Dapat mendeteksi plagiarisme telah menjadi salah satu tantangan tersendiri bagi dunia pendidikan, telebih sebagian besar dari pelajar atau peneliti sering melakukan kecurangan saat melakukan pekerjaannya. Penelitian sebelumnya sudah menerapkan beberapa algoritma yang berfungsi sebagai fingerprint dokumen untuk mendeteksi plagiarisme dokumen teks, diantaranya adalah algoritma Rabin-Karp dan algoritma Winnowing. Namun algoritma ini hanya bisa memeriksa setiap kata dalam file dokumen dan tidak dapat mendeteksi tindakan plagiarisme yang dilakukan dengan cara mengambil karya orang lain dalam bahasa asing kemudian ditulis ulang menggunakan bahasa yang berbeda. Diusulkan penggunaan algoritma Winnowing yang dikombinasikan dengan Google Translate API untuk meminimalisir aksi plagiarisme lintas bahasa Indonesia-Inggris. Dari hasil pengujian yang membandingkan Winnowing dengan aplikasi Plagiarism Checker X mendapatkan nilai rata-rata selisih perbedaan sebesar 0.60% dalam skala 0%-100%. Sedangkan penilaian secara umum dari hasil translasi Google Translate API yang dilakukan oleh pakar bahasa Inggris didapatkan nilai rata-rata sebesar 79.3 dalam skala 0-100.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100042&gt;
{&#39;Abstrak&#39;: &#39;Salah satu dampak negatif dari perkembangan teknologi adalah aksi plagiarisme yang dilakukan oleh orang-orang tidak bertanggung jawab. Plagiarisme adalah tindakan yang disengaja atau tidak disengaja dengan menggunakan atau berusaha untuk mendapatkan pengakuan atau nilai untuk studi ilmiah. Hal ini dapat terjadi dengan mengutip sebagian atau keseluruhan dari karya orang lain tanpa menyertakan sumber aslinya. Mendeteksi plagiarisme sangatlah penting dalam dunia pendidikan, karena kredibilitas lembaga ini sebagian besar didasarkan pada orisinalitas. Dapat mendeteksi plagiarisme telah menjadi salah satu tantangan tersendiri bagi dunia pendidikan, telebih sebagian besar dari pelajar atau peneliti sering melakukan kecurangan saat melakukan pekerjaannya. Penelitian sebelumnya sudah menerapkan beberapa algoritma yang berfungsi sebagai fingerprint dokumen untuk mendeteksi plagiarisme dokumen teks, diantaranya adalah algoritma Rabin-Karp dan algoritma Winnowing. Namun algoritma ini hanya bisa memeriksa setiap kata dalam file dokumen dan tidak dapat mendeteksi tindakan plagiarisme yang dilakukan dengan cara mengambil karya orang lain dalam bahasa asing kemudian ditulis ulang menggunakan bahasa yang berbeda. Diusulkan penggunaan algoritma Winnowing yang dikombinasikan dengan Google Translate API untuk meminimalisir aksi plagiarisme lintas bahasa Indonesia-Inggris. Dari hasil pengujian yang membandingkan Winnowing dengan aplikasi Plagiarism Checker X mendapatkan nilai rata-rata selisih perbedaan sebesar 0.60% dalam skala 0%-100%. Sedangkan penilaian secara umum dari hasil translasi Google Translate API yang dilakukan oleh pakar bahasa Inggris didapatkan nilai rata-rata sebesar 79.3 dalam skala 0-100.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100042&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100042&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100042&gt;
{&#39;Abstrak&#39;: &#39;Saat memasuki SSB (Sekolah Sepak Bola) seorang pemain berada di posisi yang di inginkan. Setelah menjadi pemain professional pemain tersebut kadang berubah posisi dari yang semestinya. Seorang pelatih akan menentukan posisi pemain yang tepat dalam permainan dengan melihat data pemain. Tugas inilah yang terkadang membuat pelatih kesulitan dalam membuat keputusan yang tepat dengan menilai pemain secara obyektif. Selain itu juga, pada umumnya proses pegambilan keputusan masih mengandalkan insting dari pelatih. Oleh karena itu, kehadiran teknologi sistem pendukung keputusan menentukan posisi pemain sepakbola oleh seorang pelatih tentulah sangat membantu untuk mencapai hasil maksimal dalam setiap pertandingan. Teknologi yang penulis tawarkan adalah membangun sistem pendukung keputusan pemilihan posisi pemain terbaik yang berasal dari data pemain menggunakan metode SAW (Simple Additive Weighting) dan Fuzzy. SAW (Simple Additive Weighting) merupakan metode penjumlahan terbobot. Konsep dasar metode SAW (Simple Additive Weighting) adalah mencari penjumlahan terbobot dari rating kinerja pada setiap alternatif pada semua kriteria. Sedangkan Fuzzy MADM digunakan untuk mencari alternatif dari sejumlah alternatif dengan kriteria tertentu.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100042&gt;
{&#39;Abstrak&#39;: &#39;Saat memasuki SSB (Sekolah Sepak Bola) seorang pemain berada di posisi yang di inginkan. Setelah menjadi pemain professional pemain tersebut kadang berubah posisi dari yang semestinya. Seorang pelatih akan menentukan posisi pemain yang tepat dalam permainan dengan melihat data pemain. Tugas inilah yang terkadang membuat pelatih kesulitan dalam membuat keputusan yang tepat dengan menilai pemain secara obyektif. Selain itu juga, pada umumnya proses pegambilan keputusan masih mengandalkan insting dari pelatih. Oleh karena itu, kehadiran teknologi sistem pendukung keputusan menentukan posisi pemain sepakbola oleh seorang pelatih tentulah sangat membantu untuk mencapai hasil maksimal dalam setiap pertandingan. Teknologi yang penulis tawarkan adalah membangun sistem pendukung keputusan pemilihan posisi pemain terbaik yang berasal dari data pemain menggunakan metode SAW (Simple Additive Weighting) dan Fuzzy. SAW (Simple Additive Weighting) merupakan metode penjumlahan terbobot. Konsep dasar metode SAW (Simple Additive Weighting) adalah mencari penjumlahan terbobot dari rating kinerja pada setiap alternatif pada semua kriteria. Sedangkan Fuzzy MADM digunakan untuk mencari alternatif dari sejumlah alternatif dengan kriteria tertentu.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100043&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100043&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100043&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100043&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100043&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100043&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100043&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100043&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100043&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100043&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100043&gt;
{&#39;Abstrak&#39;: &#39;Manajemen berkas dosen dalam dunia pendidikan formal universitas merupakan hal yang sangat penting, berkas yang berisi data penelitian, data karya ilmiah (jurnal atau prosiding), berkas pengabdian kepada masyarakat dan juga data pengajaran dosen serta data profil dosen seperti ijazah dan trakskrip nilai adalah berkas yang wajib dimiliki oleh setiap dosen. Dalam pelayanan manajemen berkas dosen masih banyak permasalahan diantaranya penyimpanan berkas dosen masih terbilang manual dengan menyimpan berkas didalam ordner sehingga berkas rentan hilang, rusak atau disebabkan hal lain. Pembuatan aplikasi ini bertujuan untuk mengelola berkas dosen sehingga lebih efektif dan efesien serta lebih aman. Pembuatan aplikasi dengan memanfaatkan salah satu media penyimpanan online yaitu google drive, dengan pembuatan aplikasi manajemen berkas dosen menggunakan penyimpanan online google drive berguna untuk mempermudah pengolahan data berkas dosen. Google drive sebagai media penyimpanan online menyediakan penyimpanan online gratis sehingga sangat efektif dan efisien untuk menyimpan banyak berkas. Dengan menyimpan berkas ke dalam google drive, berkas tidak mudah hilang dan mudah ditemukan. Berdasarkan hasil pengujian dapat disimpulkan bahwa tingkat efektivitas dan efesiensi aplikasi manajemen berkas dosen adalah sangat efektif dan efisien.\n\nKata Kunci : Manajemen Berkas Dosen, Penyimpananan Online, Google Drive&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100043&gt;
{&#39;Abstrak&#39;: &#39;Manajemen berkas dosen dalam dunia pendidikan formal universitas merupakan hal yang sangat penting, berkas yang berisi data penelitian, data karya ilmiah (jurnal atau prosiding), berkas pengabdian kepada masyarakat dan juga data pengajaran dosen serta data profil dosen seperti ijazah dan trakskrip nilai adalah berkas yang wajib dimiliki oleh setiap dosen. Dalam pelayanan manajemen berkas dosen masih banyak permasalahan diantaranya penyimpanan berkas dosen masih terbilang manual dengan menyimpan berkas didalam ordner sehingga berkas rentan hilang, rusak atau disebabkan hal lain. Pembuatan aplikasi ini bertujuan untuk mengelola berkas dosen sehingga lebih efektif dan efesien serta lebih aman. Pembuatan aplikasi dengan memanfaatkan salah satu media penyimpanan online yaitu google drive, dengan pembuatan aplikasi manajemen berkas dosen menggunakan penyimpanan online google drive berguna untuk mempermudah pengolahan data berkas dosen. Google drive sebagai media penyimpanan online menyediakan penyimpanan online gratis sehingga sangat efektif dan efisien untuk menyimpan banyak berkas. Dengan menyimpan berkas ke dalam google drive, berkas tidak mudah hilang dan mudah ditemukan. Berdasarkan hasil pengujian dapat disimpulkan bahwa tingkat efektivitas dan efesiensi aplikasi manajemen berkas dosen adalah sangat efektif dan efisien.\n\nKata Kunci : Manajemen Berkas Dosen, Penyimpananan Online, Google Drive&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100043&gt;
{&#39;Abstrak&#39;: &#39;Atribut pejalan kaki banyak digunakan dalam pengawasan visual. Teknologi yang digunakan dalam pengawasan visual salah satunya adalah Close Circuit Television (CCTV). Dalam pengawasan dunia nyata kamera CCTV biasanya dipasang pada jarak yang jauh untuk menjangkau area yang luas, dengan demikian pejalan kaki terrekam kamera CCTV dengan resolusi yang rendah, oleh karena itu, identifikasi atribut pejalan kaki penting diimplementasikan untuk mengenali pejalan kaki. Pada penelitian ini diusulkan metode Convolutional Neural Network (CNN), dengan algoritma Multi Task Learning (MTL) untuk identifikasi atribut pejalan kaki. Atribut yang digunakan dalam identifikasi atribut pejalan kaki berjumlah tujuh atribut, yaitu laki-laki, rambut panjang, sandal, celana pendek, tanpa bawaan, tas punggung, dan topi. Pada penelitian ini dilakukan uji coba jumlah lapisan konvolusi pada bagian Sharing Layer dan bagian Specific Sharing Layer. Hasil uji coba penggunaan jumlah lapisan konvolusi pada bagian Sharing Layer dan Specific Sharing Layer berpengaruh terhadap kinerja model yang dihasilkan. Semakin banyak jumlah lapisan konvolusi semakin meningkat hasil akurasi yang didapatkan, secara beturut-turut rata-rata akurasi yang dihasilkan pada bagian Sharing Layer dengan jumlah lapisan konvolusi satu, dua, dan tiga adalah sebesar 33.48%, 44.92% dan 50.77%. Sedangkan pada bagian Specific Sharing Layer jumlah lapisan konvolusi satu, dua, dan tiga secara berturut-turut memperoleh rata-rata akurasi sebesar 30.53%, 45.61% dan 50.24%. Berdasarkan uji coba yang telah dilakukan, bagian Sharing Layer dan Specific Sharing Layer mempunyai peran penting yang sama untuk meningkatkan kinerja identifikasi.\n\nKata Kunci: Identifikasi Atribut, Multi Task Learning, Convolutional Neural Network, Sharing Layer dan Specific Sharing Layer.\n?\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100043&gt;
{&#39;Abstrak&#39;: &#39;Atribut pejalan kaki banyak digunakan dalam pengawasan visual. Teknologi yang digunakan dalam pengawasan visual salah satunya adalah Close Circuit Television (CCTV). Dalam pengawasan dunia nyata kamera CCTV biasanya dipasang pada jarak yang jauh untuk menjangkau area yang luas, dengan demikian pejalan kaki terrekam kamera CCTV dengan resolusi yang rendah, oleh karena itu, identifikasi atribut pejalan kaki penting diimplementasikan untuk mengenali pejalan kaki. Pada penelitian ini diusulkan metode Convolutional Neural Network (CNN), dengan algoritma Multi Task Learning (MTL) untuk identifikasi atribut pejalan kaki. Atribut yang digunakan dalam identifikasi atribut pejalan kaki berjumlah tujuh atribut, yaitu laki-laki, rambut panjang, sandal, celana pendek, tanpa bawaan, tas punggung, dan topi. Pada penelitian ini dilakukan uji coba jumlah lapisan konvolusi pada bagian Sharing Layer dan bagian Specific Sharing Layer. Hasil uji coba penggunaan jumlah lapisan konvolusi pada bagian Sharing Layer dan Specific Sharing Layer berpengaruh terhadap kinerja model yang dihasilkan. Semakin banyak jumlah lapisan konvolusi semakin meningkat hasil akurasi yang didapatkan, secara beturut-turut rata-rata akurasi yang dihasilkan pada bagian Sharing Layer dengan jumlah lapisan konvolusi satu, dua, dan tiga adalah sebesar 33.48%, 44.92% dan 50.77%. Sedangkan pada bagian Specific Sharing Layer jumlah lapisan konvolusi satu, dua, dan tiga secara berturut-turut memperoleh rata-rata akurasi sebesar 30.53%, 45.61% dan 50.24%. Berdasarkan uji coba yang telah dilakukan, bagian Sharing Layer dan Specific Sharing Layer mempunyai peran penting yang sama untuk meningkatkan kinerja identifikasi.\n\nKata Kunci: Identifikasi Atribut, Multi Task Learning, Convolutional Neural Network, Sharing Layer dan Specific Sharing Layer.\n?\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100043&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100043&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100044&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100044&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100044&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100044&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100044&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100044&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100044&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100044&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100044&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100044&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100044&gt;
{&#39;Abstrak&#39;: &#39;Pada saat ini, kredit sangat diminati oleh masyarakat dikarenakan dengan mengajukan permintaan kredit, masyarakat dapat membuka usaha atau untuk mengembangkan usahanya agar lebih maju. Bank BPR UMKM sendiri bergerak dalam bidang perkreditan usaha rakyat yang dimana sistem keputusan pemberian kreditnya masih menggunakan perhitungan manual dimana resiko adanya kredit yang bermasalah masih tinggi. Oleh sebab itu diperlukan sistem pendukung keputusan kelayakan kredit pada Bank BPR UMKM untuk mengetahui seberapa cepat proses yang dilakukan oleh pihak bank untuk melakukan penialaian kelayakan kredit menggunakan sistem ini. Berkaitan dengan tujuan tersebut penelitian ini menerapkan metode logika fuzzy tsukamoto. Dari data uji sebanyak 50 data yang telah dilakukan menghasilkan tingkat akurasi sebesar 90% &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100044&gt;
{&#39;Abstrak&#39;: &#39;Pada saat ini, kredit sangat diminati oleh masyarakat dikarenakan dengan mengajukan permintaan kredit, masyarakat dapat membuka usaha atau untuk mengembangkan usahanya agar lebih maju. Bank BPR UMKM sendiri bergerak dalam bidang perkreditan usaha rakyat yang dimana sistem keputusan pemberian kreditnya masih menggunakan perhitungan manual dimana resiko adanya kredit yang bermasalah masih tinggi. Oleh sebab itu diperlukan sistem pendukung keputusan kelayakan kredit pada Bank BPR UMKM untuk mengetahui seberapa cepat proses yang dilakukan oleh pihak bank untuk melakukan penialaian kelayakan kredit menggunakan sistem ini. Berkaitan dengan tujuan tersebut penelitian ini menerapkan metode logika fuzzy tsukamoto. Dari data uji sebanyak 50 data yang telah dilakukan menghasilkan tingkat akurasi sebesar 90% &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100044&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100044&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100044&gt;
{&#39;Abstrak&#39;: &#39;Topik deteksi objek telah menarik perhatian yang besar dalam perkembangan teknologi terutama bidang computer vision. Deteksi objek memiliki peranan sangat penting dalam kehidupan sehari hari, seperti sistem keamanan pada area umum yang digunakan untuk membantu polisi dalam mencari tersangka kejahatan, serta digunakan dalam mengidentifikasi keramaian suatu area. Salah satu contoh metode one stage detector adalah algoritma You Only Look Once versi 2 (YOLO v2). YOLO v2 menggabungkan dua proses yang berbeda dilakukan secara bersamaan dalam satu framework sehingga mengurangi waktu komputasi. Terdapat lima tahap YOLO v2 dalam penelitian ini, yaitu menentukan jumlah dan ukuran anchor box dalam setiap grid, pembentukan data target, menentukan arsitektur YOLO v2, proses pelatihan dan pengujian. Dari hasil pengujian yang telah dilakukan menghasikan kesimpulan bahwa penggunaan pretrained model dan jumlah epoch pada pelatihan berpengaruh terhadap akurasi yang dihasilkan, didapatkan jumlah epoch pelatihan terbaik untuk dapat mendeteksi manusia pada sebuah citra adalah sebanyak 200 epoch dengan menggunakan pretrained model yang menghasilkan rata-rata f1-score sebesar 64.1%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:37 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100044&gt;
{&#39;Abstrak&#39;: &#39;Topik deteksi objek telah menarik perhatian yang besar dalam perkembangan teknologi terutama bidang computer vision. Deteksi objek memiliki peranan sangat penting dalam kehidupan sehari hari, seperti sistem keamanan pada area umum yang digunakan untuk membantu polisi dalam mencari tersangka kejahatan, serta digunakan dalam mengidentifikasi keramaian suatu area. Salah satu contoh metode one stage detector adalah algoritma You Only Look Once versi 2 (YOLO v2). YOLO v2 menggabungkan dua proses yang berbeda dilakukan secara bersamaan dalam satu framework sehingga mengurangi waktu komputasi. Terdapat lima tahap YOLO v2 dalam penelitian ini, yaitu menentukan jumlah dan ukuran anchor box dalam setiap grid, pembentukan data target, menentukan arsitektur YOLO v2, proses pelatihan dan pengujian. Dari hasil pengujian yang telah dilakukan menghasikan kesimpulan bahwa penggunaan pretrained model dan jumlah epoch pada pelatihan berpengaruh terhadap akurasi yang dihasilkan, didapatkan jumlah epoch pelatihan terbaik untuk dapat mendeteksi manusia pada sebuah citra adalah sebanyak 200 epoch dengan menggunakan pretrained model yang menghasilkan rata-rata f1-score sebesar 64.1%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100045&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100045&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100045&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100045&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100045&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100045&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100045&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100045&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100045&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100045&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100045&gt;
{&#39;Abstrak&#39;: &#39;Rekam medis dalam dunia kedokteran merupakan hal yang sangat penting, data rekam medis bersifat pribadi dan wajib bagi pasien saat menjalani pelayanan kesehatan. Dalam peningkatan pelayanan kesehatan masih banyak permasalahan diantaranya sistem pencatatan rekam medis masih tradisional dan belum menggunakan basis data dalam penyimpanannya serta masih banyak keluhan kartu kunjungan hilang atau ketinggalan saat pasien ingin berobat. Pengembangan  aplikasi ini bertujuan untuk mengelola data rekam medis pasien sehingga lebih efisien dan lebih aman. Maka dari itu, diperlukan pengembangan aplikasi rekam medis berbasis fingerprint dengan mengembangkan aplikasi rekam medis berbasis fingerprint berguna untuk mempermudah dalam pengolahan data rekam medis hingga sampai pada pembuatan laporan rekam medis. Aplikasi rekam medis berbasis fingerprint pasien mencakup pelolahan data rekam medis yang bersifat pribadi dan rahasia. Maka sistem ini diperlukan juga penerapan algoritma dalam mengamankan data rekam medis. Adapun algoritma yang digunakan untuk mengamankan data hasil diagnosis pasien yaitu dengan menggunakan algoritma AES 256. Setelah tahapan implementasi selesai diperoleh hasil, yaitu proses pengolahan data pasien lebih cepat, penyimpanan data lebih rapih, keamanan data lebih terjamin karena sudah dilengkapi dengan proses validasi user serta penerapan algoritma, dan dalam pembuatan laporan waktu yang dibutuhkan menjadi lebih singkat dibanding sebelumnya. Diharapkan aplikasi ini juga dapat membantu meberikan kinerja kegiatan pelayanan data rekam medis pasien yang lebih nyaman. Berdasarkan hasil pengujian diperoleh perbandingan antara sistem manual puskesmas dengan sistem aplikasi memperoleh hasil rata-rata yaitu 11 menit dengan menggunakan sistem aplikasi sedangankan dengan menggunakan sistem menual Puskesmas Socah yaitu 18 menit dengan selisih waktu 7 menit. Dapat disimpulkan bahwa aplikasi rekam medis pasien berbasis fingerprint adalah sangat efektif dalam proses pelayanan rekam medis pasien dibanding dengan sistem manual Puskesmas Socah dan menjadikan teknologi fingerprint sebagai pengganti kartu berobat pasien.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100045&gt;
{&#39;Abstrak&#39;: &#39;Rekam medis dalam dunia kedokteran merupakan hal yang sangat penting, data rekam medis bersifat pribadi dan wajib bagi pasien saat menjalani pelayanan kesehatan. Dalam peningkatan pelayanan kesehatan masih banyak permasalahan diantaranya sistem pencatatan rekam medis masih tradisional dan belum menggunakan basis data dalam penyimpanannya serta masih banyak keluhan kartu kunjungan hilang atau ketinggalan saat pasien ingin berobat. Pengembangan  aplikasi ini bertujuan untuk mengelola data rekam medis pasien sehingga lebih efisien dan lebih aman. Maka dari itu, diperlukan pengembangan aplikasi rekam medis berbasis fingerprint dengan mengembangkan aplikasi rekam medis berbasis fingerprint berguna untuk mempermudah dalam pengolahan data rekam medis hingga sampai pada pembuatan laporan rekam medis. Aplikasi rekam medis berbasis fingerprint pasien mencakup pelolahan data rekam medis yang bersifat pribadi dan rahasia. Maka sistem ini diperlukan juga penerapan algoritma dalam mengamankan data rekam medis. Adapun algoritma yang digunakan untuk mengamankan data hasil diagnosis pasien yaitu dengan menggunakan algoritma AES 256. Setelah tahapan implementasi selesai diperoleh hasil, yaitu proses pengolahan data pasien lebih cepat, penyimpanan data lebih rapih, keamanan data lebih terjamin karena sudah dilengkapi dengan proses validasi user serta penerapan algoritma, dan dalam pembuatan laporan waktu yang dibutuhkan menjadi lebih singkat dibanding sebelumnya. Diharapkan aplikasi ini juga dapat membantu meberikan kinerja kegiatan pelayanan data rekam medis pasien yang lebih nyaman. Berdasarkan hasil pengujian diperoleh perbandingan antara sistem manual puskesmas dengan sistem aplikasi memperoleh hasil rata-rata yaitu 11 menit dengan menggunakan sistem aplikasi sedangankan dengan menggunakan sistem menual Puskesmas Socah yaitu 18 menit dengan selisih waktu 7 menit. Dapat disimpulkan bahwa aplikasi rekam medis pasien berbasis fingerprint adalah sangat efektif dalam proses pelayanan rekam medis pasien dibanding dengan sistem manual Puskesmas Socah dan menjadikan teknologi fingerprint sebagai pengganti kartu berobat pasien.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100045&gt;
{&#39;Abstrak&#39;: &#39;Monitoring kegiatan asrama Universitas Trunojoyo Madura diperlukan agar pendidikan karakter di asrama dapat berjalan dengan maksimal yang diimplementasikan melalui sebuah aplikasi monitoring &amp; evaluasi  kegiatan asrama dengan menerapkan teknologi web service yang diimplementasikan melalui web sebagai server dan diakses melalui android untuk client, aplikasi ini berjalan sesuai dengan fungsionalitas aplikasi dan sesuai dengan kebutuhan monitoring &amp; evaluasi kegiatan asrama dengan nilai sebesar 88,8%, untuk mendapatkan hasil evaluasi yang objektif maka diterapkan metode SMART (Simple Multi Attribute Rating Technique) untuk memutuskan warga yang akan menetap di asrama. Hasil akurasi pengujian penerapan metode SMART menghasilkan tingkat akurasi 65% yang menunjukkan bahwa hasil penilaian menggunakan metode SMART Lebih objektif san akurat dibandingkan  dengan penilaian pengurus asrama.\nKata kunci: Evaluasi, Monitoring, Metode SMART.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100045&gt;
{&#39;Abstrak&#39;: &#39;Monitoring kegiatan asrama Universitas Trunojoyo Madura diperlukan agar pendidikan karakter di asrama dapat berjalan dengan maksimal yang diimplementasikan melalui sebuah aplikasi monitoring &amp; evaluasi  kegiatan asrama dengan menerapkan teknologi web service yang diimplementasikan melalui web sebagai server dan diakses melalui android untuk client, aplikasi ini berjalan sesuai dengan fungsionalitas aplikasi dan sesuai dengan kebutuhan monitoring &amp; evaluasi kegiatan asrama dengan nilai sebesar 88,8%, untuk mendapatkan hasil evaluasi yang objektif maka diterapkan metode SMART (Simple Multi Attribute Rating Technique) untuk memutuskan warga yang akan menetap di asrama. Hasil akurasi pengujian penerapan metode SMART menghasilkan tingkat akurasi 65% yang menunjukkan bahwa hasil penilaian menggunakan metode SMART Lebih objektif san akurat dibandingkan  dengan penilaian pengurus asrama.\nKata kunci: Evaluasi, Monitoring, Metode SMART.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100045&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100045&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100046&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100046&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100046&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100046&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100046&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100046&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100046&gt;
{&#39;Abstrak&#39;: &#39;Proses seleksi penerimaan tenaga kerja merupakan faktor penting yang harus diperhitungkan. Begitupun dengan masalah yang dihadapi PT Satya yang belum menggunakan kriteria tetap dalam seleksi penerimaan tenaga kerjanya. Solusi yang ditawarkan adalah dengan membuat sistem pendukung keputusan penerimaan satpam dengan metode Technique for Others Reference by Similarity to Ideal Solution (TOPSIS) yang merupakan salah satu metode dalam Multiple Attribute Decision Making (MADM) yang menyelesaikan dengan pengambilan keputusan mulitikriteria. Metode ini sangat sesuai dengan kebutuhan sistem dimana memiliki banyak kriteria.Penelitian ini menghasilkan aplikasi sistem pendukung keputusan yang dapat menghitung dan merangking berdasarkan kriteria yang telah dibobot perusahaan. Hasil pengujian berjalan sesuai yang direncanakan dan menghasilkan sebuah perangkingan dengan akurasi mencapai 66% yang dapat membantu HRD perusahaan .&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100046&gt;
{&#39;Abstrak&#39;: &#39;Proses seleksi penerimaan tenaga kerja merupakan faktor penting yang harus diperhitungkan. Begitupun dengan masalah yang dihadapi PT Satya yang belum menggunakan kriteria tetap dalam seleksi penerimaan tenaga kerjanya. Solusi yang ditawarkan adalah dengan membuat sistem pendukung keputusan penerimaan satpam dengan metode Technique for Others Reference by Similarity to Ideal Solution (TOPSIS) yang merupakan salah satu metode dalam Multiple Attribute Decision Making (MADM) yang menyelesaikan dengan pengambilan keputusan mulitikriteria. Metode ini sangat sesuai dengan kebutuhan sistem dimana memiliki banyak kriteria.Penelitian ini menghasilkan aplikasi sistem pendukung keputusan yang dapat menghitung dan merangking berdasarkan kriteria yang telah dibobot perusahaan. Hasil pengujian berjalan sesuai yang direncanakan dan menghasilkan sebuah perangkingan dengan akurasi mencapai 66% yang dapat membantu HRD perusahaan .&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100046&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100046&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100046&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100046&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100046&gt;
{&#39;Abstrak&#39;: &#39;Belimbing manis (Averhoa Carambola L.) merupakan salah satu\npotensi hortikultura yang bersifat komersial dan berpeluang sebagai sumber pendapatan bagi masyarakat. Banyak masyarakat yang ingin membudidayakan buah belimbing, akan tetapi buah belimbing sangat rentan terhadap organisme pengganggu tanaman hal ini dapat membuat petani harus berpikir ulang. Masalah utama yang terdapat pada buah belimbing yaitu serangan hama lalat buah dan ulat buah yang memiliki gejala hampir sama, jika tidak dilakukan penanganan secara benar akan mengakibatkan dampak yang tidak diinginkan seperti kegagalan panen sehingga dapat mengakibatkan produksi buah belimbing berkurang. Dalam penelitian ini menggunakan metode Decision Tree C4.5. Metode Decision Tree C4.5 merupakan metode yang digunakan untuk klasifikasi berdasarkan cabang pohon atau pertanyaan klasifikasi dan daun atau disebut dengan kelas. Akurasi yang diperoleh sistem diagnosa penyakit buah belimbing dengan dilakukan pengujian K-Fold Cross Validation untuk membagi data menjadi 5 bagian yang terdiri dari 160 data training dan 40 data testing diperoleh nilai rata-rata akurasi menggunakan metode Confusion Matrix sebesar 99.5%. Hasil perhitungan rata-rata F-Measure diperoleh nilai akurasi Precision dan Recall lalat buah sebesar 99.62% dan ulat buah sebesar 99.62%. Tingkat kelayakan pemodelan pada sistem diagnosa penyakit buah belimbing diperoleh nilai rata-rata akurasi sebesar 94.57% yang melibatkan 6 responden dengan pertanyaan kuesioner sebanyak 10.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100046&gt;
{&#39;Abstrak&#39;: &#39;Belimbing manis (Averhoa Carambola L.) merupakan salah satu\npotensi hortikultura yang bersifat komersial dan berpeluang sebagai sumber pendapatan bagi masyarakat. Banyak masyarakat yang ingin membudidayakan buah belimbing, akan tetapi buah belimbing sangat rentan terhadap organisme pengganggu tanaman hal ini dapat membuat petani harus berpikir ulang. Masalah utama yang terdapat pada buah belimbing yaitu serangan hama lalat buah dan ulat buah yang memiliki gejala hampir sama, jika tidak dilakukan penanganan secara benar akan mengakibatkan dampak yang tidak diinginkan seperti kegagalan panen sehingga dapat mengakibatkan produksi buah belimbing berkurang. Dalam penelitian ini menggunakan metode Decision Tree C4.5. Metode Decision Tree C4.5 merupakan metode yang digunakan untuk klasifikasi berdasarkan cabang pohon atau pertanyaan klasifikasi dan daun atau disebut dengan kelas. Akurasi yang diperoleh sistem diagnosa penyakit buah belimbing dengan dilakukan pengujian K-Fold Cross Validation untuk membagi data menjadi 5 bagian yang terdiri dari 160 data training dan 40 data testing diperoleh nilai rata-rata akurasi menggunakan metode Confusion Matrix sebesar 99.5%. Hasil perhitungan rata-rata F-Measure diperoleh nilai akurasi Precision dan Recall lalat buah sebesar 99.62% dan ulat buah sebesar 99.62%. Tingkat kelayakan pemodelan pada sistem diagnosa penyakit buah belimbing diperoleh nilai rata-rata akurasi sebesar 94.57% yang melibatkan 6 responden dengan pertanyaan kuesioner sebanyak 10.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100046&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100046&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100047&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100047&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100047&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100047&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100047&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100047&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100047&gt;
{&#39;Abstrak&#39;: &#39;-&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100047&gt;
{&#39;Abstrak&#39;: &#39;-&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100047&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100047&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100047&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:38 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100047&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100047&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100047&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100047&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100047&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100048&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100048&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100048&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100048&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100048&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100048&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100048&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100048&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100048&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100048&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100048&gt;
{&#39;Abstrak&#39;: &#39;ABSTRAK \nPemerintahan Desa (kelurahan) merupakan satu pemerintahan yang bertugas mengelola dan mempunyai kewajiban dalam melayani administrasi penduduk di tingkat desa. Proses adminnistrasi penduduk di Desa Larangan Dalam, Pamekasan, Madura ini sekarang masih berjalan manual yaitu seperti proses pengajuan atau pendaftaran bagi penduduk yang ingin mengajukan surat keterangan dll, masih terbilang cukup sulit, karena penduduk harus mendatangi rumah petugas desa dan masih diproses sehari setelah pengajuan tersebut, dan juga penyediaan berkas yang masih tidak efektif karena sistem penyimpanan berkas saat ini masih terbilang tradisional dengan menyimpan berkas dalam ordner. Penyimpanan berkas digital sebagai Salinan berkas asli masih dikelola secara manual yang kemudian semakin tidak terstruktur sehingga kurang efisien. Dari permasalahan di atas akan mengimplementasikan metode Model View Controller (MVC) untuk proses membangun aplikasi yang berbasis web dan API Disdukcapil untuk mempermudah petugas desa mendapatkan data diri dari penduduk yang melakukan proses administrasi dengan hanya memasukkan NIK. Harapan dari penelitian ini, aplikasi Pelayanan Administrasi Desa yang berbasis web dapat mempermudah petugas desa dalam pemprosesan administras yang diajuakan penduduk desa agar lebih efektif dan efisien serta terstruktur. \n \nKata Kunci : Administrasi Desa, Surat, Metode MVC, Framework Laravel.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100048&gt;
{&#39;Abstrak&#39;: &#39;ABSTRAK \nPemerintahan Desa (kelurahan) merupakan satu pemerintahan yang bertugas mengelola dan mempunyai kewajiban dalam melayani administrasi penduduk di tingkat desa. Proses adminnistrasi penduduk di Desa Larangan Dalam, Pamekasan, Madura ini sekarang masih berjalan manual yaitu seperti proses pengajuan atau pendaftaran bagi penduduk yang ingin mengajukan surat keterangan dll, masih terbilang cukup sulit, karena penduduk harus mendatangi rumah petugas desa dan masih diproses sehari setelah pengajuan tersebut, dan juga penyediaan berkas yang masih tidak efektif karena sistem penyimpanan berkas saat ini masih terbilang tradisional dengan menyimpan berkas dalam ordner. Penyimpanan berkas digital sebagai Salinan berkas asli masih dikelola secara manual yang kemudian semakin tidak terstruktur sehingga kurang efisien. Dari permasalahan di atas akan mengimplementasikan metode Model View Controller (MVC) untuk proses membangun aplikasi yang berbasis web dan API Disdukcapil untuk mempermudah petugas desa mendapatkan data diri dari penduduk yang melakukan proses administrasi dengan hanya memasukkan NIK. Harapan dari penelitian ini, aplikasi Pelayanan Administrasi Desa yang berbasis web dapat mempermudah petugas desa dalam pemprosesan administras yang diajuakan penduduk desa agar lebih efektif dan efisien serta terstruktur. \n \nKata Kunci : Administrasi Desa, Surat, Metode MVC, Framework Laravel.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100048&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100048&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100048&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100048&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100049&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100049&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100049&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100049&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100049&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100049&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100049&gt;
{&#39;Abstrak&#39;: &#39;Sepak bola merupakan salah satu yang paling popular dalam penonton dan partisipasi dalam olahraga di dunia ini. Angka yang adamenunjukkan bahwa popularitas sepak bola tidak dibatasi oleh geografi, usia, budaya dan jenis kelamin. Dalam olahraga sepak bola, setiap pemain selain kiper dapat dikategorikan ke dalam salah satu dari tiga posisi: bek, gelandang, penyerang. Kombinasi dari gaya permainan yang berbeda dari pemain di lapangan disebut sebagai formasi. Sebuah formasi membutuhkan pemain yang sesuai dengan skema permainan. Pelatih memiliki wewenang tertinggi dalam menentukan pemain dan juga formasi tim. Kesalahan dalam menentukan pemain akan berakibat fatal pada sebuah tim yang tidak memenuhi ekspektasi tim dan juga dalam penentuan pemain yang dipilih oleh pelatih tidak sesuai antara standar yang diinginkan pelatih dengan skill atau kemampuan tiap pemain. Untuk mempermudah dalam menentukan pemain dibutuhkan sistem yang bisa merekemondasikan pemain yang mampu menyeleksi dan memilih pemain yang terbaik dari nilai-nilai tiap pemain dan kemudian pemain yang terpilih dibentuk dengan gaya dan skema permainan yang diinginkan. Dengan menggunakan metode fuzzy tsukamoto sekiranya bisa membantu menghasilkan starting line up sepak bola sesuai harapan. Dari hasil akhir perhitungan metode fuzzy tsukamoto bisa diketahui nilai akhir setiap pemain dan pelatih bisa melihat dan menentukan pemain yang layak untuk starting line up. Hasil dari penilaian metode fuzzy tsukamoto ini menghasilkan akurasi 67%, dimana nilai didapat dari perbandingan antara rekomendasi hasil sistem dan rekomendasi dari line up pelatih saat pertandingan.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100049&gt;
{&#39;Abstrak&#39;: &#39;Sepak bola merupakan salah satu yang paling popular dalam penonton dan partisipasi dalam olahraga di dunia ini. Angka yang adamenunjukkan bahwa popularitas sepak bola tidak dibatasi oleh geografi, usia, budaya dan jenis kelamin. Dalam olahraga sepak bola, setiap pemain selain kiper dapat dikategorikan ke dalam salah satu dari tiga posisi: bek, gelandang, penyerang. Kombinasi dari gaya permainan yang berbeda dari pemain di lapangan disebut sebagai formasi. Sebuah formasi membutuhkan pemain yang sesuai dengan skema permainan. Pelatih memiliki wewenang tertinggi dalam menentukan pemain dan juga formasi tim. Kesalahan dalam menentukan pemain akan berakibat fatal pada sebuah tim yang tidak memenuhi ekspektasi tim dan juga dalam penentuan pemain yang dipilih oleh pelatih tidak sesuai antara standar yang diinginkan pelatih dengan skill atau kemampuan tiap pemain. Untuk mempermudah dalam menentukan pemain dibutuhkan sistem yang bisa merekemondasikan pemain yang mampu menyeleksi dan memilih pemain yang terbaik dari nilai-nilai tiap pemain dan kemudian pemain yang terpilih dibentuk dengan gaya dan skema permainan yang diinginkan. Dengan menggunakan metode fuzzy tsukamoto sekiranya bisa membantu menghasilkan starting line up sepak bola sesuai harapan. Dari hasil akhir perhitungan metode fuzzy tsukamoto bisa diketahui nilai akhir setiap pemain dan pelatih bisa melihat dan menentukan pemain yang layak untuk starting line up. Hasil dari penilaian metode fuzzy tsukamoto ini menghasilkan akurasi 67%, dimana nilai didapat dari perbandingan antara rekomendasi hasil sistem dan rekomendasi dari line up pelatih saat pertandingan.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100049&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100049&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100049&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100049&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100049&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100049&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100049&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:39 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100049&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100050&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100050&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100050&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100050&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100050&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100050&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100050&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100050&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100050&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100050&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100050&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100050&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100050&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100050&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100050&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100050&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100051&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100051&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100051&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100051&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100051&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100051&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100051&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100051&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100051&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100051&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100051&gt;
{&#39;Abstrak&#39;: &#39;ABSTRAK\nKendaraan bermotor adalah alat transportasi yang cukup digemari terutama kendaraan bermotor roda empat yang semakin meningkat. Kesadaran masyarakat dan kurang efisiennya sistem lalu lintas memberikan dampak waktu empuh dalam melakukan perjalanan, dampak yang lebih parah yakni lumpuhnya lalulintas di kota-kota besar. Dari permasalahan tersebut, penelitian ini melakukan deteksi letak plat nomor menggunakan metode Harris Corner dan segmentasi karakter plat nomor menggunakan Otsu Threshold sebagai salah satu upaya untuk menerapkan sistem lalu lintas cerdas. Dengan menggunakan data uji sebanyak 100 citra kendraan bermotor, hasil deteksi letak plat nomor menggunakan Harris Corner sebesar 90%, sedangkan segmentasi karakter plat nomor menggunakan metode Otsu Threshold mempunyai hasil akurasi sebesar 84,14%. Keduanya memiliki akurasi yang cukup tinggi dan bisa menjadi opsi untuk menghindari lumpuhnya lalu lintas terutama pada pintu masuk tol.\n\nKata Kunci :Deteksi letak plat nomor, Harris corner, Segmentasi karakter, otsu threshold.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100051&gt;
{&#39;Abstrak&#39;: &#39;ABSTRAK\nKendaraan bermotor adalah alat transportasi yang cukup digemari terutama kendaraan bermotor roda empat yang semakin meningkat. Kesadaran masyarakat dan kurang efisiennya sistem lalu lintas memberikan dampak waktu empuh dalam melakukan perjalanan, dampak yang lebih parah yakni lumpuhnya lalulintas di kota-kota besar. Dari permasalahan tersebut, penelitian ini melakukan deteksi letak plat nomor menggunakan metode Harris Corner dan segmentasi karakter plat nomor menggunakan Otsu Threshold sebagai salah satu upaya untuk menerapkan sistem lalu lintas cerdas. Dengan menggunakan data uji sebanyak 100 citra kendraan bermotor, hasil deteksi letak plat nomor menggunakan Harris Corner sebesar 90%, sedangkan segmentasi karakter plat nomor menggunakan metode Otsu Threshold mempunyai hasil akurasi sebesar 84,14%. Keduanya memiliki akurasi yang cukup tinggi dan bisa menjadi opsi untuk menghindari lumpuhnya lalu lintas terutama pada pintu masuk tol.\n\nKata Kunci :Deteksi letak plat nomor, Harris corner, Segmentasi karakter, otsu threshold.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100051&gt;
{&#39;Abstrak&#39;: &#39;Citra adalah salah satu bentuk data yang banyak digunakan untuk mendapatkan informasi. Content Based Image Retrieval (CBIR) atau Temu Kembali Citra Berbasis Isi merupakan suatu sistem untuk mendapatkan kembali citra berdasarkan content dari citra, yaitu dengan menggunakan citra sebagai query. Dalam penerapannya pencarian menggunakan CBIR dapat menghasilkan pencarian yang sesuai dengan query citra , tetapi seringkali tidak seperti apa yang diinginkan oleh pengguna. Oleh karena itu untuk mengatasi permasalahan tersebut digunakan relevance feedback atau umpan balik untuk mendapatkan masukan dari pengguna, yang dikombinasikan CBIR. Terdapat  4 tahapan utama dalam penelitian ini, pertama proses ekstraksi fitur pada warna dan tekstur mengunakan Integrated Color and Intensity Co-occurrence Matrix (ICICM), kedua, pengukuran kemiripan dengan Cosine similarity, ketiga, pembentukan query baru dengan Algoritma Rocchio, dan tahap terakhir adalah pengukuran kemiripan dengan Cosine similarity. Pada penelitian akan dilakukan beberapa skenario percobaan untuk mengetahui akurasi dari precision dan recall dari hasil retrieval. Uji coba dilakukan pada dataset Corel 1000 image database dari Semantics-Sensitive Integrated Matching for Picture Libraries dan 100 citra gedung Universitas Trunojoyo Madura. Dari hasil uji coba yang telah dilakukan membuktikan bahwa kombinasi ICICM dan Algoritma Rocchio untuk temu kembali citra berbasis isi dengan Relevance Feedback  mendapatkan kenaikan akurasi sebesar 17%, yaitu dengan mendapatkan akurasi precision tertinggi sebesar 0,9628548, sedangkan tanpa menggunakan relevance feedback hanya mendapatkan akurasi precision sebesar 0,7940402.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100051&gt;
{&#39;Abstrak&#39;: &#39;Citra adalah salah satu bentuk data yang banyak digunakan untuk mendapatkan informasi. Content Based Image Retrieval (CBIR) atau Temu Kembali Citra Berbasis Isi merupakan suatu sistem untuk mendapatkan kembali citra berdasarkan content dari citra, yaitu dengan menggunakan citra sebagai query. Dalam penerapannya pencarian menggunakan CBIR dapat menghasilkan pencarian yang sesuai dengan query citra , tetapi seringkali tidak seperti apa yang diinginkan oleh pengguna. Oleh karena itu untuk mengatasi permasalahan tersebut digunakan relevance feedback atau umpan balik untuk mendapatkan masukan dari pengguna, yang dikombinasikan CBIR. Terdapat  4 tahapan utama dalam penelitian ini, pertama proses ekstraksi fitur pada warna dan tekstur mengunakan Integrated Color and Intensity Co-occurrence Matrix (ICICM), kedua, pengukuran kemiripan dengan Cosine similarity, ketiga, pembentukan query baru dengan Algoritma Rocchio, dan tahap terakhir adalah pengukuran kemiripan dengan Cosine similarity. Pada penelitian akan dilakukan beberapa skenario percobaan untuk mengetahui akurasi dari precision dan recall dari hasil retrieval. Uji coba dilakukan pada dataset Corel 1000 image database dari Semantics-Sensitive Integrated Matching for Picture Libraries dan 100 citra gedung Universitas Trunojoyo Madura. Dari hasil uji coba yang telah dilakukan membuktikan bahwa kombinasi ICICM dan Algoritma Rocchio untuk temu kembali citra berbasis isi dengan Relevance Feedback  mendapatkan kenaikan akurasi sebesar 17%, yaitu dengan mendapatkan akurasi precision tertinggi sebesar 0,9628548, sedangkan tanpa menggunakan relevance feedback hanya mendapatkan akurasi precision sebesar 0,7940402.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100051&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100051&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100052&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100052&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100052&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100052&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100052&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:40 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100052&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100052&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100052&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100052&gt;
{&#39;Abstrak&#39;: &#39;Tuberkulosis merupakan penyakit yang disebabkan oleh bakteri, dapat ditularkan melalui dahak ataupun udara. Penyakit ini dapat menyerang semua usia dari berbagai kalangan, namun kebanyakan yang mengidap tuberkulosis adalah usia produktif antara 15 – 55 tahun. Sedangkan banyak masyarakat yang tidak mengetahui bahaya dari penyakit tuberkulosis, masyarakat enggan melakukan pemeriksaan karena membutuhkan serangkaian pengujian laboraturium. Sehingga perlu adanya sistem pakar yang dapat membantu dalam melakukan diagnosis dini pada penyakit tuberkulosis untuk menggurangi penyebaran dan mempercepat penangganan pasien. Sistem pakar diagnosis penyakit tuberkulosis ini menerapkan algoritma Naïve bayes yang menghasilkan keputusan dari konsultasi menjawab beberapa pertanyaan berupa gejala – gejala yang dialami, selain itu agar penderita dapat memiliki status gizi yang baik untuk membantu proses penyembuhan dibutuhkan menu diet yang diimplementasi melalui metode Forward chaining dengan memanfaatkan fakta - fakta yang dimiliki pengguna untuk dicocokkan dengan aturan yang ada pada sistem. Sistem ini memilki tingkat akurasi 97,2% pada diagnosis dengan naive bayes dan 93% pada rekomendasi menu diet dengan metode forward chaining.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100052&gt;
{&#39;Abstrak&#39;: &#39;Tuberkulosis merupakan penyakit yang disebabkan oleh bakteri, dapat ditularkan melalui dahak ataupun udara. Penyakit ini dapat menyerang semua usia dari berbagai kalangan, namun kebanyakan yang mengidap tuberkulosis adalah usia produktif antara 15 – 55 tahun. Sedangkan banyak masyarakat yang tidak mengetahui bahaya dari penyakit tuberkulosis, masyarakat enggan melakukan pemeriksaan karena membutuhkan serangkaian pengujian laboraturium. Sehingga perlu adanya sistem pakar yang dapat membantu dalam melakukan diagnosis dini pada penyakit tuberkulosis untuk menggurangi penyebaran dan mempercepat penangganan pasien. Sistem pakar diagnosis penyakit tuberkulosis ini menerapkan algoritma Naïve bayes yang menghasilkan keputusan dari konsultasi menjawab beberapa pertanyaan berupa gejala – gejala yang dialami, selain itu agar penderita dapat memiliki status gizi yang baik untuk membantu proses penyembuhan dibutuhkan menu diet yang diimplementasi melalui metode Forward chaining dengan memanfaatkan fakta - fakta yang dimiliki pengguna untuk dicocokkan dengan aturan yang ada pada sistem. Sistem ini memilki tingkat akurasi 97,2% pada diagnosis dengan naive bayes dan 93% pada rekomendasi menu diet dengan metode forward chaining.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100052&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100052&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100053&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100053&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100052&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100052&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100053&gt;
{&#39;Abstrak&#39;: &#39;Dalam proses pengambilan keputusan terdapat banyak kriteria dan banyak pula metode yang digunakan. Permasalahannya adalah bagaimana menentukan kriteria-kriteria dan metode-metode yang tepat untuk mendukung proses pengambilan keputusan dalam membantu pemilihan guru teladan SMP di Sampang. Dikarenakan saat ini dalam pemilihan guru SMP di Sampang belum mempunyai program aplikasi yang dapat mendukung proses pemilihan guru teladan sehingga masih menggunakan sistem penilaian secara manual (Ms. Office) sehingga pada prosesnya masih terdapat masalah-masalah seperti memerlukan waktu yang lama dan adanya kemungkinan terjadinya kesalahan pada proses perankingan guru teladan. Untuk mengatasi masalah-masalah yang terjadi maka diperlukan sebuah sistem informasi yang tepat guna dan sesuai dengan kebutuhan yaitu sistem pendukung keputusan. Pada penelitian ini penulis akan menggunakan metode WP (Weighted Product) dalam menentukan alternatif terbaik pemilihan guru teladan SMP di Sampang.  Dari hasil pengujian yang telah dilakukan, perankingan pemilihan guru teladan dengan menggunakan metode Weighted Product dari 12 data memiliki tingkat akurasi sebesar 75 %. Hal ini menunjukkan bahwa penggunaan metode Weighted Product dalam sistem pendukung keputusan ini berhasil.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100053&gt;
{&#39;Abstrak&#39;: &#39;Dalam proses pengambilan keputusan terdapat banyak kriteria dan banyak pula metode yang digunakan. Permasalahannya adalah bagaimana menentukan kriteria-kriteria dan metode-metode yang tepat untuk mendukung proses pengambilan keputusan dalam membantu pemilihan guru teladan SMP di Sampang. Dikarenakan saat ini dalam pemilihan guru SMP di Sampang belum mempunyai program aplikasi yang dapat mendukung proses pemilihan guru teladan sehingga masih menggunakan sistem penilaian secara manual (Ms. Office) sehingga pada prosesnya masih terdapat masalah-masalah seperti memerlukan waktu yang lama dan adanya kemungkinan terjadinya kesalahan pada proses perankingan guru teladan. Untuk mengatasi masalah-masalah yang terjadi maka diperlukan sebuah sistem informasi yang tepat guna dan sesuai dengan kebutuhan yaitu sistem pendukung keputusan. Pada penelitian ini penulis akan menggunakan metode WP (Weighted Product) dalam menentukan alternatif terbaik pemilihan guru teladan SMP di Sampang.  Dari hasil pengujian yang telah dilakukan, perankingan pemilihan guru teladan dengan menggunakan metode Weighted Product dari 12 data memiliki tingkat akurasi sebesar 75 %. Hal ini menunjukkan bahwa penggunaan metode Weighted Product dalam sistem pendukung keputusan ini berhasil.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100052&gt;
{&#39;Abstrak&#39;: &#39;Penerapan computer vision dalam melakukan identifikasi atribut pejalan kaki mendapat perhatian yang besar terutama di bidang sistem pengawasan visual. Salah satu contoh penerapan sistem tersebut adalah pencarian tersangka tindak kejahatan berdasarkan ciri-ciri atribut yang dikenakan menurut laporan dari saksi. Identifikasi atribut dilakukan menggunakan Convolutional Neural Network (CNN) yang mampu melakukan pembelajaran fitur secara otomatis (feature learning). CNN terdiri dari lapisan konvolusi, ReLU, Pooling, dan Fully-connected. CNN memiliki 2 jenis output, yaitu binary-class dan multi-class. Penggunaan binary-class kurang efektif dalam mengidentifikasi banyak atribut sekaligus karena memerlukan pelatihan model yang baru untuk mengidentifikasi atribut yang lain. Sedangkan multi-class dapat mengidentifikasi banyak atribut dengan menggunakan sebuah model. Multi-class mempunyai 2 jenis label, yaitu single-label yang menghasilkan satu label pada ouput dan multi-label yang menghasilkan output berupa banyak label. Pada penelitian ini diusulkan metode multi-class multi-label CNN. Beberapa hyper-parameter seperti jumlah filter dan lapisan konvolusi pada CNN berpengaruh terhadap kinerja yang dihasilkan. Sehingga pada penelitian ini akan dilakukan beberapa skenario percobaan untuk mengetahui pengaruh jumlah filter dan lapisan konvolusi terhadap kinerja CNN. Beberapa arsitektur CNN yang berbeda dilatih dan diuji menggunakan PETA dataset dengan 35 atribut. Uji coba pengaruh jumlah filter dan lapisan konvolusi menghasilkan model terbaik dengan rata-rata f1 score sebesar 72.69% dan 75.66%. Dari hasil uji coba, dapat disimpulkan bahwa semakin banyak jumlah filter dan lapisan konvolusi yang digunakan, kinerja CNN menjadi semakin baik.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100052&gt;
{&#39;Abstrak&#39;: &#39;Penerapan computer vision dalam melakukan identifikasi atribut pejalan kaki mendapat perhatian yang besar terutama di bidang sistem pengawasan visual. Salah satu contoh penerapan sistem tersebut adalah pencarian tersangka tindak kejahatan berdasarkan ciri-ciri atribut yang dikenakan menurut laporan dari saksi. Identifikasi atribut dilakukan menggunakan Convolutional Neural Network (CNN) yang mampu melakukan pembelajaran fitur secara otomatis (feature learning). CNN terdiri dari lapisan konvolusi, ReLU, Pooling, dan Fully-connected. CNN memiliki 2 jenis output, yaitu binary-class dan multi-class. Penggunaan binary-class kurang efektif dalam mengidentifikasi banyak atribut sekaligus karena memerlukan pelatihan model yang baru untuk mengidentifikasi atribut yang lain. Sedangkan multi-class dapat mengidentifikasi banyak atribut dengan menggunakan sebuah model. Multi-class mempunyai 2 jenis label, yaitu single-label yang menghasilkan satu label pada ouput dan multi-label yang menghasilkan output berupa banyak label. Pada penelitian ini diusulkan metode multi-class multi-label CNN. Beberapa hyper-parameter seperti jumlah filter dan lapisan konvolusi pada CNN berpengaruh terhadap kinerja yang dihasilkan. Sehingga pada penelitian ini akan dilakukan beberapa skenario percobaan untuk mengetahui pengaruh jumlah filter dan lapisan konvolusi terhadap kinerja CNN. Beberapa arsitektur CNN yang berbeda dilatih dan diuji menggunakan PETA dataset dengan 35 atribut. Uji coba pengaruh jumlah filter dan lapisan konvolusi menghasilkan model terbaik dengan rata-rata f1 score sebesar 72.69% dan 75.66%. Dari hasil uji coba, dapat disimpulkan bahwa semakin banyak jumlah filter dan lapisan konvolusi yang digunakan, kinerja CNN menjadi semakin baik.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100053&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100053&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100053&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100053&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100053&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100053&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100053&gt;
{&#39;Abstrak&#39;: &#39;Padi merupakan hasil pertanian yang sangat utama dijadikan sebagai makanan pokok sehari-hari. Namun, adanya perubahan musim yang tidak menentu menyebabkan banyaknya penyakit yang menyerang tanaman padi mengakibatkan pertumbuhan tanaman terganggu, bahkan dapat menggagalkan terwujudnya produksi yang maksimal. Oleh karena itu, dibutuhkan suatu sistem pakar agar dapat membantu mempermudah dalam mendeteksi hama dan penyakit yang ada pada tanaman padi. Sistem ini bertujuan untuk mengetahui tingkat akurasi metode Fuzzy K-Nearest Neighbor dalam mendeteksi hama dan penyakit pada tanaman padi. Fuzzy K-nearest Neighbor (F-KNN) ini digunakan karena dalam penentuan kelas akhirnya tidak hanya memperhitungkan jumlah data yang mengikuti sebuah kelas tetapi juga jarak pada tetangga terdekatnya. Dari pengujian yang telah dilakukan dengan menggunakan 43 data uji terhadap 130 data latih dengan menggunakan nilai k= 4. Hasil akurasi tertinggi yang diperoleh adalah 86,05%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100053&gt;
{&#39;Abstrak&#39;: &#39;Padi merupakan hasil pertanian yang sangat utama dijadikan sebagai makanan pokok sehari-hari. Namun, adanya perubahan musim yang tidak menentu menyebabkan banyaknya penyakit yang menyerang tanaman padi mengakibatkan pertumbuhan tanaman terganggu, bahkan dapat menggagalkan terwujudnya produksi yang maksimal. Oleh karena itu, dibutuhkan suatu sistem pakar agar dapat membantu mempermudah dalam mendeteksi hama dan penyakit yang ada pada tanaman padi. Sistem ini bertujuan untuk mengetahui tingkat akurasi metode Fuzzy K-Nearest Neighbor dalam mendeteksi hama dan penyakit pada tanaman padi. Fuzzy K-nearest Neighbor (F-KNN) ini digunakan karena dalam penentuan kelas akhirnya tidak hanya memperhitungkan jumlah data yang mengikuti sebuah kelas tetapi juga jarak pada tetangga terdekatnya. Dari pengujian yang telah dilakukan dengan menggunakan 43 data uji terhadap 130 data latih dengan menggunakan nilai k= 4. Hasil akurasi tertinggi yang diperoleh adalah 86,05%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100053&gt;
{&#39;Abstrak&#39;: &#39;Sepak bola adalah salah satu olahraga yang saat ini paling digemari oleh remaja hampir di seluruh belahan dunia sejak abad 21. Dalam sepak bola tak jarang sebuah tim ataupun club sepak bola yang tepat dalam penentuan posisi pemainnya. Pemilihan posisi pemain adalah hal yang sangat rawan bagi sebuah tim sepak bola. Terlebih pemain yang masih junior yang hanya memikirkan kesenangan dalam memilih posisinya, tentu ini sangat merugikan bagi timnya. Maka salah satu cara agar pemilihan dapat efektif dan objektif maka dilakukan dengan teknologi yang telah berkembang yakni pembuatan sistem pendukung keputusan. Tujuan sistem pendukung keputusan ini yaitu membantu tim dalam merekomendasikan seorang pemain sepak bola layak berada di posisinya dengan skill yang dimiliki. Namun sebuah sistem pendukung keputusan juga kurang akurat tanpa adanya sebuah metode yang digunakan dalam sistem tersebut. Untuk itu dalam penelitian ini menggunakan metode profile matching untuk mendukung hasil sistem pendukung keputusan dengan nilai yang layak. Metode ini sangat sesuai digunakan untuk pengambilan keputusan karena perhitungan dilakukan dengan pembobotan dan perhitungan GAP untuk menghasilkan nilai bobot yang lebih untuk calon kandidat. Selain itu konsistensin yang logis dalam penilaian yang digunakan untuk menentukan prioritas sehingga menghasilkan alternative yang tidak banyak. Penelitian ini nantinya akan menghasilkan sebuah rekomendasi posisi pemain yang ada di tim sepak bola Persatuan Sepak Bola Surabaya (PERSEBAYA) usia 14 tahun. Penelitian ini nantinya akan menghasilkan sebuah rekomendasi posisi pemain yang ada di tim sepak bola Persatuan Sepak Bola Surabaya (PERSEBAYA) usia 14 tahun. Berdasarkan data yang ada output yang akan dihasilkan adalah tiga posisi utama yaitu pemain depan, pemain tengah, dan pemain belakang.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100053&gt;
{&#39;Abstrak&#39;: &#39;Sepak bola adalah salah satu olahraga yang saat ini paling digemari oleh remaja hampir di seluruh belahan dunia sejak abad 21. Dalam sepak bola tak jarang sebuah tim ataupun club sepak bola yang tepat dalam penentuan posisi pemainnya. Pemilihan posisi pemain adalah hal yang sangat rawan bagi sebuah tim sepak bola. Terlebih pemain yang masih junior yang hanya memikirkan kesenangan dalam memilih posisinya, tentu ini sangat merugikan bagi timnya. Maka salah satu cara agar pemilihan dapat efektif dan objektif maka dilakukan dengan teknologi yang telah berkembang yakni pembuatan sistem pendukung keputusan. Tujuan sistem pendukung keputusan ini yaitu membantu tim dalam merekomendasikan seorang pemain sepak bola layak berada di posisinya dengan skill yang dimiliki. Namun sebuah sistem pendukung keputusan juga kurang akurat tanpa adanya sebuah metode yang digunakan dalam sistem tersebut. Untuk itu dalam penelitian ini menggunakan metode profile matching untuk mendukung hasil sistem pendukung keputusan dengan nilai yang layak. Metode ini sangat sesuai digunakan untuk pengambilan keputusan karena perhitungan dilakukan dengan pembobotan dan perhitungan GAP untuk menghasilkan nilai bobot yang lebih untuk calon kandidat. Selain itu konsistensin yang logis dalam penilaian yang digunakan untuk menentukan prioritas sehingga menghasilkan alternative yang tidak banyak. Penelitian ini nantinya akan menghasilkan sebuah rekomendasi posisi pemain yang ada di tim sepak bola Persatuan Sepak Bola Surabaya (PERSEBAYA) usia 14 tahun. Penelitian ini nantinya akan menghasilkan sebuah rekomendasi posisi pemain yang ada di tim sepak bola Persatuan Sepak Bola Surabaya (PERSEBAYA) usia 14 tahun. Berdasarkan data yang ada output yang akan dihasilkan adalah tiga posisi utama yaitu pemain depan, pemain tengah, dan pemain belakang.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100053&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100053&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100054&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100054&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100054&gt;
{&#39;Abstrak&#39;: &#39;Dalam mengatasi permasalahan kemiskinan, Kabupaten Sampang  melaksanakan program Gerakan Bersama Menuju Sampang Harmonis Dan Bermartabat di mana program ini merupakan komitmen antara bupati sampang dengan gubernur profinsi jawa timur yang di amanatkan dalam rencana pembangunan jangka menengah daerah kabupaten sampang dalam mengentaskan kemiskinan di sampang yang memiliki angka kamiskinan paling tinggi se-jawa timur[1]. Karena tingginya kemiskinan tersebut di butukan sebuah sistem yang dapat merangking keluarga miskin, untuk itu dalam penelitian ini di bangun sebuah sistem pendukung keputusan dengan menggunakan metode Simple Multi-Atribut Ranting Technique Exploitng Ranks  di mana metode tersebut merupakan bagian dari metode Multiple Criteria Decision Making.  Hasil yang di peroleh sistem dapat merangking keluarga miskin dengan efisien (cepat dan mudah), yang kelayakannyadi ukur menggunakan metode descriptive statistical .&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100054&gt;
{&#39;Abstrak&#39;: &#39;Dalam mengatasi permasalahan kemiskinan, Kabupaten Sampang  melaksanakan program Gerakan Bersama Menuju Sampang Harmonis Dan Bermartabat di mana program ini merupakan komitmen antara bupati sampang dengan gubernur profinsi jawa timur yang di amanatkan dalam rencana pembangunan jangka menengah daerah kabupaten sampang dalam mengentaskan kemiskinan di sampang yang memiliki angka kamiskinan paling tinggi se-jawa timur[1]. Karena tingginya kemiskinan tersebut di butukan sebuah sistem yang dapat merangking keluarga miskin, untuk itu dalam penelitian ini di bangun sebuah sistem pendukung keputusan dengan menggunakan metode Simple Multi-Atribut Ranting Technique Exploitng Ranks  di mana metode tersebut merupakan bagian dari metode Multiple Criteria Decision Making.  Hasil yang di peroleh sistem dapat merangking keluarga miskin dengan efisien (cepat dan mudah), yang kelayakannyadi ukur menggunakan metode descriptive statistical .&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100054&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100054&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100054&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100054&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100054&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100054&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100054&gt;
{&#39;Abstrak&#39;: &#39;Pada pertanian modern sistem pengolahan tumbuh kembang\ntanaman menjadi hal yang lebih diprioritaskan yang bertujuan untuk\nmendapatkan hasil tumbuhan yang berkualitas seperti halnya pengolahan\ntanaman dalam greenhouse. Pengendalian lingkungan dalam greenhouse\npenting dilakukan yang mana disesuaikan dengan kasus yang terjadi di\nUPT pengembangan agribisnis tanaman pangan dan holikultura Lebo\nSidoarjo yang memiliki greenhouse dengan lebar 40 meter, panjang 80\nmeter dan tinggi 16 meter. Selain itu varietas melon yang di tanam dalam\ngreenhouse tersebut memerlukan suhu 25-30°C dan kelembaban berkisar\n70% sampai 80%. Dengan kondisi seperti itu maka suhu dan kelembaban\ndalam ruangan harus di jaga kestabilannya. Masalah-masalah tersebut\ndiselesaikan dengan memanfaatkan Internet of Things (IoT) berbasis\naplikasi android dengan pengambilan data melalui sensor mikrokontroler\nArduino sehingga dapat mempermudah pertani dalam melakukan\nmonitoring suhu dan kelembaban ruangan greenhouse secara realtime\ndari jarak jauh. Dari pengujian yang telah dilakukan dihasilkan Root\nMean Square Error (RMSE) suhu sebesar 2.93 dan kelembaban sebesar\n11.67. Sedangkan pengujian pada tanaman yang belum berbuah diperoleh\nhasil suhu sebesar 2.92 dan kelembaban sebesar 13.17. sedangkan pada\ntanaman yang sudah berbuah dan diperoleh hasil suhu sebesar 2.97 dan\nkelembaban sebesar 8.23. Sedangkan pengujian yang telah dilakukan\npada tanaman pagi hari diperoleh suhu sebesar 3.32 dan kelembaban\nsebesar 12.43. Sedangkan pengujian pada siang hari diperoleh hasil suhu\nsebesar 2.18 dan kelembaban sebesar 10.35. Dari hasil tersebut dapat\ndisimpulkan bahwa Root Mean Square Error (RMSE) yang lebih kecil\ndikatakan lebih akurat dari pada hasil lebih besar.\nKata Kunci: Petanian, Greenhouse, Internet of Things (IoT),\nMikrokontroller Arduino, Root Mean Square Error (RMSE).&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100054&gt;
{&#39;Abstrak&#39;: &#39;Pada pertanian modern sistem pengolahan tumbuh kembang\ntanaman menjadi hal yang lebih diprioritaskan yang bertujuan untuk\nmendapatkan hasil tumbuhan yang berkualitas seperti halnya pengolahan\ntanaman dalam greenhouse. Pengendalian lingkungan dalam greenhouse\npenting dilakukan yang mana disesuaikan dengan kasus yang terjadi di\nUPT pengembangan agribisnis tanaman pangan dan holikultura Lebo\nSidoarjo yang memiliki greenhouse dengan lebar 40 meter, panjang 80\nmeter dan tinggi 16 meter. Selain itu varietas melon yang di tanam dalam\ngreenhouse tersebut memerlukan suhu 25-30°C dan kelembaban berkisar\n70% sampai 80%. Dengan kondisi seperti itu maka suhu dan kelembaban\ndalam ruangan harus di jaga kestabilannya. Masalah-masalah tersebut\ndiselesaikan dengan memanfaatkan Internet of Things (IoT) berbasis\naplikasi android dengan pengambilan data melalui sensor mikrokontroler\nArduino sehingga dapat mempermudah pertani dalam melakukan\nmonitoring suhu dan kelembaban ruangan greenhouse secara realtime\ndari jarak jauh. Dari pengujian yang telah dilakukan dihasilkan Root\nMean Square Error (RMSE) suhu sebesar 2.93 dan kelembaban sebesar\n11.67. Sedangkan pengujian pada tanaman yang belum berbuah diperoleh\nhasil suhu sebesar 2.92 dan kelembaban sebesar 13.17. sedangkan pada\ntanaman yang sudah berbuah dan diperoleh hasil suhu sebesar 2.97 dan\nkelembaban sebesar 8.23. Sedangkan pengujian yang telah dilakukan\npada tanaman pagi hari diperoleh suhu sebesar 3.32 dan kelembaban\nsebesar 12.43. Sedangkan pengujian pada siang hari diperoleh hasil suhu\nsebesar 2.18 dan kelembaban sebesar 10.35. Dari hasil tersebut dapat\ndisimpulkan bahwa Root Mean Square Error (RMSE) yang lebih kecil\ndikatakan lebih akurat dari pada hasil lebih besar.\nKata Kunci: Petanian, Greenhouse, Internet of Things (IoT),\nMikrokontroller Arduino, Root Mean Square Error (RMSE).&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100054&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100054&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100055&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100055&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100054&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:41 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100054&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100055&gt;
{&#39;Abstrak&#39;: &#39;Peramalan adalah proses untuk memperkirakan beberapa kebutuhan dimasa mendatang yang meliputi kebutuhan dalam ukuran kuantitas, kualitas, waktu dan lokasi yang dibutuhkan dalam rangka memenuhi permintaan barang ataupun jasa. Untuk menjalankan penjualan dengan baik, Toko Deeolshop membutuhkan sebuah sistem yang membantu dalam peningkatan penjualan. Toko Deeolshop belum memiliki sistem terstandar dalam mengatur perencanaan stok barang. Perencanaan biasanya hanya dilakukan berdasarkan pengalaman dan perkiraan pemilik saja,\nsehingga toko saat ini masih mengalami kendala dalam pengelolaan persediaannya, dimana stok barang seringkali mengalami kekurangan ataupun penumpukan stok barang di gudang. Berdasarkan permasalahan diatas, diperlukan adanya suatu sistem yang dapat membantu memprediksi stok barang untuk bulan berikutnya. Metode yang digunakan untuk melakukan peramalan pada sistem ini adalah metode Double Moving Average. Peramalan stok ini menggunakan acuan data hasil penjualan pada periode-periode sebelumnya. Metode tersebut digunakan untuk meramalkan banyaknya stok barang untuk periode berikutnya. Tingkat akurasi peramalan dihitung dengan MAPE dan diperoleh sebesar 10,36% dan menghasilkan akurasi sebesar 89.64%. Hasil peramalan item Totebag Zara untuk bulan berikutnya yaitu sebanyak 840 pcs. Dengan adanya sistem ini diharapkan Toko Deeolshop dapat lebih cepat dan efisien dalam menentukan stok barang, sehingga tidak akan terjadi kekurangan stok ataupun penumpukan stok barang.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100055&gt;
{&#39;Abstrak&#39;: &#39;Peramalan adalah proses untuk memperkirakan beberapa kebutuhan dimasa mendatang yang meliputi kebutuhan dalam ukuran kuantitas, kualitas, waktu dan lokasi yang dibutuhkan dalam rangka memenuhi permintaan barang ataupun jasa. Untuk menjalankan penjualan dengan baik, Toko Deeolshop membutuhkan sebuah sistem yang membantu dalam peningkatan penjualan. Toko Deeolshop belum memiliki sistem terstandar dalam mengatur perencanaan stok barang. Perencanaan biasanya hanya dilakukan berdasarkan pengalaman dan perkiraan pemilik saja,\nsehingga toko saat ini masih mengalami kendala dalam pengelolaan persediaannya, dimana stok barang seringkali mengalami kekurangan ataupun penumpukan stok barang di gudang. Berdasarkan permasalahan diatas, diperlukan adanya suatu sistem yang dapat membantu memprediksi stok barang untuk bulan berikutnya. Metode yang digunakan untuk melakukan peramalan pada sistem ini adalah metode Double Moving Average. Peramalan stok ini menggunakan acuan data hasil penjualan pada periode-periode sebelumnya. Metode tersebut digunakan untuk meramalkan banyaknya stok barang untuk periode berikutnya. Tingkat akurasi peramalan dihitung dengan MAPE dan diperoleh sebesar 10,36% dan menghasilkan akurasi sebesar 89.64%. Hasil peramalan item Totebag Zara untuk bulan berikutnya yaitu sebanyak 840 pcs. Dengan adanya sistem ini diharapkan Toko Deeolshop dapat lebih cepat dan efisien dalam menentukan stok barang, sehingga tidak akan terjadi kekurangan stok ataupun penumpukan stok barang.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100055&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100055&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100055&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100055&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100055&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100055&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100055&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100055&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100055&gt;
{&#39;Abstrak&#39;: &#39;Indonesia memiliki beragam kekayaan budaya salah satunya aksara had (Lampung). Namun saat ini bahasa dan aksara lampung sudah sangat jarang digunakan. Maka dari itu diperlukan adanya pengembangan dalam bidang sistem informasi sebagai upaya pelestarian aksara lampung. Seperti pembuatan sistem pengenalan tulisan aksara lampung. Dalam proses pengenalan aksara ada beberapa metode yang dapat digunakan, salah satunya metode Learning Vector Quantization (LVQ). Namun, metode LVQ memiliki tingkat akurasi rendah karena banyaknya target yang pada akhirnya mempengaruhi perhitungan bobot, ketika bobot terus diupdate untuk memperoleh bobot akhir. Pada penelitian ini diusulkan metode backpropagation dengan menggunakan metode ekstraksi fitur zoning untuk melakukan pengenalan tulisan tangan aksara Lampung. Sistem dimulai dengan mengubah gambar menjadi binner, lalu cropping, setelah itu proses ekstraksi fitur menggunakan zoning. Zoning dengan algoritma gabungan ICZ (Image Centroid and Zone) dan ZCZ (Zone Centroid and Zone) dikenal sebagai ekstraksi ciri yang optimal, algoritma ini memberikan tingkat kesalahan yang relatif rendah. Dari hasil uji coba, penggunaan ekstraksi fitur Zoning algoritma ICZ dan klasifikasi backpropagation dalam pengenalan aksara lampung mendapatkan akurasi sebesar 73,5%\n\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100055&gt;
{&#39;Abstrak&#39;: &#39;Indonesia memiliki beragam kekayaan budaya salah satunya aksara had (Lampung). Namun saat ini bahasa dan aksara lampung sudah sangat jarang digunakan. Maka dari itu diperlukan adanya pengembangan dalam bidang sistem informasi sebagai upaya pelestarian aksara lampung. Seperti pembuatan sistem pengenalan tulisan aksara lampung. Dalam proses pengenalan aksara ada beberapa metode yang dapat digunakan, salah satunya metode Learning Vector Quantization (LVQ). Namun, metode LVQ memiliki tingkat akurasi rendah karena banyaknya target yang pada akhirnya mempengaruhi perhitungan bobot, ketika bobot terus diupdate untuk memperoleh bobot akhir. Pada penelitian ini diusulkan metode backpropagation dengan menggunakan metode ekstraksi fitur zoning untuk melakukan pengenalan tulisan tangan aksara Lampung. Sistem dimulai dengan mengubah gambar menjadi binner, lalu cropping, setelah itu proses ekstraksi fitur menggunakan zoning. Zoning dengan algoritma gabungan ICZ (Image Centroid and Zone) dan ZCZ (Zone Centroid and Zone) dikenal sebagai ekstraksi ciri yang optimal, algoritma ini memberikan tingkat kesalahan yang relatif rendah. Dari hasil uji coba, penggunaan ekstraksi fitur Zoning algoritma ICZ dan klasifikasi backpropagation dalam pengenalan aksara lampung mendapatkan akurasi sebesar 73,5%\n\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100056&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100056&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100055&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100055&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100056&gt;
{&#39;Abstrak&#39;: &#39;-&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100056&gt;
{&#39;Abstrak&#39;: &#39;-&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100056&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100056&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100056&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100056&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100056&gt;
{&#39;Abstrak&#39;: &#39;Content Based Image Retrieval (CBIR) ialah salah satu teknik yang digunakan untuk melakukan pencarian citra berbasis isi. Meskipun hasil pencarian dari CBIR relevan dengan query yang diberikan oleh user, tetapi terkadang hasilnya tidak seperti yang diinginkan oleh user. Sehingga untuk mengatasi permasalahan tersebut dalam penelitian ini akan digunakan dua lapis sistem temu kembali yang mengkombinasikan text retrieval dengan model Vector Space Model (VSM) dan pembobotan menggunakan Term Frequency - Inverse - Document Frequency (TF-IDF) dikombinasikan dengan CBIR yang menggunakan Integrated Color and Intensity Co-Occurence Matrix (ICICM) sebagai metode feature extraction untuk citra. Feature yang digunakan pada ICICM ialah tekstur dan warna yang merupakan 2 feature tingkat rendah yang sering digunakan untuk klasifikasi citra dan retrieval. Tujuan dari penelitian ini ialah mengkombinasikan dua lapis sistem temu kembali yaitu text dan content based untuk mendapatkan hasil retrieval yang lebih baik. Data yang digunakan dalam penelitian ini berasal dari media sosial Twitter dengan query teks berupa “wisata madura”. Hasil yang didapat dari penelitian ini adalah dengan menggunakan kombinasi text based dengan content based dapat meningkatkan precision dan recall hasil retrieval meskipun tanpa melakukan pencarian dalam seluruh dataset. Hasil yang yang didapatkan pada penelitian ini adalah dengan menggunakan kombinasi antara text based dengan content based hasilnya lebih baik dibandingkan dengan menggunakan text based saja yaitu dengan kenaikan sebesar 0,0576 untuk precision dan dengan recall yang sama. Sedangkan dengan menggunakan kombinasi antara text based dengan content based hasilnya lebih baik dibandingkan dengan menggunakan content based saja yaitu dengan kenaikan sebesar 0,0238 untuk precision dan dengan recall sebesar 0,2000.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100056&gt;
{&#39;Abstrak&#39;: &#39;Content Based Image Retrieval (CBIR) ialah salah satu teknik yang digunakan untuk melakukan pencarian citra berbasis isi. Meskipun hasil pencarian dari CBIR relevan dengan query yang diberikan oleh user, tetapi terkadang hasilnya tidak seperti yang diinginkan oleh user. Sehingga untuk mengatasi permasalahan tersebut dalam penelitian ini akan digunakan dua lapis sistem temu kembali yang mengkombinasikan text retrieval dengan model Vector Space Model (VSM) dan pembobotan menggunakan Term Frequency - Inverse - Document Frequency (TF-IDF) dikombinasikan dengan CBIR yang menggunakan Integrated Color and Intensity Co-Occurence Matrix (ICICM) sebagai metode feature extraction untuk citra. Feature yang digunakan pada ICICM ialah tekstur dan warna yang merupakan 2 feature tingkat rendah yang sering digunakan untuk klasifikasi citra dan retrieval. Tujuan dari penelitian ini ialah mengkombinasikan dua lapis sistem temu kembali yaitu text dan content based untuk mendapatkan hasil retrieval yang lebih baik. Data yang digunakan dalam penelitian ini berasal dari media sosial Twitter dengan query teks berupa “wisata madura”. Hasil yang didapat dari penelitian ini adalah dengan menggunakan kombinasi text based dengan content based dapat meningkatkan precision dan recall hasil retrieval meskipun tanpa melakukan pencarian dalam seluruh dataset. Hasil yang yang didapatkan pada penelitian ini adalah dengan menggunakan kombinasi antara text based dengan content based hasilnya lebih baik dibandingkan dengan menggunakan text based saja yaitu dengan kenaikan sebesar 0,0576 untuk precision dan dengan recall yang sama. Sedangkan dengan menggunakan kombinasi antara text based dengan content based hasilnya lebih baik dibandingkan dengan menggunakan content based saja yaitu dengan kenaikan sebesar 0,0238 untuk precision dan dengan recall sebesar 0,2000.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100056&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100056&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100056&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100056&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100057&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100057&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100056&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100056&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100057&gt;
{&#39;Abstrak&#39;: &#39;Toko tas Deeolshop menjual berbagai macam tas model kekinian yang dijual secara online maupun offline. Permasalahan muncul ketika semakin banyaknya transaksi penjualan dan semakin banyak macam-macam tas yang dijual . Akibatnya, toko sering mengalami kekurangan stok sehingga tidak dapat memenuhi permintaan pelanggan dan kelebihan stok sehingga terjadi penumpukan barang digudang. Permasalahan ini timbul karena pengelolaan persediaan barang dilakukan secara manual dan tidak memiliki acuan yang pasti tentang jumlah barang yang harus dipesan dan kapan harus melakukan pemesanan barang. Pemesanan baru dilakukan jika stok barang tertentu hampir habis, dengan jumlah yang mengacu pada penggunaan sebelumnya sehingga persediaan barang tidak akurat. Untuk meminimalkan dan mengatasi permalasalahan tersebut perlu adanya sistem peramalan stok barang dengan memprediksi hasil penjualan barang dimasa mendatang berdasarkan data yang telah direkam sebelumnya. Prediksi tersebut sangat berpengaruh pada keputusan untuk menentukan jumlah barang yang akan dijual dibulan yang akan datang. Metode yang digunakan dalam penelitian ini adalah Double Exponential Smoothing karena metode ini tergolong dalam metode time series ( runtut waktu ) yang mempergunakan data masa lalu untuk memprediksi sesuai dimasa yang akan datang. Dari penelitian ini, menghasilkan nilai MAPE terkecil dengan menggunakan alpha 0,4 sebesar 8,83%. Hasil peramalan item Totebag Zara  untuk bulan berikutnya sebesar 911 pcs. Dengan adanya sistem ini diharapkan Toko Deeolshop dapat lebih cepat dan efisien dalam menentukan stok barang, sehingga tidak akan terjadi kekurangan stok ataupun penumpukan stok barang.\n \nKata kunci : Sistem, Peramalan, Double Exponential Smoothing, Penjualan  \n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100057&gt;
{&#39;Abstrak&#39;: &#39;Toko tas Deeolshop menjual berbagai macam tas model kekinian yang dijual secara online maupun offline. Permasalahan muncul ketika semakin banyaknya transaksi penjualan dan semakin banyak macam-macam tas yang dijual . Akibatnya, toko sering mengalami kekurangan stok sehingga tidak dapat memenuhi permintaan pelanggan dan kelebihan stok sehingga terjadi penumpukan barang digudang. Permasalahan ini timbul karena pengelolaan persediaan barang dilakukan secara manual dan tidak memiliki acuan yang pasti tentang jumlah barang yang harus dipesan dan kapan harus melakukan pemesanan barang. Pemesanan baru dilakukan jika stok barang tertentu hampir habis, dengan jumlah yang mengacu pada penggunaan sebelumnya sehingga persediaan barang tidak akurat. Untuk meminimalkan dan mengatasi permalasalahan tersebut perlu adanya sistem peramalan stok barang dengan memprediksi hasil penjualan barang dimasa mendatang berdasarkan data yang telah direkam sebelumnya. Prediksi tersebut sangat berpengaruh pada keputusan untuk menentukan jumlah barang yang akan dijual dibulan yang akan datang. Metode yang digunakan dalam penelitian ini adalah Double Exponential Smoothing karena metode ini tergolong dalam metode time series ( runtut waktu ) yang mempergunakan data masa lalu untuk memprediksi sesuai dimasa yang akan datang. Dari penelitian ini, menghasilkan nilai MAPE terkecil dengan menggunakan alpha 0,4 sebesar 8,83%. Hasil peramalan item Totebag Zara  untuk bulan berikutnya sebesar 911 pcs. Dengan adanya sistem ini diharapkan Toko Deeolshop dapat lebih cepat dan efisien dalam menentukan stok barang, sehingga tidak akan terjadi kekurangan stok ataupun penumpukan stok barang.\n \nKata kunci : Sistem, Peramalan, Double Exponential Smoothing, Penjualan  \n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100057&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100057&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100057&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:42 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100057&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100057&gt;
{&#39;Abstrak&#39;: &#39;Penyakit kusta adalah penyakit menahun dengan dampak cacat fisik pada penderita. Indonesia berada dalam urutan ketiga dengan jumlah kasus penderita penyakit kusta di dunia dalam rentang tahun 2005 hingga 2016. Pada tahun 2016, provinsi Jawa Timur ditemukan 3.636 penderita baru. Kasus terdeteksi di Kabupaten Sampang sebanyak 329 kasus dengan angka prevalensi sebesar 3,47 per 10.000 penduduk. Dinas Kesehatan Kabupaten Sampang telah melakukan upaya pengawasan, pencegahan dan pengobatan terhadap pasien kusta untuk mengurangi angka prevalensi. Masalah yang dihadapi adalah belum adanya pemetaan dan manajemen yang tersentral dalam pengolahan data sehingga instansi dan stakeholder terkait tidak memiliki gambaran persebaran spasial pada setiap wilayah di Kabupaten Sampang. Berdasarkan hasil dari pembangunan sistem informasi dalam penelitian ini, mendapatkan penilaian evaluasi kelayakan sebesar 86.36%. Sehingga sistem informasi pemetaan untuk pengolahan data pasien kusta beserta persebarannya di Kabupaten Sampang dikategorikan sangat layak sebagai informasi dasar dalam program pengendalian penyakit kusta.\nKata Kunci : Kusta, Sistem Informasi Geografis, WEB GIS, Sampang.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100057&gt;
{&#39;Abstrak&#39;: &#39;Penyakit kusta adalah penyakit menahun dengan dampak cacat fisik pada penderita. Indonesia berada dalam urutan ketiga dengan jumlah kasus penderita penyakit kusta di dunia dalam rentang tahun 2005 hingga 2016. Pada tahun 2016, provinsi Jawa Timur ditemukan 3.636 penderita baru. Kasus terdeteksi di Kabupaten Sampang sebanyak 329 kasus dengan angka prevalensi sebesar 3,47 per 10.000 penduduk. Dinas Kesehatan Kabupaten Sampang telah melakukan upaya pengawasan, pencegahan dan pengobatan terhadap pasien kusta untuk mengurangi angka prevalensi. Masalah yang dihadapi adalah belum adanya pemetaan dan manajemen yang tersentral dalam pengolahan data sehingga instansi dan stakeholder terkait tidak memiliki gambaran persebaran spasial pada setiap wilayah di Kabupaten Sampang. Berdasarkan hasil dari pembangunan sistem informasi dalam penelitian ini, mendapatkan penilaian evaluasi kelayakan sebesar 86.36%. Sehingga sistem informasi pemetaan untuk pengolahan data pasien kusta beserta persebarannya di Kabupaten Sampang dikategorikan sangat layak sebagai informasi dasar dalam program pengendalian penyakit kusta.\nKata Kunci : Kusta, Sistem Informasi Geografis, WEB GIS, Sampang.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100057&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100057&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100057&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100057&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100058&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100058&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100057&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100057&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100058&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100058&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100058&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100058&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100058&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100058&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100058&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100058&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100058&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100058&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100058&gt;
{&#39;Abstrak&#39;: &#39;Pemberian peringkat dalam sistem rekomendasi biasanya hanya mempertimbangkan satu kriteria nilai, tetapi terdapat beberapa data yang memiliki lebih dari satu kriteria (multi-kriteria). Multi-kriteria memiliki tingkat keakuratan yang lebih tinggi dibandingkan dengan kriteria tunggal karena preferensinya lebih lengkap, namun skala penilaian antar kriteria berbeda. Skala penilaian yang berbeda menyebabkan nilai rating tidak seimbang dan menyebabkan tingkat akurasi sistem menjadi rendah, sehingga diperlukan metode normalisasi untuk meningkatkan nilai akurasi. Ada beberapa metode yang digunakan oleh para peneliti dalam melakukan rekomendasi, diantaranya Collaborative Filtering (user-item based), Content-based, Hybird dan Normalisasi Collaborative Filtering. Pada penelitian ini menggunakan metode Normalisasi rating min-max  yang dikombinasikan dengan User-based Collaborative Filtering dan Item-based Collaborative Filtering. Metode ini digunakan karena dapat memperbaiki rekomendasi dengan cara normalisasi rating dan menghitung prediksi berdasarkan user-based dan item-based. Penelitian ini mampu menghasilkan akurasi rekomendasi yang lebih tinggi, dengan nilai akurasi menggunakan metrik evaluasi Precision@15 = 0,000505341 dan NDCG@15 = 0,000506436 yang diperoleh dari uji coba variasi parameter.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100058&gt;
{&#39;Abstrak&#39;: &#39;Pemberian peringkat dalam sistem rekomendasi biasanya hanya mempertimbangkan satu kriteria nilai, tetapi terdapat beberapa data yang memiliki lebih dari satu kriteria (multi-kriteria). Multi-kriteria memiliki tingkat keakuratan yang lebih tinggi dibandingkan dengan kriteria tunggal karena preferensinya lebih lengkap, namun skala penilaian antar kriteria berbeda. Skala penilaian yang berbeda menyebabkan nilai rating tidak seimbang dan menyebabkan tingkat akurasi sistem menjadi rendah, sehingga diperlukan metode normalisasi untuk meningkatkan nilai akurasi. Ada beberapa metode yang digunakan oleh para peneliti dalam melakukan rekomendasi, diantaranya Collaborative Filtering (user-item based), Content-based, Hybird dan Normalisasi Collaborative Filtering. Pada penelitian ini menggunakan metode Normalisasi rating min-max  yang dikombinasikan dengan User-based Collaborative Filtering dan Item-based Collaborative Filtering. Metode ini digunakan karena dapat memperbaiki rekomendasi dengan cara normalisasi rating dan menghitung prediksi berdasarkan user-based dan item-based. Penelitian ini mampu menghasilkan akurasi rekomendasi yang lebih tinggi, dengan nilai akurasi menggunakan metrik evaluasi Precision@15 = 0,000505341 dan NDCG@15 = 0,000506436 yang diperoleh dari uji coba variasi parameter.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100059&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100059&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100058&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100058&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100059&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100059&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100059&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100059&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100059&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100059&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100059&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100059&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100059&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100059&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100059&gt;
{&#39;Abstrak&#39;: &#39;Sistem temu kembali informasi dapat digunakan untuk memberikan alternatif berupa metode similarity yang dapat digunakan untuk melakukan pencarian teks yang relevan dengan yang kita butuhkan. Metode similarity yang digunakan adalah metode Sqrt Cosine Similarity dengan pembobotan kata menggunakan metode TF-IDF. Metode Sqrt Cosine Similarity ini bisa dimanfaatkan untuk melakukan pencarian terjemahan syarah hadits agar masyarakat tidak perlu bingung dalam memahami suatu hadits. Input query dari user diproses dalam beberapa tahap yang kemudian dilakukan pengukuran tingkat kemiripan dengan terjemahan syarah hadits berbahasa Indonesia yang tersimpan dalam database, sehingga dapat ditemukan hadits yang sesuai dengan query yang dicari. Hasil dari penelitian ini memiliki nilai rata- rata presisi sebesar 73% untuk metode sqrt cosine similarity dan untuk metode cosine similarity sebesar 79%. Hasil ini menunjukkan bahwa metode sqrt cosine similarity memiliki penurunan presisi dari metode cosine similarity yaitu sebesar 6%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100059&gt;
{&#39;Abstrak&#39;: &#39;Sistem temu kembali informasi dapat digunakan untuk memberikan alternatif berupa metode similarity yang dapat digunakan untuk melakukan pencarian teks yang relevan dengan yang kita butuhkan. Metode similarity yang digunakan adalah metode Sqrt Cosine Similarity dengan pembobotan kata menggunakan metode TF-IDF. Metode Sqrt Cosine Similarity ini bisa dimanfaatkan untuk melakukan pencarian terjemahan syarah hadits agar masyarakat tidak perlu bingung dalam memahami suatu hadits. Input query dari user diproses dalam beberapa tahap yang kemudian dilakukan pengukuran tingkat kemiripan dengan terjemahan syarah hadits berbahasa Indonesia yang tersimpan dalam database, sehingga dapat ditemukan hadits yang sesuai dengan query yang dicari. Hasil dari penelitian ini memiliki nilai rata- rata presisi sebesar 73% untuk metode sqrt cosine similarity dan untuk metode cosine similarity sebesar 79%. Hasil ini menunjukkan bahwa metode sqrt cosine similarity memiliki penurunan presisi dari metode cosine similarity yaitu sebesar 6%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100060&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100060&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100059&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:43 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100059&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100060&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100060&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100060&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100060&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100060&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100060&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100060&gt;
{&#39;Abstrak&#39;: &#39;Dinas Pekerjaan Umum dan Penataan Ruang (PUPR) Kabupaten Bangkalan bertanggungjawab untuk memperbaiki kerusakan jalan tingkat kabupaten. Dalam penanganannya terdapat beberapa kendala diantaranya keterbatasan jumlah dana dari pusat pemerintah dan banyaknya jumlah jalan yang rusak. Oleh karena itu, perlu dilakukan penelitian untuk menentukan prioritas perbaikan jalan dengan memperhatikan kriteria-kriteria yang ada diantaranya panjang ruas jalan, lebar ruas jalan, panjang tiap kondisi (baik, sedang, rusak ringan dan rusak berat). Dalam penelitian ini dilakukan penggabungan dua metode yaitu Fuzzy C-Means (FCM) dan Metode Simple Multi Attribute Rating Technique (SMART). Metode FCM adalah metode yang mampu mengelompokkan data berdasarkan karakteristik yang dimilikinya dan SMART merupakan metode yang mampu menyelesaikan masalah dengan multikriteria. Dengan penggabungan dua metode pada penentuan prioritas perbaikan jalan menghasilkan tingkat akurasi sebesar 80%. Nilai akurasi ini diperoleh dengan cara menganalisa tingkat persamaan hasil perhitungan yang dilakukan oleh orang ahli di dinas Pekerjaan Umum dan Bina Marga Kota Surabaya terhadap sistem yang kita buat. Pembuatan SPK ini memiliki tingkat kesesuaian seperti apa yang diinginkan oleh user /  pengguna sebesar 73,4% berdasarkan kuesioner terhadap 6 responden.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100060&gt;
{&#39;Abstrak&#39;: &#39;Dinas Pekerjaan Umum dan Penataan Ruang (PUPR) Kabupaten Bangkalan bertanggungjawab untuk memperbaiki kerusakan jalan tingkat kabupaten. Dalam penanganannya terdapat beberapa kendala diantaranya keterbatasan jumlah dana dari pusat pemerintah dan banyaknya jumlah jalan yang rusak. Oleh karena itu, perlu dilakukan penelitian untuk menentukan prioritas perbaikan jalan dengan memperhatikan kriteria-kriteria yang ada diantaranya panjang ruas jalan, lebar ruas jalan, panjang tiap kondisi (baik, sedang, rusak ringan dan rusak berat). Dalam penelitian ini dilakukan penggabungan dua metode yaitu Fuzzy C-Means (FCM) dan Metode Simple Multi Attribute Rating Technique (SMART). Metode FCM adalah metode yang mampu mengelompokkan data berdasarkan karakteristik yang dimilikinya dan SMART merupakan metode yang mampu menyelesaikan masalah dengan multikriteria. Dengan penggabungan dua metode pada penentuan prioritas perbaikan jalan menghasilkan tingkat akurasi sebesar 80%. Nilai akurasi ini diperoleh dengan cara menganalisa tingkat persamaan hasil perhitungan yang dilakukan oleh orang ahli di dinas Pekerjaan Umum dan Bina Marga Kota Surabaya terhadap sistem yang kita buat. Pembuatan SPK ini memiliki tingkat kesesuaian seperti apa yang diinginkan oleh user /  pengguna sebesar 73,4% berdasarkan kuesioner terhadap 6 responden.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100060&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100060&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100060&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100060&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100061&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100061&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100060&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100060&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100061&gt;
{&#39;Abstrak&#39;: &#39;Kesehatan gigi dan mulut merupakan hal yang sangat penting bagi setiap orang. Terkadang orang tidak terlalu memikirkan masalah terhadap kesehatan giginya sehingga secara tidak langsung mengalami sakit gigi atau terkena penyakit gigi dan mulut. Dengan begitu penanganan dan perawatan yang tepat dapat membantu penyembuhan penyakit gigi lebih cepat, namun sebaliknya jika penanganannya tidak tepat maka kemungkinan menambah permasalahan pada kesehatan giginya, kemampuan analisa yang tepat dan akurat merupakan hal penting yang diperlukan dalam melakukan diagnosa penyakit. Dalam hal ini, untuk mengatasi permasalahan tersebut salah satu solusinya adalah sistem pakar yang dapat mendiagnosa penyakit gigi dan mulut, agar dapat melakukan pencegahan lebih awal. Sistem pakar tersebut mengadopsi pengetahuan para ahli dibidangnya. Sistem pakar yang dibangun menggunakan metode Naive Bayes, metode ini sangat cocok dalam pengambilan keputusan untuk mendiagnosa penyakit gigi dan mulut karena menggunakan konsep yang sederhana dan mudah dipahami. Sistem yang dibangun berbasis web untuk memudahkan dalam penggunaanya, sehingga dapat digunakan oleh masyarakat luas. Pengujian sistem menggunakan 90 data dan dilakukan 3 uji coba atau skenario. Dari hasil uji konsultasi dengan sistem ini menunjukkan bahwa sistem mampu menentukan penyakit dengan presentase tingkat akurasi keberhasil sebesar 70%. \n\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100061&gt;
{&#39;Abstrak&#39;: &#39;Kesehatan gigi dan mulut merupakan hal yang sangat penting bagi setiap orang. Terkadang orang tidak terlalu memikirkan masalah terhadap kesehatan giginya sehingga secara tidak langsung mengalami sakit gigi atau terkena penyakit gigi dan mulut. Dengan begitu penanganan dan perawatan yang tepat dapat membantu penyembuhan penyakit gigi lebih cepat, namun sebaliknya jika penanganannya tidak tepat maka kemungkinan menambah permasalahan pada kesehatan giginya, kemampuan analisa yang tepat dan akurat merupakan hal penting yang diperlukan dalam melakukan diagnosa penyakit. Dalam hal ini, untuk mengatasi permasalahan tersebut salah satu solusinya adalah sistem pakar yang dapat mendiagnosa penyakit gigi dan mulut, agar dapat melakukan pencegahan lebih awal. Sistem pakar tersebut mengadopsi pengetahuan para ahli dibidangnya. Sistem pakar yang dibangun menggunakan metode Naive Bayes, metode ini sangat cocok dalam pengambilan keputusan untuk mendiagnosa penyakit gigi dan mulut karena menggunakan konsep yang sederhana dan mudah dipahami. Sistem yang dibangun berbasis web untuk memudahkan dalam penggunaanya, sehingga dapat digunakan oleh masyarakat luas. Pengujian sistem menggunakan 90 data dan dilakukan 3 uji coba atau skenario. Dari hasil uji konsultasi dengan sistem ini menunjukkan bahwa sistem mampu menentukan penyakit dengan presentase tingkat akurasi keberhasil sebesar 70%. \n\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100061&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100061&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100061&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100061&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100061&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100061&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100061&gt;
{&#39;Abstrak&#39;: &#39;Madura merupakan salah satu pulau yang terletak di provinsi Jawa Timur yang memiliki 4 kabupaten yaitu bangkalan, sampang, pamekasan, sumenep. Di setiap kabupaten/ daerah yang berada di madura memiliki potensi wisata yang dapat dikunjungi. Namun permasalahan yang dihadapi yaitu belum adanya sistem yang mewadahi potensi wisata di Madura. Selain itu, wisatawan kesulitan mendapatkan informasi wisata resmi mengenai objek wisata dalam ruang lingkup Madura. Oleh sebab itu, diperlukan suatu sistem pendukung keputusan untuk pemilihan objek wisata di Madura  sebagai salah satu cara dalam memberikan  kemudahan pada calon wisatawan untuk dapat memilih objek wisata di Madura yang sesuai kriteria dan banyaknya pengunjung.  Berkaitan dengan  tujuan tersebut penelitian ini menerapkan metode logika Fuzzy sebagai model pendukung keputusan dalam pemilihan daftar objek wisata di Madura. Fuzzy digunakan karena metode ini merupakan suatu bentuk model pendukung keputusan dimana peralatan utamanya adalah sebuah hirarki fungsional dengan input utamanya kriteria yang telang ditentukan. Sehingga nantinya hasil yang diharapkan dapat membantu mempermudah calon wisatawan dalam mengambil keputusan untuk memilih objek wisata yang ada di Madura. Berdasarkan hasil penelitian yang dilakukan menghasilkan tingkat akurasi 100%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100061&gt;
{&#39;Abstrak&#39;: &#39;Madura merupakan salah satu pulau yang terletak di provinsi Jawa Timur yang memiliki 4 kabupaten yaitu bangkalan, sampang, pamekasan, sumenep. Di setiap kabupaten/ daerah yang berada di madura memiliki potensi wisata yang dapat dikunjungi. Namun permasalahan yang dihadapi yaitu belum adanya sistem yang mewadahi potensi wisata di Madura. Selain itu, wisatawan kesulitan mendapatkan informasi wisata resmi mengenai objek wisata dalam ruang lingkup Madura. Oleh sebab itu, diperlukan suatu sistem pendukung keputusan untuk pemilihan objek wisata di Madura  sebagai salah satu cara dalam memberikan  kemudahan pada calon wisatawan untuk dapat memilih objek wisata di Madura yang sesuai kriteria dan banyaknya pengunjung.  Berkaitan dengan  tujuan tersebut penelitian ini menerapkan metode logika Fuzzy sebagai model pendukung keputusan dalam pemilihan daftar objek wisata di Madura. Fuzzy digunakan karena metode ini merupakan suatu bentuk model pendukung keputusan dimana peralatan utamanya adalah sebuah hirarki fungsional dengan input utamanya kriteria yang telang ditentukan. Sehingga nantinya hasil yang diharapkan dapat membantu mempermudah calon wisatawan dalam mengambil keputusan untuk memilih objek wisata yang ada di Madura. Berdasarkan hasil penelitian yang dilakukan menghasilkan tingkat akurasi 100%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100061&gt;
{&#39;Abstrak&#39;: &#39;Kemampuan komputer dalam melakukan identifikasi manusia atau objek saat ini menjadi topik penelitian yang muncul dalam visi komputer, penelitian tersebut memiliki potensi yang sangat tinggi diberbagai bidang seperti intelijen bisnis berbasis video dan pengawasan visual. Para peneliti sebelumnya menggunakan model Convolutional Neural Network  (CNN) untuk identifikasi atribut pejalan kaki. Convolutional Neural Network  memiliki kemampuan untuk melakukan pembelajaran fitur secara otomatis (fature learning). Tetapi model ini memiliki kelemahan yaitu inisialisasi bobot yang dibangkitkan secara acak terkadang menyebabkan redundancy bobot dan korelasi antar bobot saling berhubungan sehingga tidak terdapat indenpedensi. Diusulkan Principal Component Analisys untuk ekstraksi eigenvector dan inisialisasi kernel konvolusi yang dikombinasikan dengan proses training pada model Convolutional Neural Network. Pada penelitian ini, dilakukan beberapa skenario pengujian untuk mengetahui pengaruh PCA terhadap kinerja CNN, arsitektur CNN yang dibuat di latih dan di uji menggunakan dataset PETA. Hasil dari uji coba yang dilakukan dengan inisialisasi filter pada layer konvolusi menggunakan pca - random, pca, dan random memperoleh rata-rata f1 score sebesar 49.7%, 48.3%, dan 46.6%. Dapat disimpulkan dari hasil yang diperoleh yaitu inisialisasi filter pada layer konvolusi menggunakan pca dapat mempengaruhi kinerja pada CNN.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100061&gt;
{&#39;Abstrak&#39;: &#39;Kemampuan komputer dalam melakukan identifikasi manusia atau objek saat ini menjadi topik penelitian yang muncul dalam visi komputer, penelitian tersebut memiliki potensi yang sangat tinggi diberbagai bidang seperti intelijen bisnis berbasis video dan pengawasan visual. Para peneliti sebelumnya menggunakan model Convolutional Neural Network  (CNN) untuk identifikasi atribut pejalan kaki. Convolutional Neural Network  memiliki kemampuan untuk melakukan pembelajaran fitur secara otomatis (fature learning). Tetapi model ini memiliki kelemahan yaitu inisialisasi bobot yang dibangkitkan secara acak terkadang menyebabkan redundancy bobot dan korelasi antar bobot saling berhubungan sehingga tidak terdapat indenpedensi. Diusulkan Principal Component Analisys untuk ekstraksi eigenvector dan inisialisasi kernel konvolusi yang dikombinasikan dengan proses training pada model Convolutional Neural Network. Pada penelitian ini, dilakukan beberapa skenario pengujian untuk mengetahui pengaruh PCA terhadap kinerja CNN, arsitektur CNN yang dibuat di latih dan di uji menggunakan dataset PETA. Hasil dari uji coba yang dilakukan dengan inisialisasi filter pada layer konvolusi menggunakan pca - random, pca, dan random memperoleh rata-rata f1 score sebesar 49.7%, 48.3%, dan 46.6%. Dapat disimpulkan dari hasil yang diperoleh yaitu inisialisasi filter pada layer konvolusi menggunakan pca dapat mempengaruhi kinerja pada CNN.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100062&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100062&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100061&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100061&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100062&gt;
{&#39;Abstrak&#39;: &#39;Banyaknya jumlah IKM (Industri Kecil Menengah) yang masuk kedalam data calon penerima bantuan Restrukturisasi Mesin di DISPERINDAG BANGKALAN menyebabkan adanya kesulitan dalam menentukan IKM yang tepat untuk penerimaan bantuan tersebut, dimana proses penyaluran yang dilakukan secara manualpun dirasa belum cukup efektif untuk diterapkan. Oleh sebab itu, perlu adanya suatu metode yang dirancang kedalam sebuah sistem pendukung keputusan  yang dapat mencakup kriteria-kriteria penilaian serta mampu menyimpan data-data yang berkaitan dengan pemilihan Industri Kecil Menengah (IKM) di Bangkalan. Dari sekian banyak metode yang dapat dilandaskan untuk sistem pendukung keputusan terdapat satu metode yang dianggap tepat, yakni Metode TOPSIS (Technique For Order Reference by Similarity to Ideal Solution). TOPSIS memiliki konsep dimana alternatif (kandidat) yang terpilih merupakan alternatif terbaik yang memiliki jarak terpendek dari solusi ideal positif dan jarak terjauh dari solusi ideal negatif. Hasil dari penentuan kriteria pemilihan didapatkan tujuh kriteria yang digunakan yaitu Investasi, Tenaga Kerja, Legalitas Usaha, Izin Industri, Sertifikat SNI, Partisipasi dan Mesin.Penerapan aplikasi ini diharapkan dapat memberikan kontribusi yang besar khususnya kepada pihak DESPERINDAG dalam sisi eferktifitas dan efisiensi waktu. &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100062&gt;
{&#39;Abstrak&#39;: &#39;Banyaknya jumlah IKM (Industri Kecil Menengah) yang masuk kedalam data calon penerima bantuan Restrukturisasi Mesin di DISPERINDAG BANGKALAN menyebabkan adanya kesulitan dalam menentukan IKM yang tepat untuk penerimaan bantuan tersebut, dimana proses penyaluran yang dilakukan secara manualpun dirasa belum cukup efektif untuk diterapkan. Oleh sebab itu, perlu adanya suatu metode yang dirancang kedalam sebuah sistem pendukung keputusan  yang dapat mencakup kriteria-kriteria penilaian serta mampu menyimpan data-data yang berkaitan dengan pemilihan Industri Kecil Menengah (IKM) di Bangkalan. Dari sekian banyak metode yang dapat dilandaskan untuk sistem pendukung keputusan terdapat satu metode yang dianggap tepat, yakni Metode TOPSIS (Technique For Order Reference by Similarity to Ideal Solution). TOPSIS memiliki konsep dimana alternatif (kandidat) yang terpilih merupakan alternatif terbaik yang memiliki jarak terpendek dari solusi ideal positif dan jarak terjauh dari solusi ideal negatif. Hasil dari penentuan kriteria pemilihan didapatkan tujuh kriteria yang digunakan yaitu Investasi, Tenaga Kerja, Legalitas Usaha, Izin Industri, Sertifikat SNI, Partisipasi dan Mesin.Penerapan aplikasi ini diharapkan dapat memberikan kontribusi yang besar khususnya kepada pihak DESPERINDAG dalam sisi eferktifitas dan efisiensi waktu. &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100062&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100062&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100062&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100062&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100062&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:44 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100062&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100062&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100062&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100062&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100062&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100063&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100063&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100062&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100062&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100063&gt;
{&#39;Abstrak&#39;: &#39;Striker adalah pemain yang berada di barisan depan dan berhadapan langsung dengan bek lawan, tugasnya adalah memasukkan bola ke gawang lawan. Seorang striker harus  memiliki akurasi shooting atau tendangan yang baik. Bukan hanya itu saja, seorang striker juga harus bisa membuka ruang tembak dan membuat peluang yang baik  untuk dirinya sendiri sehingga dapat mencetak gol, untuk itu dibutuhkan kejelian yang bagus dari seorang pelatih sepakbola dalam hal memilih striker. Seorang pelatih dalam memilih striker tidak hanya mengandalkan pengamatannya saja, tetapi harus melihat catatan data yang signifikan yang dapat mendukung keputusan tersebut, maka dibutuhkan sistem pendukung keputusan untuk menyelesaikan masalah tersebut. Sistem ini menerapkan metode WP (Weight Product) yang tujuannya memberikan rekomendasi kepada pelatih untuk pemilihan posisi setiap pemain, serta mengetahui kebutuhan team pemain mana yang cocok ditempatkan pada posisi striker. Dari hasil penelitian WP (Weight Product) dapat diimplementasikan dalam sistem pemilihan striker dan memiliki nilai akurasi 55% yang didapatkan dari hasil perbandingan antara hasil perhitungan sistem dengan data rekomendasi pelatih.\nKata kunci : Sepakbola, Pemilihan Striker , WP (Weight Product).\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100063&gt;
{&#39;Abstrak&#39;: &#39;Striker adalah pemain yang berada di barisan depan dan berhadapan langsung dengan bek lawan, tugasnya adalah memasukkan bola ke gawang lawan. Seorang striker harus  memiliki akurasi shooting atau tendangan yang baik. Bukan hanya itu saja, seorang striker juga harus bisa membuka ruang tembak dan membuat peluang yang baik  untuk dirinya sendiri sehingga dapat mencetak gol, untuk itu dibutuhkan kejelian yang bagus dari seorang pelatih sepakbola dalam hal memilih striker. Seorang pelatih dalam memilih striker tidak hanya mengandalkan pengamatannya saja, tetapi harus melihat catatan data yang signifikan yang dapat mendukung keputusan tersebut, maka dibutuhkan sistem pendukung keputusan untuk menyelesaikan masalah tersebut. Sistem ini menerapkan metode WP (Weight Product) yang tujuannya memberikan rekomendasi kepada pelatih untuk pemilihan posisi setiap pemain, serta mengetahui kebutuhan team pemain mana yang cocok ditempatkan pada posisi striker. Dari hasil penelitian WP (Weight Product) dapat diimplementasikan dalam sistem pemilihan striker dan memiliki nilai akurasi 55% yang didapatkan dari hasil perbandingan antara hasil perhitungan sistem dengan data rekomendasi pelatih.\nKata kunci : Sepakbola, Pemilihan Striker , WP (Weight Product).\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100063&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100063&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100063&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100063&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100063&gt;
{&#39;Abstrak&#39;: &#39;Mojokerto merupakan salah satu kabupaten di Jawa Timur yang memiliki berbagai macam kebudayaan, tradisi, sejarah hingga wisata yang menarik. Keanekaragaman tersebut berpotensi menjadikan Mojokerto menjadi tempat yang ramai dikunjungi para wisatawan. Waktu yang singkat dan banyaknya destinasi wisata yang ingin dikunjungi, membuat wisatawan harus menjadwalkan perjalanan wisatanya seefektif mungkin. Dengan mengimplemetasikan Traveling Salesman Problem menggunakan algoritma Greedy aplikasi dapat memberikan informasi kepada pengguna tentang rute paling optimum menuju beberapa lokasi wisata, pengguna dapat menentukan jalur yang akan dilalui untuk mengatasi efesiensi waktu. Algoritma Greedy dipilih dalam kasus Traveling Salesman Porblem karena algoritma ini dapat memberikan sebuah solusi terbaik untuk permasalahan optimasi dengan waktu pemrosesan yang cepat. Selain memberikan rute paling optimum, sistem juga memberikan informasi deskripsi mengenai destinasi wisata, tempata makan, dan penginapan yang dibutuhkan oleh wisatawan. Hasil dari implementasi Sistem Informasi Geografis Menggunakan Algoritma Greedy, didapatkan performa yang Baik dimana dapat dilihat dari akurasi ketepatan rekomendasi rute yang diberikan cukup sesuai dengan rekomendasi yang diberikan oleh dinas pariwisata, dan dalam pemroresan Algoritma Greedy cukup singkat dengan kisaran waktu kurang dari 1 detik. Sistem cukup membantu wisatawan dalam memberikan informasi mengenai destinasi wisata dan menunjukan rekomendasi rute yang optimum yang dapat dilihat dari pengujian respon user yang mendapatkan nilai 79,8 %.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100063&gt;
{&#39;Abstrak&#39;: &#39;Mojokerto merupakan salah satu kabupaten di Jawa Timur yang memiliki berbagai macam kebudayaan, tradisi, sejarah hingga wisata yang menarik. Keanekaragaman tersebut berpotensi menjadikan Mojokerto menjadi tempat yang ramai dikunjungi para wisatawan. Waktu yang singkat dan banyaknya destinasi wisata yang ingin dikunjungi, membuat wisatawan harus menjadwalkan perjalanan wisatanya seefektif mungkin. Dengan mengimplemetasikan Traveling Salesman Problem menggunakan algoritma Greedy aplikasi dapat memberikan informasi kepada pengguna tentang rute paling optimum menuju beberapa lokasi wisata, pengguna dapat menentukan jalur yang akan dilalui untuk mengatasi efesiensi waktu. Algoritma Greedy dipilih dalam kasus Traveling Salesman Porblem karena algoritma ini dapat memberikan sebuah solusi terbaik untuk permasalahan optimasi dengan waktu pemrosesan yang cepat. Selain memberikan rute paling optimum, sistem juga memberikan informasi deskripsi mengenai destinasi wisata, tempata makan, dan penginapan yang dibutuhkan oleh wisatawan. Hasil dari implementasi Sistem Informasi Geografis Menggunakan Algoritma Greedy, didapatkan performa yang Baik dimana dapat dilihat dari akurasi ketepatan rekomendasi rute yang diberikan cukup sesuai dengan rekomendasi yang diberikan oleh dinas pariwisata, dan dalam pemroresan Algoritma Greedy cukup singkat dengan kisaran waktu kurang dari 1 detik. Sistem cukup membantu wisatawan dalam memberikan informasi mengenai destinasi wisata dan menunjukan rekomendasi rute yang optimum yang dapat dilihat dari pengujian respon user yang mendapatkan nilai 79,8 %.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100063&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100063&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100063&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100063&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100064&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100064&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100063&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100063&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100064&gt;
{&#39;Abstrak&#39;: &#39;Madura memiliki berbagai macam tempat wisata yang menarik. Banyaknya pantai yang eksotis, serta tempat wisata lain yang tidak kalah menarik, membuat Madura memiliki potensi pariwisata yang tinggi. Sayangnya dengan berbagai tempat wisata yang menarik tersebut, masih banyak masyarakat luas yang belum mengetahui lokasi – lokasi wisata tersebut berada, tempat wisata di madura juga membutuhkan wadah promosi untuk menunjang kemajuan wisatanya.\nPenelitian ini ditujukan untuk membuat aplikasi Digital Guide dengan menggunakan konsep Location Based Service (LBS), LBS  digunakan untuk mengetahui informasi suatu lokasi sesuai dengan koordinat tersebut sehingga dapat mengetahui jarak lokasi tersebut dari lokasi pengguna. Teknologi Augmented Reality digunakan pengguna menggunakan kamera smartphone untuk mengetahui letak lokasi wisata yang akan dituju.\nDari hasil penelitian yang dilakukan, didapat hasil bahwa pada fitur augmented reality membutuhkan setidaknya 2 kali percobaan untuk bisa mengaksesnya menggunakan koneksi internet. Dan dari hasil ujicoba User Experience yang berbentuk kuisioner kepada responden didapat hasil 1060 dari 1200 skala nilai maksimal yang menunjukkan tingkat kepuasan cukup bagus. \n\nKata Kunci: Location Based Servise, Global Positioning System, Android, Smartphone, Wisata Madura, Augmented Reality.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100064&gt;
{&#39;Abstrak&#39;: &#39;Madura memiliki berbagai macam tempat wisata yang menarik. Banyaknya pantai yang eksotis, serta tempat wisata lain yang tidak kalah menarik, membuat Madura memiliki potensi pariwisata yang tinggi. Sayangnya dengan berbagai tempat wisata yang menarik tersebut, masih banyak masyarakat luas yang belum mengetahui lokasi – lokasi wisata tersebut berada, tempat wisata di madura juga membutuhkan wadah promosi untuk menunjang kemajuan wisatanya.\nPenelitian ini ditujukan untuk membuat aplikasi Digital Guide dengan menggunakan konsep Location Based Service (LBS), LBS  digunakan untuk mengetahui informasi suatu lokasi sesuai dengan koordinat tersebut sehingga dapat mengetahui jarak lokasi tersebut dari lokasi pengguna. Teknologi Augmented Reality digunakan pengguna menggunakan kamera smartphone untuk mengetahui letak lokasi wisata yang akan dituju.\nDari hasil penelitian yang dilakukan, didapat hasil bahwa pada fitur augmented reality membutuhkan setidaknya 2 kali percobaan untuk bisa mengaksesnya menggunakan koneksi internet. Dan dari hasil ujicoba User Experience yang berbentuk kuisioner kepada responden didapat hasil 1060 dari 1200 skala nilai maksimal yang menunjukkan tingkat kepuasan cukup bagus. \n\nKata Kunci: Location Based Servise, Global Positioning System, Android, Smartphone, Wisata Madura, Augmented Reality.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100064&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100064&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100064&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100064&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100064&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100064&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100064&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100064&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100064&gt;
{&#39;Abstrak&#39;: &#39;Sistem rekomendasi adalah sistem yang memprediksi rating atau preferensi yang akan diberikan user ke suatu item.Tujuan dari sistem rekomendasi agar  secara otomatis menghasilkan item yang disarankan untuk pengguna sesuai dengan preferensi historis mereka dan menghemat waktu pencarian mereka secara online dengan mengumpulkan data yang berhubungan dengan user atau item yang bermanfaat. Rekomendasi film adalah aplikasi yang paling populer digunakan ditambah dengan platform multimedia online. Dalam menghasilkan rekomendasi ada beberapa pendekatan metode tradisional yaitu metode Collaborative Filtering(CF) dan Content-Based (CB). Meskipun kedua metode memiliki kelebihan, mereka juga memiliki kelemahan tertentu pada masing-masing setiap metode. Secara umum pada pendekatan metode CF melaporkan kinerja yang lebih baik daripada pendekatan CB, tetapi keberhasilannya bergantung pada jumlah rating user yang mencukupi (Sparsity). Dalam situasi ini penggunaan pendekatan CB muncul sebagai alternatif. Namun demikian, pendekatan ini memiliki keterbatasannya sendiri. Misalnya, kata kunci yang digunakan untuk mewakili konten item mungkin tidak terlalu representatif. Salah satu algoritma yang sering digunakan pada metode CF ini yaitu item-based dan user-based. Item-based CF mempunyai akurasi yang lebih baik dibandingkan user-based CF. Maka solusi yang ditawarkan dengan menutupi kekurangan kedua metode pada penelitian ini dilakukanlah metode Hybrid(CB dan CF item-based). Pada CB akan dilakukan text mining untuk melakukan text prepocessing nya dan algoritma K-Means untuk melakukan clustering data karena metode ini telah dikenal sangat efisien dan diperhitungkan dalam melakukan clustering. Dala penelitian ini hasil evaluasi dengan pendekatan metode hybrid (CB dan CF item-based) dalam mengatasi sparsity data dan kelemahan pada metode CB dan CF item-based dalam menghasilkan suatu rekomendasi diperoleh hasil evaluasi DCG dengan menggunakan nilai  parameter jumlah neighbour(Q) = 40, jumlah cluster(k) = 520 dan Top-10 adalah 0,03840.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100064&gt;
{&#39;Abstrak&#39;: &#39;Sistem rekomendasi adalah sistem yang memprediksi rating atau preferensi yang akan diberikan user ke suatu item.Tujuan dari sistem rekomendasi agar  secara otomatis menghasilkan item yang disarankan untuk pengguna sesuai dengan preferensi historis mereka dan menghemat waktu pencarian mereka secara online dengan mengumpulkan data yang berhubungan dengan user atau item yang bermanfaat. Rekomendasi film adalah aplikasi yang paling populer digunakan ditambah dengan platform multimedia online. Dalam menghasilkan rekomendasi ada beberapa pendekatan metode tradisional yaitu metode Collaborative Filtering(CF) dan Content-Based (CB). Meskipun kedua metode memiliki kelebihan, mereka juga memiliki kelemahan tertentu pada masing-masing setiap metode. Secara umum pada pendekatan metode CF melaporkan kinerja yang lebih baik daripada pendekatan CB, tetapi keberhasilannya bergantung pada jumlah rating user yang mencukupi (Sparsity). Dalam situasi ini penggunaan pendekatan CB muncul sebagai alternatif. Namun demikian, pendekatan ini memiliki keterbatasannya sendiri. Misalnya, kata kunci yang digunakan untuk mewakili konten item mungkin tidak terlalu representatif. Salah satu algoritma yang sering digunakan pada metode CF ini yaitu item-based dan user-based. Item-based CF mempunyai akurasi yang lebih baik dibandingkan user-based CF. Maka solusi yang ditawarkan dengan menutupi kekurangan kedua metode pada penelitian ini dilakukanlah metode Hybrid(CB dan CF item-based). Pada CB akan dilakukan text mining untuk melakukan text prepocessing nya dan algoritma K-Means untuk melakukan clustering data karena metode ini telah dikenal sangat efisien dan diperhitungkan dalam melakukan clustering. Dala penelitian ini hasil evaluasi dengan pendekatan metode hybrid (CB dan CF item-based) dalam mengatasi sparsity data dan kelemahan pada metode CB dan CF item-based dalam menghasilkan suatu rekomendasi diperoleh hasil evaluasi DCG dengan menggunakan nilai  parameter jumlah neighbour(Q) = 40, jumlah cluster(k) = 520 dan Top-10 adalah 0,03840.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100065&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100065&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100064&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100064&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100065&gt;
{&#39;Abstrak&#39;: &#39;Penyakit Stroke merupakan penyakit mematikan di Indonesia yang menempati urutan nomer tiga setelah Jantung dan Kanker. Sesuai dengan pengamatan dan peninjauan Yayasan Stroke Indonesia (Yastroki) di rumah sakit maupun yang berada dalam masyarakat, terdapat kecenderungan meningkatnya jumlah penyandang stroke di Indonesia. Untuk mendukung para pakar dalam mendiagnosa penyakit stroke maka dibangunlah suatu sistem pakar. Sistem ini dibangun menggunakan Metode Certainty Factor, yaitu suatu metode untuk membuktikan apakah suatu fakta itu pasti ataukah tidak pasti yang berbentuk matrik yang biasanya digunakan dalam sistem pakar. Hasil dari penelitian ini diharapkan dapat mendukung pakar dalam mendiagnosa penyakit Stroke. Dari penelitian ini telah dihasilkan sistem pakar untuk mendiagnosa penyakit Stroke dan setelah dilakukan pengujian dengan 21 data pasien, diperoleh nilai akurasi sebesar 66,67%. &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:45 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100065&gt;
{&#39;Abstrak&#39;: &#39;Penyakit Stroke merupakan penyakit mematikan di Indonesia yang menempati urutan nomer tiga setelah Jantung dan Kanker. Sesuai dengan pengamatan dan peninjauan Yayasan Stroke Indonesia (Yastroki) di rumah sakit maupun yang berada dalam masyarakat, terdapat kecenderungan meningkatnya jumlah penyandang stroke di Indonesia. Untuk mendukung para pakar dalam mendiagnosa penyakit stroke maka dibangunlah suatu sistem pakar. Sistem ini dibangun menggunakan Metode Certainty Factor, yaitu suatu metode untuk membuktikan apakah suatu fakta itu pasti ataukah tidak pasti yang berbentuk matrik yang biasanya digunakan dalam sistem pakar. Hasil dari penelitian ini diharapkan dapat mendukung pakar dalam mendiagnosa penyakit Stroke. Dari penelitian ini telah dihasilkan sistem pakar untuk mendiagnosa penyakit Stroke dan setelah dilakukan pengujian dengan 21 data pasien, diperoleh nilai akurasi sebesar 66,67%. &#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100065&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100065&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100065&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100065&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100065&gt;
{&#39;Abstrak&#39;: &#39;Penjadwalan mata kuliah pada perguruan tinggi atau universitas merupakan hal yang sangat penting dalam proses kegiatan akademik dan juga menjadi suatu persoalan yang sulit dipecahkan. Dengan keterbatasan dosen yang ada, jumlah ruangan dan kelas dituntut agar tetap bisa memenuhi kebutuhan pelayanan kepada mahasiswa. Saat ini, penjadwalan yang dilakukan pada Fakultas Pertanian Universitas Tunojoyo Madura seringkali mengalami kesulitan dalam menyusun jadwal. Dikarenakan banyaknya jumlah mata kuliah dan kelas disertai dengan terbatasnya tenaga mengajar dan ruang perkuliahan. Oleh karena itu, perlu dilakukan optimasi penjadwalan secara otomatis. Berdasarkan permasalahan yang ada, diperlukan suatu aplikasi penjadwalan perkuliahan secara otomatis agar dapat menangani hal tersebut. Ada beberapa metode pada penelitian sebelumnya yang digunakan untuk memecahkan masalah penjadwalan dan menghasilkan jadwal optimal, seperti metode Tabu Search. Dalam penelitian ini, penyelesaian masalah penjadwalan perkuliahan menggunakan metode Tabu Search. Tabu Search merupakan metode yang berlandaskan pada pencarian lokal (local search). Dalam metode Tabu Search, solusi awal berupa jadwal yang dibangkitkan secara random, kemudian dicari solusi akhirnya dan yang menjadi Tabu List adalah kumpulan move berbentuk array yang merupakan solusi jadwal mata kuliah dengan nilai total penalti paling kecil pada tiap iterasi. Penelitian ini menghasilkan rata-rata pelanggaran soft constraint sebanyak 3,15. Untuk rata-rata waktu sebanyak 37,06 detik. Rata-rata keakuratan penjadwalan adalah 94,7%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100065&gt;
{&#39;Abstrak&#39;: &#39;Penjadwalan mata kuliah pada perguruan tinggi atau universitas merupakan hal yang sangat penting dalam proses kegiatan akademik dan juga menjadi suatu persoalan yang sulit dipecahkan. Dengan keterbatasan dosen yang ada, jumlah ruangan dan kelas dituntut agar tetap bisa memenuhi kebutuhan pelayanan kepada mahasiswa. Saat ini, penjadwalan yang dilakukan pada Fakultas Pertanian Universitas Tunojoyo Madura seringkali mengalami kesulitan dalam menyusun jadwal. Dikarenakan banyaknya jumlah mata kuliah dan kelas disertai dengan terbatasnya tenaga mengajar dan ruang perkuliahan. Oleh karena itu, perlu dilakukan optimasi penjadwalan secara otomatis. Berdasarkan permasalahan yang ada, diperlukan suatu aplikasi penjadwalan perkuliahan secara otomatis agar dapat menangani hal tersebut. Ada beberapa metode pada penelitian sebelumnya yang digunakan untuk memecahkan masalah penjadwalan dan menghasilkan jadwal optimal, seperti metode Tabu Search. Dalam penelitian ini, penyelesaian masalah penjadwalan perkuliahan menggunakan metode Tabu Search. Tabu Search merupakan metode yang berlandaskan pada pencarian lokal (local search). Dalam metode Tabu Search, solusi awal berupa jadwal yang dibangkitkan secara random, kemudian dicari solusi akhirnya dan yang menjadi Tabu List adalah kumpulan move berbentuk array yang merupakan solusi jadwal mata kuliah dengan nilai total penalti paling kecil pada tiap iterasi. Penelitian ini menghasilkan rata-rata pelanggaran soft constraint sebanyak 3,15. Untuk rata-rata waktu sebanyak 37,06 detik. Rata-rata keakuratan penjadwalan adalah 94,7%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100065&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100065&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100065&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100065&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100066&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100066&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100065&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100065&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100066&gt;
{&#39;Abstrak&#39;: &#39;Acute Lymphoblastic Leukemia (ALL) adalah salah satu jenis leukemia. Leukemia merupakan jenis kanker yang terjadi pada darah dan sumsum tulang belakang. Penyakit Leukemia yang tidak mengenal usia menjadi momok bagi masyarakat karena sering terjadi keterlambatan penanganan. Hal ini terjadi karena mahalnya biaya identifikasi dengan menggunakan reaksi kimia. Menggunakan reaksi kimia ini juga membutuh tenaga dan waktu yang lama.  Mengatasi hal tersebut, dilakukan identifikasi leukemia pada citra sel darah putih. Citra darah terdiri dari sel darah putih dan background. Pemisahan sel darah putih dengan background, proses ini dinama proses segmentasi. Metode segmentasi yang dipakai metode morfologi matematis. Proses pencarian ciri menggunakan fitur tekstur metode Gray Level Co-Occurence Matrix (GLCM) dan fitur bentuk. Proses klasifikasi menggunakan metode Learning Vector Quantization(LVQ). Database menggunakan ALL-IDB2 sebanyak 260 citra, terdiri dari 130 citra positif ALL dan 130 citra negatif ALL. Klasifikasi ALL menggunakan Learning Vector Quantization(LVQ) memperlihatkan hasil rata-rata akurasi sebesar 74,59 %.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100066&gt;
{&#39;Abstrak&#39;: &#39;Acute Lymphoblastic Leukemia (ALL) adalah salah satu jenis leukemia. Leukemia merupakan jenis kanker yang terjadi pada darah dan sumsum tulang belakang. Penyakit Leukemia yang tidak mengenal usia menjadi momok bagi masyarakat karena sering terjadi keterlambatan penanganan. Hal ini terjadi karena mahalnya biaya identifikasi dengan menggunakan reaksi kimia. Menggunakan reaksi kimia ini juga membutuh tenaga dan waktu yang lama.  Mengatasi hal tersebut, dilakukan identifikasi leukemia pada citra sel darah putih. Citra darah terdiri dari sel darah putih dan background. Pemisahan sel darah putih dengan background, proses ini dinama proses segmentasi. Metode segmentasi yang dipakai metode morfologi matematis. Proses pencarian ciri menggunakan fitur tekstur metode Gray Level Co-Occurence Matrix (GLCM) dan fitur bentuk. Proses klasifikasi menggunakan metode Learning Vector Quantization(LVQ). Database menggunakan ALL-IDB2 sebanyak 260 citra, terdiri dari 130 citra positif ALL dan 130 citra negatif ALL. Klasifikasi ALL menggunakan Learning Vector Quantization(LVQ) memperlihatkan hasil rata-rata akurasi sebesar 74,59 %.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100066&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100066&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100066&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100066&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100066&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100066&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100066&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100066&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100066&gt;
{&#39;Abstrak&#39;: &#39;Identifikasi atribut adalah upaya untuk mengenali atribut yang dikenakan oleh objek pejalan kaki pada suatu citra, seperti jenis kelamin, usia, penampilan, gaya berpakaian dan aksesori. Identifikasi atribut sangat penting untuk  kepentingan keamanan, misalnya untuk mengungkap pelaku kejahatan melalui ciri-ciri atau atribut dari pelaku. Pada penelitian ini membangun model identifikasi atribut menggunakan Multi-Label Convolutional Neural Network (MLCNN). MLCNN dibangun dengan integrasi pembagian citra input menggunakan sebuah window untuk menangkap informasi atribut secara lokal (fitur lokal). Terdapat beberapa tahapan yang dilakukan, yaitu resize citra, pembagian citra, dan masing-masing hasil pembagian terintegrasi dengan CNN (feature learning dan classification). Pada penelitian ini dilakukan beberapa uji coba dengan model pembagian citra yang berbeda untuk mengetahui pengaruh yang dihasilkan terhadap kinerja MLCNN. Uji coba dilakukan pada dataset PETA yang terdiri dari 19.000 citra dan 35 atribut yang digunakan. Berdasarkan uji coba yang telah dilakukan, model pembagian citra yang digunakan mempengaruhi hasil identifikasi atribut. Pembagian citra secara horizontal menghasilkan akurasi lebih baik daripada pembagian citra secara vertikal, karena informasi atribut yang didapat lebih detail/lengkap. Model terbaik dalam mengidentifikasi 35 atribut adalah model dengan pembagian citra secara horizontal dua bagian dengan akurasi rata-rata 52,94%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100066&gt;
{&#39;Abstrak&#39;: &#39;Identifikasi atribut adalah upaya untuk mengenali atribut yang dikenakan oleh objek pejalan kaki pada suatu citra, seperti jenis kelamin, usia, penampilan, gaya berpakaian dan aksesori. Identifikasi atribut sangat penting untuk  kepentingan keamanan, misalnya untuk mengungkap pelaku kejahatan melalui ciri-ciri atau atribut dari pelaku. Pada penelitian ini membangun model identifikasi atribut menggunakan Multi-Label Convolutional Neural Network (MLCNN). MLCNN dibangun dengan integrasi pembagian citra input menggunakan sebuah window untuk menangkap informasi atribut secara lokal (fitur lokal). Terdapat beberapa tahapan yang dilakukan, yaitu resize citra, pembagian citra, dan masing-masing hasil pembagian terintegrasi dengan CNN (feature learning dan classification). Pada penelitian ini dilakukan beberapa uji coba dengan model pembagian citra yang berbeda untuk mengetahui pengaruh yang dihasilkan terhadap kinerja MLCNN. Uji coba dilakukan pada dataset PETA yang terdiri dari 19.000 citra dan 35 atribut yang digunakan. Berdasarkan uji coba yang telah dilakukan, model pembagian citra yang digunakan mempengaruhi hasil identifikasi atribut. Pembagian citra secara horizontal menghasilkan akurasi lebih baik daripada pembagian citra secara vertikal, karena informasi atribut yang didapat lebih detail/lengkap. Model terbaik dalam mengidentifikasi 35 atribut adalah model dengan pembagian citra secara horizontal dua bagian dengan akurasi rata-rata 52,94%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100067&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100067&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100066&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100066&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100067&gt;
{&#39;Abstrak&#39;: &#39;Kabupaten Bangkalan merupakan salah satu kabupaten yang mempunyai potensi Usaha Mikro Kecil dan Menengah (UMKM) yang cukup banyak. Tercatat ada 166,768 UMKM yang terdapat di Rekapitulasi Data UMKM Kabupaten Bangkalan pada Dinas Koperasi dan UMKM Bangkalan. Dari sekian banyaknya UMKM tersebut, masalah yang di hadapi adalah kurangnya media informasi secara detail terkait letak lokasi dan jenis-jenis produk UMKM yang dihasilkan di setiap wilayah kepada masyarakat umum Bangkalan maupun kepada masyarakat (asing) luar Bangkalan. Sehingga dibuatlah sebuah aplikasi web berbasis Sistem Informasi Geografis Pemetaan pada Usaha Mikro, Kecil dan Menengah (UMKM) di Bangkalan dengan menggunakan 15 data evaluator menunjukkan hasil nilai rata-rata berdasarkan nilai penggunaan sistem sebesar 86,25% dan berdasarkan nilai desain dan tampilan sistem sebesar 84,5% atau bisa dikatakan Aplikasi sudah mencapai tujuan yang diharapkan.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100067&gt;
{&#39;Abstrak&#39;: &#39;Kabupaten Bangkalan merupakan salah satu kabupaten yang mempunyai potensi Usaha Mikro Kecil dan Menengah (UMKM) yang cukup banyak. Tercatat ada 166,768 UMKM yang terdapat di Rekapitulasi Data UMKM Kabupaten Bangkalan pada Dinas Koperasi dan UMKM Bangkalan. Dari sekian banyaknya UMKM tersebut, masalah yang di hadapi adalah kurangnya media informasi secara detail terkait letak lokasi dan jenis-jenis produk UMKM yang dihasilkan di setiap wilayah kepada masyarakat umum Bangkalan maupun kepada masyarakat (asing) luar Bangkalan. Sehingga dibuatlah sebuah aplikasi web berbasis Sistem Informasi Geografis Pemetaan pada Usaha Mikro, Kecil dan Menengah (UMKM) di Bangkalan dengan menggunakan 15 data evaluator menunjukkan hasil nilai rata-rata berdasarkan nilai penggunaan sistem sebesar 86,25% dan berdasarkan nilai desain dan tampilan sistem sebesar 84,5% atau bisa dikatakan Aplikasi sudah mencapai tujuan yang diharapkan.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100067&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100067&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100067&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100067&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100067&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:46 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100067&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100067&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100067&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100067&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100067&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100067&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100067&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100068&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100068&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100068&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100068&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100068&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100068&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100068&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100068&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100068&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100068&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100068&gt;
{&#39;Abstrak&#39;: &#39;Bola voli merupakan permainan olahraga yang dimainkan oleh dua tim, satu tim  beranggotakan enam orang yang saling bertanding untuk menjadi pemenang dan menjadi juara dalam sebuah kompetisi. Dalam sebuah kompetisi terdapat banyak penghargaan selain tim yang juara, salah satunya adalah pemain terbaik atau sering disebut dengan Most Valuable Player (MVP). Namun dalam menentukan pemain terbaik dalam sebuah kompetisi masih menggunakan cara yang manual atau dengan cara menghitung nilai ranking dari semua pemain yang berkompetisi sehingga sulit bagi panitia kompetisi untuk melakukan pemilihan pemain terbaik, oleh sebab itu diperlukan suatu sistem pendukung keputusan agar panitia dapat lebih cepat dan akurat dalam mentukan siapa yang layak untuk mendapat penghargaan pemain terbaik. Sistem pendukung keputusan ini mengimplementsikan metode geometric mean dan metode TOPSIS (Technique For Others Reference by Similarity to Ideal Solution). Geometric mean digunakan untuk mencari rata-rata dari banyaknya bobot yang diinputkan, TOPSIS lebih banyak digunakan karena kesederhanaannya dalam mersepon kebutuhan pembuat keputusan dan caranya menganalisa respon. Ada beberapa kriteria yang menjadi bahan pertimbangan dalam menentukan pemain terbaik antara lain serve, receive, dig, toss, spike dan block. Pengujian dilakukan dengan cara membandingkan hasil system pendukung keputusan dengan hasil keputusan panitia yang terdiri dari 5 turnamen proliga dari tahun 2015-2019, dengan hasil tingkat akurasi sebesar 60% yang menunjukan bahwa system pendukung keputusan dapat digunakan untuk menentukan pemain terbaik dalam sebuah turnamaen atau kompetisi. \nKata kunci: Bola Voli, Sistem Pendukung Keputusan, Geometric Mean, Pemain Terbaik, TOPSIS\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100068&gt;
{&#39;Abstrak&#39;: &#39;Bola voli merupakan permainan olahraga yang dimainkan oleh dua tim, satu tim  beranggotakan enam orang yang saling bertanding untuk menjadi pemenang dan menjadi juara dalam sebuah kompetisi. Dalam sebuah kompetisi terdapat banyak penghargaan selain tim yang juara, salah satunya adalah pemain terbaik atau sering disebut dengan Most Valuable Player (MVP). Namun dalam menentukan pemain terbaik dalam sebuah kompetisi masih menggunakan cara yang manual atau dengan cara menghitung nilai ranking dari semua pemain yang berkompetisi sehingga sulit bagi panitia kompetisi untuk melakukan pemilihan pemain terbaik, oleh sebab itu diperlukan suatu sistem pendukung keputusan agar panitia dapat lebih cepat dan akurat dalam mentukan siapa yang layak untuk mendapat penghargaan pemain terbaik. Sistem pendukung keputusan ini mengimplementsikan metode geometric mean dan metode TOPSIS (Technique For Others Reference by Similarity to Ideal Solution). Geometric mean digunakan untuk mencari rata-rata dari banyaknya bobot yang diinputkan, TOPSIS lebih banyak digunakan karena kesederhanaannya dalam mersepon kebutuhan pembuat keputusan dan caranya menganalisa respon. Ada beberapa kriteria yang menjadi bahan pertimbangan dalam menentukan pemain terbaik antara lain serve, receive, dig, toss, spike dan block. Pengujian dilakukan dengan cara membandingkan hasil system pendukung keputusan dengan hasil keputusan panitia yang terdiri dari 5 turnamen proliga dari tahun 2015-2019, dengan hasil tingkat akurasi sebesar 60% yang menunjukan bahwa system pendukung keputusan dapat digunakan untuk menentukan pemain terbaik dalam sebuah turnamaen atau kompetisi. \nKata kunci: Bola Voli, Sistem Pendukung Keputusan, Geometric Mean, Pemain Terbaik, TOPSIS\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100069&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100069&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100068&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100068&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100069&gt;
{&#39;Abstrak&#39;: &#39;Proses rekrutmen dalam suatu perusahaan atau organisasi biasanya diikuti oleh banyak pelamar yang ingin mendaftar. Pada saat itu, biasanya menemukan kasus kesalahan proses rekrutmen di sebuah perusahaan atau organisasi. Juga dimungkinkan di PT. Satya Multi Sukses. Ini sebenarnya tergantung pada pihak agen yang akan melakukan seleksi penerimaannya sendiri. Sebenarnya, proses pemilihan karyawan sesuai dengan kemampuan intelektual dan kemampuan untuk bekerja sesuai dengan kualitasnya sangat sulit untuk dibedakan. Ada beberapa kriteria penilaian dalam proses pengambilan keputusan perekrutan di PT. Satya Multi Sukses. Adapun penilaian didasarkan pada kriteria pendidikan, pekerjaan pengalaman, usia, memiliki kendaraan, dan SIM. Tujuan yang ingin dicapai adalah menciptakan sebuah sistem yang dapat membantu pengambil keputusan untuk menentukan proses rekrutmen secara optimal dengan menggunakan metode Simple Additive Weighting. Hasil penelitian bertujuan membangun sistem pendukung keputusan untuk penerimaan calon kurir, dan akhirnya bisa digunakan sebagai penunjang keputusan untuk pihak majemen perusahaan.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100069&gt;
{&#39;Abstrak&#39;: &#39;Proses rekrutmen dalam suatu perusahaan atau organisasi biasanya diikuti oleh banyak pelamar yang ingin mendaftar. Pada saat itu, biasanya menemukan kasus kesalahan proses rekrutmen di sebuah perusahaan atau organisasi. Juga dimungkinkan di PT. Satya Multi Sukses. Ini sebenarnya tergantung pada pihak agen yang akan melakukan seleksi penerimaannya sendiri. Sebenarnya, proses pemilihan karyawan sesuai dengan kemampuan intelektual dan kemampuan untuk bekerja sesuai dengan kualitasnya sangat sulit untuk dibedakan. Ada beberapa kriteria penilaian dalam proses pengambilan keputusan perekrutan di PT. Satya Multi Sukses. Adapun penilaian didasarkan pada kriteria pendidikan, pekerjaan pengalaman, usia, memiliki kendaraan, dan SIM. Tujuan yang ingin dicapai adalah menciptakan sebuah sistem yang dapat membantu pengambil keputusan untuk menentukan proses rekrutmen secara optimal dengan menggunakan metode Simple Additive Weighting. Hasil penelitian bertujuan membangun sistem pendukung keputusan untuk penerimaan calon kurir, dan akhirnya bisa digunakan sebagai penunjang keputusan untuk pihak majemen perusahaan.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100068&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100068&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.crawler:Received SIGINT, shutting down gracefully. Send again to force 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100069&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100069&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.core.engine:Closing spider (shutdown)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.engine] INFO: Closing spider (shutdown)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100069&gt;
{&#39;Abstrak&#39;: &#39;Jagung merupakan salah satu tanaman yang cukup penting, karena jagung adalah komoditas pangan terbesar kedua setelah padi. Akan tetapi kebutuhan atas komoditas jagung di Indonesia masih belum tercukupi sehingga harus mengimpor dari negara lain. Di antara salah satu faktornya adalah hama dan penyakit yang menyerang tanaman jagung yang menyebabkan rendahnya hasil panen jagung. Sehingga teknik pemrosesan citra digital perlu diterapkan untuk mendeteksi penyakit tanaman jagung sejak dini. Metode yang akan digunakan adalah Fuzzy Color Histogram (FCH) untuk ekstraksi warna karena keunggulan metode ini yaitu tidak terlalu sensitif dengan noisy dan perbedaan cahaya. Sedangkan untuk ekstraksi fitur tekstur, metode yang akan digunakan adalah metode Gray Level Run-Length Matrix (GLRLM). Dari data uji sebanyak 3.847 citra daun jagung, hasil akurasi tertinggi dari metode FCH adalah 73.95%, untuk metode GLRLM adalah 69.17%, sedangkan untuk penggabungan keduanya menghasilkan akurasi paling tinggi yaitu 81.29%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:47 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100069&gt;
{&#39;Abstrak&#39;: &#39;Jagung merupakan salah satu tanaman yang cukup penting, karena jagung adalah komoditas pangan terbesar kedua setelah padi. Akan tetapi kebutuhan atas komoditas jagung di Indonesia masih belum tercukupi sehingga harus mengimpor dari negara lain. Di antara salah satu faktornya adalah hama dan penyakit yang menyerang tanaman jagung yang menyebabkan rendahnya hasil panen jagung. Sehingga teknik pemrosesan citra digital perlu diterapkan untuk mendeteksi penyakit tanaman jagung sejak dini. Metode yang akan digunakan adalah Fuzzy Color Histogram (FCH) untuk ekstraksi warna karena keunggulan metode ini yaitu tidak terlalu sensitif dengan noisy dan perbedaan cahaya. Sedangkan untuk ekstraksi fitur tekstur, metode yang akan digunakan adalah metode Gray Level Run-Length Matrix (GLRLM). Dari data uji sebanyak 3.847 citra daun jagung, hasil akurasi tertinggi dari metode FCH adalah 73.95%, untuk metode GLRLM adalah 69.17%, sedangkan untuk penggabungan keduanya menghasilkan akurasi paling tinggi yaitu 81.29%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100069&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100069&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100069&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100069&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100069&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100069&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100069&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100069&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100070&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100070&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100070&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100070&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100070&gt;
{&#39;Abstrak&#39;: &#39;Acute Lymphoblastic Leukemia (ALL) merupakan penyakit kanker yang ditandai dengan pertumbuhan sel darah putih yang sangat cepat dan mematikan. Apabila tidak segera diobati akan menyebabkan kematian dalam hitungan minggu hingga hari, untuk itu perlu penanganan secara cepat. Diagnosa penyakit ALL kebanyakan dilakukan secara manual, membutuhkan tenaga ahli, peralatan laboratorium yang memadai serta waktu yang cukup lama. Untuk mengatasi permasalahan tersebut pada penelitian ini dilakukan identifikasi Acute Lymphoblastic Leukemia menggunakan teknik pengolahan citra. Adapun tahapan-tahapan yang dilakukan adalah preprocessing, segmentasi, ekstraksi fitur dan klasifikasi citra. Metode yang diterapkan pada setiap tahapan adalah sebagai berikut metode contras stretching untuk perbaiakan citra, metode otsu Thresholding berdasarkan warna HSV untuk segmentasi, sedangkan untuk ekstraksi fitur menggunakan fitur hibrid gabungan antara fitur bentuk dan tekstur Gray Level Co-occurrancy Matrix (GLCM), yang kemudian akan di klasifikasikan menggunakana metode Mahalanobis Distance. Database yang digunkan dalam penelitian ini adalah database ALLIDB2, yang terdiri dari 260 gambar yaitu 130 ALL-Positif dan 130 ALL-Negatif. Pada pengujian ini mendapatkan rata-rata akurasi tertinggi sebesar 85.40% dengan sensitivity 85.8 % dan specificity 85.0%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100070&gt;
{&#39;Abstrak&#39;: &#39;Acute Lymphoblastic Leukemia (ALL) merupakan penyakit kanker yang ditandai dengan pertumbuhan sel darah putih yang sangat cepat dan mematikan. Apabila tidak segera diobati akan menyebabkan kematian dalam hitungan minggu hingga hari, untuk itu perlu penanganan secara cepat. Diagnosa penyakit ALL kebanyakan dilakukan secara manual, membutuhkan tenaga ahli, peralatan laboratorium yang memadai serta waktu yang cukup lama. Untuk mengatasi permasalahan tersebut pada penelitian ini dilakukan identifikasi Acute Lymphoblastic Leukemia menggunakan teknik pengolahan citra. Adapun tahapan-tahapan yang dilakukan adalah preprocessing, segmentasi, ekstraksi fitur dan klasifikasi citra. Metode yang diterapkan pada setiap tahapan adalah sebagai berikut metode contras stretching untuk perbaiakan citra, metode otsu Thresholding berdasarkan warna HSV untuk segmentasi, sedangkan untuk ekstraksi fitur menggunakan fitur hibrid gabungan antara fitur bentuk dan tekstur Gray Level Co-occurrancy Matrix (GLCM), yang kemudian akan di klasifikasikan menggunakana metode Mahalanobis Distance. Database yang digunkan dalam penelitian ini adalah database ALLIDB2, yang terdiri dari 260 gambar yaitu 130 ALL-Positif dan 130 ALL-Negatif. Pada pengujian ini mendapatkan rata-rata akurasi tertinggi sebesar 85.40% dengan sensitivity 85.8 % dan specificity 85.0%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100070&gt;
{&#39;Abstrak&#39;: &#39;Berbagai cabang olahraga seperti sepak bola, tenis meja, bulu tangkis, dan lainnya mengharuskan setiap berita olahraga untuk dikelompokkan sesuai dengan cabangnya. Oleh karena itu diperlukan cara untuk mengelompokkan berita olahraga yang memiliki kesamaan. Pengelompokkan dapat dilakukan dengan banyak metode. Metode yang bisa menangani permasalah ini salah satunya adalah k-means clustering. K-means clustering adalah metode pengelompokan yang bisa bekerja dengan dataset yang besar dengan efisien. Namun metode ini memiliki permasalahan disaat penentuan awal pusat cluster. Hasil akhir cluster dari k-means sangat bergantung pada penentuan awal ini. Metode cosine similairty dapat membantu k-means clustering mendapatkan pusat cluster yang baik. Pada penelitian ini pengelompokan berita olahraga berbahasa Indonesia dilakukan dengan metode k-means clustering yang telah dimodifikasi dengan cosine similarity. Hasil yang didapatkan dari percobaan adalah pusat cluster terbaik yang dihasilkan oleh metode k-means selalu terjadi perubahan, bergantung pada penentuan awal pusat cluster. Setelah dilakukan modifikasi pada penentuan awal, pusat cluster terbaik cenderung konstan, yaitu sebanyak 4 pusat cluster dengan nilai akurasi rata-rata 0.895.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100070&gt;
{&#39;Abstrak&#39;: &#39;Berbagai cabang olahraga seperti sepak bola, tenis meja, bulu tangkis, dan lainnya mengharuskan setiap berita olahraga untuk dikelompokkan sesuai dengan cabangnya. Oleh karena itu diperlukan cara untuk mengelompokkan berita olahraga yang memiliki kesamaan. Pengelompokkan dapat dilakukan dengan banyak metode. Metode yang bisa menangani permasalah ini salah satunya adalah k-means clustering. K-means clustering adalah metode pengelompokan yang bisa bekerja dengan dataset yang besar dengan efisien. Namun metode ini memiliki permasalahan disaat penentuan awal pusat cluster. Hasil akhir cluster dari k-means sangat bergantung pada penentuan awal ini. Metode cosine similairty dapat membantu k-means clustering mendapatkan pusat cluster yang baik. Pada penelitian ini pengelompokan berita olahraga berbahasa Indonesia dilakukan dengan metode k-means clustering yang telah dimodifikasi dengan cosine similarity. Hasil yang didapatkan dari percobaan adalah pusat cluster terbaik yang dihasilkan oleh metode k-means selalu terjadi perubahan, bergantung pada penentuan awal pusat cluster. Setelah dilakukan modifikasi pada penentuan awal, pusat cluster terbaik cenderung konstan, yaitu sebanyak 4 pusat cluster dengan nilai akurasi rata-rata 0.895.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100070&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100070&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100070&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100070&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100070&gt;
{&#39;Abstrak&#39;: &#39;Temu kembali citra (Image Retrieval) adalah sistem pencarian citra yang sesuai dengan keinginan pengguna, secara umum ada dua pendekatan dalam temu kembali citra yaitu berbasis isi (content based) dan berbasis teks (text based). Content Based Image Retrieval (CBIR) adalah sistem pencarian citra dengan query citra yang dihitung kemiripanya dengan database berdasarkan fitur-fitur yang terdapat pada citra, seperti warna, bentuk, tekstur, dsb. Pada proses temu kembali citra berbasis isi ekstraksi fitur yang sering digunakan adalah Color Histogram, karena warna mudah dan cepat dalam ekstraksi. Ekstraksi fitur Color Histogram memiliki masalah dalam pengolahan citra. Permasalahan ini disebabkan Color Histogram tidak dapat membedakan dua citra yang berbeda tetapi memiliki histogram yang sama. Untuk membuat Temu Kembali Citra lebih efektif penelitian ini menggunakan ekstraksi fitur Annular Color Histogram, kemiripan citra dihitung berdasarkan Euclidean Distance. Hasil dalam penelitian ini menunjukkan bahwa dengan metode yang digunakan berhasil meningkatkan efisiensi pencarian Color Histogram dengan rata-rata precision 0,897 dibandingkan dengan 0,830 pada proses Temu Kembali Citra Berbasis Isi.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100070&gt;
{&#39;Abstrak&#39;: &#39;Temu kembali citra (Image Retrieval) adalah sistem pencarian citra yang sesuai dengan keinginan pengguna, secara umum ada dua pendekatan dalam temu kembali citra yaitu berbasis isi (content based) dan berbasis teks (text based). Content Based Image Retrieval (CBIR) adalah sistem pencarian citra dengan query citra yang dihitung kemiripanya dengan database berdasarkan fitur-fitur yang terdapat pada citra, seperti warna, bentuk, tekstur, dsb. Pada proses temu kembali citra berbasis isi ekstraksi fitur yang sering digunakan adalah Color Histogram, karena warna mudah dan cepat dalam ekstraksi. Ekstraksi fitur Color Histogram memiliki masalah dalam pengolahan citra. Permasalahan ini disebabkan Color Histogram tidak dapat membedakan dua citra yang berbeda tetapi memiliki histogram yang sama. Untuk membuat Temu Kembali Citra lebih efektif penelitian ini menggunakan ekstraksi fitur Annular Color Histogram, kemiripan citra dihitung berdasarkan Euclidean Distance. Hasil dalam penelitian ini menunjukkan bahwa dengan metode yang digunakan berhasil meningkatkan efisiensi pencarian Color Histogram dengan rata-rata precision 0,897 dibandingkan dengan 0,830 pada proses Temu Kembali Citra Berbasis Isi.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100071&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100071&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100071&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100071&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100070&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100070&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100071&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100071&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100071&gt;
{&#39;Abstrak&#39;: &#39;Diabetes adalah penyakit yang disebabkan karena peningkatan gula darah dalam tubuh. Diabetes termasuk penyakit mematikan yang jumlah penderitanya terus meningkat dari tahun ke tahun. Hal ini disebabkan karena keterlambatan diagnosis dan pola makan yang kurang baik. Penyakit ini ditandai dengan peningkatan kadar gula yang berkelanjutan terutama setelah makan. Sehingga penderita diabetes sangat dianjurkan mengatur pola makan sesuai dengan jumlah kalori yang dibutuhkan. Kurangnya pengetahuan masyarakat tentang gizi menjadi hal sulit bagi mereka dalam menentukan pola makan sehat. Terkadang beberapa orang melakukan diet yang salah dan berakibat memperburuk kesehatan tubuh. Untuk itu diperlukan adanya sebuah aplikasi yang bisa membantu dalam mendiagnosis penyakit diabetes dan memberi rekomendasi pola makan. Aplikasi tersebut dibangun dengan implementasi fuzzy logic metode sugeno dan metode naïve bayes. Fuzzy logic metode sugeno digunakan untuk diagnosis penyakit diabetes sedangkan metode naïve bayes untuk rekomendasi pola makan. Hasil dari implementasi fuzzy logic metode sugeno dalam mendiagnosis penyakit diabetes, didapat nilai akurasi sebesar 76.67%. Dengan demikian hasil konversi akurasi diagnosis menunjukkan bahwa hasil diagnosis adalah “baik”. Sedangkan untuk rekomendasi pola makan, setelah dilakukan 5 kali uji rekomendasi maka didapat hasil rata-rata akurasi sebesar 72%. Dengan demikian implementasi metode naïve bayes dalam rekomendasi pola makan menunjukkan bahwa hasil rekomendasi adalah “baik”.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100071&gt;
{&#39;Abstrak&#39;: &#39;Diabetes adalah penyakit yang disebabkan karena peningkatan gula darah dalam tubuh. Diabetes termasuk penyakit mematikan yang jumlah penderitanya terus meningkat dari tahun ke tahun. Hal ini disebabkan karena keterlambatan diagnosis dan pola makan yang kurang baik. Penyakit ini ditandai dengan peningkatan kadar gula yang berkelanjutan terutama setelah makan. Sehingga penderita diabetes sangat dianjurkan mengatur pola makan sesuai dengan jumlah kalori yang dibutuhkan. Kurangnya pengetahuan masyarakat tentang gizi menjadi hal sulit bagi mereka dalam menentukan pola makan sehat. Terkadang beberapa orang melakukan diet yang salah dan berakibat memperburuk kesehatan tubuh. Untuk itu diperlukan adanya sebuah aplikasi yang bisa membantu dalam mendiagnosis penyakit diabetes dan memberi rekomendasi pola makan. Aplikasi tersebut dibangun dengan implementasi fuzzy logic metode sugeno dan metode naïve bayes. Fuzzy logic metode sugeno digunakan untuk diagnosis penyakit diabetes sedangkan metode naïve bayes untuk rekomendasi pola makan. Hasil dari implementasi fuzzy logic metode sugeno dalam mendiagnosis penyakit diabetes, didapat nilai akurasi sebesar 76.67%. Dengan demikian hasil konversi akurasi diagnosis menunjukkan bahwa hasil diagnosis adalah “baik”. Sedangkan untuk rekomendasi pola makan, setelah dilakukan 5 kali uji rekomendasi maka didapat hasil rata-rata akurasi sebesar 72%. Dengan demikian implementasi metode naïve bayes dalam rekomendasi pola makan menunjukkan bahwa hasil rekomendasi adalah “baik”.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100071&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100071&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100071&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100071&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100071&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100071&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100072&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:48 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100072&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100072&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:49 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/140411100072&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100071&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:49 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100071&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100072&gt;
{&#39;Abstrak&#39;: &#39;-&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:49 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100072&gt;
{&#39;Abstrak&#39;: &#39;-&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100072&gt;
{&#39;Abstrak&#39;: &#39;\nDonor ASI adalah proses pemberian ASI secara sukarela untuk maksud dan tujuan membantu memenuhi kebutuhan ASI bagi bayi orang lain yang membutuhkan. Berdasarkan Data Survei Sosial Ekonomi Nasional (Susenas) tahun 2010 menyebutkan bahwa hanya 33,6% bayi berumur 0-6 bulan yang mendapat ASI (Air Susu Ibu) eksklusif. Tingkat pemberian ASI eksklusif di Indonesia masih rendah. Proses penyampaian informasi donor ASI pada masyarakat masih terbatas dari media sosial. Banyak yang ingin mendonorkan ASI untuk membantu sesama tetapi karena informasi yang masih kurang, masyarakat tidak tahu bagaimana cara mengetahui informasi tentang donor ASI. Sehingga perlu adanya sistem informasi yang dapat membantu dalam melakukan Donor ASI, yang dilengkapi dengan informasi mengenai ASI. Metodologi yang digunakan untuk membangun sistem ini menggunakan metode Naive Bayes Classifieruntuk menentukan klasifikasi pendonor. Hasil dari penelitian ini adalah aplikasi android Donor ASI khususnya daerah Surabaya. Sehingga mempermudah pendonor dan resipien untuk dapat mengetahui informasi tentang Donor ASI, cara, dan syarat -syarat donor ASI. Aplikasi ini memilki tingkat akurasi 91,32% pada klasifikasi pendonor dengan Metode Naive Bayes Classifier.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:49 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/140411100072&gt;
{&#39;Abstrak&#39;: &#39;\nDonor ASI adalah proses pemberian ASI secara sukarela untuk maksud dan tujuan membantu memenuhi kebutuhan ASI bagi bayi orang lain yang membutuhkan. Berdasarkan Data Survei Sosial Ekonomi Nasional (Susenas) tahun 2010 menyebutkan bahwa hanya 33,6% bayi berumur 0-6 bulan yang mendapat ASI (Air Susu Ibu) eksklusif. Tingkat pemberian ASI eksklusif di Indonesia masih rendah. Proses penyampaian informasi donor ASI pada masyarakat masih terbatas dari media sosial. Banyak yang ingin mendonorkan ASI untuk membantu sesama tetapi karena informasi yang masih kurang, masyarakat tidak tahu bagaimana cara mengetahui informasi tentang donor ASI. Sehingga perlu adanya sistem informasi yang dapat membantu dalam melakukan Donor ASI, yang dilengkapi dengan informasi mengenai ASI. Metodologi yang digunakan untuk membangun sistem ini menggunakan metode Naive Bayes Classifieruntuk menentukan klasifikasi pendonor. Hasil dari penelitian ini adalah aplikasi android Donor ASI khususnya daerah Surabaya. Sehingga mempermudah pendonor dan resipien untuk dapat mengetahui informasi tentang Donor ASI, cara, dan syarat -syarat donor ASI. Aplikasi ini memilki tingkat akurasi 91,32% pada klasifikasi pendonor dengan Metode Naive Bayes Classifier.\n&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100073&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:49 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/130411100073&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100072&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:49 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/150411100072&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.engine:Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100072&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:49 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/160411100072&gt; (referer: None)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100073&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:49 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/130411100073&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100072&gt;
{&#39;Abstrak&#39;: &#39;Multi-Label Classification (MLC) adalah salah satu topik yang menjadi perhatian dalam dunia machine learning dan telah diterapkan pada banyak bidang, seperti klasifikasi teks, anotasi citra, anotasi video, bioinformatics, jaringan sosial dan kategori musik. Selain itu MLC dapat digunakan untuk identifikasi atribut pada citra pejalan kaki. Berbeda dengan single-label classification yang hanya mengklasifikasikan setiap atribut secara terpisah, multi-label classification mengklasifikasi semua atribut secara langsung. Pada penelitian ini diusulkan Classifier Chains (CC) sebagai metode untuk identifikasi atribut pejalan kaki, CC dipilih karena mempertimbangkan hubungan antara kelas yang mungkin terjadi. Serta menggunakan metode ekstraksi fitur warna color histogram dan ekstraksi fitur tekstur Multi-Block Local Binary Pattern (MB-LBP). Fitur gabungan yang dihasilkan dari color histogram dan MB-LBP akan digunakan sebagai proses input pada proses klasifikasi menggunakan CC. Percobaan dilakukan dengan beberapa urutan label atau atribut pejalan kaki yang berbeda pada saat pembangunan model. Percobaan dilakukan untuk mengetahui pengaruh urutan label berdasarkan tiga model yang berbeda, akurasi yang didapatkan pada model berturut-turut adalah 26.60%, 26.67% dan 26.82%. Berdasarkan hasil tersebut maka urutan label pada saat pembangunan model tidak mempengaruhi kinerja model secara signifikan dengen selisih dibawah 1%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:49 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/150411100072&gt;
{&#39;Abstrak&#39;: &#39;Multi-Label Classification (MLC) adalah salah satu topik yang menjadi perhatian dalam dunia machine learning dan telah diterapkan pada banyak bidang, seperti klasifikasi teks, anotasi citra, anotasi video, bioinformatics, jaringan sosial dan kategori musik. Selain itu MLC dapat digunakan untuk identifikasi atribut pada citra pejalan kaki. Berbeda dengan single-label classification yang hanya mengklasifikasikan setiap atribut secara terpisah, multi-label classification mengklasifikasi semua atribut secara langsung. Pada penelitian ini diusulkan Classifier Chains (CC) sebagai metode untuk identifikasi atribut pejalan kaki, CC dipilih karena mempertimbangkan hubungan antara kelas yang mungkin terjadi. Serta menggunakan metode ekstraksi fitur warna color histogram dan ekstraksi fitur tekstur Multi-Block Local Binary Pattern (MB-LBP). Fitur gabungan yang dihasilkan dari color histogram dan MB-LBP akan digunakan sebagai proses input pada proses klasifikasi menggunakan CC. Percobaan dilakukan dengan beberapa urutan label atau atribut pejalan kaki yang berbeda pada saat pembangunan model. Percobaan dilakukan untuk mengetahui pengaruh urutan label berdasarkan tiga model yang berbeda, akurasi yang didapatkan pada model berturut-turut adalah 26.60%, 26.67% dan 26.82%. Berdasarkan hasil tersebut maka urutan label pada saat pembangunan model tidak mempengaruhi kinerja model secara signifikan dengen selisih dibawah 1%.&#39;}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEBUG:scrapy.core.scraper:Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100072&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:49 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/160411100072&gt;
{&#39;Abstrak&#39;: None}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.extensions.feedexport:Stored csv feed (289 items) in: Abstraksi.csv
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:49 [scrapy.extensions.feedexport] INFO: Stored csv feed (289 items) in: Abstraksi.csv
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.statscollectors:Dumping Scrapy stats:
{&#39;downloader/request_bytes&#39;: 183317,
 &#39;downloader/request_count&#39;: 289,
 &#39;downloader/request_method_count/GET&#39;: 289,
 &#39;downloader/response_bytes&#39;: 1303666,
 &#39;downloader/response_count&#39;: 289,
 &#39;downloader/response_status_count/200&#39;: 289,
 &#39;elapsed_time_seconds&#39;: 30.58298,
 &#39;feedexport/success_count/FileFeedStorage&#39;: 1,
 &#39;finish_reason&#39;: &#39;shutdown&#39;,
 &#39;finish_time&#39;: datetime.datetime(2022, 12, 13, 15, 5, 49, 333241),
 &#39;httpcompression/response_bytes&#39;: 4243370,
 &#39;httpcompression/response_count&#39;: 289,
 &#39;item_scraped_count&#39;: 289,
 &#39;log_count/DEBUG&#39;: 583,
 &#39;log_count/INFO&#39;: 12,
 &#39;memusage/max&#39;: 138129408,
 &#39;memusage/startup&#39;: 138129408,
 &#39;response_received_count&#39;: 289,
 &#39;scheduler/dequeued&#39;: 289,
 &#39;scheduler/dequeued/memory&#39;: 289,
 &#39;scheduler/enqueued&#39;: 289,
 &#39;scheduler/enqueued/memory&#39;: 289,
 &#39;start_time&#39;: datetime.datetime(2022, 12, 13, 15, 5, 18, 750261)}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{&#39;downloader/request_bytes&#39;: 183317,
 &#39;downloader/request_count&#39;: 289,
 &#39;downloader/request_method_count/GET&#39;: 289,
 &#39;downloader/response_bytes&#39;: 1303666,
 &#39;downloader/response_count&#39;: 289,
 &#39;downloader/response_status_count/200&#39;: 289,
 &#39;elapsed_time_seconds&#39;: 30.58298,
 &#39;feedexport/success_count/FileFeedStorage&#39;: 1,
 &#39;finish_reason&#39;: &#39;shutdown&#39;,
 &#39;finish_time&#39;: datetime.datetime(2022, 12, 13, 15, 5, 49, 333241),
 &#39;httpcompression/response_bytes&#39;: 4243370,
 &#39;httpcompression/response_count&#39;: 289,
 &#39;item_scraped_count&#39;: 289,
 &#39;log_count/DEBUG&#39;: 583,
 &#39;log_count/INFO&#39;: 12,
 &#39;memusage/max&#39;: 138129408,
 &#39;memusage/startup&#39;: 138129408,
 &#39;response_received_count&#39;: 289,
 &#39;scheduler/dequeued&#39;: 289,
 &#39;scheduler/dequeued/memory&#39;: 289,
 &#39;scheduler/enqueued&#39;: 289,
 &#39;scheduler/enqueued/memory&#39;: 289,
 &#39;start_time&#39;: datetime.datetime(2022, 12, 13, 15, 5, 18, 750261)}
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:scrapy.core.engine:Spider closed (shutdown)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-12-13 15:05:49 [scrapy.core.engine] INFO: Spider closed (shutdown)
</pre></div>
</div>
</div>
</div>
</section>
<section id="buang-baris-kosong">
<h2><strong>Buang Baris Kosong</strong><a class="headerlink" href="#buang-baris-kosong" title="Permalink to this headline">#</a></h2>
<p>Setelah didapat hasil crawling kita baca file csv tersebut, akan tetapi pada hasil crawling tersebut masih terdapat baris yang kosong yang didapat dari link yang kosong, untuk itu perlu dihilangkan dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> 
<span class="nb">abs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;Abstraksi.csv&quot;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:numexpr.utils:NumExpr defaulting to 2 threads.
2022-10-10 16:34:03 [numexpr.utils] INFO: NumExpr defaulting to 2 threads.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">abs</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">abs</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Abstrak    0
dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Setelah berhasil dihapus, simpan kembali dalam format csv</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">abs</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;hasil_crawling.csv&quot;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="baca-hasil-crawling">
<h2><strong>Baca Hasil Crawling</strong><a class="headerlink" href="#baca-hasil-crawling" title="Permalink to this headline">#</a></h2>
<p>Setelah baris kosong dari hasil crawling sudah dihapus kita tampilkan hasil crawling data absrak dari pta.trunojoyo seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;hasil_crawling.csv&quot;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-10c4fe2f-ba3f-4c31-a30d-0e078f439552">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Abstrak</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bola voli dapat dikatakan sebagai salah satu o...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Pemberian reward bagi perawat yang telah beker...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Sparsity merupakan suatu masalah yang umum ter...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Pada era teknologi seperti saat ini, setiap pe...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Permasalahan yang dihadapi oleh instansi pemer...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>120</th>
      <td>Multi-Label Classification (MLC) adalah salah ...</td>
    </tr>
    <tr>
      <th>121</th>
      <td>Penjualan melalui internet seperti website tel...</td>
    </tr>
    <tr>
      <th>122</th>
      <td>Konveksi Total Sport dalam proses produksinya ...</td>
    </tr>
    <tr>
      <th>123</th>
      <td>Multi Criteria Group Decision Making adalah pe...</td>
    </tr>
    <tr>
      <th>124</th>
      <td>Kambing adalah salah satu hewan ternak yang di...</td>
    </tr>
  </tbody>
</table>
<p>125 rows × 1 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-10c4fe2f-ba3f-4c31-a30d-0e078f439552')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-10c4fe2f-ba3f-4c31-a30d-0e078f439552 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-10c4fe2f-ba3f-4c31-a30d-0e078f439552');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
</section>
<section id="kesimpulan">
<h2><strong>Kesimpulan</strong><a class="headerlink" href="#kesimpulan" title="Permalink to this headline">#</a></h2>
<p>Dari hasil yang diperoleh, didapat data abstrak sebanyak 125 data abstrak yang diperoleh dari <a class="reference external" href="http://pta.trunojoyo.ac.id">pta.trunojoyo.ac.id</a> dengan mengambil data abstrak fakultas teknik mulai dari angkatan 13 hingga 16, dengan urutan NIM dari 0-75. Data abstrak yang diperoleh tersebut disimpan dalam bentuk csv.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="klasifikasi-clustering">
<h1>Klasifikasi &amp; Clustering<a class="headerlink" href="#klasifikasi-clustering" title="Permalink to this headline">#</a></h1>
<p>Klasifikasi dan Klustering data merupakan salah satu teknik dari Web Mining, yang mana klasifikasi adalah pemprosesan untuk menemukan sebuah model atau fungsi yang menjelaskan dan mencirikan konsep atau kelas data, untuk kepentingan tertentu. Sedangkan clustering digunakan untuk pengelompokkan data berdasarkan kemiripan pada objek data dan sebaliknya meminimalkan kemiripan terhadap kluster yang lain. Untuk dapat melakukan klasifikasi dan clustering lakukan proses berikut.</p>
<section id="praprepocessing-text">
<h2><strong>Praprepocessing Text</strong><a class="headerlink" href="#praprepocessing-text" title="Permalink to this headline">#</a></h2>
<p>Proses ini merupakan proses awal sebelum melakukan proses prepocessing text, yaitu proses untuk mendapatkan dataset yang akan digunakan untuk proses prepocessing, yang mana dataset yang akan digunakan diambil dari website dengan melakukan crawling pada website.</p>
<section id="crawling-tweeter">
<h3>Crawling Tweeter<a class="headerlink" href="#crawling-tweeter" title="Permalink to this headline">#</a></h3>
<p>Crawling merupakan suatu proses pengambilan data dengan menggunakan mesin yang dilakukan secara online. Proses ini dilakukan untuk mengimpor data yang ditemukan kedalam file lokal komputer. Kemudian data yang telah di impor tersebut akan dilakukan tahap prepocessing text. Pada proses crawling kali ini dilakukan crawling data pada twitter dengan menggunakan tools Twint.</p>
<section id="installasi-twint">
<h4>Installasi Twint<a class="headerlink" href="#installasi-twint" title="Permalink to this headline">#</a></h4>
<p>Twint merupakan sebuah tools yang digunakan untuk dapat melakukan scraping data dari media sosial yaitu twitter dengan menggunakan bahasa pemrograman python. Twint dapat dijalankan tanpa harus menggunakan API twitter itu sendiri, namun kapasitas scrapingnya dibatasi sebanyak 3200 tweet.</p>
<p>Twint tidak hanya digunakan untuk mengambil data tweet, twint juga bisa digunakan untuk mengambil data user, follower, retweet, dan sejenisnya. Twint memanfaatkan operator pencarian twitter yang digunakan untuk memilih dan memilah informasi yang sensitif, termasuk email dan nomor telepon di dalamnya.</p>
<p>Proses installasi Twint dapat dilakukan dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>git clone --depth<span class="o">=</span><span class="m">1</span> https://github.com/twintproject/twint.git
<span class="o">%</span><span class="k">cd</span> twint
<span class="o">!</span>pip3 install . -r requirements.txt
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cloning into &#39;twint&#39;...
remote: Enumerating objects: 47, done.
remote: Counting objects: 100% (47/47), done.
remote: Compressing objects: 100% (44/44), done.
remote: Total 47 (delta 3), reused 14 (delta 0), pack-reused 0
Unpacking objects: 100% (47/47), done.
/content/twint
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Processing /content/twint
<span class=" -Color -Color-Yellow">  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.</span>
<span class=" -Color -Color-Yellow">   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.</span>
Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (3.7.0)
Collecting aiodns
  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)
Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (4.6.3)
Collecting cchardet
  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)
     |████████████████████████████████| 263 kB 5.2 MB/s 
?25hCollecting dataclasses
  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)
Collecting elasticsearch
  Downloading elasticsearch-8.4.2-py3-none-any.whl (384 kB)
     |████████████████████████████████| 384 kB 69.4 MB/s 
?25hRequirement already satisfied: pysocks in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.7.1)
Requirement already satisfied: pandas&gt;=0.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.3.5)
Collecting aiohttp_socks&lt;=0.4.1
  Downloading aiohttp_socks-0.4.1-py3-none-any.whl (17 kB)
Collecting schedule
  Downloading schedule-1.1.0-py2.py3-none-any.whl (10 kB)
Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.17.0)
Collecting fake-useragent
  Downloading fake-useragent-0.1.11.tar.gz (13 kB)
Collecting googletransx
  Downloading googletransx-2.4.2.tar.gz (13 kB)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.23.0-&gt;-r requirements.txt (line 8)) (2.8.2)
Requirement already satisfied: numpy&gt;=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.23.0-&gt;-r requirements.txt (line 8)) (1.21.6)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.23.0-&gt;-r requirements.txt (line 8)) (2022.2.1)
Requirement already satisfied: attrs&gt;=19.2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp_socks&lt;=0.4.1-&gt;-r requirements.txt (line 9)) (22.1.0)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (6.0.2)
Requirement already satisfied: chardet&lt;4.0,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (3.0.4)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (1.8.1)
Requirement already satisfied: async-timeout&lt;4.0,&gt;=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (3.0.1)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=0.23.0-&gt;-r requirements.txt (line 8)) (1.15.0)
Requirement already satisfied: idna&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp-&gt;-r requirements.txt (line 1)) (2.10)
Requirement already satisfied: typing-extensions&gt;=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp-&gt;-r requirements.txt (line 1)) (4.1.1)
Collecting pycares&gt;=4.0.0
  Downloading pycares-4.2.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)
     |████████████████████████████████| 288 kB 59.1 MB/s 
?25hRequirement already satisfied: cffi&gt;=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pycares&gt;=4.0.0-&gt;aiodns-&gt;-r requirements.txt (line 2)) (1.15.1)
Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi&gt;=1.5.0-&gt;pycares&gt;=4.0.0-&gt;aiodns-&gt;-r requirements.txt (line 2)) (2.21)
Collecting elastic-transport&lt;9,&gt;=8
  Downloading elastic_transport-8.4.0-py3-none-any.whl (59 kB)
     |████████████████████████████████| 59 kB 6.9 MB/s 
?25hCollecting urllib3&lt;2,&gt;=1.26.2
  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)
     |████████████████████████████████| 140 kB 70.0 MB/s 
?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elastic-transport&lt;9,&gt;=8-&gt;elasticsearch-&gt;-r requirements.txt (line 6)) (2022.6.15)
Requirement already satisfied: geographiclib&lt;2,&gt;=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy-&gt;-r requirements.txt (line 11)) (1.52)
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from googletransx-&gt;-r requirements.txt (line 13)) (2.23.0)
Collecting requests
  Downloading requests-2.28.1-py3-none-any.whl (62 kB)
     |████████████████████████████████| 62 kB 1.5 MB/s 
?25hRequirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;googletransx-&gt;-r requirements.txt (line 13)) (2.1.1)
Building wheels for collected packages: twint, fake-useragent, googletransx
  Building wheel for twint (setup.py) ... ?25l?25hdone
  Created wheel for twint: filename=twint-2.1.21-py3-none-any.whl size=38871 sha256=ee1f532dceb10171414f0477a83ef4883a2cf42ee8ac18f927e3263980fd6b0a
  Stored in directory: /tmp/pip-ephem-wheel-cache-7qc34nmp/wheels/f7/3e/11/2803f3c6890e87a9bec35bb8e37ef1ad0777a00f43e2441fb1
  Building wheel for fake-useragent (setup.py) ... ?25l?25hdone
  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=c6a2787a063e8ce4d95c28292b078880afaba7f143f87ef5d34f31451ddaefc2
  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031
  Building wheel for googletransx (setup.py) ... ?25l?25hdone
  Created wheel for googletransx: filename=googletransx-2.4.2-py3-none-any.whl size=15968 sha256=fcde2f54e8e42c4da2721cc8dc757c3a49b974fd66c96325a7c3424b626a86cf
  Stored in directory: /root/.cache/pip/wheels/66/d5/b1/31104b338f7fd45aa8f7d22587765db06773b13df48a89735f
Successfully built twint fake-useragent googletransx
Installing collected packages: urllib3, requests, pycares, elastic-transport, schedule, googletransx, fake-useragent, elasticsearch, dataclasses, cchardet, aiohttp-socks, aiodns, twint
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.3
    Uninstalling urllib3-1.24.3:
      Successfully uninstalled urllib3-1.24.3
  Attempting uninstall: requests
    Found existing installation: requests 2.23.0
    Uninstalling requests-2.23.0:
      Successfully uninstalled requests-2.23.0
Successfully installed aiodns-3.0.0 aiohttp-socks-0.4.1 cchardet-2.1.7 dataclasses-0.6 elastic-transport-8.4.0 elasticsearch-8.4.2 fake-useragent-0.1.11 googletransx-2.4.2 pycares-4.2.2 requests-2.28.1 schedule-1.1.0 twint-2.1.21 urllib3-1.26.12
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install nest-asyncio
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (1.5.6)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install <span class="nv">aiohttp</span><span class="o">==</span><span class="m">3</span>.7.0
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: aiohttp==3.7.0 in /usr/local/lib/python3.7/dist-packages (3.7.0)
Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (22.1.0)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (1.8.1)
Requirement already satisfied: chardet&lt;4.0,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (3.0.4)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (6.0.2)
Requirement already satisfied: async-timeout&lt;4.0,&gt;=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (3.0.1)
Requirement already satisfied: idna&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp==3.7.0) (2.10)
Requirement already satisfied: typing-extensions&gt;=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp==3.7.0) (4.1.1)
</pre></div>
</div>
</div>
</div>
</section>
<section id="scraping-data-tweeter">
<h4>Scraping Data Tweeter<a class="headerlink" href="#scraping-data-tweeter" title="Permalink to this headline">#</a></h4>
<p>Setelah proses installasi Twint berhasil selanjutnya lakukan scraping data tweeter. Scraping sendiri merupakan proses pengambilan data dari website. Untuk melakukan proses scraping data dari tweeter, tinggal import twint untuk melakukan scraping data tweeter dengan tweet yang mengandung kata “#rockygerung” dengan limit 100 menggunakan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nest_asyncio</span>
<span class="n">nest_asyncio</span><span class="o">.</span><span class="n">apply</span><span class="p">()</span> <span class="c1">#digunakan sekali untuk mengaktifkan tindakan serentak dalam notebook jupyter.</span>
<span class="kn">import</span> <span class="nn">twint</span> <span class="c1">#untuk import twint</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">twint</span><span class="o">.</span><span class="n">Config</span><span class="p">()</span>
<span class="n">c</span><span class="o">.</span><span class="n">Search</span> <span class="o">=</span> <span class="s1">&#39;#rockygerung&#39;</span>
<span class="n">c</span><span class="o">.</span><span class="n">Lang</span> <span class="o">=</span> <span class="s2">&quot;in&quot;</span>
<span class="n">c</span><span class="o">.</span><span class="n">Pandas</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">c</span><span class="o">.</span><span class="n">Limit</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">twint</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">Search</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1577284749894172672 2022-10-04 13:09:23 +0000 &lt;Rgtvchannel_id&gt; #Rockymendation #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond
1577260717719187456 2022-10-04 11:33:53 +0000 &lt;Rgtvchannel_id&gt; Salam Akal Sehat,  #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #RGTVChannelid #IndonesiaBerpikir #ZoyaAmirin
1577226374976151554 2022-10-04 09:17:25 +0000 &lt;Rgtvchannel_id&gt; Nantikan lanjutan episode kali ini di  tayangan BAB - 2 Besok Rabu 05/10/2022, pantengin terus sosial media RGTV Channel dan nyalakan notifikasi Youtube RGTV Channel ID.  #RGTVChannelid mengajak #IndonesiaBerpikir  #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #ZoyaAmirin
1577190112395288577 2022-10-04 06:53:20 +0000 &lt;Rgtvchannel_id&gt; Saksikan selengkapnya hanya di Youtube RGTV Channel ID temukan dalam link berikut:  https://t.co/WOgd7COtCH  Salam Akal Sehat, #RockyGerung #RGTVChannelid #PolitcsAndBeyond #RockyGerung #IndonesiaBerpikir #ZoyaAmirin
1577188106628788224 2022-10-04 06:45:22 +0000 &lt;syafhirashora&gt; Terkait Insiden Kanjuruhan, Rocky Gerung Singgung Etika Kedewasaan Pemimpin  #kanjuruhan #KanjuruhanBerdukaCita #arema #AremaniaBerduka #AremavsPersebaya #rockygerung #Etika #Pemimpin   https://t.co/O0sxKK0wsA
1576937388924100610 2022-10-03 14:09:06 +0000 &lt;kr1t1kp3d45_pro&gt; Peristiwa di Kanjuruhan, Malang, Bukan Tragedi.  Itu adalah hasil kegagalan dalam mengantisipasi perencanaan pengendalian massa..‼️ #RockyMind  #politicsandbeyond  #PrayForKanjuruhan  #RockyGerung  https://t.co/n1yuSfZGJI
1576909624212525057 2022-10-03 12:18:46 +0000 &lt;rockygerungcom&gt; Quote:   Pengetahuan adalah keingintahuan. Di kampus-kampus kecil, itu sedang tumbuh. Sementara anak kolam masih terus ngamuk sepanjang hari.  Ajaib:)  | #kampus | #rockygerungcom | #rockygerung
1576881668907945984 2022-10-03 10:27:41 +0000 &lt;Rgtvchannel_id&gt; #RGTVChannelid #PolitcsAndBeyond #RockyGerung #IndonesiaBerpikir #ZoyaAmirin
1576871343982710784 2022-10-03 09:46:39 +0000 &lt;Rgtvchannel_id&gt; #RGTVChannelid #PolitcsAndBeyond #RockyGerung #IndonesiaBerpikir #ZoyaAmirin
1576848294697111553 2022-10-03 08:15:04 +0000 &lt;nolantv_berita&gt; [Politik] Speak panas‼️Rocky Gerung “kebijakan pemerintah tdk pro rakyat” #shorts #rockygerung #politik  https://t.co/PO2MZScPHr #Video #rockygerung #gerung #kebijakan
1576806152804847618 2022-10-03 05:27:37 +0000 &lt;Rgtvchannel_id&gt; Nantikan Video Selengkapnya hanya di Youtube RGTV Channel ID  #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir #SalamAkalSehat #ZoyaAmirin
1576785302080741376 2022-10-03 04:04:45 +0000 &lt;Rgtvchannel_id&gt; Kerja untuk hidup atau hidup untuk kerja?  Selamat pagi,  Selamat hari Senin.   Salam Akal Sehat, #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #SemangatPagi #SalamAkalSehat  https://t.co/oceDOQEVuY
1576773358821089280 2022-10-03 03:17:18 +0000 &lt;lawjusticeco&gt; Heboh Isu Firli Jegal Anies, Rocky Gerung Malah Gembira, Ini Sebabnya  https://t.co/0qOePIaWrV  #rockygerung #lawjustice #firlibahuri #KPK #PDIPerjuangan #demokrat #jokowi #luhut  https://t.co/r3dZw6Muxa
1576577511890132993 2022-10-02 14:19:04 +0000 &lt;Rgtvchannel_id&gt; Rumus Rindu Berjarak ≠ Menjauh  Setuju?  Salam Akal Sehat,  #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir #SalamAkalSehat #FilasafatRindu  https://t.co/Xpn8MBMDc4
1576561900611338240 2022-10-02 13:17:02 +0000 &lt;terkinidotid&gt; Rocky Gerung Soroti Isu Ketua KPK Firli Bahuri Jegal Anies Baswedan: Ini Cuma Analisis: Beredarnya isu yang menyebutkan bahwa Ketua KPK yakni Firli Bahuri sengaja bermanuver untuk menjegal…  https://t.co/NxuPzJYjLa #News #rockygerung #ketuakpk #firlibahuri #firlibahurianies
1576530942109175810 2022-10-02 11:14:01 +0000 &lt;Rgtvchannel_id&gt; #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir #SalamAkalSehat
1576485603465535488 2022-10-02 08:13:52 +0000 &lt;Rgtvchannel_id&gt; Seringkali tabu dibicarakan tapi nikmat dilakukan. Mengapa?  #Trailernewpodcast3 #RGTVChannelid #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir #SalamAkalSehat  https://t.co/47RgjuCTLD
1576428668817063936 2022-10-02 04:27:37 +0000 &lt;twectan&gt; @aewin86 Ternaksud yang katanya cerdas lebel prof. #rockygerung  Malu nya kita punya prof seperti ini? Inilah kadrun indonesia sampah!
1576424148896579586 2022-10-02 04:09:40 +0000 &lt;sonkapal&gt; #komik #anime #kartun #bbm #standupcomedy #subsidi #rockygerung #rizalramli #ekonomi  https://t.co/RsZClJQA6Z
1576403030324391936 2022-10-02 02:45:45 +0000 &lt;rockygerungcom&gt; Quote:  Dari pertemuan saya dengan Gibran sebenarnya ada kecemburuan. Baik cebong maupun kadrun. Saya ngobrol sama Gibran itu hampir 2 jam. Gibran datang untuk berbicara soal keadaan. Kunjungan Gibran ini betul-betul incognito.  | #gibran | #rockygerungcom | #rockygerung
1576213508257361921 2022-10-01 14:12:39 +0000 &lt;Muthiap23&gt; Sopan santun itu adalah bahasa tubuh, pikiran tidak merupakan sopan santun  Pikiran yang di sopan santun kan adalah kemunafikan #rockygerung #jaktim
1576199080677502977 2022-10-01 13:15:19 +0000 &lt;Rgtvchannel_id&gt; Tulis nama bintang tamu yang Anda inginkan duduk berbincang dengan saya.  #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir #SalamAkalSehat  https://t.co/12e92jyTpR
1576188925563269120 2022-10-01 12:34:58 +0000 &lt;rockygerungcom&gt; Quote:   Dia ini kan masih panjang usianya. Tiga kali pemilu masih ada di situ. Dan Gibran juga kasih otokritik terhadap keadaan parpol. Jadi tidak ada yang saya edit-edit dalam pertemuan itu.  | #gibran | #rockygerungcom | #rockygerung
1576182259744636929 2022-10-01 12:08:29 +0000 &lt;Rgtvchannel_id&gt; Kekerasan dengan alasan apapun tak dapat dibenarkan. Main hakim sendiri jangan jadi kebiasaan.  RGTV Channel ID, mengajak #IndonesiaBerpikir #RockyMind #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir #SalamAkalSehat
1576146126897487872 2022-10-01 09:44:54 +0000 &lt;lookinside000&gt; @muly1701 #rockygerung = sy ocky!!
1576097908763480065 2022-10-01 06:33:18 +0000 &lt;ynzpenjualbuku&gt; Jurnal Maarif: Demokrasi yang Dibajak Ahmad Syafii Maarif, Rocky Gerung, JJ Rizal, dkk Maarif Institute Vol. 6, No. 1-April 2011 186 halaman Rp. 40.000,-  #jurnalmaarif #ahmadsyafiimaarif #rockygerung #jjrizal  https://t.co/LYj6yFtoX4
1576083688051208192 2022-10-01 05:36:48 +0000 &lt;Rgtvchannel_id&gt; #RockyGerung #RockyGerungOfficial #IndonesiaBerpikir #Suwardi
1576035689669349376 2022-10-01 02:26:04 +0000 &lt;Rgtvchannel_id&gt; IQ rata-rata orang Indonesia sangat rendah dibanding negara lain. Beban presiden berikutnya untuk tingkatkan IQ.  Salam Akal Sehat #RockyGerung #RockyGerungOfficial #IndonesiaBerpikir #rockymind #politicsandbeyond #indonesia  https://t.co/2zOvTIryp2
1575866675550789632 2022-09-30 15:14:28 +0000 &lt;RasyidTarra&gt; Filsuf 👏🏻👏🏻 #rockygerung  https://t.co/ZLfRKtleht lewat @YouTube
1575770176192057344 2022-09-30 08:51:01 +0000 &lt;Rgtvchannel_id&gt; Siapa yang tertarik dengan MMA?   Saya berlatih di Neo Fighting Camp bukan cuma untuk bertarung dan adu pukul. Di sini Anda juga dilatih membentuk karakter sportif.  Salam Akal Sehat, #RockyGerung #RockyGerungOfficial #IndonesiaBerpikir #Suwardi  https://t.co/VBUlJVNkmB
1575743593830313984 2022-09-30 07:05:23 +0000 &lt;indeksncom&gt; Anggaran BSSN Naik Rp 624 Miliar Hacker Bjorka Tiba-Tiba Menghilang, Rocky Gerung Curiga  https://t.co/5L1UYIptT9 lewat @Indeks News #Bjorka #RockyGerung #BSSN
1575742701445603329 2022-09-30 07:01:50 +0000 &lt;tribunkaltim&gt; Viral Puan Maharani Bagi-bagi Kaos, Rocky Gerung Sindir Wong Cilik dan Istana    https://t.co/xcc90ibiFK lewat @tribunkaltim   #RockyGerung #PuanMaharani #WongCilik #PDIP #Viral
1575656022567370758 2022-09-30 01:17:24 +0000 &lt;gntalorenzky23&gt; Hal yg pertama kali dilakukan Rocky jika jadi presiden ❗❗#rockygerung  https://t.co/erJzOUK2qd lewat @YouTube
1575632099230437376 2022-09-29 23:42:20 +0000 &lt;rockygerungcom&gt; Quote:  Jadi semua soal kita bicarakan tentu dengan keinginan agar supaya ada perubahan dalam cara Presiden Jokowi mengambil keputusan.  | #presiden | #rockygerungcom | #rockygerung
1575456358312611842 2022-09-29 12:04:01 +0000 &lt;tribunkaltim&gt; Anggaran Siber Meningkat di Tengah Maraknya Kasus Peretasan, Rocky Gerung Singgung soal Bjorka  #Anggaran #Siber #Kasus #Peretasan #RockyGerung #Bjorka     https://t.co/SJMQ5Z0Dh9 lewat @tribunkaltim
1575455329822728192 2022-09-29 11:59:55 +0000 &lt;Rgtvchannel_id&gt; #RockyGerung #PolitcsAndBeyond #RockyGerung #IndonesiaBerpikir #Suwardi #MMA
1575449347663302656 2022-09-29 11:36:09 +0000 &lt;bb_sports_id&gt; Cerita Suwardi, Juara MMA One Pride, Usai Diajak Berduel Melawan Rocky Gerung  https://t.co/pQoYxsjq87 baca juga berita dari media lainnya di Indonesia di  https://t.co/GkwQxScnBB   #rockygerung #onepride #mma #petarungmma
1575426375808258048 2022-09-29 10:04:52 +0000 &lt;Rgtvchannel_id&gt; Persaingan politik mesti berlangsung fair. Tak perlu memata-matai Najwa yang matanya sudah indah.   #RGTVchannelid  #RockyGerung  #MataNajwa  #AJI #AJIIndonesia #Peretasan #Hacking  https://t.co/exsZbRyJV3
1575401694300499968 2022-09-29 08:26:48 +0000 &lt;irzairham&gt; Tonton &quot;Gile bener Rocky Gerung ini! #shorts #rockygerung #fyp #akalsehat #viral&quot; di YouTube  https://t.co/WGXpV0SCg1  ya kalo bener , terimakasih banyak sudah membantu anak anak bangsa ini pak !
1575367232955129856 2022-09-29 06:09:51 +0000 &lt;Rgtvchannel_id&gt; Teman teman, bagi yang belum menonton Podcast #1 yang viral itu, “MENATAP INDONESIA PASCA 2024” Tonton versi UNCUT di link berikut ini  https://t.co/zFWeSOKQVU    Salam Akal Sehat,  #RockyGerung #RockygerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir  #LuhutBinsarPandjaitan
1575361432526278656 2022-09-29 05:46:48 +0000 &lt;rockygerungcom&gt; #Quote:  Terus terang saya ngomong apa yang tidak baik. Termasuk soal presiden Jokowi. Saya bilang sama Gibran bahwa saya tetap jadi pengkritik. Karena saya ingin agar supaya Indonesia pulih.  | #gibran #rockygerungcom | #rockygerung
1575312872653000704 2022-09-29 02:33:51 +0000 &lt;wowsiapdotcom&gt; Rocky Gerung: Nabi Muhammad Itu Pemimpin Terbaik Dunia  https://t.co/M0xImOtCrE #RockyGerung #NabiMuhammad #pemimpin #Penguasa #petugas #Terbaikdunia #JenghisKhan #Inspirasi #Wowsiap.com
1575276315170680833 2022-09-29 00:08:35 +0000 &lt;af_safuan&gt; @sup3r4banx @maspiyuaja @f_h3rl Ini akun #RockyGerung ya ..... suka2 ente ajelah Tong...gua nurut ape kate lu aje 😁😍
1575112365909356545 2022-09-28 13:17:06 +0000 &lt;terkinidotid&gt; Rocky Gerung Komentari Saling Balas Sindiran Antara PDIP dan Gerindra Soal Usulan Megawati: Pengamat politik, Rocky Gerung mengomentari soal saling balas sindiran antara politisi Gerindra…  https://t.co/eUss6uxu28 #News #rockygerung #pdipgerindra #pdipmegawati #rockygerungpdip
1575112307574611968 2022-09-28 13:16:52 +0000 &lt;Rgtvchannel_id&gt; #RockyGerung #RGTVChannelid #PolitcsAndBeyond #RockyGerung #IndonesiaBerpikir #Suwardi #MMA
1575093037604417537 2022-09-28 12:00:18 +0000 &lt;inong911&gt; Outstanding Rocky Gerung 👍 #rockygerung  https://t.co/ibRdstvsTc
1575081523954429953 2022-09-28 11:14:33 +0000 &lt;abdulhakim1480&gt; ngeriii ...kosongkan pabrik2 seluruh indonesia. akai sejuta buruh serang istana merdeka 101022  #daengwahidin #drsrizalramli #nicho_silalhi #sahabatjumhur #saiddidu #rockygerung #fahiraidris #prabowosubianto #luhutbinsarpanjaitan  https://t.co/NJCw2zjtQX
1575072517034635265 2022-09-28 10:38:46 +0000 &lt;Rgtvchannel_id&gt; #RGTVChannelid #PolitcsAndBeyond #RockyGerung #IndonesiaBerpikir #Suwardi
1575043883033309184 2022-09-28 08:44:59 +0000 &lt;Wartech_24&gt; Kans Gus Muhaimin ikut dalam kontestasi Pilpres nanti semakin kuat, apalagi pula ditunjang dengan trend positif elektabilitasnya beberapa waktu belakangan.  #wartech24 #rockygerung #politik  https://t.co/gnsrMK3Tgc
1575032999678050304 2022-09-28 08:01:44 +0000 &lt;Rgtvchannel_id&gt; Suwardi mulai kewalahan menerima pukulan akal sehat Rocky Gerung.  Sobat Akal Sehat, pertarungan ini semakin seru!  Selengkapnya akan tayang hari ini 28/09/2022 pukul 18:00 WIB  Hanya di Youtube RGTV Channel ID  #RockyGerung #RGTVChannelid #PolitcsAndBeyond  #IndonesiaBerpikir  https://t.co/7THmhOsvwm
1575004913536749569 2022-09-28 06:10:08 +0000 &lt;mromadoni53&gt; Ijazah itu bukti bahwa Kita pernah sekolah, bukan bukti bahwa kita pernah belajar.  Jadi untuk apa sekolah tinggi kalo tujuannya hanya untuk Mendapat gelar atau ijazah? ga ada gunanya itu.   #rockygerung
1574998325241081857 2022-09-28 05:43:57 +0000 &lt;Rgtvchannel_id&gt; Saksikan hanya di Youtube RGTV Channel ID  #RockyGerung #RGTVChannelid #PolitcsAndBeyond #RockyGerung #IndonesiaBerpikir #Suwardi #MMA
1574917793341788161 2022-09-28 00:23:57 +0000 &lt;rockygerungcom&gt; Quote:  Membaca itu pake otak. Supaya bila ngamuk, tak terlihat dungu.  | #otak | #rockygerungcom | #rockygerung
1574785610727837696 2022-09-27 15:38:42 +0000 &lt;abdulhakim1480&gt; heeboohhh ....sejuta buruh serang istana !!10/10/2022    https://t.co/ybXLVyeU8Q  #sahabatjumhur #daengwahidin #saiddidu #rockygerung #prabowosubianto #rafliharun
1574755092401889282 2022-09-27 13:37:26 +0000 &lt;af_safuan&gt; Anies itu Penantang 👈👉 said #RockyGerung    https://t.co/SRtTYQAjXO  https://t.co/ZPvD2ZAf0F
1574747262944624640 2022-09-27 13:06:19 +0000 &lt;Rgtvchannel_id&gt; #RockyGerung #RGTVChannelid #PolitcsAndBeyond #RockyGerung #IndonesiaBerpikir #Suwardi #MMA
1574727615599943680 2022-09-27 11:48:15 +0000 &lt;MilenialSamaAH&gt; KODE DARI OPUNG LUHUT!!  Tidak mau jadi calon presiden, tapi datang ke acara KIB pimpinan Airlangga Hartarto. Gimana nih arti kode dari Opung?  #airlanggahartarto #luhutbinsarpandjaitan #rockygerung #thenext2024 #fyp #foryou #foryoupage #xyzbca #golkar bukan #Anies #TimnasDay  https://t.co/MAq9KSM6KV
1574724551422144512 2022-09-27 11:36:04 +0000 &lt;terkinidotid&gt; Rocky Gerung Bicara Soal Keberlangsungan Pemerintahan Jokowi: Pengamat politik Rocky Gerung kembali memberikan pendapatnya tentang pemerintahan era Presiden Jokowi. Menurutnya Presiden…  https://t.co/fTq2fC2pR6 #News #presidenjokowi #jokowitigaperiode #rockygerung #jokowimundur
1574717427249602561 2022-09-27 11:07:46 +0000 &lt;Rgtvchannel_id&gt; #RockyGerung #RGTVChannelid #PolitcsAndBeyond #RockyGerung #IndonesiaBerpikir #Suwardi #MMA
1574644765747863553 2022-09-27 06:19:02 +0000 &lt;Rgtvchannel_id&gt; RGTV Channel id, mengajak #IndonesiaBerpikir  #RGTVChannelid #PolitcsAndBeyond #RockyGerung #IndonesiaBerpikir
1574591153881522177 2022-09-27 02:46:00 +0000 &lt;RADARSOLO_&gt; Wali Kota Solo Gibran Rakabuming Raka mengakui menerima banyak kritikan dari pengamat politik Rocky Gerung. Keduanya bertemu beberapa waktu lalu. #rockygerung #gibranrockygerung  @gibran_tweet   https://t.co/WBmdbRcuqM
1574587911156436992 2022-09-27 02:33:07 +0000 &lt;hayckalp17&gt; Dan sekolah juga menandakan kita seorang pelajar, belom tentu seorang pemikir  #rockygerung
1574446256151150592 2022-09-26 17:10:13 +0000 &lt;rockygerungcom&gt; Quote: Jadi Gibran datang itu, ada kalangan istana menelepon saya. Gibran pengen berkunjung. Saya bilang ya silakan saja berkunjung. Kita bicara tentang apa yg bisa kita ucapkan kepada publik. Dari sisi ekonomi, politik dan segala macam. | #gibran | #rockygerungcom | #rockygerung  https://t.co/6HkR8tUo0h
1574406350272352256 2022-09-26 14:31:39 +0000 &lt;jpnncom&gt; #BeritaJateng Dikritik Habis Rocky Gerung, Gibran Sadar, Lalu Ingin Belajar @gibran_tweet  #gibranrakabumingraka #rockygerung   https://t.co/FQdg1uIJ0m
1574406075637714944 2022-09-26 14:30:34 +0000 &lt;terkinidotid&gt; Gibran Dikritik Rocky Gerung: Otak Kosong, Dungu: Wali Kota Solo, Gibran Rakabuming mengaku mendapat banyak kritikan dari Rocky Gerung saat bertandang ke kediaman pengamat politik itu,…  https://t.co/E1xbw2YQKe #News #gibran #rockygerung #gibranrockygerung #gibrandikritik
1574390837265371136 2022-09-26 13:30:01 +0000 &lt;matamilenialID&gt; Gibran Sebut Rocky Gerung Orang Jenius yang Beri Banyak Masukan untuk Solo  Baca selengkapnya disini  https://t.co/AU7c0woEYM  #MataIndonesia #rockygerung #gibranrakabumingraka #walikotasolo
1574336091401768960 2022-09-26 09:52:28 +0000 &lt;officialntv_&gt; Gibran dan Rocky Gerung Bertemu Bahas Dungu-dunguan   https://t.co/5e7IZlYkdf  #news #Rockygerung #gibranrockygerung #Gibran
1574327340305240064 2022-09-26 09:17:42 +0000 &lt;Rgtvchannel_id&gt; Saksikan selengkapnya hanya di Youtube RGTV Channel ID temukan dalam link berikut:  https://t.co/WOgd7COtCH  #RGTVChannelid #PolitcsAndBeyond #RockyGerung #IndonesiaBerpikir #Suwardi
1574313693260587008 2022-09-26 08:23:28 +0000 &lt;notifindonesia&gt; Gibran Rakabuming Akui &#39;Disemprot&#39; Habis oleh Rocky Gerung: Otak Kosong, Dungu Dibahas Semua #GibranRakabuming #gibran #rockygerung #gibranrockygerung   https://t.co/XKwSnocKkY
1574302113991041024 2022-09-26 07:37:27 +0000 &lt;suaramerdeka&gt; Presiden Xi Jinping Dikudeta, Apa Dampaknya untuk Indonesia?   https://t.co/cK5ECOfAXJ  #dunia #presiden #china #xijinping #presidencihina #kudeta #militer #Militerchina #twitter #jeniferzeng #ham #hakasasimanusia #ccp #rockygerung #informasi
1574293142932664320 2022-09-26 07:01:48 +0000 &lt;Rgtvchannel_id&gt; #RGTVChannelid #PolitcsAndBeyond #RockyGerung #IndonesiaBerpikir #Suwardi
1574266926125092864 2022-09-26 05:17:38 +0000 &lt;Rgtvchannel_id&gt; #RGTVChannelid #PolitcsAndBeyond #RockyGerung #IndonesiaBerpikir #Suwardi
1574217371598090240 2022-09-26 02:00:43 +0000 &lt;Rgtvchannel_id&gt; Awali harimu dengan semangat.  Selamat hari Senin Sobat Akal Sehat!  Salam Akal Sehat,  #RockyMind #RGTVChannelid #PolitcsAndBeyond #RockyGerung #IndonesiaBerpikir #Suwardi  https://t.co/h4rzjvc3Fk
1574099426725220352 2022-09-25 18:12:03 +0000 &lt;wahananewsdotco&gt; Gibran Ingin “Berguru” ke Rocky Gerung  https://t.co/0T9p1e9ds4 #GibranTemuiRockyGerung #GibranRakabumingRaka #RockyGerung
1574054642354630656 2022-09-25 15:14:05 +0000 &lt;terkinidotid&gt; Reaksi Gibran Rakabuming Saat Disinggung Rocky Gerung Soal Oligarki: Pengamat politik, Rocky Gerung menceritakan soal momen pertemuan antara dirinya dengan Wali Kota Solo sekaligus putra Presiden…  https://t.co/dgfOW4CmgN #News #gibranrakabuming #rockygerung #rockygerungoligarki
1574050708336222208 2022-09-25 14:58:27 +0000 &lt;abdulhakim1480&gt; aliansi 1001 serikat buruh bersatu berama quen of longmarct bergerak puncak -istana negara jakarta 20 - 22 sep 2022 #turunkanhargabbm #cabutuudciptakerja #hentikanpenderitaanrakyat  #daengwahidin #nicosilalhi #sahabatjumhur #egisujana #jokowidodo #rockygerung #PrabowoSubianto  https://t.co/Q8GdvIv8L2
1574044961259270145 2022-09-25 14:35:37 +0000 &lt;terkinidotid&gt; Rocky Gerung Bertemu Gibran Rakabuming: Nggak Ada Urusan Politik: Sebuah unggahan foto di media sosial menuai sorotan publik, lantaran memperlihatkan Rocky Gerung bersama Gibran Rakabuming merupakan…  https://t.co/5frvjBiJug #News #gibranrakabuming #rockygerung #presidenjokowi
1574041737818886144 2022-09-25 14:22:49 +0000 &lt;agus_sopar&gt; @gibran_tweet Lagi bahas penjajagan pasangan mas @gibran_tweet X bang #rockygerung  manyambut tahun politik 2024 😊
1574038342718496769 2022-09-25 14:09:19 +0000 &lt;Rgtvchannel_id&gt; Saksikan pertarungan kami hanya di youtube RGTV Channel id pada link berikut:  https://t.co/WOgd7COtCH  #PolitcsAndBeyond  #RockyGerung #RockyGerungOfficial #RGTVChannelid #IndonesiaBerpikir #Suwardi
1574033010059399169 2022-09-25 13:48:08 +0000 &lt;Rgtvchannel_id&gt; Saksikan pertarungan kami hanya di youtube RGTV Channel id pada link berikut:  https://t.co/WOgd7COtCH  #PolitcsAndBeyond  #RockyGerung #RockyGerungOfficial #RGTVChannelid #IndonesiaBerpikir #Suwardi
[!] No more data! Scraping will stop now.
found 0 deleted tweets in this search.
</pre></div>
</div>
</div>
</div>
</section>
<section id="ambil-tweet">
<h4>Ambil Tweet<a class="headerlink" href="#ambil-tweet" title="Permalink to this headline">#</a></h4>
<p>Setelah proses crawling didapatkan data tweeter diatas, pada data tersebut terdapat data yang tidak diperlukan. Untuk melakukan prepocessing hanya memerlukan data tweet dari user, maka dari itu buang data yang tidak diperlukan dan ambil data tweet yang akan digunakan dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Tweets_dfs</span> <span class="o">=</span> <span class="n">twint</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">panda</span><span class="o">.</span><span class="n">Tweets_df</span>
<span class="n">Tweets_dfs</span><span class="p">[</span><span class="s2">&quot;tweet&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     #Rockymendation #RockyGerung #RockyGerungOffic...
1     Salam Akal Sehat,  #RockyGerung #RockyGerungOf...
2     Nantikan lanjutan episode kali ini di  tayanga...
3     Saksikan selengkapnya hanya di Youtube RGTV Ch...
4     Terkait Insiden Kanjuruhan, Rocky Gerung Singg...
                            ...                        
75    aliansi 1001 serikat buruh bersatu berama quen...
76    Rocky Gerung Bertemu Gibran Rakabuming: Nggak ...
77    @gibran_tweet Lagi bahas penjajagan pasangan m...
78    Saksikan pertarungan kami hanya di youtube RGT...
79    Saksikan pertarungan kami hanya di youtube RGT...
Name: tweet, Length: 80, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="upload-data-tweet">
<h3>Upload Data Tweet<a class="headerlink" href="#upload-data-tweet" title="Permalink to this headline">#</a></h3>
<p>Setelah data tweet di dapatkan, simpan data tweet tersebut dalam bentuk csv, kemudian download dan upload ke github untuk nanti digunakan sebagai dataset dari proses prepocessing text.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Tweets_dfs</span><span class="p">[</span><span class="s2">&quot;tweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;RG.csv&quot;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="prepocessing-text">
<h2><strong>Prepocessing Text</strong><a class="headerlink" href="#prepocessing-text" title="Permalink to this headline">#</a></h2>
<p>Setelah proses crawling, selanjutnya dilakukan prepocessing text, yaitu sebuah proses mesin yang digunakan untuk menyeleksi data teks agar lebih terstruktur dengan melalui beberapa tahapan-tahapan yang meliputi tahapan case folding, tokenizing, filtering dan stemming.
Sebelum melakukan tahapan-tahapan tersebut, terlebih dahulu kita import data crawling yang diupload ke github tadi dengan menggunakan library pandas pada source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> 

<span class="n">tweets</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/Fahrur190125/Data/main/RG.csv&quot;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">tweets</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-b12a8383-9a57-44ac-9801-6101218caba8">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tweet</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Anies itu Penantang 👈👉 said #RockyGerung    ht...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>#RockyGerung #RGTVChannelid #PolitcsAndBeyond ...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>KODE DARI OPUNG LUHUT!!  Tidak mau jadi calon ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Rocky Gerung Bicara Soal Keberlangsungan Pemer...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>#RockyGerung #RGTVChannelid #PolitcsAndBeyond ...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>Jaman REZIM SKRG kaya bapa tiri di sinetron......</td>
    </tr>
    <tr>
      <th>96</th>
      <td>Sobat akal sehat nantikan video part 2 yang ak...</td>
    </tr>
    <tr>
      <th>97</th>
      <td>Menteri Koordinator bidang Kemaritiman dan Inv...</td>
    </tr>
    <tr>
      <th>98</th>
      <td>PEMBODOHAN YANG BERLANGSUNG DALAM KURIKULUM ET...</td>
    </tr>
    <tr>
      <th>99</th>
      <td>Setuju dengan Bung Rocky?!  Saksikan selengkap...</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 1 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-b12a8383-9a57-44ac-9801-6101218caba8')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-b12a8383-9a57-44ac-9801-6101218caba8 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-b12a8383-9a57-44ac-9801-6101218caba8');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<p>Setelah data crawling berhasil di import, selanjutnya lakukan tahapan-tahapan prepocessing seperti berikut.</p>
<section id="case-folding">
<h3>Case Folding<a class="headerlink" href="#case-folding" title="Permalink to this headline">#</a></h3>
<p>Setelah berhassil mengambil dataset, selanjutnya ke proses prepocessing ke tahapan case folding yaitu tahapan pertama untuk melakukan prepocessing text dengan mengubah text menjadi huruf kecil semua dengan menghilangkan juga karakter spesial, angka, tanda baca, spasi serta huruf yang tidak penting.</p>
<section id="merubah-huruf-kecil-semua">
<h4>Merubah Huruf Kecil Semua<a class="headerlink" href="#merubah-huruf-kecil-semua" title="Permalink to this headline">#</a></h4>
<p>Tahapan case folding yang pertama yaitu merubah semua huruf menjadi huruf kecil semua menggunakan fungsi lower() dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>


<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     anies itu penantang 👈👉 said #rockygerung    ht...
1     #rockygerung #rgtvchannelid #politcsandbeyond ...
2     kode dari opung luhut!!  tidak mau jadi calon ...
3     rocky gerung bicara soal keberlangsungan pemer...
4     #rockygerung #rgtvchannelid #politcsandbeyond ...
                            ...                        
95    jaman rezim skrg kaya bapa tiri di sinetron......
96    sobat akal sehat nantikan video part 2 yang ak...
97    menteri koordinator bidang kemaritiman dan inv...
98    pembodohan yang berlangsung dalam kurikulum et...
99    setuju dengan bung rocky?!  saksikan selengkap...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="menghapus-karakter-spesial">
<h4>Menghapus Karakter Spesial<a class="headerlink" href="#menghapus-karakter-spesial" title="Permalink to this headline">#</a></h4>
<p>Tahapan case folding selanjutnya ialah menghapus karakter spesial dengan menggunakan library nltk, untuk menggunakan librarynya terlebih dahulu install dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#install library nltk</span>
<span class="o">!</span>pip install nltk
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)
Requirement already satisfied: regex&gt;=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)
Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)
Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)
Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)
</pre></div>
</div>
</div>
</div>
<p>Setelah library nltk terinstall kita import librarynya dan buat sebuah function untuk menghapus karakter spesial tersebut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">string</span> 
<span class="kn">import</span> <span class="nn">re</span> <span class="c1">#regex library</span>
<span class="c1"># import word_tokenize &amp; FreqDist from NLTK</span>

<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span> 
<span class="kn">from</span> <span class="nn">nltk.probability</span> <span class="kn">import</span> <span class="n">FreqDist</span>


<span class="k">def</span> <span class="nf">remove_special</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># remove tab, new line, ans back slice</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">t&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">n&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">u&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">f&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">r&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
    <span class="c1"># remove non ASCII (emoticon, chinese word, .etc)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;ascii&#39;</span><span class="p">,</span> <span class="s1">&#39;replace&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;ascii&#39;</span><span class="p">)</span>
    <span class="c1"># remove mention, link, hashtag</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;([@#][A-Za-z0-9]+)|(\w+:\/\/\S+)&quot;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
    <span class="c1"># remove incomplete URL</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;http://&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;https://&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
                
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_special</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                           anies itu penantang ?? said
1                                                      
2     kode dari opung luhut!! tidak mau jadi calon p...
3     rocky gerung bicara soal keberlangsungan pemer...
4                                                      
                            ...                        
95    jaman rezim skrg kaya bapa tiri di sinetron......
96    sobat akal sehat nantikan video part 2 yang ak...
97    menteri koordinator bidang kemaritiman dan inv...
98    pembodohan yang berlangsung dalam kurikulum et...
99    setuju dengan bung rocky?! saksikan selengkapn...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="menghapus-angka">
<h4>Menghapus Angka<a class="headerlink" href="#menghapus-angka" title="Permalink to this headline">#</a></h4>
<p>Selanjutnya melakukan penghapusan angka, penghapusan angka disini fleksibel, jika angka ingin dijadikan fitur maka penghapusan angka tidak perlu dilakukan. Untuk data tweet ini saya tidak ingin menjadikan angka sebagai fitur, untuk itu dilakukan penghapusan angka dengan function berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#remove number</span>
<span class="k">def</span> <span class="nf">remove_number</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span>  <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\d+&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_number</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                           anies itu penantang ?? said
1                                                      
2     kode dari opung luhut!! tidak mau jadi calon p...
3     rocky gerung bicara soal keberlangsungan pemer...
4                                                      
                            ...                        
95    jaman rezim skrg kaya bapa tiri di sinetron......
96    sobat akal sehat nantikan video part  yang aka...
97    menteri koordinator bidang kemaritiman dan inv...
98    pembodohan yang berlangsung dalam kurikulum et...
99    setuju dengan bung rocky?! saksikan selengkapn...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="menghapus-tanda-baca">
<h4>Menghapus Tanda Baca<a class="headerlink" href="#menghapus-tanda-baca" title="Permalink to this headline">#</a></h4>
<p>Selanjutnya penghapusan tanda baca yang tidak perlu yang dilakukan dengan function punctuation berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#remove punctuation</span>
<span class="k">def</span> <span class="nf">remove_punctuation</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="nb">str</span><span class="o">.</span><span class="n">maketrans</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">))</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_punctuation</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                             anies itu penantang  said
1                                                      
2     kode dari opung luhut tidak mau jadi calon pre...
3     rocky gerung bicara soal keberlangsungan pemer...
4                                                      
                            ...                        
95    jaman rezim skrg kaya bapa tiri di sinetron di...
96    sobat akal sehat nantikan video part  yang aka...
97    menteri koordinator bidang kemaritiman dan inv...
98    pembodohan yang berlangsung dalam kurikulum et...
99    setuju dengan bung rocky saksikan selengkapnya...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="menghapus-spasi">
<h4>Menghapus Spasi<a class="headerlink" href="#menghapus-spasi" title="Permalink to this headline">#</a></h4>
<p>Selanjutnya melakukan penghapusan spasi dengab menggunakan function berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#remove whitespace leading &amp; trailing</span>
<span class="k">def</span> <span class="nf">remove_whitespace_LT</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_whitespace_LT</span><span class="p">)</span>


<span class="c1">#remove multiple whitespace into single whitespace</span>
<span class="k">def</span> <span class="nf">remove_whitespace_multiple</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span><span class="s1">&#39; &#39;</span><span class="p">,</span><span class="n">text</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_whitespace_multiple</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                              anies itu penantang said
1                                                      
2     kode dari opung luhut tidak mau jadi calon pre...
3     rocky gerung bicara soal keberlangsungan pemer...
4                                                      
                            ...                        
95    jaman rezim skrg kaya bapa tiri di sinetron di...
96    sobat akal sehat nantikan video part yang akan...
97    menteri koordinator bidang kemaritiman dan inv...
98    pembodohan yang berlangsung dalam kurikulum et...
99    setuju dengan bung rocky saksikan selengkapnya...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="menghapus-huruf">
<h4>Menghapus Huruf<a class="headerlink" href="#menghapus-huruf" title="Permalink to this headline">#</a></h4>
<p>Selanjutnya melakukan penghapusan huruf yang tidak bermakna dengan function berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># remove single char</span>
<span class="k">def</span> <span class="nf">remove_singl_char</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\b[a-zA-Z]\b&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_singl_char</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                              anies itu penantang said
1                                                      
2     kode dari opung luhut tidak mau jadi calon pre...
3     rocky gerung bicara soal keberlangsungan pemer...
4                                                      
                            ...                        
95    jaman rezim skrg kaya bapa tiri di sinetron di...
96    sobat akal sehat nantikan video part yang akan...
97    menteri koordinator bidang kemaritiman dan inv...
98    pembodohan yang berlangsung dalam kurikulum et...
99    setuju dengan bung rocky saksikan selengkapnya...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="tokenizing">
<h3>Tokenizing<a class="headerlink" href="#tokenizing" title="Permalink to this headline">#</a></h3>
<p>Setelah tahapan case folding selesai, selanjutnya masuk ke tahapan tokenizing yang merupakan tahapan prepocessing yang memecah kalimat dari text menjadi kata agar membedakan antara kata pemisah atau bukan. Untuk melakukan tokenizing dapat menggunakan dengan library nltk dan function berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span>
<span class="c1"># NLTK word Tokenize </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt.zip.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># NLTK word Tokenize </span>
<span class="k">def</span> <span class="nf">word_tokenize_wrapper</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">word_tokenize_wrapper</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                         [anies, itu, penantang, said]
1                                                    []
2     [kode, dari, opung, luhut, tidak, mau, jadi, c...
3     [rocky, gerung, bicara, soal, keberlangsungan,...
4                                                    []
                            ...                        
95    [jaman, rezim, skrg, kaya, bapa, tiri, di, sin...
96    [sobat, akal, sehat, nantikan, video, part, ya...
97    [menteri, koordinator, bidang, kemaritiman, da...
98    [pembodohan, yang, berlangsung, dalam, kurikul...
99    [setuju, dengan, bung, rocky, saksikan, seleng...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="filtering-stopword">
<h3>Filtering(Stopword)<a class="headerlink" href="#filtering-stopword" title="Permalink to this headline">#</a></h3>
<p>Tahapan prepocessing selanjutnya ialah filtering atau disebut juga stopword yang merupakan lanjutan dari tahapan tokenizing yang digunakan untuk mengambil kata-kata penting dari hasil tokenizing tersebut dengan menghapus kata hubung yang tidak memiliki makna.</p>
<p>Proses stopword dapat dilakukan dengan mengimport library stopword dan function berikut untuk melakukan stopword.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;stopwords&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Unzipping corpora/stopwords.zip.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">list_stopwords</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;indonesian&#39;</span><span class="p">)</span>

<span class="c1"># append additional stopword</span>
<span class="n">list_stopwords</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s2">&quot;yg&quot;</span><span class="p">,</span> <span class="s2">&quot;dg&quot;</span><span class="p">,</span> <span class="s2">&quot;rt&quot;</span><span class="p">,</span> <span class="s2">&quot;dgn&quot;</span><span class="p">,</span> <span class="s2">&quot;ny&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="s1">&#39;klo&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;kalo&#39;</span><span class="p">,</span> <span class="s1">&#39;amp&#39;</span><span class="p">,</span> <span class="s1">&#39;biar&#39;</span><span class="p">,</span> <span class="s1">&#39;bikin&#39;</span><span class="p">,</span> <span class="s1">&#39;bilang&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;gak&#39;</span><span class="p">,</span> <span class="s1">&#39;ga&#39;</span><span class="p">,</span> <span class="s1">&#39;krn&#39;</span><span class="p">,</span> <span class="s1">&#39;nya&#39;</span><span class="p">,</span> <span class="s1">&#39;nih&#39;</span><span class="p">,</span> <span class="s1">&#39;sih&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;si&#39;</span><span class="p">,</span> <span class="s1">&#39;tau&#39;</span><span class="p">,</span> <span class="s1">&#39;tdk&#39;</span><span class="p">,</span> <span class="s1">&#39;tuh&#39;</span><span class="p">,</span> <span class="s1">&#39;utk&#39;</span><span class="p">,</span> <span class="s1">&#39;ya&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;jd&#39;</span><span class="p">,</span> <span class="s1">&#39;jgn&#39;</span><span class="p">,</span> <span class="s1">&#39;sdh&#39;</span><span class="p">,</span> <span class="s1">&#39;aja&#39;</span><span class="p">,</span> <span class="s1">&#39;n&#39;</span><span class="p">,</span> <span class="s1">&#39;t&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;nyg&#39;</span><span class="p">,</span> <span class="s1">&#39;hehe&#39;</span><span class="p">,</span> <span class="s1">&#39;pen&#39;</span><span class="p">,</span> <span class="s1">&#39;u&#39;</span><span class="p">,</span> <span class="s1">&#39;nan&#39;</span><span class="p">,</span> <span class="s1">&#39;loh&#39;</span><span class="p">,</span> <span class="s1">&#39;rt&#39;</span><span class="p">,</span>
                       <span class="s1">&#39;&amp;amp&#39;</span><span class="p">,</span> <span class="s1">&#39;yah&#39;</span><span class="p">])</span>

<span class="c1"># convert list to dictionary</span>
<span class="n">list_stopwords</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">list_stopwords</span><span class="p">)</span>

<span class="c1">#Menghapus Stopword dari list token</span>
<span class="k">def</span> <span class="nf">stopwords_removal</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">list_stopwords</span><span class="p">]</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">stopwords_removal</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                              [anies, penantang, said]
1                                                    []
2     [kode, opung, luhut, calon, presiden, acara, k...
3     [rocky, gerung, bicara, keberlangsungan, pemer...
4                                                    []
                            ...                        
95    [jaman, rezim, skrg, kaya, bapa, tiri, sinetro...
96    [sobat, akal, sehat, nantikan, video, part, ta...
97    [menteri, koordinator, bidang, kemaritiman, in...
98        [pembodohan, kurikulum, etika, rocky, gerung]
99    [setuju, rocky, saksikan, selengkapnya, youtub...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="stemming">
<h3>Stemming<a class="headerlink" href="#stemming" title="Permalink to this headline">#</a></h3>
<p>Tahapan terakhir dari proses prepocessing ialah stemming yang merupakan penghapusan suffix maupun prefix pada text sehingga menjadi kata dasar. Proses ini dapat dilakukan dengan menggunakan library sastrawi dan swifter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install Sastrawi
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting Sastrawi
  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)
     |████████████████████████████████| 209 kB 5.3 MB/s 
?25hInstalling collected packages: Sastrawi
Successfully installed Sastrawi-1.0.1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install swifter
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting swifter
  Downloading swifter-1.3.4.tar.gz (830 kB)
     |████████████████████████████████| 830 kB 7.3 MB/s 
?25hRequirement already satisfied: pandas&gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (1.3.5)
Collecting psutil&gt;=5.6.6
  Downloading psutil-5.9.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)
     |████████████████████████████████| 281 kB 13.6 MB/s 
?25hRequirement already satisfied: dask[dataframe]&gt;=2.10.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (2022.2.0)
Requirement already satisfied: tqdm&gt;=4.33.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (4.64.1)
Requirement already satisfied: ipywidgets&gt;=7.0.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (7.7.1)
Requirement already satisfied: cloudpickle&gt;=0.2.2 in /usr/local/lib/python3.7/dist-packages (from swifter) (1.5.0)
Requirement already satisfied: parso&gt;0.4.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (0.8.3)
Requirement already satisfied: bleach&gt;=3.1.1 in /usr/local/lib/python3.7/dist-packages (from swifter) (5.0.1)
Requirement already satisfied: six&gt;=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bleach&gt;=3.1.1-&gt;swifter) (1.15.0)
Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach&gt;=3.1.1-&gt;swifter) (0.5.1)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (21.3)
Requirement already satisfied: fsspec&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (2022.8.2)
Requirement already satisfied: toolz&gt;=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (0.12.0)
Requirement already satisfied: pyyaml&gt;=5.3.1 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (6.0)
Requirement already satisfied: partd&gt;=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (1.3.0)
Requirement already satisfied: numpy&gt;=1.18 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (1.21.6)
Requirement already satisfied: jupyterlab-widgets&gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (3.0.3)
Requirement already satisfied: traitlets&gt;=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (5.1.1)
Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (0.2.0)
Requirement already satisfied: ipython&gt;=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (7.9.0)
Requirement already satisfied: ipykernel&gt;=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (5.3.4)
Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (3.6.1)
Requirement already satisfied: tornado&gt;=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.1.1)
Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (6.1.12)
Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.4.2)
Collecting jedi&gt;=0.10
  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)
     |████████████████████████████████| 1.6 MB 48.5 MB/s 
?25hRequirement already satisfied: setuptools&gt;=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (57.4.0)
Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.2.0)
Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.8.0)
Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.6.1)
Requirement already satisfied: prompt-toolkit&lt;2.1.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.0.10)
Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.7.5)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging&gt;=20.0-&gt;dask[dataframe]&gt;=2.10.0-&gt;swifter) (3.0.9)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=1.0.0-&gt;swifter) (2022.2.1)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=1.0.0-&gt;swifter) (2.8.2)
Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd&gt;=0.3.10-&gt;dask[dataframe]&gt;=2.10.0-&gt;swifter) (1.0.0)
Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit&lt;2.1.0,&gt;=2.0.0-&gt;ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.2.5)
Requirement already satisfied: notebook&gt;=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.3.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.11.3)
Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.6.1)
Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (1.8.0)
Requirement already satisfied: terminado&gt;=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.13.3)
Requirement already satisfied: jupyter-core&gt;=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.11.1)
Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.4.0)
Requirement already satisfied: pyzmq&gt;=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client-&gt;ipykernel&gt;=4.5.1-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (23.2.1)
Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado&gt;=0.8.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.7.0)
Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.0.1)
Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.7.1)
Requirement already satisfied: pandocfilters&gt;=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (1.5.0)
Requirement already satisfied: entrypoints&gt;=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.4)
Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.6.0)
Requirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.8.4)
Requirement already satisfied: jsonschema&gt;=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.3.3)
Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.16.1)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (22.1.0)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.12.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.18.1)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.1.1)
Requirement already satisfied: importlib-resources&gt;=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.9.0)
Requirement already satisfied: zipp&gt;=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources&gt;=1.4.0-&gt;jsonschema&gt;=2.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (3.8.1)
Building wheels for collected packages: swifter
  Building wheel for swifter (setup.py) ... ?25l?25hdone
  Created wheel for swifter: filename=swifter-1.3.4-py3-none-any.whl size=16322 sha256=7475e0c4d5c8ebf1d4c94e0596837312ded7f20a87b702a4317c9a395ca61b1c
  Stored in directory: /root/.cache/pip/wheels/29/a7/0e/3a8f17ac69d759e1e93647114bc9bdc95957e5b0cbfd405205
Successfully built swifter
Installing collected packages: jedi, psutil, swifter
  Attempting uninstall: psutil
    Found existing installation: psutil 5.4.8
    Uninstalling psutil-5.4.8:
      Successfully uninstalled psutil-5.4.8
Successfully installed jedi-0.18.1 psutil-5.9.2 swifter-1.3.4
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">Sastrawi.Stemmer.StemmerFactory</span> <span class="kn">import</span> <span class="n">StemmerFactory</span>
<span class="kn">import</span> <span class="nn">swifter</span>


<span class="c1"># create stemmer</span>
<span class="n">factory</span> <span class="o">=</span> <span class="n">StemmerFactory</span><span class="p">()</span>
<span class="n">stemmer</span> <span class="o">=</span> <span class="n">factory</span><span class="o">.</span><span class="n">create_stemmer</span><span class="p">()</span>

<span class="c1"># stemmed</span>
<span class="k">def</span> <span class="nf">stemmed_wrapper</span><span class="p">(</span><span class="n">term</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">term</span><span class="p">)</span>

<span class="n">term_dict</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">document</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">term</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">term_dict</span><span class="p">:</span>
            <span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span>
            
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">term_dict</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">term_dict</span><span class="p">:</span>
    <span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">=</span> <span class="n">stemmed_wrapper</span><span class="p">(</span><span class="n">term</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">term</span><span class="p">,</span><span class="s2">&quot;:&quot;</span> <span class="p">,</span><span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">])</span>
    
<span class="nb">print</span><span class="p">(</span><span class="n">term_dict</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------&quot;</span><span class="p">)</span>


<span class="c1"># apply stemmed term to dataframe</span>
<span class="k">def</span> <span class="nf">get_stemmed_term</span><span class="p">(</span><span class="n">document</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">document</span><span class="p">]</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">swifter</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_stemmed_term</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>424
------------------------
anies : anies
penantang : tantang
said : said
kode : kode
opung : opung
luhut : luhut
calon : calon
presiden : presiden
acara : acara
kib : kib
pimpinan : pimpin
airlangga : airlangga
hartarto : hartarto
gimana : gimana
arti : arti
rocky : rocky
gerung : gerung
bicara : bicara
keberlangsungan : langsung
pemerintahan : perintah
jokowi : jokowi
pengamat : amat
politik : politik
pendapatnya : dapat
era : era
menurutnya : turut
rgtv : rgtv
channel : channel
id : id
mengajak : ajak
wali : wali
kota : kota
solo : solo
gibran : gibran
rakabuming : rakabuming
raka : raka
mengakui : aku
menerima : terima
kritikan : kritik
bertemu : temu
tweet : tweet
sekolah : sekolah
menandakan : tanda
pelajar : ajar
belom : bom
pemikir : pikir
quote : quote
kalangan : kalang
istana : istana
menelepon : telepon
pengen : ken
berkunjung : kunjung
silakan : sila
ucapkan : ucap
publik : publik
sisi : sisi
ekonomi : ekonomi
dikritik : kritik
habis : habis
sadar : sadar
belajar : ajar
otak : otak
kosong : kosong
dungu : dungu
mengaku : aku
bertandang : tandang
kediaman : diam
orang : orang
jenius : jenius
masukan : masuk
baca : baca
selengkapnya : lengkap
bahas : bahas
dungudunguan : dungudunguan
saksikan : saksi
youtube : youtube
temukan : temu
link : link
akui : aku
disemprot : semprot
dibahas : bahas
xi : xi
jinping : jinping
dikudeta : kudeta
dampaknya : dampak
indonesia : indonesia
tantang : tantang
juara : juara
kelas : kelas
terbang : terbang
one : one
pride : pride
mma : mma
dukung : dukung
bertarung : tarung
ring : ring
duel : duel
sengit : sengit
penyandang : sandang
menang : menang
awali : awal
harimu : hari
semangat : semangat
selamat : selamat
senin : senin
sobat : sobat
akal : akal
sehat : sehat
salam : salam
berguru : guru
reaksi : reaksi
disinggung : singgung
oligarki : oligarki
menceritakan : cerita
momen : momen
pertemuan : temu
putra : putra
aliansi : aliansi
serikat : serikat
buruh : buruh
bersatu : satu
berama : ama
quen : quen
of : of
longmarct : longmarct
bergerak : gerak
puncak : puncak
negara : negara
jakarta : jakarta
sep : sep
nggak : nggak
urusan : urus
unggahan : unggah
foto : foto
media : media
sosial : sosial
menuai : tuai
sorotan : sorot
lantaran : lantar
penjajagan : penjajagan
pasangan : pasang
mas : mas
bang : bang
manyambut : manyambut
pertarungan : tarung
tamu : tamu
tebak : tebak
clue : clue
pria : pria
kelahiran : lahir
magetan : magetan
jawa : jawa
timur : timur
hobi : hobi
muay : muay
thai : thai
berjualan : jual
bakso : bakso
heran : heran
disambangi : sambang
dibenci : benci
nicho : nicho
silalahi : silalahi
soroti : sorot
maksa : maksa
statemen : statemen
berbahaya : bahaya
pegiat : giat
aktivis : aktivis
menyoroti : sorot
pernyataan : nyata
pndah : pndah
dr : dr
jkt : jkt
beliau : beliau
cm : cm
pindah : pindah
merdeka : merdeka
selatan : selatan
utara : utara
bukabukaan : bukabukaan
obrolan : obrol
jam : jam
bareng : bareng
buzzerp : buzzerp
visible : visible
confusion : confusion
baswedan : baswedan
legitimasi : legitimasi
menilai : nilai
gubernur : gubernur
dki : dki
memiliki : milik
republik : republik
heboh : heboh
rumor : rumor
militer : militer
china : china
ditahan : tahan
rumah : rumah
tahanan : tahan
persaingan : saing
jenderal : jenderal
laporan : lapor
tentara : tentara
akrab : akrab
kekuasaan : kuasa
mendekat : dekat
rg : rg
didatangi : datang
diyakini : yakin
berkantor : kantor
medan : medan
kunjungi : kunjung
pastikan : pasti
cebongkampret : cebongkampret
pan : pan
berminat : minat
mengasuh : asuh
mending : mending
diasuh : asuh
partai : partai
amanat : amanat
nasional : nasional
peluang : peluang
selesai : selesai
jarangjarang : jarangjarang
lord : lord
menatap : tatap
pasca : pasca
via : via
part : part
tonton : tonton
ditakedown : ditakedown
klik : klik
kebebasan : bebas
freedom : freedom
natural : natural
right : right
konstitusi : konstitusi
tugas : tugas
pemerintah : perintah
melindungi : lindung
sambangi : sambang
pembahasannya : bahas
pesan : pesan
ramai : ramai
netizen : netizen
bersuara : suara
pertalite : pertalite
boros : boros
cepat : cepat
harganya : harga
coba : coba
simak : simak
videonya : video
terbagi : bagi
demo : demo
golput : golput
tempo : tempo
kritik : kritik
idolakan : idola
cuitan : cuit
viral : viral
menyebut : sebut
cebong : cebong
kampret : kampret
joko : joko
widodo : widodo
istilah : istilah
mengunjungi : unjung
masuk : masuk
angin : angin
temui : temu
om : om
pangeran : pangeran
ngobrol : ngobrol
tolong : tolong
cariin : cariin
cewe : cewe
doi : doi
grogi : grogi
ama : ama
cowo : cowo
kekekekkek : kekekekkek
ketemu : ketemu
lemes : lemes
saudara : saudara
rumahnya : rumah
kirakira : kirakira
prediksi : prediksi
gangguan : ganggu
terciptanya : cipta
hoax : hoax
kebodohan : bodoh
tim : tim
bocorkan : bocor
pembahasan : bahas
disangka : sangka
akun : akun
twitter : twitter
pribadinya : pribadi
menanggapi : tanggap
mementionnya : mementionnya
dll : dll
cemas : cemas
kadrun : kadrun
cemburu : cemburu
siapkan : siap
hadiah : hadiah
sepatu : sepatu
nasib : nasib
pensiun : pensiun
jabatannya : jabat
sinyal : sinyal
diganggu : ganggu
penguasa : kuasa
sprindik : sprindik
sowan : sowan
tegaskan : tegas
bapaknya : bapak
berkawan : kawan
botol : botol
minuman : minum
gagal : gagal
fokus : fokus
kabar : kabar
gembira : gembira
sayembara : sayembara
komentar : komentar
terlucu : lucu
hadiahnya : hadiah
tercengang : cengang
anak : anak
walikota : walikota
mengunggah : unggah
fotonya : foto
lei : lei
host : host
desain : desain
jelang : jelang
pilpres : pilpres
duga : duga
dipanggil : panggil
kpk : kpk
salah : salah
idola : idola
janjikan : janji
nawarin : nawarin
operasi : operasi
katarak : katarak
yaa : yaa
bhuehuehue : bhuehuehue
angkat : angkat
mengomentari : komentar
insiden : insiden
penembakan : tembak
brigadir : brigadir
dikepalai : palai
ferdy : ferdy
sambo : sambo
berita : berita
periode : periode
menko : menko
singgung : singgung
big : big
data : data
binsar : binsar
pandjaitan : pandjaitan
berbincang : bincang
contohi : contoh
amerika : amerika
usul : usul
sistem : sistem
pilkada : pilkada
dievalusi : dievalusi
tamparan : tampar
rakyat : rakyat
parpol : parpol
serang : serang
berebut : rebut
elektabilitas : elektabilitas
enak : enak
nontonnya : nontonnya
marves : marves
mustahil : mustahil
kalean : kalean
mesti : mesti
nonton : nonton
menteri : menteri
koordinator : koordinator
bidang : bidang
kemaritiman : maritim
investasi : investasi
usil : usil
bintang : bintang
podcast : podcast
jaman : jaman
rezim : rezim
skrg : skrg
kaya : kaya
bapa : bapa
tiri : tiri
sinetron : sinetron
kasih : kasih
makan : makan
bsu : bsu
blt : blt
anakrakyat : anakrakyat
udh : udh
kekenyangan : kenyang
trs : trs
pecutin : pecutin
nantikan : nanti
video : video
tayang : tayang
rabu : rabu
wib : wib
isu : isu
diperbincangkan : bincang
pembodohan : bodoh
kurikulum : kurikulum
etika : etika
setuju : tuju
{&#39;anies&#39;: &#39;anies&#39;, &#39;penantang&#39;: &#39;tantang&#39;, &#39;said&#39;: &#39;said&#39;, &#39;kode&#39;: &#39;kode&#39;, &#39;opung&#39;: &#39;opung&#39;, &#39;luhut&#39;: &#39;luhut&#39;, &#39;calon&#39;: &#39;calon&#39;, &#39;presiden&#39;: &#39;presiden&#39;, &#39;acara&#39;: &#39;acara&#39;, &#39;kib&#39;: &#39;kib&#39;, &#39;pimpinan&#39;: &#39;pimpin&#39;, &#39;airlangga&#39;: &#39;airlangga&#39;, &#39;hartarto&#39;: &#39;hartarto&#39;, &#39;gimana&#39;: &#39;gimana&#39;, &#39;arti&#39;: &#39;arti&#39;, &#39;rocky&#39;: &#39;rocky&#39;, &#39;gerung&#39;: &#39;gerung&#39;, &#39;bicara&#39;: &#39;bicara&#39;, &#39;keberlangsungan&#39;: &#39;langsung&#39;, &#39;pemerintahan&#39;: &#39;perintah&#39;, &#39;jokowi&#39;: &#39;jokowi&#39;, &#39;pengamat&#39;: &#39;amat&#39;, &#39;politik&#39;: &#39;politik&#39;, &#39;pendapatnya&#39;: &#39;dapat&#39;, &#39;era&#39;: &#39;era&#39;, &#39;menurutnya&#39;: &#39;turut&#39;, &#39;rgtv&#39;: &#39;rgtv&#39;, &#39;channel&#39;: &#39;channel&#39;, &#39;id&#39;: &#39;id&#39;, &#39;mengajak&#39;: &#39;ajak&#39;, &#39;wali&#39;: &#39;wali&#39;, &#39;kota&#39;: &#39;kota&#39;, &#39;solo&#39;: &#39;solo&#39;, &#39;gibran&#39;: &#39;gibran&#39;, &#39;rakabuming&#39;: &#39;rakabuming&#39;, &#39;raka&#39;: &#39;raka&#39;, &#39;mengakui&#39;: &#39;aku&#39;, &#39;menerima&#39;: &#39;terima&#39;, &#39;kritikan&#39;: &#39;kritik&#39;, &#39;bertemu&#39;: &#39;temu&#39;, &#39;tweet&#39;: &#39;tweet&#39;, &#39;sekolah&#39;: &#39;sekolah&#39;, &#39;menandakan&#39;: &#39;tanda&#39;, &#39;pelajar&#39;: &#39;ajar&#39;, &#39;belom&#39;: &#39;bom&#39;, &#39;pemikir&#39;: &#39;pikir&#39;, &#39;quote&#39;: &#39;quote&#39;, &#39;kalangan&#39;: &#39;kalang&#39;, &#39;istana&#39;: &#39;istana&#39;, &#39;menelepon&#39;: &#39;telepon&#39;, &#39;pengen&#39;: &#39;ken&#39;, &#39;berkunjung&#39;: &#39;kunjung&#39;, &#39;silakan&#39;: &#39;sila&#39;, &#39;ucapkan&#39;: &#39;ucap&#39;, &#39;publik&#39;: &#39;publik&#39;, &#39;sisi&#39;: &#39;sisi&#39;, &#39;ekonomi&#39;: &#39;ekonomi&#39;, &#39;dikritik&#39;: &#39;kritik&#39;, &#39;habis&#39;: &#39;habis&#39;, &#39;sadar&#39;: &#39;sadar&#39;, &#39;belajar&#39;: &#39;ajar&#39;, &#39;otak&#39;: &#39;otak&#39;, &#39;kosong&#39;: &#39;kosong&#39;, &#39;dungu&#39;: &#39;dungu&#39;, &#39;mengaku&#39;: &#39;aku&#39;, &#39;bertandang&#39;: &#39;tandang&#39;, &#39;kediaman&#39;: &#39;diam&#39;, &#39;orang&#39;: &#39;orang&#39;, &#39;jenius&#39;: &#39;jenius&#39;, &#39;masukan&#39;: &#39;masuk&#39;, &#39;baca&#39;: &#39;baca&#39;, &#39;selengkapnya&#39;: &#39;lengkap&#39;, &#39;bahas&#39;: &#39;bahas&#39;, &#39;dungudunguan&#39;: &#39;dungudunguan&#39;, &#39;saksikan&#39;: &#39;saksi&#39;, &#39;youtube&#39;: &#39;youtube&#39;, &#39;temukan&#39;: &#39;temu&#39;, &#39;link&#39;: &#39;link&#39;, &#39;akui&#39;: &#39;aku&#39;, &#39;disemprot&#39;: &#39;semprot&#39;, &#39;dibahas&#39;: &#39;bahas&#39;, &#39;xi&#39;: &#39;xi&#39;, &#39;jinping&#39;: &#39;jinping&#39;, &#39;dikudeta&#39;: &#39;kudeta&#39;, &#39;dampaknya&#39;: &#39;dampak&#39;, &#39;indonesia&#39;: &#39;indonesia&#39;, &#39;tantang&#39;: &#39;tantang&#39;, &#39;juara&#39;: &#39;juara&#39;, &#39;kelas&#39;: &#39;kelas&#39;, &#39;terbang&#39;: &#39;terbang&#39;, &#39;one&#39;: &#39;one&#39;, &#39;pride&#39;: &#39;pride&#39;, &#39;mma&#39;: &#39;mma&#39;, &#39;dukung&#39;: &#39;dukung&#39;, &#39;bertarung&#39;: &#39;tarung&#39;, &#39;ring&#39;: &#39;ring&#39;, &#39;duel&#39;: &#39;duel&#39;, &#39;sengit&#39;: &#39;sengit&#39;, &#39;penyandang&#39;: &#39;sandang&#39;, &#39;menang&#39;: &#39;menang&#39;, &#39;awali&#39;: &#39;awal&#39;, &#39;harimu&#39;: &#39;hari&#39;, &#39;semangat&#39;: &#39;semangat&#39;, &#39;selamat&#39;: &#39;selamat&#39;, &#39;senin&#39;: &#39;senin&#39;, &#39;sobat&#39;: &#39;sobat&#39;, &#39;akal&#39;: &#39;akal&#39;, &#39;sehat&#39;: &#39;sehat&#39;, &#39;salam&#39;: &#39;salam&#39;, &#39;berguru&#39;: &#39;guru&#39;, &#39;reaksi&#39;: &#39;reaksi&#39;, &#39;disinggung&#39;: &#39;singgung&#39;, &#39;oligarki&#39;: &#39;oligarki&#39;, &#39;menceritakan&#39;: &#39;cerita&#39;, &#39;momen&#39;: &#39;momen&#39;, &#39;pertemuan&#39;: &#39;temu&#39;, &#39;putra&#39;: &#39;putra&#39;, &#39;aliansi&#39;: &#39;aliansi&#39;, &#39;serikat&#39;: &#39;serikat&#39;, &#39;buruh&#39;: &#39;buruh&#39;, &#39;bersatu&#39;: &#39;satu&#39;, &#39;berama&#39;: &#39;ama&#39;, &#39;quen&#39;: &#39;quen&#39;, &#39;of&#39;: &#39;of&#39;, &#39;longmarct&#39;: &#39;longmarct&#39;, &#39;bergerak&#39;: &#39;gerak&#39;, &#39;puncak&#39;: &#39;puncak&#39;, &#39;negara&#39;: &#39;negara&#39;, &#39;jakarta&#39;: &#39;jakarta&#39;, &#39;sep&#39;: &#39;sep&#39;, &#39;nggak&#39;: &#39;nggak&#39;, &#39;urusan&#39;: &#39;urus&#39;, &#39;unggahan&#39;: &#39;unggah&#39;, &#39;foto&#39;: &#39;foto&#39;, &#39;media&#39;: &#39;media&#39;, &#39;sosial&#39;: &#39;sosial&#39;, &#39;menuai&#39;: &#39;tuai&#39;, &#39;sorotan&#39;: &#39;sorot&#39;, &#39;lantaran&#39;: &#39;lantar&#39;, &#39;penjajagan&#39;: &#39;penjajagan&#39;, &#39;pasangan&#39;: &#39;pasang&#39;, &#39;mas&#39;: &#39;mas&#39;, &#39;bang&#39;: &#39;bang&#39;, &#39;manyambut&#39;: &#39;manyambut&#39;, &#39;pertarungan&#39;: &#39;tarung&#39;, &#39;tamu&#39;: &#39;tamu&#39;, &#39;tebak&#39;: &#39;tebak&#39;, &#39;clue&#39;: &#39;clue&#39;, &#39;pria&#39;: &#39;pria&#39;, &#39;kelahiran&#39;: &#39;lahir&#39;, &#39;magetan&#39;: &#39;magetan&#39;, &#39;jawa&#39;: &#39;jawa&#39;, &#39;timur&#39;: &#39;timur&#39;, &#39;hobi&#39;: &#39;hobi&#39;, &#39;muay&#39;: &#39;muay&#39;, &#39;thai&#39;: &#39;thai&#39;, &#39;berjualan&#39;: &#39;jual&#39;, &#39;bakso&#39;: &#39;bakso&#39;, &#39;heran&#39;: &#39;heran&#39;, &#39;disambangi&#39;: &#39;sambang&#39;, &#39;dibenci&#39;: &#39;benci&#39;, &#39;nicho&#39;: &#39;nicho&#39;, &#39;silalahi&#39;: &#39;silalahi&#39;, &#39;soroti&#39;: &#39;sorot&#39;, &#39;maksa&#39;: &#39;maksa&#39;, &#39;statemen&#39;: &#39;statemen&#39;, &#39;berbahaya&#39;: &#39;bahaya&#39;, &#39;pegiat&#39;: &#39;giat&#39;, &#39;aktivis&#39;: &#39;aktivis&#39;, &#39;menyoroti&#39;: &#39;sorot&#39;, &#39;pernyataan&#39;: &#39;nyata&#39;, &#39;pndah&#39;: &#39;pndah&#39;, &#39;dr&#39;: &#39;dr&#39;, &#39;jkt&#39;: &#39;jkt&#39;, &#39;beliau&#39;: &#39;beliau&#39;, &#39;cm&#39;: &#39;cm&#39;, &#39;pindah&#39;: &#39;pindah&#39;, &#39;merdeka&#39;: &#39;merdeka&#39;, &#39;selatan&#39;: &#39;selatan&#39;, &#39;utara&#39;: &#39;utara&#39;, &#39;bukabukaan&#39;: &#39;bukabukaan&#39;, &#39;obrolan&#39;: &#39;obrol&#39;, &#39;jam&#39;: &#39;jam&#39;, &#39;bareng&#39;: &#39;bareng&#39;, &#39;buzzerp&#39;: &#39;buzzerp&#39;, &#39;visible&#39;: &#39;visible&#39;, &#39;confusion&#39;: &#39;confusion&#39;, &#39;baswedan&#39;: &#39;baswedan&#39;, &#39;legitimasi&#39;: &#39;legitimasi&#39;, &#39;menilai&#39;: &#39;nilai&#39;, &#39;gubernur&#39;: &#39;gubernur&#39;, &#39;dki&#39;: &#39;dki&#39;, &#39;memiliki&#39;: &#39;milik&#39;, &#39;republik&#39;: &#39;republik&#39;, &#39;heboh&#39;: &#39;heboh&#39;, &#39;rumor&#39;: &#39;rumor&#39;, &#39;militer&#39;: &#39;militer&#39;, &#39;china&#39;: &#39;china&#39;, &#39;ditahan&#39;: &#39;tahan&#39;, &#39;rumah&#39;: &#39;rumah&#39;, &#39;tahanan&#39;: &#39;tahan&#39;, &#39;persaingan&#39;: &#39;saing&#39;, &#39;jenderal&#39;: &#39;jenderal&#39;, &#39;laporan&#39;: &#39;lapor&#39;, &#39;tentara&#39;: &#39;tentara&#39;, &#39;akrab&#39;: &#39;akrab&#39;, &#39;kekuasaan&#39;: &#39;kuasa&#39;, &#39;mendekat&#39;: &#39;dekat&#39;, &#39;rg&#39;: &#39;rg&#39;, &#39;didatangi&#39;: &#39;datang&#39;, &#39;diyakini&#39;: &#39;yakin&#39;, &#39;berkantor&#39;: &#39;kantor&#39;, &#39;medan&#39;: &#39;medan&#39;, &#39;kunjungi&#39;: &#39;kunjung&#39;, &#39;pastikan&#39;: &#39;pasti&#39;, &#39;cebongkampret&#39;: &#39;cebongkampret&#39;, &#39;pan&#39;: &#39;pan&#39;, &#39;berminat&#39;: &#39;minat&#39;, &#39;mengasuh&#39;: &#39;asuh&#39;, &#39;mending&#39;: &#39;mending&#39;, &#39;diasuh&#39;: &#39;asuh&#39;, &#39;partai&#39;: &#39;partai&#39;, &#39;amanat&#39;: &#39;amanat&#39;, &#39;nasional&#39;: &#39;nasional&#39;, &#39;peluang&#39;: &#39;peluang&#39;, &#39;selesai&#39;: &#39;selesai&#39;, &#39;jarangjarang&#39;: &#39;jarangjarang&#39;, &#39;lord&#39;: &#39;lord&#39;, &#39;menatap&#39;: &#39;tatap&#39;, &#39;pasca&#39;: &#39;pasca&#39;, &#39;via&#39;: &#39;via&#39;, &#39;part&#39;: &#39;part&#39;, &#39;tonton&#39;: &#39;tonton&#39;, &#39;ditakedown&#39;: &#39;ditakedown&#39;, &#39;klik&#39;: &#39;klik&#39;, &#39;kebebasan&#39;: &#39;bebas&#39;, &#39;freedom&#39;: &#39;freedom&#39;, &#39;natural&#39;: &#39;natural&#39;, &#39;right&#39;: &#39;right&#39;, &#39;konstitusi&#39;: &#39;konstitusi&#39;, &#39;tugas&#39;: &#39;tugas&#39;, &#39;pemerintah&#39;: &#39;perintah&#39;, &#39;melindungi&#39;: &#39;lindung&#39;, &#39;sambangi&#39;: &#39;sambang&#39;, &#39;pembahasannya&#39;: &#39;bahas&#39;, &#39;pesan&#39;: &#39;pesan&#39;, &#39;ramai&#39;: &#39;ramai&#39;, &#39;netizen&#39;: &#39;netizen&#39;, &#39;bersuara&#39;: &#39;suara&#39;, &#39;pertalite&#39;: &#39;pertalite&#39;, &#39;boros&#39;: &#39;boros&#39;, &#39;cepat&#39;: &#39;cepat&#39;, &#39;harganya&#39;: &#39;harga&#39;, &#39;coba&#39;: &#39;coba&#39;, &#39;simak&#39;: &#39;simak&#39;, &#39;videonya&#39;: &#39;video&#39;, &#39;terbagi&#39;: &#39;bagi&#39;, &#39;demo&#39;: &#39;demo&#39;, &#39;golput&#39;: &#39;golput&#39;, &#39;tempo&#39;: &#39;tempo&#39;, &#39;kritik&#39;: &#39;kritik&#39;, &#39;idolakan&#39;: &#39;idola&#39;, &#39;cuitan&#39;: &#39;cuit&#39;, &#39;viral&#39;: &#39;viral&#39;, &#39;menyebut&#39;: &#39;sebut&#39;, &#39;cebong&#39;: &#39;cebong&#39;, &#39;kampret&#39;: &#39;kampret&#39;, &#39;joko&#39;: &#39;joko&#39;, &#39;widodo&#39;: &#39;widodo&#39;, &#39;istilah&#39;: &#39;istilah&#39;, &#39;mengunjungi&#39;: &#39;unjung&#39;, &#39;masuk&#39;: &#39;masuk&#39;, &#39;angin&#39;: &#39;angin&#39;, &#39;temui&#39;: &#39;temu&#39;, &#39;om&#39;: &#39;om&#39;, &#39;pangeran&#39;: &#39;pangeran&#39;, &#39;ngobrol&#39;: &#39;ngobrol&#39;, &#39;tolong&#39;: &#39;tolong&#39;, &#39;cariin&#39;: &#39;cariin&#39;, &#39;cewe&#39;: &#39;cewe&#39;, &#39;doi&#39;: &#39;doi&#39;, &#39;grogi&#39;: &#39;grogi&#39;, &#39;ama&#39;: &#39;ama&#39;, &#39;cowo&#39;: &#39;cowo&#39;, &#39;kekekekkek&#39;: &#39;kekekekkek&#39;, &#39;ketemu&#39;: &#39;ketemu&#39;, &#39;lemes&#39;: &#39;lemes&#39;, &#39;saudara&#39;: &#39;saudara&#39;, &#39;rumahnya&#39;: &#39;rumah&#39;, &#39;kirakira&#39;: &#39;kirakira&#39;, &#39;prediksi&#39;: &#39;prediksi&#39;, &#39;gangguan&#39;: &#39;ganggu&#39;, &#39;terciptanya&#39;: &#39;cipta&#39;, &#39;hoax&#39;: &#39;hoax&#39;, &#39;kebodohan&#39;: &#39;bodoh&#39;, &#39;tim&#39;: &#39;tim&#39;, &#39;bocorkan&#39;: &#39;bocor&#39;, &#39;pembahasan&#39;: &#39;bahas&#39;, &#39;disangka&#39;: &#39;sangka&#39;, &#39;akun&#39;: &#39;akun&#39;, &#39;twitter&#39;: &#39;twitter&#39;, &#39;pribadinya&#39;: &#39;pribadi&#39;, &#39;menanggapi&#39;: &#39;tanggap&#39;, &#39;mementionnya&#39;: &#39;mementionnya&#39;, &#39;dll&#39;: &#39;dll&#39;, &#39;cemas&#39;: &#39;cemas&#39;, &#39;kadrun&#39;: &#39;kadrun&#39;, &#39;cemburu&#39;: &#39;cemburu&#39;, &#39;siapkan&#39;: &#39;siap&#39;, &#39;hadiah&#39;: &#39;hadiah&#39;, &#39;sepatu&#39;: &#39;sepatu&#39;, &#39;nasib&#39;: &#39;nasib&#39;, &#39;pensiun&#39;: &#39;pensiun&#39;, &#39;jabatannya&#39;: &#39;jabat&#39;, &#39;sinyal&#39;: &#39;sinyal&#39;, &#39;diganggu&#39;: &#39;ganggu&#39;, &#39;penguasa&#39;: &#39;kuasa&#39;, &#39;sprindik&#39;: &#39;sprindik&#39;, &#39;sowan&#39;: &#39;sowan&#39;, &#39;tegaskan&#39;: &#39;tegas&#39;, &#39;bapaknya&#39;: &#39;bapak&#39;, &#39;berkawan&#39;: &#39;kawan&#39;, &#39;botol&#39;: &#39;botol&#39;, &#39;minuman&#39;: &#39;minum&#39;, &#39;gagal&#39;: &#39;gagal&#39;, &#39;fokus&#39;: &#39;fokus&#39;, &#39;kabar&#39;: &#39;kabar&#39;, &#39;gembira&#39;: &#39;gembira&#39;, &#39;sayembara&#39;: &#39;sayembara&#39;, &#39;komentar&#39;: &#39;komentar&#39;, &#39;terlucu&#39;: &#39;lucu&#39;, &#39;hadiahnya&#39;: &#39;hadiah&#39;, &#39;tercengang&#39;: &#39;cengang&#39;, &#39;anak&#39;: &#39;anak&#39;, &#39;walikota&#39;: &#39;walikota&#39;, &#39;mengunggah&#39;: &#39;unggah&#39;, &#39;fotonya&#39;: &#39;foto&#39;, &#39;lei&#39;: &#39;lei&#39;, &#39;host&#39;: &#39;host&#39;, &#39;desain&#39;: &#39;desain&#39;, &#39;jelang&#39;: &#39;jelang&#39;, &#39;pilpres&#39;: &#39;pilpres&#39;, &#39;duga&#39;: &#39;duga&#39;, &#39;dipanggil&#39;: &#39;panggil&#39;, &#39;kpk&#39;: &#39;kpk&#39;, &#39;salah&#39;: &#39;salah&#39;, &#39;idola&#39;: &#39;idola&#39;, &#39;janjikan&#39;: &#39;janji&#39;, &#39;nawarin&#39;: &#39;nawarin&#39;, &#39;operasi&#39;: &#39;operasi&#39;, &#39;katarak&#39;: &#39;katarak&#39;, &#39;yaa&#39;: &#39;yaa&#39;, &#39;bhuehuehue&#39;: &#39;bhuehuehue&#39;, &#39;angkat&#39;: &#39;angkat&#39;, &#39;mengomentari&#39;: &#39;komentar&#39;, &#39;insiden&#39;: &#39;insiden&#39;, &#39;penembakan&#39;: &#39;tembak&#39;, &#39;brigadir&#39;: &#39;brigadir&#39;, &#39;dikepalai&#39;: &#39;palai&#39;, &#39;ferdy&#39;: &#39;ferdy&#39;, &#39;sambo&#39;: &#39;sambo&#39;, &#39;berita&#39;: &#39;berita&#39;, &#39;periode&#39;: &#39;periode&#39;, &#39;menko&#39;: &#39;menko&#39;, &#39;singgung&#39;: &#39;singgung&#39;, &#39;big&#39;: &#39;big&#39;, &#39;data&#39;: &#39;data&#39;, &#39;binsar&#39;: &#39;binsar&#39;, &#39;pandjaitan&#39;: &#39;pandjaitan&#39;, &#39;berbincang&#39;: &#39;bincang&#39;, &#39;contohi&#39;: &#39;contoh&#39;, &#39;amerika&#39;: &#39;amerika&#39;, &#39;usul&#39;: &#39;usul&#39;, &#39;sistem&#39;: &#39;sistem&#39;, &#39;pilkada&#39;: &#39;pilkada&#39;, &#39;dievalusi&#39;: &#39;dievalusi&#39;, &#39;tamparan&#39;: &#39;tampar&#39;, &#39;rakyat&#39;: &#39;rakyat&#39;, &#39;parpol&#39;: &#39;parpol&#39;, &#39;serang&#39;: &#39;serang&#39;, &#39;berebut&#39;: &#39;rebut&#39;, &#39;elektabilitas&#39;: &#39;elektabilitas&#39;, &#39;enak&#39;: &#39;enak&#39;, &#39;nontonnya&#39;: &#39;nontonnya&#39;, &#39;marves&#39;: &#39;marves&#39;, &#39;mustahil&#39;: &#39;mustahil&#39;, &#39;kalean&#39;: &#39;kalean&#39;, &#39;mesti&#39;: &#39;mesti&#39;, &#39;nonton&#39;: &#39;nonton&#39;, &#39;menteri&#39;: &#39;menteri&#39;, &#39;koordinator&#39;: &#39;koordinator&#39;, &#39;bidang&#39;: &#39;bidang&#39;, &#39;kemaritiman&#39;: &#39;maritim&#39;, &#39;investasi&#39;: &#39;investasi&#39;, &#39;usil&#39;: &#39;usil&#39;, &#39;bintang&#39;: &#39;bintang&#39;, &#39;podcast&#39;: &#39;podcast&#39;, &#39;jaman&#39;: &#39;jaman&#39;, &#39;rezim&#39;: &#39;rezim&#39;, &#39;skrg&#39;: &#39;skrg&#39;, &#39;kaya&#39;: &#39;kaya&#39;, &#39;bapa&#39;: &#39;bapa&#39;, &#39;tiri&#39;: &#39;tiri&#39;, &#39;sinetron&#39;: &#39;sinetron&#39;, &#39;kasih&#39;: &#39;kasih&#39;, &#39;makan&#39;: &#39;makan&#39;, &#39;bsu&#39;: &#39;bsu&#39;, &#39;blt&#39;: &#39;blt&#39;, &#39;anakrakyat&#39;: &#39;anakrakyat&#39;, &#39;udh&#39;: &#39;udh&#39;, &#39;kekenyangan&#39;: &#39;kenyang&#39;, &#39;trs&#39;: &#39;trs&#39;, &#39;pecutin&#39;: &#39;pecutin&#39;, &#39;nantikan&#39;: &#39;nanti&#39;, &#39;video&#39;: &#39;video&#39;, &#39;tayang&#39;: &#39;tayang&#39;, &#39;rabu&#39;: &#39;rabu&#39;, &#39;wib&#39;: &#39;wib&#39;, &#39;isu&#39;: &#39;isu&#39;, &#39;diperbincangkan&#39;: &#39;bincang&#39;, &#39;pembodohan&#39;: &#39;bodoh&#39;, &#39;kurikulum&#39;: &#39;kurikulum&#39;, &#39;etika&#39;: &#39;etika&#39;, &#39;setuju&#39;: &#39;tuju&#39;}
------------------------
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "1da9850e2b57405ba3daf42e5bd053b3"}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                                [anies, tantang, said]
1                                                    []
2     [kode, opung, luhut, calon, presiden, acara, k...
3     [rocky, gerung, bicara, langsung, perintah, jo...
4                                                    []
                            ...                        
95    [jaman, rezim, skrg, kaya, bapa, tiri, sinetro...
96    [sobat, akal, sehat, nanti, video, part, tayan...
97    [menteri, koordinator, bidang, maritim, invest...
98             [bodoh, kurikulum, etika, rocky, gerung]
99    [tuju, rocky, saksi, lengkap, youtube, rgtv, c...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
<p>Setelah tahap stemming proses prepocessing sudah selesai, namun pada dataset masih belum memiliki kelas atau label untuk itu akan dilakukan pemberian label atau kelas dengan menggunakan nilai polarity.</p>
</section>
</section>
<section id="labelling-dataset">
<h2><strong>Labelling Dataset</strong><a class="headerlink" href="#labelling-dataset" title="Permalink to this headline">#</a></h2>
<p>Setelah proses prepocesing selesai didapat sebuah dataset yang masih belum memiliki label, untuk itu pada tahapan ini dataset akan diberikan kelas atau label yang sesuai. Akan tetapi tahap pelabelan ini akan memerlukan waktu yang lama jika dilakukan secara manual. Untuk itu pada tahapan ini saya memberikan kelas atau label pada masing-masing data secara otomatis dengan menggunakan nilai polarity.</p>
<section id="nilai-polarity">
<h3>Nilai Polarity<a class="headerlink" href="#nilai-polarity" title="Permalink to this headline">#</a></h3>
<p>Nilai polarity merupakan nilai yang menunjukkan apakah kata tersebut bernilai negatif atau positif ataupun netral. Nilai polarity didapatkan dengan menjumlahkan nilai dari setiap kata dataset yang menunjukkan bahwa kata tersebut bernilai positif atau negatif ataupun netral.<br>
Didalam satu kalimat atau data,nilai dari kata-kata didalam satu kalimat tersebut akan dijumlah sehingga akan didapatkan nilai atau skor polarity. Nilai atau skor tersebutlah yang akan menentukan kalimat atau data tersebut berkelas positif(pro) atau negatif(kontra) ataupun netral.<br>
Jika nilai polarity yang didapat lebih dari 0 maka kalimat atau data tersebut diberi label atau kelas pro. Jika nilai polarity yang didapat kurang dari 0 maka kalimat atau data tersebut diberi label atau kelas kontra. Sedangkan jika nilai polarity sama dengan 0 maka kalimat atau data tersebut diberi label netral.</p>
</section>
<section id="ambil-nilai-polarity">
<h3>Ambil Nilai Polarity<a class="headerlink" href="#ambil-nilai-polarity" title="Permalink to this headline">#</a></h3>
<p>Sebelum melakukan pemberian label atau kelas dengan menggunakan nilai polarity, kita ambil nilai polarity dari setiap kata apakah positif atau negatif. Untuk itu saya mengambil nilai polarity dari github yang di dapat dari link github berikut <a class="reference external" href="https://github.com/fajri91/InSet">https://github.com/fajri91/InSet</a>
Nilai lexicon positif dan negatif yang didapat dari github tersebut saya download kemudian saya upload ke github saya dan kemudian saya ambil data lexicon positif dan negatif tersebut dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">positive</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/Fahrur190125/Data/main/positive.csv&quot;</span><span class="p">)</span>
<span class="n">positive</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;lexpos.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">negative</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/Fahrur190125/Data/main/negative.csv&quot;</span><span class="p">)</span>
<span class="n">negative</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;lexneg.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="menentukan-kelas-label-dengan-nilai-polarity">
<h3>Menentukan Kelas/Label dengan Nilai Polarity<a class="headerlink" href="#menentukan-kelas-label-dengan-nilai-polarity" title="Permalink to this headline">#</a></h3>
<p>Setelah berhasil mengambil nilai polarity lexicon positif dan negatif selanjutnya kita tentukan kelas dari masing masing data dengan menjumlahkan nilai polarity yang didapat dengan ketentuan jika lebih dari 0 maka memiliki kelas pro, jika kurang dari 0 maka diberi kelas kontra, dan jika sama dengan 0 maka memiliki kelas netral, dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Determine sentiment polarity of tweets using indonesia sentiment lexicon (source : https://github.com/fajri91/InSet)</span>
<span class="c1"># Loads lexicon positive and negative data</span>
<span class="n">lexicon_positive</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;lexpos.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvfile</span><span class="p">:</span>
    <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">csvfile</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
        <span class="n">lexicon_positive</span><span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">lexicon_negative</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;lexneg.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvfile</span><span class="p">:</span>
    <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">csvfile</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
        <span class="n">lexicon_negative</span><span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        
<span class="c1"># Function to determine sentiment polarity of tweets        </span>
<span class="k">def</span> <span class="nf">sentiment_analysis_lexicon_indonesia</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1">#for word in text:</span>
    <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="n">lexicon_positive</span><span class="p">):</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">score</span> <span class="o">+</span> <span class="n">lexicon_positive</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="n">lexicon_negative</span><span class="p">):</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">score</span> <span class="o">+</span> <span class="n">lexicon_negative</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
    <span class="n">polarity</span><span class="o">=</span><span class="s1">&#39;&#39;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">score</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="n">polarity</span> <span class="o">=</span> <span class="s1">&#39;pro&#39;</span>
    <span class="k">elif</span> <span class="p">(</span><span class="n">score</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="n">polarity</span> <span class="o">=</span> <span class="s1">&#39;kontra&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">polarity</span> <span class="o">=</span> <span class="s1">&#39;netral&#39;</span>
    <span class="k">return</span> <span class="n">score</span><span class="p">,</span> <span class="n">polarity</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Results from determine sentiment polarity of tweets</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sentiment_analysis_lexicon_indonesia</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">results</span><span class="p">))</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;polarity_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>pro       41
kontra    40
netral    19
Name: label, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Setelah didapat dataset yang sudah memiliki label selanjutnya kita simpan dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Export to csv file</span>
<span class="n">tweets</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;Prepocessing_label.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">tweets</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-bde35faf-e397-4f2f-a2fc-5b654e2a44c3">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tweet</th>
      <th>polarity_score</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[anies, tantang, said]</td>
      <td>-4</td>
      <td>kontra</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[]</td>
      <td>0</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[kode, opung, luhut, calon, presiden, acara, k...</td>
      <td>-2</td>
      <td>kontra</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[rocky, gerung, bicara, langsung, perintah, jo...</td>
      <td>9</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[]</td>
      <td>0</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>[jaman, rezim, skrg, kaya, bapa, tiri, sinetro...</td>
      <td>3</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>96</th>
      <td>[sobat, akal, sehat, nanti, video, part, tayan...</td>
      <td>7</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>97</th>
      <td>[menteri, koordinator, bidang, maritim, invest...</td>
      <td>6</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>98</th>
      <td>[bodoh, kurikulum, etika, rocky, gerung]</td>
      <td>0</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>99</th>
      <td>[tuju, rocky, saksi, lengkap, youtube, rgtv, c...</td>
      <td>2</td>
      <td>pro</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 3 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-bde35faf-e397-4f2f-a2fc-5b654e2a44c3')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-bde35faf-e397-4f2f-a2fc-5b654e2a44c3 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-bde35faf-e397-4f2f-a2fc-5b654e2a44c3');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
</section>
</section>
<section id="term-frequncy-tf">
<h2><strong>Term Frequncy(TF)</strong><a class="headerlink" href="#term-frequncy-tf" title="Permalink to this headline">#</a></h2>
<p>Term Frequency(TF) merupakan banyaknya jumlah kemunculan term pada suatu dokumen. Untuk menghitung nilai TF terdapat beberapa cara, cara yang paling sederhana ialah dengan menghitung banyaknya jumlah kemunculan kata dalam 1 dokumen.<br>
Sedangkan untuk menghitung nilai TF dengan menggunakan mesin dapat menggunakan library sklearn dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span><span class="p">,</span> <span class="n">TfidfVectorizer</span><span class="p">,</span> <span class="n">CountVectorizer</span>
<span class="c1">#Membuat Dataframe</span>
<span class="n">dataTextPre</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Prepocessing_label.csv&#39;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dataTextPre</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;polarity_score&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">bag</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">dataTextPre</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">])</span>
<span class="n">dataTextPre</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-1afbad52-30b8-427e-b19c-0b2089eca85b">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tweet</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>['anies', 'tantang', 'said']</td>
      <td>kontra</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[]</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>2</th>
      <td>['kode', 'opung', 'luhut', 'calon', 'presiden'...</td>
      <td>kontra</td>
    </tr>
    <tr>
      <th>3</th>
      <td>['rocky', 'gerung', 'bicara', 'langsung', 'per...</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[]</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>['jaman', 'rezim', 'skrg', 'kaya', 'bapa', 'ti...</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>96</th>
      <td>['sobat', 'akal', 'sehat', 'nanti', 'video', '...</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>97</th>
      <td>['menteri', 'koordinator', 'bidang', 'maritim'...</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>98</th>
      <td>['bodoh', 'kurikulum', 'etika', 'rocky', 'geru...</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>99</th>
      <td>['tuju', 'rocky', 'saksi', 'lengkap', 'youtube...</td>
      <td>pro</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 2 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-1afbad52-30b8-427e-b19c-0b2089eca85b')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-1afbad52-30b8-427e-b19c-0b2089eca85b button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-1afbad52-30b8-427e-b19c-0b2089eca85b');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<section id="matrik-vsm-visual-space-model">
<h3>Matrik VSM(Visual Space Model)<a class="headerlink" href="#matrik-vsm-visual-space-model" title="Permalink to this headline">#</a></h3>
<p>Sebelum menghitung nilai TF, terlebih dahulu buat matrik vsm untuk menentukan bobot nilai term pada dokumen dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">matrik_vsm</span> <span class="o">=</span> <span class="n">bag</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="c1">#print(matrik_vsm)</span>
<span class="n">matrik_vsm</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(100, 390)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">matrik_vsm</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
</pre></div>
</div>
</div>
</div>
<p>Untuk menampilkan nilai TF yang didapat menggunakan source code berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span><span class="o">=</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">matrik_vsm</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]))</span>
<span class="c1">#dfb =pd.DataFrame(data=matrik_vsm,index=df,columns=[a])</span>
<span class="n">dataTF</span> <span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">matrik_vsm</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">matrik_vsm</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">)),</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>
<span class="n">dataTF</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;TF.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dataTF</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100
</pre></div>
</div>
<div class="output text_html">
  <div id="df-f0b39c71-0ad9-42d2-9aa7-cf6b576925ee">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>acara</th>
      <th>airlangga</th>
      <th>ajak</th>
      <th>ajar</th>
      <th>akal</th>
      <th>akrab</th>
      <th>aktivis</th>
      <th>aku</th>
      <th>akun</th>
      <th>aliansi</th>
      <th>...</th>
      <th>viral</th>
      <th>visible</th>
      <th>wali</th>
      <th>walikota</th>
      <th>wib</th>
      <th>widodo</th>
      <th>xi</th>
      <th>yaa</th>
      <th>yakin</th>
      <th>youtube</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>96</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>97</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>98</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>99</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>100</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 390 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-f0b39c71-0ad9-42d2-9aa7-cf6b576925ee')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-f0b39c71-0ad9-42d2-9aa7-cf6b576925ee button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-f0b39c71-0ad9-42d2-9aa7-cf6b576925ee');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
</section>
<section id="nilai-term-dokumen">
<h3>Nilai Term Dokumen<a class="headerlink" href="#nilai-term-dokumen" title="Permalink to this headline">#</a></h3>
<p>Setelah didapat nilai matrik vsm, selanjutnya tentukan nilai term pada masing masing dokumen menggunakan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">datalabel</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Prepocessing_label.csv&#39;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">TF</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;TF.csv&#39;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dataJurnal</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">TF</span><span class="p">,</span> <span class="n">datalabel</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dataJurnal</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-c6f60990-ab9d-464f-94e1-f3a2594ea45d">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>acara</th>
      <th>airlangga</th>
      <th>ajak</th>
      <th>ajar</th>
      <th>akal</th>
      <th>akrab</th>
      <th>aktivis</th>
      <th>aku</th>
      <th>akun</th>
      <th>aliansi</th>
      <th>...</th>
      <th>visible</th>
      <th>wali</th>
      <th>walikota</th>
      <th>wib</th>
      <th>widodo</th>
      <th>xi</th>
      <th>yaa</th>
      <th>yakin</th>
      <th>youtube</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>kontra</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>kontra</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>96</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>97</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>98</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>99</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>pro</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 391 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-c6f60990-ab9d-464f-94e1-f3a2594ea45d')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-c6f60990-ab9d-464f-94e1-f3a2594ea45d button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-c6f60990-ab9d-464f-94e1-f3a2594ea45d');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
</section>
<section id="mengambil-data-label">
<h3>Mengambil Data label<a class="headerlink" href="#mengambil-data-label" title="Permalink to this headline">#</a></h3>
<p>Setelah didapat nilai term pada masing masing dokumen kita ambil data label pada masing masing dokumen.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataJurnal</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;kontra&#39;, &#39;netral&#39;, &#39;pro&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataJurnal</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 100 entries, 0 to 99
Columns: 391 entries, acara to label
dtypes: int64(390), object(1)
memory usage: 305.6+ KB
</pre></div>
</div>
</div>
</div>
</section>
<section id="split-data">
<h3>Split Data<a class="headerlink" href="#split-data" title="Permalink to this headline">#</a></h3>
<p>Selanjutnya kita split dataset menjadi data training dan testing dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### Train test split to avoid overfitting</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="o">=</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">dataJurnal</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">dataJurnal</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">],</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="data-training">
<h4>Data Training<a class="headerlink" href="#data-training" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-8ac9034a-05bb-4802-949c-e65c185d2f76">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>acara</th>
      <th>airlangga</th>
      <th>ajak</th>
      <th>ajar</th>
      <th>akal</th>
      <th>akrab</th>
      <th>aktivis</th>
      <th>aku</th>
      <th>akun</th>
      <th>aliansi</th>
      <th>...</th>
      <th>viral</th>
      <th>visible</th>
      <th>wali</th>
      <th>walikota</th>
      <th>wib</th>
      <th>widodo</th>
      <th>xi</th>
      <th>yaa</th>
      <th>yakin</th>
      <th>youtube</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>33</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>96</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>67</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>64</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>47</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>44</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>85 rows × 390 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-8ac9034a-05bb-4802-949c-e65c185d2f76')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-8ac9034a-05bb-4802-949c-e65c185d2f76 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-8ac9034a-05bb-4802-949c-e65c185d2f76');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
</section>
<section id="data-testing">
<h4>Data Testing<a class="headerlink" href="#data-testing" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-694953da-90c9-4b85-a2f8-b527c52adbd6">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>acara</th>
      <th>airlangga</th>
      <th>ajak</th>
      <th>ajar</th>
      <th>akal</th>
      <th>akrab</th>
      <th>aktivis</th>
      <th>aku</th>
      <th>akun</th>
      <th>aliansi</th>
      <th>...</th>
      <th>viral</th>
      <th>visible</th>
      <th>wali</th>
      <th>walikota</th>
      <th>wib</th>
      <th>widodo</th>
      <th>xi</th>
      <th>yaa</th>
      <th>yakin</th>
      <th>youtube</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>26</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>86</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>55</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>75</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>93</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>73</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>54</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>95</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>53</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>92</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 390 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-694953da-90c9-4b85-a2f8-b527c52adbd6')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-694953da-90c9-4b85-a2f8-b527c52adbd6 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-694953da-90c9-4b85-a2f8-b527c52adbd6');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
</section>
</section>
</section>
<section id="information-gain">
<h2><strong>Information Gain</strong><a class="headerlink" href="#information-gain" title="Permalink to this headline">#</a></h2>
<p>Metode Information Gain adalah metode yang menggunakan teknik scoring untuk pembobotan sebuah fitur dengan menggunakan maksimal entropy. Fitur yang dipilih adalah fitur dengan nilai Information Gain yang lebih besar atau sama dengan nilai threshold tertentu. Nilai information gain dapat dihitung dengan menggunakan rumus berikut.<br></p>
<div class="math notranslate nohighlight">
\[Gain(S,A) = Entropy(S) - \sum values(a)\frac{|SV|}{|S|} Entropy(S_{v})\]</div>
<p>Yang mana :<br>
Gain(S,A) : nilai Gain dari fitur <br>
A : fitur<br>
v : kemungkinan nilai fitur 𝐴<br>
𝑉𝑎𝑙𝑢𝑒𝑠(𝐴) : kemungkinan nilai himpunan 𝐴<br>
𝑆𝑣 : jumlah contoh nilai dari 𝑣<br>
𝑆 : jumlah keseluruhan sampel data<br>
Entropy(Sv) : 𝐸𝑛𝑡𝑟𝑜𝑝𝑦 contoh nilai v<br></p>
<p>Namun sebelum menghitung nilai information gain terlebih dahulu kita harus menghitung nilai entropy dengan rumus berikut.<br></p>
<div class="math notranslate nohighlight">
\[Entropy(S) = \sum_{i}^{c} -p_{i}\log_{2}p_{i}\]</div>
<p>Yang mana :<br>
𝑐 : akumulasi nilai dari kelas klasfikasi<br>
𝑃𝑖 : merupakan akumulasi sampel dari kelas 𝑖.<br>
Sedangkan untuk menghitung nilai information gain dengan mesin dapat mwnggunakan library mutual information seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">mutual_info_classif</span>
<span class="c1"># determine the mutual information</span>
<span class="n">mutual_info</span> <span class="o">=</span> <span class="n">mutual_info_classif</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">mutual_info</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       9.36366645e-02, 3.92477973e-02, 3.15670797e-03, 0.00000000e+00,
       0.00000000e+00, 1.19340451e-05, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 9.50068676e-02, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.52403974e-02,
       0.00000000e+00, 0.00000000e+00, 2.58217844e-02, 9.47066976e-03,
       0.00000000e+00, 6.14169392e-02, 0.00000000e+00, 1.58804095e-01,
       5.15635394e-02, 1.29996159e-01, 0.00000000e+00, 3.89204913e-02,
       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.45064323e-02,
       0.00000000e+00, 0.00000000e+00, 8.21864831e-02, 0.00000000e+00,
       9.95986114e-02, 1.17830975e-01, 0.00000000e+00, 1.74441521e-02,
       1.61218362e-02, 0.00000000e+00, 0.00000000e+00, 1.51065032e-01,
       0.00000000e+00, 0.00000000e+00, 4.25916490e-03, 0.00000000e+00,
       7.01582091e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       1.64170562e-01, 0.00000000e+00, 8.71917695e-02, 1.16568761e-02,
       3.45954180e-02, 0.00000000e+00, 1.24531808e-02, 0.00000000e+00,
       7.04923333e-03, 0.00000000e+00, 0.00000000e+00, 9.86850032e-02,
       0.00000000e+00, 7.53342380e-03, 0.00000000e+00, 0.00000000e+00,
       2.79903925e-02, 8.01960062e-02, 0.00000000e+00, 7.21506482e-02,
       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.94569062e-02,
       7.37620302e-02, 5.17456362e-02, 2.14875941e-02, 0.00000000e+00,
       3.92093928e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       2.43663169e-02, 5.32911903e-02, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 1.80286276e-02, 0.00000000e+00,
       0.00000000e+00, 1.24222027e-02, 0.00000000e+00, 0.00000000e+00,
       5.70151223e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       9.19632406e-02, 0.00000000e+00, 0.00000000e+00, 7.03348666e-02,
       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 2.08943945e-02, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       1.40018995e-02, 8.74693323e-02, 1.14918873e-02, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 1.60337344e-01, 3.43037705e-03,
       0.00000000e+00, 0.00000000e+00, 7.69565944e-02, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.65646972e-02,
       5.00480727e-02, 0.00000000e+00, 8.00183008e-03, 1.22608807e-01,
       4.33710939e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       8.71437522e-02, 1.26543826e-02, 6.11833356e-02, 1.33451322e-02,
       0.00000000e+00, 5.90605047e-03, 0.00000000e+00, 5.65335148e-02,
       0.00000000e+00, 0.00000000e+00, 5.36644300e-02, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 2.63429079e-02, 0.00000000e+00,
       0.00000000e+00, 1.30338640e-01, 0.00000000e+00, 5.33177264e-02,
       1.04550043e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       7.48931606e-02, 1.15076561e-01, 2.05775304e-02, 2.43048720e-02,
       0.00000000e+00, 3.13337752e-03, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 1.26836173e-01, 0.00000000e+00, 6.47452077e-02,
       1.75519093e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 6.63516826e-02, 2.66800421e-02,
       0.00000000e+00, 4.08089153e-02, 2.23419563e-02, 0.00000000e+00,
       4.51802927e-02, 0.00000000e+00, 1.41805661e-02, 5.00401167e-02,
       0.00000000e+00, 0.00000000e+00, 9.02491325e-02, 1.96851793e-02,
       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.80867222e-02,
       0.00000000e+00, 3.30187675e-02, 2.15139085e-02, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 6.76598618e-02, 3.17518881e-02,
       0.00000000e+00, 0.00000000e+00, 1.24047497e-01, 0.00000000e+00,
       0.00000000e+00, 5.82673056e-02, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 3.83055427e-02, 0.00000000e+00, 5.55717116e-03,
       1.94191424e-02, 0.00000000e+00, 1.18902044e-01, 5.34207786e-02,
       2.26503583e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       3.62670458e-02, 1.83729850e-02, 2.03660509e-02, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 1.13775739e-01, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 7.90296903e-04, 3.03817064e-02,
       8.03309217e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       1.45854952e-01, 4.86914390e-02, 4.74374755e-02, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 3.52680815e-02, 1.30177202e-02,
       0.00000000e+00, 6.89793803e-02, 0.00000000e+00, 3.12520699e-02,
       0.00000000e+00, 0.00000000e+00, 1.47550114e-01, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       9.62056159e-03, 0.00000000e+00, 3.11054256e-02, 2.02749234e-02,
       2.41930587e-02, 1.55093728e-01, 0.00000000e+00, 0.00000000e+00,
       1.41477343e-02, 1.09376611e-01, 0.00000000e+00, 0.00000000e+00,
       5.26427420e-02, 0.00000000e+00, 0.00000000e+00, 4.48887959e-02,
       1.05776990e-01, 3.24610719e-02, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.07745681e-02,
       6.37558661e-02, 6.27908738e-02, 0.00000000e+00, 0.00000000e+00,
       3.59560367e-02, 0.00000000e+00, 0.00000000e+00, 3.54089520e-02,
       8.25987958e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       5.56236444e-05, 9.21741139e-02, 0.00000000e+00, 2.88469749e-02,
       8.54701948e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 1.69972154e-01, 0.00000000e+00, 1.66983027e-02,
       0.00000000e+00, 5.08467085e-02, 7.86012040e-02, 5.73454692e-02,
       0.00000000e+00, 1.01572499e-02, 0.00000000e+00, 3.70368286e-02,
       8.19118326e-02, 2.27212711e-02, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 1.33628084e-01, 3.06060132e-04, 8.22131565e-03,
       1.46409769e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       5.23526020e-03, 3.25990456e-02, 0.00000000e+00, 4.47955999e-02,
       0.00000000e+00, 1.35861916e-02, 0.00000000e+00, 0.00000000e+00,
       4.82799470e-03, 6.16099267e-02, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.69181420e-02,
       2.08784883e-02, 0.00000000e+00, 2.33188043e-02, 3.17275128e-02,
       3.51243304e-02, 4.93630676e-02, 1.22754888e-01, 0.00000000e+00,
       2.07342491e-02, 4.72874689e-02, 0.00000000e+00, 0.00000000e+00,
       0.00000000e+00, 0.00000000e+00, 2.98016701e-02, 0.00000000e+00,
       3.32685797e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
       2.79852497e-02, 6.83737350e-03])
</pre></div>
</div>
</div>
</div>
<section id="sorting-information-gain">
<h3>Sorting Information Gain<a class="headerlink" href="#sorting-information-gain" title="Permalink to this headline">#</a></h3>
<p>Setelah didapat nilai information gainnya, selanjutnya kita dapat mengurutkan nilai information gain dari yang tertinggi hingga yang terendah dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mutual_info</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">mutual_info</span><span class="p">)</span>
<span class="n">mutual_info</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>
<span class="n">mutual_info</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>skrg          0.169972
cebong        0.164171
istilah       0.160337
bang          0.158804
ring          0.155094
                ...   
ken           0.000000
kekekekkek    0.000000
kawan         0.000000
kalean        0.000000
manyambut     0.000000
Length: 390, dtype: float64
</pre></div>
</div>
</div>
</div>
</section>
<section id="membuat-grafik-information-gain">
<h3>Membuat Grafik Information Gain<a class="headerlink" href="#membuat-grafik-information-gain" title="Permalink to this headline">#</a></h3>
<p>Selanjutnya kita juga dapat membuat grafiknya dengan menggunakan matplotlib seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#let&#39;s plot the ordered mutual_info values per feature</span>
<span class="n">mutual_info</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">80</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fae34bd4d50&gt;
</pre></div>
</div>
<img alt="_images/crawling_88_1.png" src="_images/crawling_88_1.png" />
</div>
</div>
</section>
<section id="pilih-fitur-penting">
<h3>Pilih Fitur Penting<a class="headerlink" href="#pilih-fitur-penting" title="Permalink to this headline">#</a></h3>
<p>Selanjutnya kita juga dapat memilih fitur yang penting berdasarkan nilai information gain yang diperoleh, semakin tinggi nilai fitur maka semakin penting fitur tersebut. Disini saya memilih 100 data fitur penting dengan menggunakan library SelectBest.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#No we Will select the  top 5 important features</span>
<span class="n">sel_five_cols</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">mutual_info_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">sel_five_cols</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">sel_five_cols</span><span class="o">.</span><span class="n">get_support</span><span class="p">()]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;akun&#39;, &#39;aliansi&#39;, &#39;amat&#39;, &#39;amerika&#39;, &#39;angin&#39;, &#39;anies&#39;, &#39;arti&#39;, &#39;asuh&#39;,
       &#39;bakso&#39;, &#39;bang&#39;, &#39;beliau&#39;, &#39;bicara&#39;, &#39;bincang&#39;, &#39;brigadir&#39;, &#39;cipta&#39;,
       &#39;clue&#39;, &#39;coba&#39;, &#39;dapat&#39;, &#39;data&#39;, &#39;dekat&#39;, &#39;desain&#39;, &#39;ditakedown&#39;,
       &#39;dukung&#39;, &#39;dungu&#39;, &#39;era&#39;, &#39;habis&#39;, &#39;hari&#39;, &#39;heboh&#39;, &#39;hoax&#39;, &#39;investasi&#39;,
       &#39;jam&#39;, &#39;jaman&#39;, &#39;janji&#39;, &#39;joko&#39;, &#39;kalang&#39;, &#39;kalean&#39;, &#39;kampret&#39;,
       &#39;kantor&#39;, &#39;kasih&#39;, &#39;katarak&#39;, &#39;kawan&#39;, &#39;kib&#39;, &#39;kirakira&#39;, &#39;koordinator&#39;,
       &#39;kota&#39;, &#39;lantar&#39;, &#39;lengkap&#39;, &#39;magetan&#39;, &#39;masuk&#39;, &#39;merdeka&#39;, &#39;mesti&#39;,
       &#39;minat&#39;, &#39;minum&#39;, &#39;mma&#39;, &#39;mustahil&#39;, &#39;nawarin&#39;, &#39;negara&#39;, &#39;netizen&#39;,
       &#39;panggil&#39;, &#39;part&#39;, &#39;pecutin&#39;, &#39;pesan&#39;, &#39;prediksi&#39;, &#39;pria&#39;, &#39;puncak&#39;,
       &#39;quen&#39;, &#39;rakyat&#39;, &#39;ramai&#39;, &#39;rezim&#39;, &#39;right&#39;, &#39;sadar&#39;, &#39;salam&#39;,
       &#39;sambang&#39;, &#39;sambo&#39;, &#39;selesai&#39;, &#39;sila&#39;, &#39;silalahi&#39;, &#39;simak&#39;, &#39;suara&#39;,
       &#39;tampar&#39;, &#39;tamu&#39;, &#39;tanda&#39;, &#39;tantang&#39;, &#39;tarung&#39;, &#39;tatap&#39;, &#39;tayang&#39;,
       &#39;telepon&#39;, &#39;tempo&#39;, &#39;tim&#39;, &#39;tolong&#39;, &#39;tonton&#39;, &#39;tugas&#39;, &#39;turut&#39;,
       &#39;tweet&#39;, &#39;udh&#39;, &#39;via&#39;, &#39;video&#39;, &#39;wali&#39;, &#39;walikota&#39;, &#39;yaa&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="klasifikasi-data">
<h2><strong>Klasifikasi Data</strong><a class="headerlink" href="#klasifikasi-data" title="Permalink to this headline">#</a></h2>
<p>Klasifikasi adalah proses penemuan model (atau fungsi) yang
menggambarkan dan membedakan kelas data atau konsep yang bertujuan agar
bisa digunakan untuk memprediksi kelas dari objek yang label kelasnya tidak
diketahui.Klasifikasi data terdiri dari 2 langkah proses. Pertama
adalah learning (fase training), dimana algoritma klasifikasi dibuat untuk
menganalisis data training lalu direpresentasikan dalam bentuk rule klasifikasi.
Proses kedua adalah klasifikasi, dimana data tes digunakan untuk memperkirakan
akurasi dari rule klasifikasi. Terdapat beberapa metode klasifikasi, diantaranya sebagai berikut.</p>
<section id="knn-k-nearest-neighbor">
<h3>KNN (K-Nearest Neighbor)<a class="headerlink" href="#knn-k-nearest-neighbor" title="Permalink to this headline">#</a></h3>
<p>K-Nearest Neighbor (KNN) merupakan salah satu metode yang digunakan
dalam menyelesaikan masalah pengklasifikasian. Prinsip KNN yaitu
mengelompokkan atau mengklasifikasikan suatu data baru yang belum diketahui
kelasnya berdasarkan jarak data baru itu ke beberapa tetangga (neighbor) terdekat.
Tetangga terdekat adalah objek latih yang memiliki nilai kemiripan terbesar atau
ketidakmiripan terkecil dari data lama. Jumlah tetangga terdekat dinyatakan
dengan k. Nilai k yang terbaik tergantung pada data.
Nilai k umumnya ditentukan dalam jumlah ganjil (3, 5, 7) untuk
menghindari munculnya jumlah jarak yang sama dalam proses pengklasifikasian.
Apabila terjadi dua atau lebih jumlah kelas yang muncul sama maka nilai k
menjadi k – 1 (satu tetangga kurang), jika masih ada yang sama lagi maka nilai k
menjadi k – 2 , begitu seterusnya sampai tidak ditemukan lagi kelas yang sama
banyak. Banyaknya kelas yang paling banyak dengan jarak terdekat akan menjadi
kelas dimana data yang dievaluasi berada. Dekat atau jauhnya tetangga (neighbor)
biasanya dihitung berdasarkan jarak Euclidean (Euclidean Distance). Berikut
rumus pencarian jarak menggunakan rumus Euclidian :</p>
<div class="math notranslate nohighlight">
\[d_i = \sqrt{\sum_{i=1}^{p}(x_2i-x_1i)^{2}}\]</div>
<p>dengan:<br>
<span class="math notranslate nohighlight">\(x_1\)</span> = sampel data<br>
<span class="math notranslate nohighlight">\(x_2\)</span> = data uji<br>
i = variabel data<br>
<span class="math notranslate nohighlight">\(d_i\)</span> = jarak<br>
p = dimensi data<br></p>
<p>Berikut merupakan klasifikasi data dengan metode KNN dengan library scikit learn menggunakan nilai k yang di ubah-ubah.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="n">K_range</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">K_score</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)):</span>
  <span class="n">classifier</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">i</span><span class="p">)</span> 
  <span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
  <span class="n">score</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
  <span class="n">K_range</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
  <span class="n">K_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi KNN saat Menggunakan K =&quot;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="s2">&quot;:&quot;</span><span class="p">,</span><span class="n">score</span><span class="p">)</span>
  <span class="c1">#print(classification_report(y_test, y_pred))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi KNN saat Menggunakan K = 2 : 0.6
Akurasi KNN saat Menggunakan K = 3 : 0.6
Akurasi KNN saat Menggunakan K = 4 : 0.5333333333333333
Akurasi KNN saat Menggunakan K = 5 : 0.6
Akurasi KNN saat Menggunakan K = 6 : 0.6
Akurasi KNN saat Menggunakan K = 7 : 0.6666666666666666
Akurasi KNN saat Menggunakan K = 8 : 0.6666666666666666
Akurasi KNN saat Menggunakan K = 9 : 0.6
Akurasi KNN saat Menggunakan K = 10 : 0.5333333333333333
Akurasi KNN saat Menggunakan K = 11 : 0.5333333333333333
Akurasi KNN saat Menggunakan K = 12 : 0.5333333333333333
Akurasi KNN saat Menggunakan K = 13 : 0.4666666666666667
Akurasi KNN saat Menggunakan K = 14 : 0.4
</pre></div>
</div>
</div>
</div>
<p>Berikut merupakan grafik nilai akurasi KNN berdasarkan nilai k.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">K_range</span><span class="p">,</span> <span class="n">K_score</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Nilai Accuracy KNN Berdasarkan Nilai K&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Nilai K&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Nilai Akurasi&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/crawling_96_0.png" src="_images/crawling_96_0.png" />
</div>
</div>
</section>
<section id="naive-bayes">
<h3>Naive Bayes<a class="headerlink" href="#naive-bayes" title="Permalink to this headline">#</a></h3>
<p>Algoritma Naive Bayes adalah algoritma yang mempelajari probabilitas suatu objek dengan ciri-ciri tertentu yang termasuk dalam kelompok/kelas tertentu. Singkatnya, ini adalah pengklasifikasi probabilistik. Berikut merupakan klasifikasi naive bayes dengan mengunakan library scikit learn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="c1"># Mengaktifkan/memanggil/membuat fungsi klasifikasi Naive Bayes</span>
<span class="n">modelnb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="c1"># Memasukkan data training pada fungsi klasifikasi Naive Bayes</span>
<span class="n">nbtrain</span> <span class="o">=</span> <span class="n">modelnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Menentukan hasil prediksi dari x_test</span>
<span class="c1">#y_pred = nbtrain.predict(X_test)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi Naive Bayes :&quot;</span><span class="p">,</span><span class="n">nbtrain</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>

<span class="c1">#print(classification_report(y_test, y_pred))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi Naive Bayes : 0.8666666666666667
</pre></div>
</div>
</div>
</div>
</section>
<section id="svm-support-vector-machine">
<h3>SVM(Support Vector Machine)<a class="headerlink" href="#svm-support-vector-machine" title="Permalink to this headline">#</a></h3>
<p>Support Vector Machine (SVM) merupakan salah satu metode dalam supervised learning yang biasanya digunakan untuk klasifikasi (seperti Support Vector Classification) dan regresi (Support Vector Regression). Dalam pemodelan klasifikasi, SVM memiliki konsep yang lebih matang dan lebih jelas secara matematis dibandingkan dengan teknik-teknik klasifikasi lainnya. SVM juga dapat mengatasi masalah klasifikasi dan regresi dengan linear maupun non linear. Berikut merupakan klasifikasi SVM dengan mengunakan library scikit learn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Import svm model</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>

<span class="c1">#Create a svm Classifier</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">()</span> <span class="c1"># Linear Kernel</span>

<span class="c1">#Train the model using the training sets</span>
<span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1">#Predict the response for test dataset</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Model Accuracy: how often is the classifier correct?</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi SVM :&quot;</span><span class="p">,</span><span class="n">svm</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi SVM : 0.7333333333333333
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="klustering-data">
<h2><strong>Klustering Data</strong><a class="headerlink" href="#klustering-data" title="Permalink to this headline">#</a></h2>
<p>Clustering adalah suatu kegiatan mengelompokkan dokumen berdasarkan pada karakteristik yang terkandung di dalamnya. Proses analisa clustering pada intinya terdapat dua tahapan :<br>
yang pertama mentransformasi document ke dalam bentuk quantitative data, dan<br>
yang kedua menganalisa dokumen dalam bentuk quantitative data tersebut dengan metode clustering yang ditentukan.<br>
Untuk proses tahapan kedua ada berbagai jenis metode clustering yang bisa digunakan. Diantara metode-metode tersebut ialah metode K-Means, mixture modelling atau tulisan-tulisan clustering lainnya.<br></p>
<p>Yang umumnya menjadi permasalahan dalam pelaksanaan clustering ini adalah bagaimana cara merepresentasikan dokumen ke dalam bentuk data quantitative. Ada beberapa cara yang umum digunakan, salah satunya adalah Vector Space Model(VSM) yang merepresentasikan dokumen ke dalam bentuk vector dari term yang muncul dalam dokumen yang dianalisa. Salah satu bentuk representasinya adalah term-frequency (TF) vector yang bisa dilambangkan dengan :<br></p>
<div class="math notranslate nohighlight">
\[dtf = (tf_1, tf_2, . . . , tf_m)\]</div>
<p>dimana<br>
<span class="math notranslate nohighlight">\(tf_i\)</span> : adalah frekuensi dari term ke-i di dalam suatu dokumen.<br>
Kemudian selanjutnya untuk menganalisa dokumen yang sudah dalam bentuk quantitative dengan menggunakan metode K-Means dijelaskan seperti berikut.</p>
<section id="k-means-clustering">
<h3>K-Means Clustering<a class="headerlink" href="#k-means-clustering" title="Permalink to this headline">#</a></h3>
<p>K-Means clustering adalah algoritma untuk membagi n pengamatan menjadi k kelompok sedemikian hingga tiap pengamatan termasuk ke dalam kelompok dengan rata-rata terdekat (titik tengah kelompok). Algoritma ini memiliki hubungan yang renggang dengan algoritma KNN, algoritma pemelajaran mesin yang cukup terkenal dan sering disalah artikan dengan K-Means karena kemiripan namanya.<br>
Algoritme pengklasteran k rata-rata adalah sebagai berikut.<br></p>
<ol class="simple">
<li><p>Pilih k buah titik tengah secara acak.<br></p></li>
<li><p>Kelompokkan data sehingga terbentuk k buah kelompok dengan titik tengah tiap kelompok merupakan titik tengah yang telah dipilih sebelumnya.<br></p></li>
<li><p>Perbarui nilai titik tengah tiap kelompok.<br></p></li>
<li><p>Ulangi langkah 2 dan 3 sampai titik tengah semua kelompok tidak lagi berubah.<br></p></li>
</ol>
<p>Proses pengklasteran data ke dalam suatu kelompok dapat dilakukan dengan cara menghitung jarak terdekat dari suatu data ke sebuah titik tengah. Perhitungan jarak Minkowski dapat digunakan untuk menghitung jarak antara 2 buah data.</p>
<p>Pembaruan titik tengah dapat dilakukan dengan rumus berikut:<br></p>
<div class="math notranslate nohighlight">
\[{\displaystyle \mu _{k}={\frac {1}{N_{k}}}\sum _{j=1}^{N_{k}}x_{j}}\]</div>
<p>dengan <span class="math notranslate nohighlight">\(µk\)</span> adalah titik tengah kelompok ke-k, <span class="math notranslate nohighlight">\(Nk\)</span> adalah banyak data dalam kelompok ke-k, dan <span class="math notranslate nohighlight">\(xj\)</span> adalah data ke-j dalam kelompok ke-k.<br>
Untuk melakukan clustering dengan menggunakan mesin dapat menggunakan library sklearn seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="n">Kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">Kmeans</span> <span class="o">=</span> <span class="n">Kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataTF</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">Kmeans</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dataTF</span><span class="p">)</span>
<span class="n">centroids</span> <span class="o">=</span> <span class="n">Kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Kmeans</span><span class="o">.</span><span class="n">labels_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([2, 2, 2, 1, 2, 2, 1, 2, 2, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0,
       1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2,
       2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 1, 2, 2, 0, 0, 2, 2, 0, 2, 2, 0, 0,
       0, 0, 0, 2, 1, 2, 2, 2, 0, 1, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2,
       0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2], dtype=int32)
</pre></div>
</div>
</div>
</div>
</section>
<section id="hasil-clustering">
<h3>Hasil Clustering<a class="headerlink" href="#hasil-clustering" title="Permalink to this headline">#</a></h3>
<p>Hasil kluster dengan menggunakan metode K-Means ialah sebagai berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataTF</span><span class="p">[</span><span class="s1">&#39;Cluster_Id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Kmeans</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">dataTF</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-a37162a3-172e-4f0b-bf35-ce8dee8f2e96">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>acara</th>
      <th>airlangga</th>
      <th>ajak</th>
      <th>ajar</th>
      <th>akal</th>
      <th>akrab</th>
      <th>aktivis</th>
      <th>aku</th>
      <th>akun</th>
      <th>aliansi</th>
      <th>...</th>
      <th>visible</th>
      <th>wali</th>
      <th>walikota</th>
      <th>wib</th>
      <th>widodo</th>
      <th>xi</th>
      <th>yaa</th>
      <th>yakin</th>
      <th>youtube</th>
      <th>Cluster_Id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>96</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>97</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>98</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>99</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>100</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 391 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-a37162a3-172e-4f0b-bf35-ce8dee8f2e96')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-a37162a3-172e-4f0b-bf35-ce8dee8f2e96 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-a37162a3-172e-4f0b-bf35-ce8dee8f2e96');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<p>Jumlah dari masing-masing kluster dengan 3 kluster sebagai berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">unique</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">Kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">dict_data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unique</span><span class="p">,</span> <span class="n">counts</span><span class="p">))</span>
<span class="n">dict_data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{0: 56, 1: 36, 2: 8}
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id1">
<h2><strong>Kesimpulan</strong><a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h2>
<p>Berdasarkan nilai akurasi yang diperoleh dari 3 metode (KNN, Naive Bayes, dan SVM) yang dilakukan, klasifikasi dengan metode Naive Bayes memiliki nilai akurasi yang lebih baik dibandingkan dengan metode KNN dan SVM. Nilai akurasi yang diperoleh dari metode Naive Bayes sebesar 87%.<br>
Sedangkan nilai akurasi yang diperoleh dengan menggunakan metode KNN didapat akurasi tertinggi sebesar 66% pada saat nilai k = 7 dan 8 dan akuarasi yang didapat dari metode SVM sebesar 73%. Sehingga dapat disimpulkan bahwa klasifikasi dari dataset yang mengandung kata “#rockygerung” yang diperoleh dari tweeter lebih baik menggunakan metode Naive Bayes dibandingkan dengan metode KNN dan SVM.<br>
Dengan nilai akurasi yang didapat dari metode naive bayes tersebut, klasifikasi ini sudah bisa dijadikan sebagai acuan untuk menentukan tanggapan user tweeter tentang “#rockygerung” apakah beropini kontra atau pro ataupun netral. Akan tetapi klasifikasi ini masih memerlukan evaluasi atau perbaikan dari tahap prepocessing hingga modelling agar menghasilkan nilai akurasi yang lebih baik.<br>
Dan dengan proses klustering data dengan menggunakan 3 kluster dari 100 data diperoleh 56 data berkluster dengan id = 0, dan 36 data berkluster dengan id = 1, serta 8 data berkluster dengan id = 2.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="ekstraksi-ringkasan-dokumen">
<h1>Ekstraksi Ringkasan Dokumen<a class="headerlink" href="#ekstraksi-ringkasan-dokumen" title="Permalink to this headline">#</a></h1>
<p>Sistem Peringkasan adalah sistem yang digunakan untuk menentukan topik yang sangat penting dari suatu dokumen. Proses peringkasan ini dapat dilakukan dengan melalui tahapan-tahapan berikut.</p>
<section id="mengambil-dokumen">
<h2><strong>Mengambil Dokumen</strong><a class="headerlink" href="#mengambil-dokumen" title="Permalink to this headline">#</a></h2>
<p>Langkah awal untuk melakukan ekstraksi ringkasan dokumen ialah dengan mengambil dokumen tersebut dengan mengcrawling data dokumen dengan menggunakan scrapy &amp; crochet seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install scrapy
<span class="o">!</span>pip install crochet
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting scrapy
  Downloading Scrapy-2.6.3-py2.py3-none-any.whl (264 kB)
     |████████████████████████████████| 264 kB 35.3 MB/s 
?25hCollecting itemadapter&gt;=0.1.0
  Downloading itemadapter-0.7.0-py3-none-any.whl (10 kB)
Requirement already satisfied: lxml&gt;=3.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (4.9.1)
Collecting PyDispatcher&gt;=2.0.5
  Downloading PyDispatcher-2.0.6.tar.gz (38 kB)
Collecting zope.interface&gt;=5.0.0
  Downloading zope.interface-5.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (254 kB)
     |████████████████████████████████| 254 kB 71.2 MB/s 
?25hCollecting cryptography&gt;=3.3
  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)
     |████████████████████████████████| 4.0 MB 60.9 MB/s 
?25hCollecting parsel&gt;=1.5.0
  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)
Collecting protego&gt;=0.1.15
  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)
Collecting Twisted&gt;=18.9.0
  Downloading Twisted-22.8.0-py3-none-any.whl (3.1 MB)
     |████████████████████████████████| 3.1 MB 71.3 MB/s 
?25hCollecting service-identity&gt;=18.1.0
  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)
Collecting w3lib&gt;=1.17.0
  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)
Collecting itemloaders&gt;=1.0.1
  Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)
Collecting queuelib&gt;=1.4.2
  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)
Collecting cssselect&gt;=0.9.1
  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)
Collecting tldextract
  Downloading tldextract-3.4.0-py3-none-any.whl (93 kB)
     |████████████████████████████████| 93 kB 2.8 MB/s 
?25hCollecting pyOpenSSL&gt;=21.0.0
  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)
     |████████████████████████████████| 57 kB 5.9 MB/s 
?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from scrapy) (57.4.0)
Requirement already satisfied: cffi&gt;=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography&gt;=3.3-&gt;scrapy) (1.15.1)
Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi&gt;=1.12-&gt;cryptography&gt;=3.3-&gt;scrapy) (2.21)
Collecting jmespath&gt;=0.9.5
  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)
Requirement already satisfied: six&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from parsel&gt;=1.5.0-&gt;scrapy) (1.15.0)
Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity&gt;=18.1.0-&gt;scrapy) (0.4.8)
Requirement already satisfied: attrs&gt;=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity&gt;=18.1.0-&gt;scrapy) (22.1.0)
Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity&gt;=18.1.0-&gt;scrapy) (0.2.8)
Collecting Automat&gt;=0.8.0
  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)
Collecting constantly&gt;=15.1
  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)
Collecting hyperlink&gt;=17.1.1
  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)
     |████████████████████████████████| 74 kB 3.6 MB/s 
?25hRequirement already satisfied: typing-extensions&gt;=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=18.9.0-&gt;scrapy) (4.1.1)
Collecting incremental&gt;=21.3.0
  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)
Requirement already satisfied: idna&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink&gt;=17.1.1-&gt;Twisted&gt;=18.9.0-&gt;scrapy) (2.10)
Requirement already satisfied: requests&gt;=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract-&gt;scrapy) (2.23.0)
Collecting requests-file&gt;=1.4
  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)
Requirement already satisfied: filelock&gt;=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract-&gt;scrapy) (3.8.0)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.1.0-&gt;tldextract-&gt;scrapy) (1.24.3)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.1.0-&gt;tldextract-&gt;scrapy) (3.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.1.0-&gt;tldextract-&gt;scrapy) (2022.9.24)
Building wheels for collected packages: PyDispatcher
  Building wheel for PyDispatcher (setup.py) ... ?25l?25hdone
  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.6-py3-none-any.whl size=11958 sha256=62a44ac4acfe9636faedb24f570a1632e5827f611e0f1d2fdb2a6cf61ced9a2c
  Stored in directory: /root/.cache/pip/wheels/c9/d6/6a/de198d890277cde60ca3dbebe7ae592d3b381c7d9bb2455f4d
Successfully built PyDispatcher
Installing collected packages: w3lib, cssselect, zope.interface, requests-file, parsel, jmespath, itemadapter, incremental, hyperlink, cryptography, constantly, Automat, Twisted, tldextract, service-identity, queuelib, pyOpenSSL, PyDispatcher, protego, itemloaders, scrapy
Successfully installed Automat-20.2.0 PyDispatcher-2.0.6 Twisted-22.8.0 constantly-15.1.0 cryptography-38.0.1 cssselect-1.1.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.7.0 itemloaders-1.0.6 jmespath-1.0.1 parsel-1.6.0 protego-0.2.1 pyOpenSSL-22.1.0 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.6.3 service-identity-21.1.0 tldextract-3.4.0 w3lib-2.0.1 zope.interface-5.5.0
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting crochet
  Downloading crochet-2.0.0-py3-none-any.whl (31 kB)
Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from crochet) (1.14.1)
Requirement already satisfied: Twisted&gt;=16.0 in /usr/local/lib/python3.7/dist-packages (from crochet) (22.8.0)
Requirement already satisfied: hyperlink&gt;=17.1.1 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (21.0.0)
Requirement already satisfied: Automat&gt;=0.8.0 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (20.2.0)
Requirement already satisfied: typing-extensions&gt;=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (4.1.1)
Requirement already satisfied: incremental&gt;=21.3.0 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (22.10.0)
Requirement already satisfied: constantly&gt;=15.1 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (15.1.0)
Requirement already satisfied: zope.interface&gt;=4.4.2 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (5.5.0)
Requirement already satisfied: attrs&gt;=19.2.0 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (22.1.0)
Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from Automat&gt;=0.8.0-&gt;Twisted&gt;=16.0-&gt;crochet) (1.15.0)
Requirement already satisfied: idna&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink&gt;=17.1.1-&gt;Twisted&gt;=16.0-&gt;crochet) (2.10)
Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface&gt;=4.4.2-&gt;Twisted&gt;=16.0-&gt;crochet) (57.4.0)
Installing collected packages: crochet
Successfully installed crochet-2.0.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">scrapy.crawler</span> <span class="kn">import</span> <span class="n">CrawlerRunner</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">crochet</span> <span class="kn">import</span> <span class="n">setup</span><span class="p">,</span> <span class="n">wait_for</span>
<span class="n">setup</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">QuotesToCsv</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;MJKQuotesToCsv&quot;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;https://tekno.tempo.co/read/1580340/peran-penting-iptekin-terhadap-kemajuan-sebuah-bangsa&#39;</span>
    <span class="p">]</span>
    <span class="n">custom_settings</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;ITEM_PIPELINES&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;__main__.ExtractFirstLine&#39;</span><span class="p">:</span> <span class="mi">1</span>
        <span class="p">},</span>
        <span class="s1">&#39;FEEDS&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;news.csv&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;format&#39;</span><span class="p">:</span> <span class="s1">&#39;csv&#39;</span><span class="p">,</span>
                <span class="s1">&#39;overwrite&#39;</span><span class="p">:</span> <span class="kc">True</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;parse data from urls&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;#isi &gt; p&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span><span class="s1">&#39;news&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">extract</span><span class="p">()}</span>


<span class="k">class</span> <span class="nc">ExtractFirstLine</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;text processing&quot;&quot;&quot;</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">item</span><span class="p">)[</span><span class="s2">&quot;news&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>
        <span class="n">first_line</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__remove_html_tags__</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;news&#39;</span><span class="p">:</span> <span class="n">first_line</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">__remove_html_tags__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;remove html tags from string&quot;&quot;&quot;</span>
        <span class="n">html_tags</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;&lt;.*?&gt;&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">html_tags</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

<span class="nd">@wait_for</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">run_spider</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;run spider with MJKQuotesToCsv&quot;&quot;&quot;</span>
    <span class="n">crawler</span> <span class="o">=</span> <span class="n">CrawlerRunner</span><span class="p">()</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">crawler</span><span class="o">.</span><span class="n">crawl</span><span class="p">(</span><span class="n">QuotesToCsv</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">run_spider</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="membaca-dokumen">
<h2><strong>Membaca Dokumen</strong><a class="headerlink" href="#membaca-dokumen" title="Permalink to this headline">#</a></h2>
<p>Setelah tahapan mengambil dokumen selesai, selanjutnya membaca dokumen yang sudah didapatkan. Untuk membaca dokumen terlebih dahulu kita convert file csv kedalam bentuk pdf dengan menggunakan library pdfkit. Untuk itu install library pdfkit terlebih dahulu seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install pdfkit

<span class="o">!</span>wget https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-1/wkhtmltox_0.12.6-1.bionic_amd64.deb

<span class="o">!</span>cp wkhtmltox_0.12.6-1.bionic_amd64.deb /usr/bin

<span class="o">!</span>sudo apt install /usr/bin/wkhtmltox_0.12.6-1.bionic_amd64.deb
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting pdfkit
  Downloading pdfkit-1.0.0-py3-none-any.whl (12 kB)
Installing collected packages: pdfkit
Successfully installed pdfkit-1.0.0
--2022-10-17 08:10:05--  https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-1/wkhtmltox_0.12.6-1.bionic_amd64.deb
Resolving github.com (github.com)... 140.82.114.3
Connecting to github.com (github.com)|140.82.114.3|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/131323182/b6d71780-ab7e-11ea-9b13-e2875e48ec6c?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221017%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20221017T081005Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=ac129807a1d251a6cacd69284fdcaeb0ecb74261772c38f0e4ea39e9fa4ff196&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;key_id=0&amp;repo_id=131323182&amp;response-content-disposition=attachment%3B%20filename%3Dwkhtmltox_0.12.6-1.bionic_amd64.deb&amp;response-content-type=application%2Foctet-stream [following]
--2022-10-17 08:10:05--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/131323182/b6d71780-ab7e-11ea-9b13-e2875e48ec6c?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221017%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20221017T081005Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=ac129807a1d251a6cacd69284fdcaeb0ecb74261772c38f0e4ea39e9fa4ff196&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;key_id=0&amp;repo_id=131323182&amp;response-content-disposition=attachment%3B%20filename%3Dwkhtmltox_0.12.6-1.bionic_amd64.deb&amp;response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 15729530 (15M) [application/octet-stream]
Saving to: ‘wkhtmltox_0.12.6-1.bionic_amd64.deb’

wkhtmltox_0.12.6-1. 100%[===================&gt;]  15.00M  --.-KB/s    in 0.04s   

2022-10-17 08:10:05 (347 MB/s) - ‘wkhtmltox_0.12.6-1.bionic_amd64.deb’ saved [15729530/15729530]

Reading package lists... Done
Building dependency tree       
Reading state information... Done
Note, selecting &#39;wkhtmltox&#39; instead of &#39;/usr/bin/wkhtmltox_0.12.6-1.bionic_amd64.deb&#39;
The following package was automatically installed and is no longer required:
  libnvidia-common-460
Use &#39;sudo apt autoremove&#39; to remove it.
The following additional packages will be installed:
  xfonts-75dpi xfonts-base xfonts-encodings xfonts-utils
Suggested packages:
  xfs | xserver
The following NEW packages will be installed:
  wkhtmltox xfonts-75dpi xfonts-base xfonts-encodings xfonts-utils
0 upgraded, 5 newly installed, 0 to remove and 12 not upgraded.
Need to get 9,947 kB/25.7 MB of archives.
After this operation, 152 MB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 xfonts-encodings all 1:1.0.4-2 [573 kB]
Get:2 /usr/bin/wkhtmltox_0.12.6-1.bionic_amd64.deb wkhtmltox amd64 1:0.12.6-1.bionic [15.7 MB]
Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 xfonts-utils amd64 1:7.7+6 [91.5 kB]
Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 xfonts-75dpi all 1:1.0.4+nmu1 [3,368 kB]
Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 xfonts-base all 1:1.0.4+nmu1 [5,914 kB]
Fetched 9,947 kB in 1s (9,558 kB/s)
debconf: unable to initialize frontend: Dialog
debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, &lt;&gt; line 5.)
debconf: falling back to frontend: Readline
debconf: unable to initialize frontend: Readline
debconf: (This frontend requires a controlling tty.)
debconf: falling back to frontend: Teletype
dpkg-preconfigure: unable to re-open stdin: 
Selecting previously unselected package xfonts-encodings.
(Reading database ... 123934 files and directories currently installed.)
Preparing to unpack .../xfonts-encodings_1%3a1.0.4-2_all.deb ...
Unpacking xfonts-encodings (1:1.0.4-2) ...
Selecting previously unselected package xfonts-utils.
Preparing to unpack .../xfonts-utils_1%3a7.7+6_amd64.deb ...
Unpacking xfonts-utils (1:7.7+6) ...
Selecting previously unselected package xfonts-75dpi.
Preparing to unpack .../xfonts-75dpi_1%3a1.0.4+nmu1_all.deb ...
Unpacking xfonts-75dpi (1:1.0.4+nmu1) ...
Selecting previously unselected package xfonts-base.
Preparing to unpack .../xfonts-base_1%3a1.0.4+nmu1_all.deb ...
Unpacking xfonts-base (1:1.0.4+nmu1) ...
Selecting previously unselected package wkhtmltox.
Preparing to unpack .../wkhtmltox_0.12.6-1.bionic_amd64.deb ...
Unpacking wkhtmltox (1:0.12.6-1.bionic) ...
Setting up xfonts-encodings (1:1.0.4-2) ...
Setting up xfonts-utils (1:7.7+6) ...
Setting up xfonts-75dpi (1:1.0.4+nmu1) ...
Setting up xfonts-base (1:1.0.4+nmu1) ...
Setting up wkhtmltox (1:0.12.6-1.bionic) ...
Processing triggers for fontconfig (2.12.6-0ubuntu2) ...
Processing triggers for man-db (2.8.3-2ubuntu0.1) ...
Processing triggers for libc-bin (2.27-3ubuntu1.6) ...
</pre></div>
</div>
</div>
</div>
<section id="convert-file-csv-ke-pdf">
<h3>Convert File CSV ke PDF<a class="headerlink" href="#convert-file-csv-ke-pdf" title="Permalink to this headline">#</a></h3>
<p>Setelah librari pdfkit berhasil diinstal, maka langsung kita import untuk mengconvert file csv yang di dapat ke dalam format pdf menggunakan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pdfkit</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">path_wkhtmltopdf</span> <span class="o">=</span> <span class="s2">&quot;/content/wkhtmltox_0.12.6-1.bionic_amd64.deb&quot;</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">pdfkit</span><span class="o">.</span><span class="n">configuration</span><span class="p">(</span><span class="n">wkhtmltopdf</span><span class="o">=</span><span class="n">path_wkhtmltopdf</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;news.csv&#39;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">html_string</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to_html</span><span class="p">()</span>
<span class="n">pdfkit</span><span class="o">.</span><span class="n">from_string</span><span class="p">(</span><span class="n">html_string</span><span class="p">,</span> <span class="s2">&quot;Dokumen.pdf&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>Setelah berhasil diconvert selanjutnya baca dokumen yang sudah diconvert tersebut dengan library PyPDF2 dan docx2txt, untuk itu kita install library tersebut terlebih dahulu dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install PyPDF2
<span class="o">!</span>pip install docx2txt
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting PyPDF2
  Downloading PyPDF2-2.11.1-py3-none-any.whl (220 kB)
     |████████████████████████████████| 220 kB 12.7 MB/s 
?25hRequirement already satisfied: typing-extensions&gt;=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from PyPDF2) (4.1.1)
Installing collected packages: PyPDF2
Successfully installed PyPDF2-2.11.1
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting docx2txt
  Downloading docx2txt-0.8.tar.gz (2.8 kB)
Building wheels for collected packages: docx2txt
  Building wheel for docx2txt (setup.py) ... ?25l?25hdone
  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=b78537f33d7719847a55a09a772f0b943f52ff69cd9479ca4d2371cc396b89ed
  Stored in directory: /root/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8
Successfully built docx2txt
Installing collected packages: docx2txt
Successfully installed docx2txt-0.8
</pre></div>
</div>
</div>
</div>
</section>
<section id="baca-dokumen">
<h3>Baca Dokumen<a class="headerlink" href="#baca-dokumen" title="Permalink to this headline">#</a></h3>
<p>Setelah berhasil diinstal selanjutnya kita import library tersebut untuk membaca dokumen yang sudah convert ke bentuk pdf dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">PyPDF2</span>
<span class="kn">import</span> <span class="nn">docx2txt</span>
<span class="kn">import</span> <span class="nn">sys</span>
</pre></div>
</div>
</div>
</div>
<p>Setelah diimport kita panggil file dokumen tersebut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">name</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Masukkan nama file: &#39;</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Anda telah memanggil dokument  </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Masukkan nama file: Dokumen.pdf
Anda telah memanggil dokument  Dokumen.pdf
</pre></div>
</div>
</div>
</div>
<p>Setelah itu baca file dokumen tersebut dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pdfFileObj</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
<span class="n">pdfReader</span> <span class="o">=</span> <span class="n">PyPDF2</span><span class="o">.</span><span class="n">PdfFileReader</span><span class="p">(</span><span class="n">pdfFileObj</span><span class="p">)</span>
<span class="n">pageObj</span> <span class="o">=</span> <span class="n">pdfReader</span><span class="o">.</span><span class="n">getPage</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">pageObj</span><span class="o">.</span><span class="n">extractText</span><span class="p">()</span>
<span class="n">document</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;news\n0\nINFO TEKNO -Â Ilmu pengetahuan, teknologi, dan inovasi (Iptekin) adalah salah satu elemen kunci dalam mendorong\ndan mempercepat pembangunan ekonomi di suatu negara. Iptekin atau yang dalam bahasa global disebut sebagai\nscience, technology, and innovation (STI) juga menjadi key driver bagi berbagai negara-negara maju yang tergabung di\ndalam Organization for Economics Cooperation and Development (OECD) seperti Austria, Amerika Serikat, Swedia,\nItalia, Inggris, Belanda, Perancis, dan negara-negara Eropa lainnya.\n1\nBahkan negara-negara Newly Industrializing Economies (NIEs) yang sempat tertinggal secara ekonomi namun\nkemudian dapat mengejar dan mempercepat pembangunan seperti China, Korea Selatan, dan Taiwan, sangat\nbergantung pada apa yang disebut dengan knowledge-based economy (KBE). Terlebih, negara-negara tersebut,\nterutama Korea Selatan dan Taiwan, sangat minim akan bahan-bahan tambang atau sumber daya alam lainnya.\n2\nBerbagai studi telah menunjukkan bagaimana negara-negara maju dan juga NIEs memberikan prioritas kepada\npengembangan iptekin nasional guna mendorong aktivitas perekonomian di suatu negara. Bahkan di antaranya juga\nsudah mulai menekankan aspek sosial, kelembagaan, dan budaya yang mempengaruhi pengembangan iptekin\nnasional.\n3\nHal ini kemudian melahirkan berbagai konsep pengembangan iptekin secara komprehensif baik dari pendekatan\ncakupan tujuan secara nasional yang kemudian disebut sistem inovasi nasional (SIN), dari pendekatan kedekatan\ngeografi (geography proximity) yang kemudian disebut sebagai sistem inovasi wilayah/daerah (SIDA), dari pendekatan\nsektor tertentu yang kemudian disebut sebagai sistem inovasi sektoral (SIS), dan kemudian juga didekati dengan\naspek teknologi atau yang disebut sebagai technological innovation system (TIS).\n4\nIlmu pengetahuan, teknologi, dan inovasi (Iptekin) adalah salah satu elemen kunci dalam mendorong dan\nmempercepat pembangunan ekonomi di suatu negara.\n5\nSaat ini, diskursus terkait ekosistem inovasi juga meningkat seiring banyak cendekiawan yang menggagas dan\nmendiskusikan hal tersebut baik di berbagai negara dan sektor.\n6\nNegara-negara berkembang juga tengah berupaya mengejar ketertinggalan ekonomi mereka melalui pendekatan\niptekin (technology catch-up) sejak tahun 1990-an. Sejumlah upaya yang dilakukan termasuk di antaranya\nmengembangkan berbagai konsep sistem inovasi sebagai bagian dari pengejaran dan akselerasi pembangunan\nekonomi dari negara-negara maju atau NIEs tersebut dengan memperhatikan berbagai aspek mulai ekonomi, sumber\ndaya alam, kebijakan pemerintah, organisasi/kelembagaan, sosial, dan aspek eksternal/lingkungan yang begitu luas\ndan kompleks.\n7\nTidak sedikit pula negara- negara sedang berkembang yang dalam implementasinya menemui banyak kendala\nsehingga mengakibatkan akselerasi pengembangan iptekin di negaranya menjadi terhambat. Akibatnya, KBE seringkali\nmenjadi tataran konsep di dalam dokumen-dokumen pemerintah atau hanya sebagai wacana yang disuarakan dari\ntahun ke tahun.\n8\nMeniru secara langsung, mereplikasi, mengadaptasi, mengabsorbsi iptekin dan sistem inovasi dari negara-negara maju\natau negara-negara yang sudah berhasil menerapkan hal tersebut menjadi salah satu praktik terbaik yang dilakukan\noleh negara-negara sedang berkembang seperti halnya Indonesia.\n9\nNamun demikian, seringkali implementasi kebijakan tersebut tidaklah berjalan sesuai dengan rencana atau tidak\nmencapai tujuan, karena seringkali apa yang dilihat dan dipraktikkan oleh negara-negara sedang berkembang memiliki\nkonteks dan konten yang berbeda.\n10\nHal ini tentu memerlukan intervensi khusus dimana pemerintah menjadi salah satu aktor penting dalam\nmenumbuhkembangkan iptekin nasional baik dengan belajar dari negara-negara maju atau yang sudah berhasil,\nmaupun dengan cara mengembangkan kemampuan berdasar kekuatan dan sumber daya lokal yang dimiliki oleh\nnegara-negara tersebut.(*)&#39;
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="memecah-dokumen">
<h2><strong>Memecah Dokumen</strong><a class="headerlink" href="#memecah-dokumen" title="Permalink to this headline">#</a></h2>
<p>Setelah berhasil membaca dokumen, selanjutnya pecah dokumen sehingga terdiri dari kalimat dan kata-kata dengan menggunakan library nltk. Maka dari itu terlebih dahulu import librarynya seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.tokenize.punkt</span> <span class="kn">import</span> <span class="n">PunktSentenceTokenizer</span>
</pre></div>
</div>
</div>
</div>
<section id="memecah-kalimat">
<h3>Memecah Kalimat<a class="headerlink" href="#memecah-kalimat" title="Permalink to this headline">#</a></h3>
<p>Setelah library yang dibutuhkan sudah di import selanjutnya pecah dokumen dalam beberapa kalimat dengan menggunakan function berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">):</span>
    <span class="c1"># Kita memecahnya menggunakan  PunktSentenceTokenizer</span>
    <span class="c1"># </span>
    <span class="n">doc_tokenizer</span> <span class="o">=</span> <span class="n">PunktSentenceTokenizer</span><span class="p">()</span>
    
    <span class="c1"># metode tokenize() memanggil dokument kita</span>
    <span class="c1"># sebagai input dan menghasilkan daftar kalimat dalam dokumen</span>
    
    <span class="c1"># sentences_list adalah daftar masing masing kalimat dari dokumen yang ada.</span>
    <span class="n">sentences_list</span> <span class="o">=</span> <span class="n">doc_tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sentences_list</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sentences_list</span> <span class="o">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Banyaknya kalimat = &quot;</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences_list</span><span class="p">)),</span><span class="s1">&#39;kalimat&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Banyaknya kalimat =  17 kalimat
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sentences_list</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----------------------------------------------------------------------------------------------------------------------&#39;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Kalimat&#39;</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----------------------------------------------------------------------------------------------------------------------&#39;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
  <span class="n">n</span> <span class="o">=</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----------------------------------------------------------------------------------------------------------------------&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>----------------------------------------------------------------------------------------------------------------------
Kalimat 1
----------------------------------------------------------------------------------------------------------------------
news
0
INFO TEKNO -Â Ilmu pengetahuan, teknologi, dan inovasi (Iptekin) adalah salah satu elemen kunci dalam mendorong
dan mempercepat pembangunan ekonomi di suatu negara.
----------------------------------------------------------------------------------------------------------------------
Kalimat 2
----------------------------------------------------------------------------------------------------------------------
Iptekin atau yang dalam bahasa global disebut sebagai
science, technology, and innovation (STI) juga menjadi key driver bagi berbagai negara-negara maju yang tergabung di
dalam Organization for Economics Cooperation and Development (OECD) seperti Austria, Amerika Serikat, Swedia,
Italia, Inggris, Belanda, Perancis, dan negara-negara Eropa lainnya.
----------------------------------------------------------------------------------------------------------------------
Kalimat 3
----------------------------------------------------------------------------------------------------------------------
1
Bahkan negara-negara Newly Industrializing Economies (NIEs) yang sempat tertinggal secara ekonomi namun
kemudian dapat mengejar dan mempercepat pembangunan seperti China, Korea Selatan, dan Taiwan, sangat
bergantung pada apa yang disebut dengan knowledge-based economy (KBE).
----------------------------------------------------------------------------------------------------------------------
Kalimat 4
----------------------------------------------------------------------------------------------------------------------
Terlebih, negara-negara tersebut,
terutama Korea Selatan dan Taiwan, sangat minim akan bahan-bahan tambang atau sumber daya alam lainnya.
----------------------------------------------------------------------------------------------------------------------
Kalimat 5
----------------------------------------------------------------------------------------------------------------------
2
Berbagai studi telah menunjukkan bagaimana negara-negara maju dan juga NIEs memberikan prioritas kepada
pengembangan iptekin nasional guna mendorong aktivitas perekonomian di suatu negara.
----------------------------------------------------------------------------------------------------------------------
Kalimat 6
----------------------------------------------------------------------------------------------------------------------
Bahkan di antaranya juga
sudah mulai menekankan aspek sosial, kelembagaan, dan budaya yang mempengaruhi pengembangan iptekin
nasional.
----------------------------------------------------------------------------------------------------------------------
Kalimat 7
----------------------------------------------------------------------------------------------------------------------
3
Hal ini kemudian melahirkan berbagai konsep pengembangan iptekin secara komprehensif baik dari pendekatan
cakupan tujuan secara nasional yang kemudian disebut sistem inovasi nasional (SIN), dari pendekatan kedekatan
geografi (geography proximity) yang kemudian disebut sebagai sistem inovasi wilayah/daerah (SIDA), dari pendekatan
sektor tertentu yang kemudian disebut sebagai sistem inovasi sektoral (SIS), dan kemudian juga didekati dengan
aspek teknologi atau yang disebut sebagai technological innovation system (TIS).
----------------------------------------------------------------------------------------------------------------------
Kalimat 8
----------------------------------------------------------------------------------------------------------------------
4
Ilmu pengetahuan, teknologi, dan inovasi (Iptekin) adalah salah satu elemen kunci dalam mendorong dan
mempercepat pembangunan ekonomi di suatu negara.
----------------------------------------------------------------------------------------------------------------------
Kalimat 9
----------------------------------------------------------------------------------------------------------------------
5
Saat ini, diskursus terkait ekosistem inovasi juga meningkat seiring banyak cendekiawan yang menggagas dan
mendiskusikan hal tersebut baik di berbagai negara dan sektor.
----------------------------------------------------------------------------------------------------------------------
Kalimat 10
----------------------------------------------------------------------------------------------------------------------
6
Negara-negara berkembang juga tengah berupaya mengejar ketertinggalan ekonomi mereka melalui pendekatan
iptekin (technology catch-up) sejak tahun 1990-an.
----------------------------------------------------------------------------------------------------------------------
Kalimat 11
----------------------------------------------------------------------------------------------------------------------
Sejumlah upaya yang dilakukan termasuk di antaranya
mengembangkan berbagai konsep sistem inovasi sebagai bagian dari pengejaran dan akselerasi pembangunan
ekonomi dari negara-negara maju atau NIEs tersebut dengan memperhatikan berbagai aspek mulai ekonomi, sumber
daya alam, kebijakan pemerintah, organisasi/kelembagaan, sosial, dan aspek eksternal/lingkungan yang begitu luas
dan kompleks.
----------------------------------------------------------------------------------------------------------------------
Kalimat 12
----------------------------------------------------------------------------------------------------------------------
7
Tidak sedikit pula negara- negara sedang berkembang yang dalam implementasinya menemui banyak kendala
sehingga mengakibatkan akselerasi pengembangan iptekin di negaranya menjadi terhambat.
----------------------------------------------------------------------------------------------------------------------
Kalimat 13
----------------------------------------------------------------------------------------------------------------------
Akibatnya, KBE seringkali
menjadi tataran konsep di dalam dokumen-dokumen pemerintah atau hanya sebagai wacana yang disuarakan dari
tahun ke tahun.
----------------------------------------------------------------------------------------------------------------------
Kalimat 14
----------------------------------------------------------------------------------------------------------------------
8
Meniru secara langsung, mereplikasi, mengadaptasi, mengabsorbsi iptekin dan sistem inovasi dari negara-negara maju
atau negara-negara yang sudah berhasil menerapkan hal tersebut menjadi salah satu praktik terbaik yang dilakukan
oleh negara-negara sedang berkembang seperti halnya Indonesia.
----------------------------------------------------------------------------------------------------------------------
Kalimat 15
----------------------------------------------------------------------------------------------------------------------
9
Namun demikian, seringkali implementasi kebijakan tersebut tidaklah berjalan sesuai dengan rencana atau tidak
mencapai tujuan, karena seringkali apa yang dilihat dan dipraktikkan oleh negara-negara sedang berkembang memiliki
konteks dan konten yang berbeda.
----------------------------------------------------------------------------------------------------------------------
Kalimat 16
----------------------------------------------------------------------------------------------------------------------
10
Hal ini tentu memerlukan intervensi khusus dimana pemerintah menjadi salah satu aktor penting dalam
menumbuhkembangkan iptekin nasional baik dengan belajar dari negara-negara maju atau yang sudah berhasil,
maupun dengan cara mengembangkan kemampuan berdasar kekuatan dan sumber daya lokal yang dimiliki oleh
negara-negara tersebut.
----------------------------------------------------------------------------------------------------------------------
Kalimat 17
----------------------------------------------------------------------------------------------------------------------
(*)
----------------------------------------------------------------------------------------------------------------------
</pre></div>
</div>
</div>
</div>
</section>
<section id="memecah-kata">
<h3>Memecah Kata<a class="headerlink" href="#memecah-kata" title="Permalink to this headline">#</a></h3>
<p>Setelah dokumen terpecah menjadi beberapa kalimat, selanjutnya kita pecah lagi menjadi kata dengan library sklearn seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span><span class="p">,</span> <span class="n">CountVectorizer</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">cv_matrix</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">sentences_list</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Banyaknya kosa kata = &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">((</span><span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())),</span><span class="s1">&#39;kosa kata&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Banyaknya kosa kata =  242 kosa kata
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;kosa kata = &quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>kosa kata =  [&#39;10&#39; &#39;1990&#39; &#39;adalah&#39; &#39;akan&#39; &#39;akibatnya&#39; &#39;akselerasi&#39; &#39;aktivitas&#39; &#39;aktor&#39;
 &#39;alam&#39; &#39;amerika&#39; &#39;an&#39; &#39;and&#39; &#39;antaranya&#39; &#39;apa&#39; &#39;aspek&#39; &#39;atau&#39; &#39;austria&#39;
 &#39;bagaimana&#39; &#39;bagi&#39; &#39;bagian&#39; &#39;bahan&#39; &#39;bahasa&#39; &#39;bahkan&#39; &#39;baik&#39; &#39;banyak&#39;
 &#39;based&#39; &#39;begitu&#39; &#39;belajar&#39; &#39;belanda&#39; &#39;berbagai&#39; &#39;berbeda&#39; &#39;berdasar&#39;
 &#39;bergantung&#39; &#39;berhasil&#39; &#39;berjalan&#39; &#39;berkembang&#39; &#39;berupaya&#39; &#39;budaya&#39;
 &#39;cakupan&#39; &#39;cara&#39; &#39;catch&#39; &#39;cendekiawan&#39; &#39;china&#39; &#39;cooperation&#39; &#39;daerah&#39;
 &#39;dalam&#39; &#39;dan&#39; &#39;dapat&#39; &#39;dari&#39; &#39;daya&#39; &#39;demikian&#39; &#39;dengan&#39; &#39;development&#39;
 &#39;di&#39; &#39;didekati&#39; &#39;dilakukan&#39; &#39;dilihat&#39; &#39;dimana&#39; &#39;dimiliki&#39; &#39;dipraktikkan&#39;
 &#39;disebut&#39; &#39;diskursus&#39; &#39;disuarakan&#39; &#39;dokumen&#39; &#39;driver&#39; &#39;economics&#39;
 &#39;economies&#39; &#39;economy&#39; &#39;ekonomi&#39; &#39;ekosistem&#39; &#39;eksternal&#39; &#39;elemen&#39; &#39;eropa&#39;
 &#39;for&#39; &#39;geografi&#39; &#39;geography&#39; &#39;global&#39; &#39;guna&#39; &#39;hal&#39; &#39;halnya&#39; &#39;hanya&#39;
 &#39;ilmu&#39; &#39;implementasi&#39; &#39;implementasinya&#39; &#39;indonesia&#39; &#39;industrializing&#39;
 &#39;info&#39; &#39;inggris&#39; &#39;ini&#39; &#39;innovation&#39; &#39;inovasi&#39; &#39;intervensi&#39; &#39;iptekin&#39;
 &#39;italia&#39; &#39;juga&#39; &#39;karena&#39; &#39;kbe&#39; &#39;ke&#39; &#39;kebijakan&#39; &#39;kedekatan&#39; &#39;kekuatan&#39;
 &#39;kelembagaan&#39; &#39;kemampuan&#39; &#39;kemudian&#39; &#39;kendala&#39; &#39;kepada&#39; &#39;ketertinggalan&#39;
 &#39;key&#39; &#39;khusus&#39; &#39;knowledge&#39; &#39;kompleks&#39; &#39;komprehensif&#39; &#39;konsep&#39; &#39;konteks&#39;
 &#39;konten&#39; &#39;korea&#39; &#39;kunci&#39; &#39;lainnya&#39; &#39;langsung&#39; &#39;lingkungan&#39; &#39;lokal&#39; &#39;luas&#39;
 &#39;maju&#39; &#39;maupun&#39; &#39;melahirkan&#39; &#39;melalui&#39; &#39;memberikan&#39; &#39;memerlukan&#39;
 &#39;memiliki&#39; &#39;mempengaruhi&#39; &#39;mempercepat&#39; &#39;memperhatikan&#39; &#39;mencapai&#39;
 &#39;mendiskusikan&#39; &#39;mendorong&#39; &#39;menekankan&#39; &#39;menemui&#39; &#39;menerapkan&#39;
 &#39;mengabsorbsi&#39; &#39;mengadaptasi&#39; &#39;mengakibatkan&#39; &#39;mengejar&#39; &#39;mengembangkan&#39;
 &#39;menggagas&#39; &#39;meningkat&#39; &#39;meniru&#39; &#39;menjadi&#39; &#39;menumbuhkembangkan&#39;
 &#39;menunjukkan&#39; &#39;mereka&#39; &#39;mereplikasi&#39; &#39;minim&#39; &#39;mulai&#39; &#39;namun&#39; &#39;nasional&#39;
 &#39;negara&#39; &#39;negaranya&#39; &#39;newly&#39; &#39;news&#39; &#39;nies&#39; &#39;oecd&#39; &#39;oleh&#39; &#39;organisasi&#39;
 &#39;organization&#39; &#39;pada&#39; &#39;pembangunan&#39; &#39;pemerintah&#39; &#39;pendekatan&#39;
 &#39;pengejaran&#39; &#39;pengembangan&#39; &#39;pengetahuan&#39; &#39;penting&#39; &#39;perancis&#39;
 &#39;perekonomian&#39; &#39;praktik&#39; &#39;prioritas&#39; &#39;proximity&#39; &#39;pula&#39; &#39;rencana&#39; &#39;saat&#39;
 &#39;salah&#39; &#39;sangat&#39; &#39;satu&#39; &#39;science&#39; &#39;sebagai&#39; &#39;secara&#39; &#39;sedang&#39; &#39;sedikit&#39;
 &#39;sehingga&#39; &#39;seiring&#39; &#39;sejak&#39; &#39;sejumlah&#39; &#39;sektor&#39; &#39;sektoral&#39; &#39;selatan&#39;
 &#39;sempat&#39; &#39;seperti&#39; &#39;serikat&#39; &#39;seringkali&#39; &#39;sesuai&#39; &#39;sida&#39; &#39;sin&#39; &#39;sis&#39;
 &#39;sistem&#39; &#39;sosial&#39; &#39;sti&#39; &#39;studi&#39; &#39;suatu&#39; &#39;sudah&#39; &#39;sumber&#39; &#39;swedia&#39;
 &#39;system&#39; &#39;tahun&#39; &#39;taiwan&#39; &#39;tambang&#39; &#39;tataran&#39; &#39;technological&#39;
 &#39;technology&#39; &#39;tekno&#39; &#39;teknologi&#39; &#39;telah&#39; &#39;tengah&#39; &#39;tentu&#39; &#39;terbaik&#39;
 &#39;tergabung&#39; &#39;terhambat&#39; &#39;terkait&#39; &#39;terlebih&#39; &#39;termasuk&#39; &#39;tersebut&#39;
 &#39;tertentu&#39; &#39;tertinggal&#39; &#39;terutama&#39; &#39;tidak&#39; &#39;tidaklah&#39; &#39;tis&#39; &#39;tujuan&#39; &#39;up&#39;
 &#39;upaya&#39; &#39;wacana&#39; &#39;wilayah&#39; &#39;yang&#39;]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="membuat-matrik-tf-idf">
<h2><strong>Membuat Matrik TF-IDF</strong><a class="headerlink" href="#membuat-matrik-tf-idf" title="Permalink to this headline">#</a></h2>
<p>Setelah memecah dokumen menjadi beberapa kalimat dan kata, selanjutnya buat sebuah matrik VSM untuk membuat TF-IDF seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  (0, 158)	1
  (0, 86)	1
  (0, 218)	1
  (0, 81)	1
  (0, 170)	1
  (0, 219)	1
  (0, 46)	2
  (0, 90)	1
  (0, 92)	1
  (0, 2)	1
  (0, 180)	1
  (0, 182)	1
  (0, 71)	1
  (0, 116)	1
  (0, 45)	1
  (0, 134)	1
  (0, 130)	1
  (0, 165)	1
  (0, 68)	1
  (0, 53)	1
  (0, 207)	1
  (0, 155)	1
  (1, 46)	1
  (1, 92)	1
  (1, 45)	2
  :	:
  (15, 78)	1
  (15, 88)	1
  (15, 23)	1
  (15, 48)	1
  (15, 142)	1
  (15, 166)	1
  (15, 33)	1
  (15, 161)	1
  (15, 0)	1
  (15, 222)	1
  (15, 127)	1
  (15, 91)	1
  (15, 108)	1
  (15, 57)	1
  (15, 7)	1
  (15, 171)	1
  (15, 147)	1
  (15, 27)	1
  (15, 123)	1
  (15, 39)	1
  (15, 102)	1
  (15, 31)	1
  (15, 100)	1
  (15, 120)	1
  (15, 58)	1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">normal_matrix</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">normal_matrix</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[0.         0.         0.24039265 ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.14208618]
 [0.         0.         0.         ... 0.         0.         0.17222078]
 ...
 [0.         0.         0.         ... 0.         0.         0.1735011 ]
 [0.17545081 0.         0.         ... 0.         0.         0.15425253]
 [0.         0.         0.         ... 0.         0.         0.        ]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="membuat-graph">
<h2><strong>Membuat Graph</strong><a class="headerlink" href="#membuat-graph" title="Permalink to this headline">#</a></h2>
<p>Setelah matrik TF-IDF terbentuk, selanjutnya buat graph berdasarkan dari matrik tersebut dengan library networkx seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">normal_matrix</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">toarray</span><span class="p">)</span>
<span class="n">res_graph</span> <span class="o">=</span> <span class="n">normal_matrix</span> <span class="o">*</span> <span class="n">normal_matrix</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;bound method _cs_matrix.toarray of &lt;242x17 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;
	with 441 stored elements in Compressed Sparse Column format&gt;&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nx_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_scipy_sparse_matrix</span><span class="p">(</span><span class="n">res_graph</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nx</span><span class="o">.</span><span class="n">draw_circular</span><span class="p">(</span><span class="n">nx_graph</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/crawling_143_0.png" src="_images/crawling_143_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Banyaknya sisi </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">number_of_edges</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Banyaknya sisi 136
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">normal_matrix</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(17, 242)
</pre></div>
</div>
</div>
</div>
</section>
<section id="menghitung-pagerank">
<h2><strong>Menghitung PageRank</strong><a class="headerlink" href="#menghitung-pagerank" title="Permalink to this headline">#</a></h2>
<p>Setelah terbentuk graph, selanjutnya hitung nilai pagerank dari masing-masing kalimat dengan source code di bawah ini. Pengertian PageRank sendiri ialah algoritma otoritas tautan yang dibuat oleh Google. Ini berguna untuk membantu mesin telusur membandingkan halaman yang memenuhi syarat untuk kueri tertentu berdasarkan seberapa sering mereka direferensikan berupa tautan di halaman situs lain.<br></p>
<center><img src='https://upload.wikimedia.org/wikipedia/commons/thumb/f/fb/PageRanks-Example.svg/330px-PageRanks-Example.svg.png'></center><center>Gambar PageRank</center><br>PageRank merupakan istilah untuk mengambarkan skor situs berdasarkan kalkulasi dari kuantitas dan kualitas tautan masuk. Ini dilakukan algoritma Google sebagai salah satu faktor penentu peringkat sebuah website.<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ranks</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">pagerank</span><span class="p">(</span><span class="n">nx_graph</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">rangking</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">:</span>
  <span class="n">m</span> <span class="o">=</span> <span class="n">ranks</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="s1">&#39;Kalimat ke&#39;</span><span class="p">,</span><span class="n">n</span>
  <span class="n">rangking</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Kalimat&#39;</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="s1">&#39;:&#39;</span><span class="p">,</span><span class="n">ranks</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
  <span class="n">n</span> <span class="o">=</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Kalimat 1 : 0.06908468250500893
Kalimat 2 : 0.06254658327467967
Kalimat 3 : 0.06313036494382007
Kalimat 4 : 0.05107416704185665
Kalimat 5 : 0.06189651471735026
Kalimat 6 : 0.05495324698876229
Kalimat 7 : 0.060570700433527774
Kalimat 8 : 0.07258194210455156
Kalimat 9 : 0.057371902749834544
Kalimat 10 : 0.05167534273727485
Kalimat 11 : 0.07439877852826626
Kalimat 12 : 0.05718939803656092
Kalimat 13 : 0.049668502087235264
Kalimat 14 : 0.07692670544992392
Kalimat 15 : 0.057259034660847447
Kalimat 16 : 0.07038420804390487
Kalimat 17 : 0.009287925696594672
</pre></div>
</div>
</div>
</div>
<p>Setelah nilai pagerank didapatkan, selanjutnya kita rangking nilai pagerank tersebut dari nilai yang paling tinggi seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rangking</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">rangking</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(0.07692670544992392, &#39;Kalimat ke&#39;, 14),
 (0.07439877852826626, &#39;Kalimat ke&#39;, 11),
 (0.07258194210455156, &#39;Kalimat ke&#39;, 8),
 (0.07038420804390487, &#39;Kalimat ke&#39;, 16),
 (0.06908468250500893, &#39;Kalimat ke&#39;, 1),
 (0.06313036494382007, &#39;Kalimat ke&#39;, 3),
 (0.06254658327467967, &#39;Kalimat ke&#39;, 2),
 (0.06189651471735026, &#39;Kalimat ke&#39;, 5),
 (0.060570700433527774, &#39;Kalimat ke&#39;, 7),
 (0.057371902749834544, &#39;Kalimat ke&#39;, 9),
 (0.057259034660847447, &#39;Kalimat ke&#39;, 15),
 (0.05718939803656092, &#39;Kalimat ke&#39;, 12),
 (0.05495324698876229, &#39;Kalimat ke&#39;, 6),
 (0.05167534273727485, &#39;Kalimat ke&#39;, 10),
 (0.05107416704185665, &#39;Kalimat ke&#39;, 4),
 (0.049668502087235264, &#39;Kalimat ke&#39;, 13),
 (0.009287925696594672, &#39;Kalimat ke&#39;, 17)]
</pre></div>
</div>
</div>
</div>
</section>
<section id="memilih-kalimat">
<h2><strong>Memilih Kalimat</strong><a class="headerlink" href="#memilih-kalimat" title="Permalink to this headline">#</a></h2>
<p>Setelah didapatkan kalimat yang memiliki nilai pagerank tertinggi, selanjutnya pilih kalimat yang memiliki nilai pagerank tertinggi, dari data dapat dilihat bahwa kalimat ke-14,11,8,16 dan seterusnya memiliki nilai pagerank dari yang paling tinggi hingga rendah.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">sentences_list</span><span class="p">[</span><span class="mi">13</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sentences_list</span><span class="p">[</span><span class="mi">10</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sentences_list</span><span class="p">[</span><span class="mi">7</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sentences_list</span><span class="p">[</span><span class="mi">15</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>8
Meniru secara langsung, mereplikasi, mengadaptasi, mengabsorbsi iptekin dan sistem inovasi dari negara-negara maju
atau negara-negara yang sudah berhasil menerapkan hal tersebut menjadi salah satu praktik terbaik yang dilakukan
oleh negara-negara sedang berkembang seperti halnya Indonesia.
Sejumlah upaya yang dilakukan termasuk di antaranya
mengembangkan berbagai konsep sistem inovasi sebagai bagian dari pengejaran dan akselerasi pembangunan
ekonomi dari negara-negara maju atau NIEs tersebut dengan memperhatikan berbagai aspek mulai ekonomi, sumber
daya alam, kebijakan pemerintah, organisasi/kelembagaan, sosial, dan aspek eksternal/lingkungan yang begitu luas
dan kompleks.
4
Ilmu pengetahuan, teknologi, dan inovasi (Iptekin) adalah salah satu elemen kunci dalam mendorong dan
mempercepat pembangunan ekonomi di suatu negara.
10
Hal ini tentu memerlukan intervensi khusus dimana pemerintah menjadi salah satu aktor penting dalam
menumbuhkembangkan iptekin nasional baik dengan belajar dari negara-negara maju atau yang sudah berhasil,
maupun dengan cara mengembangkan kemampuan berdasar kekuatan dan sumber daya lokal yang dimiliki oleh
negara-negara tersebut.
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h2><strong>Kesimpulan</strong><a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h2>
<p>Berdasar dari tahapan-tahapan yang dilakukan dapat disimpulkan bahwa ringkasan atau simpulan dokumen yang didapat ialah “Meniru secara langsung, mereplikasi, mengadaptasi, mengabsorbsi iptekin dan sistem inovasi dari negara-negara maju atau negara-negara yang sudah berhasil menerapkan hal tersebut menjadi salah satu praktik terbaik yang dilakukan oleh negara-negara sedang berkembang seperti halnya Indonesia. Sejumlah upaya yang dilakukan termasuk di antaranya
mengembangkan berbagai konsep sistem inovasi sebagai bagian dari pengejaran dan akselerasi pembangunan ekonomi dari negara-negara maju atau NIEs tersebut dengan memperhatikan berbagai aspek mulai ekonomi, sumber daya alam, kebijakan pemerintah, organisasi/kelembagaan, sosial, dan aspek eksternal/lingkungan yang begitu luas
dan kompleks.Ilmu pengetahuan, teknologi, dan inovasi (Iptekin) adalah salah satu elemen kunci dalam mendorong dan mempercepat pembangunan ekonomi di suatu negara.Hal ini tentu memerlukan intervensi khusus dimana pemerintah menjadi salah satu aktor penting dalam menumbuhkembangkan iptekin nasional baik dengan belajar dari negara-negara maju atau yang sudah berhasil, maupun dengan cara mengembangkan kemampuan berdasar kekuatan dan sumber daya lokal yang dimiliki oleh negara-negara tersebut.” Ringkasan tersebut diperoleh dari 4 data kalimat yang memiliki nilai pagerank tertinggi.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="uts-web-mining">
<h1>UTS WEB Mining<a class="headerlink" href="#uts-web-mining" title="Permalink to this headline">#</a></h1>
<ol class="simple">
<li><p>Lakukan analisa clustering dengan menggunakan k-mean clustering pada data twitter denga kunci pencarian ” tragedi kanjuruhan”<br></p></li>
<li><p>Lakukan peringkasan dokumen dari berita online ( link berita bebas) menggunakan metode pagerank</p></li>
</ol>
<section id="clustering-tragedi-kanjuruhan">
<h2><strong>1. Clustering Tragedi Kanjuruhan</strong><a class="headerlink" href="#clustering-tragedi-kanjuruhan" title="Permalink to this headline">#</a></h2>
<p>Klustering data merupakan salah satu teknik dari Web Mining, yang mana clustering digunakan untuk pengelompokkan data berdasarkan kemiripan pada objek data dan sebaliknya meminimalkan kemiripan terhadap kluster yang lain. Untuk dapat melakukan clustering lakukan proses berikut.</p>
<section id="id3">
<h3><strong>Praprepocessing Text</strong><a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h3>
<p>Proses ini merupakan proses awal sebelum melakukan proses prepocessing text, yaitu proses untuk mendapatkan dataset yang akan digunakan untuk proses prepocessing, yang mana dataset yang akan digunakan diambil dari website dengan melakukan crawling pada website.</p>
<section id="id4">
<h4>Crawling Tweeter<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h4>
<p>Crawling merupakan suatu proses pengambilan data dengan menggunakan mesin yang dilakukan secara online. Proses ini dilakukan untuk mengimpor data yang ditemukan kedalam file lokal komputer. Kemudian data yang telah di impor tersebut akan dilakukan tahap prepocessing text. Pada proses crawling kali ini dilakukan crawling data pada twitter dengan menggunakan tools Twint.</p>
</section>
<section id="id5">
<h4>Installasi Twint<a class="headerlink" href="#id5" title="Permalink to this headline">#</a></h4>
<p>Twint merupakan sebuah tools yang digunakan untuk dapat melakukan scraping data dari media sosial yaitu twitter dengan menggunakan bahasa pemrograman python. Twint dapat dijalankan tanpa harus menggunakan API twitter itu sendiri, namun kapasitas scrapingnya dibatasi sebanyak 3200 tweet.</p>
<p>Twint tidak hanya digunakan untuk mengambil data tweet, twint juga bisa digunakan untuk mengambil data user, follower, retweet, dan sejenisnya. Twint memanfaatkan operator pencarian twitter yang digunakan untuk memilih dan memilah informasi yang sensitif, termasuk email dan nomor telepon di dalamnya.</p>
<p>Proses installasi Twint dapat dilakukan dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>git clone --depth<span class="o">=</span><span class="m">1</span> https://github.com/twintproject/twint.git
<span class="o">%</span><span class="k">cd</span> twint
<span class="o">!</span>pip3 install . -r requirements.txt
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cloning into &#39;twint&#39;...
remote: Enumerating objects: 47, done.
remote: Counting objects: 100% (47/47), done.
remote: Compressing objects: 100% (44/44), done.
remote: Total 47 (delta 3), reused 14 (delta 0), pack-reused 0
Unpacking objects: 100% (47/47), done.
/content/twint
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Processing /content/twint
<span class=" -Color -Color-Yellow">  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.</span>
<span class=" -Color -Color-Yellow">   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.</span>
Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (3.8.3)
Collecting aiodns
  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)
Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (4.6.3)
Collecting cchardet
  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)
     |████████████████████████████████| 263 kB 5.1 MB/s 
?25hCollecting dataclasses
  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)
Collecting elasticsearch
  Downloading elasticsearch-8.4.3-py3-none-any.whl (384 kB)
     |████████████████████████████████| 384 kB 43.8 MB/s 
?25hRequirement already satisfied: pysocks in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.7.1)
Requirement already satisfied: pandas&gt;=0.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.3.5)
Collecting aiohttp_socks&lt;=0.4.1
  Downloading aiohttp_socks-0.4.1-py3-none-any.whl (17 kB)
Collecting schedule
  Downloading schedule-1.1.0-py2.py3-none-any.whl (10 kB)
Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.17.0)
Collecting fake-useragent
  Downloading fake-useragent-0.1.11.tar.gz (13 kB)
Collecting googletransx
  Downloading googletransx-2.4.2.tar.gz (13 kB)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.23.0-&gt;-r requirements.txt (line 8)) (2.8.2)
Requirement already satisfied: numpy&gt;=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.23.0-&gt;-r requirements.txt (line 8)) (1.21.6)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.23.0-&gt;-r requirements.txt (line 8)) (2022.4)
Requirement already satisfied: attrs&gt;=19.2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp_socks&lt;=0.4.1-&gt;-r requirements.txt (line 9)) (22.1.0)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (1.8.1)
Requirement already satisfied: charset-normalizer&lt;3.0,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (2.1.1)
Requirement already satisfied: typing-extensions&gt;=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (4.1.1)
Requirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (1.3.1)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (6.0.2)
Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (4.0.2)
Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (0.13.0)
Requirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (1.2.0)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=0.23.0-&gt;-r requirements.txt (line 8)) (1.15.0)
Requirement already satisfied: idna&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp-&gt;-r requirements.txt (line 1)) (2.10)
Collecting pycares&gt;=4.0.0
  Downloading pycares-4.2.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)
     |████████████████████████████████| 288 kB 51.8 MB/s 
?25hRequirement already satisfied: cffi&gt;=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pycares&gt;=4.0.0-&gt;aiodns-&gt;-r requirements.txt (line 2)) (1.15.1)
Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi&gt;=1.5.0-&gt;pycares&gt;=4.0.0-&gt;aiodns-&gt;-r requirements.txt (line 2)) (2.21)
Collecting elastic-transport&lt;9,&gt;=8
  Downloading elastic_transport-8.4.0-py3-none-any.whl (59 kB)
     |████████████████████████████████| 59 kB 6.6 MB/s 
?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elastic-transport&lt;9,&gt;=8-&gt;elasticsearch-&gt;-r requirements.txt (line 6)) (2022.9.24)
Collecting urllib3&lt;2,&gt;=1.26.2
  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)
     |████████████████████████████████| 140 kB 47.4 MB/s 
?25hRequirement already satisfied: geographiclib&lt;2,&gt;=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy-&gt;-r requirements.txt (line 11)) (1.52)
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from googletransx-&gt;-r requirements.txt (line 13)) (2.23.0)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;googletransx-&gt;-r requirements.txt (line 13)) (3.0.4)
Collecting requests
  Downloading requests-2.28.1-py3-none-any.whl (62 kB)
     |████████████████████████████████| 62 kB 820 kB/s 
?25hBuilding wheels for collected packages: twint, fake-useragent, googletransx
  Building wheel for twint (setup.py) ... ?25l?25hdone
  Created wheel for twint: filename=twint-2.1.21-py3-none-any.whl size=38871 sha256=9d0de8a8dec4c723d0312e10cc944eb76decd02eec673c9d618623b62d006e4b
  Stored in directory: /tmp/pip-ephem-wheel-cache-gm75xyxs/wheels/f7/3e/11/2803f3c6890e87a9bec35bb8e37ef1ad0777a00f43e2441fb1
  Building wheel for fake-useragent (setup.py) ... ?25l?25hdone
  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=7f242c1355d4e9b2d81f872e4303ba81bbe54b1ba805800a9554d133c6a6ea2b
  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031
  Building wheel for googletransx (setup.py) ... ?25l?25hdone
  Created wheel for googletransx: filename=googletransx-2.4.2-py3-none-any.whl size=15968 sha256=a1f8d3e7ba9c2f4b583d7a71a6eba180f962e20f0116a92e3b29c124e42b0331
  Stored in directory: /root/.cache/pip/wheels/66/d5/b1/31104b338f7fd45aa8f7d22587765db06773b13df48a89735f
Successfully built twint fake-useragent googletransx
Installing collected packages: urllib3, requests, pycares, elastic-transport, schedule, googletransx, fake-useragent, elasticsearch, dataclasses, cchardet, aiohttp-socks, aiodns, twint
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.3
    Uninstalling urllib3-1.24.3:
      Successfully uninstalled urllib3-1.24.3
  Attempting uninstall: requests
    Found existing installation: requests 2.23.0
    Uninstalling requests-2.23.0:
      Successfully uninstalled requests-2.23.0
Successfully installed aiodns-3.0.0 aiohttp-socks-0.4.1 cchardet-2.1.7 dataclasses-0.6 elastic-transport-8.4.0 elasticsearch-8.4.3 fake-useragent-0.1.11 googletransx-2.4.2 pycares-4.2.2 requests-2.28.1 schedule-1.1.0 twint-2.1.21 urllib3-1.26.12
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install nest-asyncio
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting nest-asyncio
  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)
Installing collected packages: nest-asyncio
Successfully installed nest-asyncio-1.5.6
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install <span class="nv">aiohttp</span><span class="o">==</span><span class="m">3</span>.7.0
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting aiohttp==3.7.0
  Downloading aiohttp-3.7.0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)
     |████████████████████████████████| 1.3 MB 4.9 MB/s 
?25hRequirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (6.0.2)
Collecting async-timeout&lt;4.0,&gt;=3.0
  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (1.8.1)
Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (22.1.0)
Requirement already satisfied: chardet&lt;4.0,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (3.0.4)
Requirement already satisfied: idna&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp==3.7.0) (2.10)
Requirement already satisfied: typing-extensions&gt;=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp==3.7.0) (4.1.1)
Installing collected packages: async-timeout, aiohttp
  Attempting uninstall: async-timeout
    Found existing installation: async-timeout 4.0.2
    Uninstalling async-timeout-4.0.2:
      Successfully uninstalled async-timeout-4.0.2
  Attempting uninstall: aiohttp
    Found existing installation: aiohttp 3.8.3
    Uninstalling aiohttp-3.8.3:
      Successfully uninstalled aiohttp-3.8.3
Successfully installed aiohttp-3.7.0 async-timeout-3.0.1
</pre></div>
</div>
</div>
</div>
</section>
<section id="id6">
<h4>Scraping Data Tweeter<a class="headerlink" href="#id6" title="Permalink to this headline">#</a></h4>
<p>Setelah proses installasi Twint berhasil selanjutnya lakukan scraping data tweeter. Scraping sendiri merupakan proses pengambilan data dari website. Untuk melakukan proses scraping data dari tweeter, tinggal import twint untuk melakukan scraping data tweeter dengan tweet yang mengandung kata “#rockygerung” dengan limit 100 menggunakan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nest_asyncio</span>
<span class="n">nest_asyncio</span><span class="o">.</span><span class="n">apply</span><span class="p">()</span> <span class="c1">#digunakan sekali untuk mengaktifkan tindakan serentak dalam notebook jupyter.</span>
<span class="kn">import</span> <span class="nn">twint</span> <span class="c1">#untuk import twint</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">twint</span><span class="o">.</span><span class="n">Config</span><span class="p">()</span>
<span class="n">c</span><span class="o">.</span><span class="n">Search</span> <span class="o">=</span> <span class="s1">&#39;tragedi kanjuruhan&#39;</span>
<span class="n">c</span><span class="o">.</span><span class="n">Lang</span> <span class="o">=</span> <span class="s2">&quot;in&quot;</span>
<span class="n">c</span><span class="o">.</span><span class="n">Pandas</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">c</span><span class="o">.</span><span class="n">Limit</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">twint</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">Search</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1581847719265591302 2022-10-17 03:21:00 +0000 &lt;IDNdihatiku&gt; Pemerintah pastikan Piala Dunia U-20 tetap digelar di Indonesia. Hal tersebut disampaikan oleh Ketua Tim Gabungan Independen Pencari Fakta (TGIPF) Tragedi Kanjuruhan, Mahfud Md.  Pemalang Kehilangan 50 MEGAPIXEL #PanglimaSantriUntukNegeri #ไบร์ทวิน #JokowiPresidenku #JokowiHebat  https://t.co/uF41BMdARC
1581847467716247553 2022-10-17 03:20:00 +0000 &lt;rakyatkuatt&gt; Pemerintah pastikan Piala Dunia U-20 tetap digelar di Indonesia. Hal tersebut disampaikan oleh Ketua Tim Gabungan Independen Pencari Fakta (TGIPF) Tragedi Kanjuruhan, Mahfud Md.  Pemalang Kehilangan 50 MEGAPIXEL #PanglimaSantriUntukNegeri #ไบร์ทวิน #JokowiPresidenku #JokowiHebat  https://t.co/eeP9HPPkes
1581847101642002433 2022-10-17 03:18:32 +0000 &lt;Beritabaruco&gt; 43 Anak Jadi Korban dalam Tragedi Kanjuruhan  https://t.co/R6DbxPHU6r #KementerianPPPA #KorbanTragediKanjuruhan #TragediKanjuruhan  https://t.co/qseUMC5EwQ
1581846928949903360 2022-10-17 03:17:51 +0000 &lt;Nada_Mayor&gt; Saya percaya mas nya bukan orang sembarangan. Mas nya tahu nggak detail semua yg terjadi wkt tragedi di kanjuruhan, sebelum kick off sampai tragedi itu selesai terjadi?
1581846478708170752 2022-10-17 03:16:04 +0000 &lt;VIVAcoid&gt; Janji Aremania Kawal Terus Tragedi Kanjuruhan Hingga Raih Keadilan  https://t.co/L57uNnKchW  https://t.co/QNLUKrlqAL
1581846455803084800 2022-10-17 03:15:59 +0000 &lt;JustHanif01&gt; Belum usai ! Jokowi beri perintah Polri lanjutkan pendalaman temuan TGIPF terhadap tragedi Kanjuruhan.  El Rumi | Kate | #OCTOPOP2022  https://t.co/zEqsfz3kk8
1581846409435041793 2022-10-17 03:15:47 +0000 &lt;Darma2711&gt; Presiden harus ambil langkah konkret sikapi rekomendasi TGIPF tragedi Kanjuruhan. #DemokratBersamaRakyat AHY Pemimpin Perubahan  https://t.co/AvjokHwviS
1581845586684555264 2022-10-17 03:12:31 +0000 &lt;korantempo&gt; Dokumen TGIPF secara jelas menyebutkan sejumlah nama yang harus bertanggung jawab dalam tragedi Kanjuruhan.   #KoranTempo  https://t.co/0L9mi8dOy7
1581845169015779328 2022-10-17 03:10:52 +0000 &lt;whereyouatluna&gt; kabar kedua dr kelanjutan investigasi tragedi kanjuruhan &amp;amp; so far w pribadi cukup puas dg hasilnya. w tau w nyaris gak bs berbuat banyak utk kasus ini. w cm butuh keadilan buat keluarga korban. jd, kalau polisi &amp;amp; pssi msh punya malu, ya udahlah cepet tanggung jawab!  https://t.co/cAqcJqLSza
1581844891465748480 2022-10-17 03:09:46 +0000 &lt;CarditoDewi&gt; Buntut Tragedi Kanjuruhan, Jokowi instruksikan seluruh stadion di Indonesia di-upgrade menjadi lebih aman dan nyaman, demi keselamatan dan kenyamanan para penonton sepak bola.  Kate | El Rumi | #UnderTheQueensUmbrellaEp2  https://t.co/yTrElD45YN
1581844711622725634 2022-10-17 03:09:03 +0000 &lt;korantempo&gt; Dokumen TGIPF menyebutkan sejumlah nama yang harus bertanggung jawab dalam tragedi Kanjuruhan.   Simak edisi terbaru #KoranTempo, klik  https://t.co/JSPrmxFxEM  https://t.co/cXntmzkhwE
1581844497293377536 2022-10-17 03:08:12 +0000 &lt;jarangmandilah&gt; @seveiira Baguss kakk, posternya sangat informatif, saya langsung semangat ikut mengusut kasus tragedi kanjuruhan✊🏻✊🏻✊🏻✊🏻
1581843808253190145 2022-10-17 03:05:27 +0000 &lt;volkpop&gt; Minggu ini Polri Gelar Rekonstruksi Tragedi Kanjuruhan dan Autopsi 2 Jenazah Korban  https://t.co/TB8E6cqTq6
1581842955542835201 2022-10-17 03:02:04 +0000 &lt;politikamalang&gt; KAHMI Forum Bahas Tragedi Kemanusiaan Stadion Kanjuruhan  https://t.co/vnlKDas8QJ
1581842702324273152 2022-10-17 03:01:04 +0000 &lt;musofaibrahim01&gt; @MafiaWasit Mbah soal tragedi kanjuruhan gimana? 😢
1581841802268508162 2022-10-17 02:57:29 +0000 &lt;PemkotMalang&gt; Wali Kota Sutiaji dalam Gala Dinner di Balaikota Malang, Minggu (17/10/22) yang dihadiri pemain, ofisial, perangkat pertandingan dan panitia menambahkan bahwa kesuksesan turnamen turut menjadi suntikan moril pasca tragedi Kanjuruhan yang lukanya dirasakan masyarakat luas.  https://t.co/iSyyRSj4Ra
1581840941320503296 2022-10-17 02:54:04 +0000 &lt;bb_sports_id&gt; Tanggapi Rekomendasi KLB PSSI, Umuh Muchtar Bilang Jangan Dulu, Ini Alasannya  https://t.co/Gza2GOv0oz baca juga berita dari media lainnya di Indonesia di  https://t.co/GkwQxRUMd1   #persibbandung #pssi #umuhmuchtar #ligaindonesia #liga1 #tragedikanjuruhan #tgipftragedikanjuruhan
1581840604983500802 2022-10-17 02:52:44 +0000 &lt;lelysuwatalbes4&gt; ini Adalah sebuah Tindakan Yg Sangat&quot;Tdk Manusiawi, Jika Kalian Berani Wahai Aparat Keamanan, pergi saja ke papua dan LAwanlah Kelompok Kriminal Bersenjata(Kkb)disana, Bertindaklah Yg Wajar Terhadap RAKYAT, karna RAKYATlah,Kalian di HORMATI.  #TragediKanjuruhan  https://t.co/Y2mjDtHyym
1581840276104286208 2022-10-17 02:51:25 +0000 &lt;NAWACITAPOST1&gt; Terkait Tragedi Kanjuruhan Bupati Jember : Alhamdulillah Sekarang Ditangani Dengan Baik  https://t.co/wSsXBj7RBQ
1581839687370477568 2022-10-17 02:49:05 +0000 &lt;AdatahRedaksi&gt; Rekomendasi TGIPF, Tragedi Kanjuruhan Periksa 16 Orang Saksi Tambahan  https://t.co/OcTEidZi5D
1581839239733399553 2022-10-17 02:47:18 +0000 &lt;triomacan2000ba&gt; Buntut Tragedi Kanjuruhan, Pegiat Olahraga Minta Sepakbola Indonesia Evaluasi Menyeluruh Termasuk Suporter agar Hormati Ketertiban  https://t.co/zwO2Lwus7k
1581839229382184960 2022-10-17 02:47:16 +0000 &lt;smaliska2001&gt; Buntut Tragedi Kanjuruhan, Pegiat Olahraga Minta Sepakbola Indonesia Evaluasi Menyeluruh Termasuk Suporter agar Hormati Ketertiban  https://t.co/X8wE0OyMlF
1581839219957567490 2022-10-17 02:47:13 +0000 &lt;revolusi_news&gt; Buntut Tragedi Kanjuruhan, Pegiat Olahraga Minta Sepakbola Indonesia Evaluasi Menyeluruh Termasuk Suporter agar Hormati Ketertiban  https://t.co/pnAgB8wLB7
1581839211518304257 2022-10-17 02:47:11 +0000 &lt;indowarta1&gt; Buntut Tragedi Kanjuruhan, Pegiat Olahraga Minta Sepakbola Indonesia Evaluasi Menyeluruh Termasuk Suporter agar Hormati Ketertiban  https://t.co/ilNgg5y6Fr
1581839201997160448 2022-10-17 02:47:09 +0000 &lt;TribunRakyat&gt; Buntut Tragedi Kanjuruhan, Pegiat Olahraga Minta Sepakbola Indonesia Evaluasi Menyeluruh Termasuk Suporter agar Hormati Ketertiban  https://t.co/prRSSt0vy4
1581839113346371584 2022-10-17 02:46:48 +0000 &lt;ilsnews_id&gt; Terkait Tragedi Kanjuruhan Bupati Jember : Alhamdulillah Sekarang Ditangani Dengan Baik  https://t.co/JI2AlRySm4  https://t.co/TTia71sOhi
1581839070128312321 2022-10-17 02:46:38 +0000 &lt;most1058&gt; Kementerian PPPA mengatakan jumlah anak yang menjadi korban meninggal dunia dalam tragedi di Stadion Kanjuruhan, menjadi 43 anak. #MostUpdate1058
1581839016302821378 2022-10-17 02:46:25 +0000 &lt;kompascom&gt; Komisi untuk Orang Hilang dan Korban Tindak Kekerasan (Kontras) yang mendampingi Tim Pencari Fakta (TPF) Aremania menemukan adanya intimidasi dari pihak aparat terhadap korban dan keluarga korban tragedi Stadion kanjuruhan.   Baca selengkapnya di sini:  https://t.co/W8KpN3k7QW  https://t.co/IQaivkFbwk
1581838088266952706 2022-10-17 02:42:44 +0000 &lt;NewscakraGroup&gt; Terkait Tragedi Kanjuruhan Bupati Jember : Alhamdulillah Sekarang Ditangani Dengan Baik  https://t.co/XGZbzqJnEJ
1581837936211136512 2022-10-17 02:42:07 +0000 &lt;jagabalicom&gt; Terkait Tragedi Kanjuruhan Bupati Jember : Alhamdulillah Sekarang Ditangani Dengan Baik  https://t.co/y9rxglPRrO
1581837851091931137 2022-10-17 02:41:47 +0000 &lt;jagabalicom&gt; Terkait Tragedi Kanjuruhan Bupati Jember : Alhamdulillah Sekarang Ditangani Dengan Baik  https://t.co/EMFvtEXWSj
1581837666189877248 2022-10-17 02:41:03 +0000 &lt;hariankompas&gt; Tragedi Kanjuruhan dengan gamblang menunjukkan bahwa kita adalah bangsa yang kalah.  Kejadian ini harus bisa dijadikan momentum untuk melakukan kebangkitan bangsa. #Opini #AdadiKompas   https://t.co/db7MdFYX7Q
1581837130011406336 2022-10-17 02:38:55 +0000 &lt;kabarhit&gt; Terkait Tragedi Kanjuruhan Bupati Jember : Alhamdulillah Sekarang Ditangani Dengan Baik  https://t.co/9YtOjODnq4 lewat @KABARHIT_COM
1581835545034260481 2022-10-17 02:32:37 +0000 &lt;RepelitaO&gt; Onlineindo News: Alvin Lim Sebut Tragedi Kanjuruhan Didalangi Konso...  https://t.co/J5dodOqOio
1581835541389012998 2022-10-17 02:32:36 +0000 &lt;Mmc99934673&gt; Terkait Tragedi Kanjuruhan Bupati Jember : Alhamdulillah Sekarang Ditangani Dengan Baik  https://t.co/DYHA2bKjHX
1581835536267767809 2022-10-17 02:32:35 +0000 &lt;transbjn&gt; Terkait Tragedi Kanjuruhan Bupati Jember : Alhamdulillah Sekarang Ditangani Dengan Baik  https://t.co/crE2zfL80I
1581834621557538817 2022-10-17 02:28:57 +0000 &lt;fendy_sapt&gt; Rekomendasi Tim Gabungan Independen Pencari Fakta (TGIPF) Tragedi Kanjuruhan..&quot;Sekarang tugas publuk adalah mengawasi rekomendasi-rekomendasi itu agar dijalankan&quot; ujar Akmal Marhali, anggota TGIPF Tragedi Kanjuruhan  https://t.co/4OqUmjxRam
1581834072271114240 2022-10-17 02:26:46 +0000 &lt;BVOICE_RADIO&gt; Polri menjadwalkan rekontruksi ulang tragedi Kanjuruhan. Hal ini dibutuhkan dalam rangka proses pembuktian agar cepat ditemukan permulaan tragedi tersebut. #MorningVoice
1581832479874650112 2022-10-17 02:20:26 +0000 &lt;MilatiAristy&gt; TRAGEDI KANJURUHAN SEGERA TERUNGKAP, TEMUAN TGIPF AKAN DISAMPAIKAN KEPADA PRESIDEN FIFA  #GOJO1KPARTY  Kehilangan 50 MEGAPIXEL Senin Pemalang Morninggg Drake  https://t.co/awtfkY4Ojx
1581831880516964352 2022-10-17 02:18:03 +0000 &lt;Reborn21s&gt; Hanya cairan haram 💉 yg dpt mempersatukan Bong-drun.  Mreka spakat tragedi kanjuruhan itu pembantaian, smentara korban 💉mereka katakan takdir  Mreka spakat diskriminasi adalah dzolim smentara aturan diskriminasi terhadap yg menolak vaksin mereka katakan salah mereka sendiri 🤦
1581831512256704513 2022-10-17 02:16:36 +0000 &lt;kris_simpati&gt; detikSport: &#39;TGIPF Tragedi Kanjuruhan Jangan Buru-buru Bubar&#39;.  https://t.co/vSa6lBOCC8  melalui @GoogleNews
1581831128301719553 2022-10-17 02:15:04 +0000 &lt;jpnncom&gt; PSM Makassar memilih meliburkan pemain karena kompetisi Liga 1 2022-2023 belum ada kepastian pasca-tragedi di Stadion Kanjuruhan, Malang. #PSMMakassar  https://t.co/wMSpkAKlPz
1581830929588240390 2022-10-17 02:14:17 +0000 &lt;IwanIwe&gt; Media seharusnya berpijak dan memihak kebenaran. Ya, kebanyakan fakta-fakta yang diangkat media dalam tragedi kanjuruhan memang benar. Tapi framing-framing tertentu sehingga menghilangkan beberapa fakta di lapangan semestinya dikritisi.
1581830746536222721 2022-10-17 02:13:33 +0000 &lt;UkanIbrahim&gt; INSTITUSI POLRI PERLU DI ROMBAK TOTAL  Citra polisi di ujung tanduk! Belum usai kegeraman publik pasca kasus Sambo dan tragedi  Kanjuruhan, terbaru muncul kasus Irjen Teddy Minahasa, Kapolda Jatim yang terjerat kasus jual beli narkoba.  Kok bisa polisi jualan narkoba?
1581830545536733184 2022-10-17 02:12:45 +0000 &lt;KompasData&gt; Tragedi Kanjuruhan dengan gamblang menunjukkan bahwa kita adalah bangsa yang kalah.  Kejadian ini harus bisa dijadikan momentum untuk melakukan kebangkitan bangsa. #Opini #AdadiKompas  https://t.co/XwU3UKst6d
1581830150324297728 2022-10-17 02:11:11 +0000 &lt;AuisGrand&gt; Tragedi Kanjuruhan dengan gamblang menunjukkan bahwa kita adalah bangsa yang kalah.  Kejadian ini harus bisa dijadikan momentum untuk melakukan kebangkitan bangsa. #Opini #AdadiKompas  https://t.co/PXm5P2ou0y
1581829176583421952 2022-10-17 02:07:19 +0000 &lt;amerika_kost&gt; Risma prioritaskan anak korban tragedi Kanjuruhan dapat Bansos ..... #SemangatPerkuatNKRI
1581828726186471424 2022-10-17 02:05:31 +0000 &lt;malangposco&gt; Kawal Hak Korban Luka Tragedi Kanjuruhan  https://t.co/sXnyu6cu22
1581828049750097920 2022-10-17 02:02:50 +0000 &lt;jarang_bicara&gt; Risma prioritaskan anak korban tragedi Kanjuruhan dapat Bansos #SemangatPerkuatNKRI
1581827981299056641 2022-10-17 02:02:34 +0000 &lt;jarang_bicara&gt; Risma prioritaskan anak korban tragedi Kanjuruhan dapat Bansos #SemangatPerkuatNKRI  https://t.co/dhdhca1Vj7
1581827547695677440 2022-10-17 02:00:50 +0000 &lt;AdatahRedaksi&gt; LPSK Sebut Ada Dugaan Tindak Pidana atas Tragedi Kanjuruhan  https://t.co/Eyy6YfoSFl
1581827466229735425 2022-10-17 02:00:31 +0000 &lt;AdatahRedaksi&gt; Soal Tragedi Kanjuruhan, LPSK Berikan Kesimpulan  https://t.co/uuWHYDPiBY
1581827307852873728 2022-10-17 01:59:53 +0000 &lt;bukamata18&gt; Hasil Investigasi TGIPF Tragedi Kanjuruhan, PSSI Harus Bertanggungjawab  @PSSI @AremafcOfficial @Indostransfer @ListyoSigitP @mohmahfudmd   https://t.co/OPrkcZURT5
1581826454689488897 2022-10-17 01:56:30 +0000 &lt;bergeloralah&gt; SIAPA TANGGUNG JAWAB NIH…? 43 Anak Meninggal Dalam Tragedi Kanjuruhan  https://t.co/40C0dynfi7
1581825687823925248 2022-10-17 01:53:27 +0000 &lt;FaisalA55496673&gt; Pelaku Utama Tragedi Kanjuruhan  https://t.co/iaYCdcZjJS
1581825564444614656 2022-10-17 01:52:58 +0000 &lt;amerika_kost&gt; Risma prioritaskan anak korban tragedi Kanjuruhan dapat Bansos ..... #SemangatPerkuatNKRI  https://t.co/RwA2sCLeEd
1581825207601627137 2022-10-17 01:51:33 +0000 &lt;BangAgus6887&gt; Arema berdoa semoga lekas terungkap tragedi Kanjuruhan #pemersatusuporterindonesia  https://t.co/FPDMQuxPYf
1581824615164178433 2022-10-17 01:49:11 +0000 &lt;bangSaid_&gt; Apakah #JKWIngkarJanji ?!_ Semoga bantuan utk korban tragedi “Kanjuruhan” terealisasi.  Khawatir #JKWIngkarJanji lagi ☕️🙏🏻
1581824584705531904 2022-10-17 01:49:04 +0000 &lt;istiadi_agif&gt; Tragedi Kanjuruhan, Segera Benahi Sepakbola Indonesia dan Mendesak Ketua Umum dan Pengurus PSSI Untuk Mengundurkan Diri #IwanBuleOut @iriawan84 @pt_lib - Tandatangani Petisi!  https://t.co/OJ2oGoBWFj lewat @ChangeOrg_ID
1581823937100464128 2022-10-17 01:46:30 +0000 &lt;LinaSianturi19&gt; Risma prioritaskan anak korban tragedi Kanjuruhan dapat bansos  #SemangatPerkuatNKRI  https://t.co/q4e0LtzqcH
1581823058452434944 2022-10-17 01:43:00 +0000 &lt;abdhy_sejiwa&gt; @restyca_yah Tolong mawas diri smuanya ya. Ingat baik² tragedi kanjuruhan. Di perkumpulan sebesar stadion pun bisa terjadi tragedi besar begitu, apalagi ini hajatan seindonesia. Hati-hati, saling menahan diri, saling mengendalikan emosi. Jaga kluarga baik²
1581819242802184192 2022-10-17 01:27:50 +0000 &lt;Snex2005&gt; Ditunggu sikap resmi @psisfcofficial terkait tragedi kanjuruhan 🙌
1581816871292051456 2022-10-17 01:18:25 +0000 &lt;genie037&gt; ∩　 ∩ 　　　 (๑＾◡＾๑) ┏♪━･━〇━･〇･━+☆+┓           Risma prioritaskan anak korban tragedi kanjuruhan dapat bansos  ┗+☆+━･━･━ + ━･━♬┛  #SemangatPerkuatNKRI #SemangatPerkuatNKRI  https://t.co/QA7BstcDUk
1581816854401536002 2022-10-17 01:18:21 +0000 &lt;egyptmoses911&gt; ∩　 ∩ 　　　 (๑＾◡＾๑) ┏♪━･━〇━･〇･━+☆+┓           Risma prioritaskan anak korban tragedi kanjuruhan dapat bansos  ┗+☆+━･━･━ + ━･━♬┛  #SemangatPerkuatNKRI #SemangatPerkuatNKRI  https://t.co/kNPDUueNmv
1581816784197648384 2022-10-17 01:18:04 +0000 &lt;21BeritaTerkini&gt; Kementerian PPPA: Total 43 Anak Tewas di Tragedi Kanjuruhan  https://t.co/SAaI3OO2GE
1581815339096354816 2022-10-17 01:12:20 +0000 &lt;achmad9909&gt; @KompasTV @msaid_didu Mau gak ada tragedi kanjuruhan juga Indonesia gak bakal jadi tuan rumah piala Asia 2023, saingannya aja Korsel n Qatar secara fasilitas sudah mendukung.. 2023 itu udah masuk tahun politik juga agenda padet..
1581814505742340096 2022-10-17 01:09:01 +0000 &lt;Arenanews1&gt; APPI dan 17 Klub Liga 1 Sumbang Rp 110 Juta untuk Korban Tragedi Kanjuruhan – Semua Halaman – Bolasport –  https://t.co/4jAnI8QwqT – #Arenanews- https://t.co/7WXozZVQ8r
1581813552397983744 2022-10-17 01:05:14 +0000 &lt;CNNIndonesia&gt; Kementerian PPPA: Total 43 Anak Tewas di Tragedi Kanjuruhan  https://t.co/jP1ay2Of0W
1581813140341202945 2022-10-17 01:03:35 +0000 &lt;PRFMnews&gt; KPPPA Sebut 43 Anak Meninggal Dunia dalam Tragedi Kanjuruhan  https://t.co/fLpA7YMO5h
1581813038336077824 2022-10-17 01:03:11 +0000 &lt;adhiyanyoedi&gt; @angginovita93 @OngisnadeNet Saya pikir Aremania bisa diperiksa asalkan tragedi Kanjuruhan ditetapkan sebagai Pelanggaran HAM berat. Karena sejak awal aparat penegak hukum selalu ngeles soal Gas Air Mata. Bisa jadi kasus ini menguap dan pelakunya bebas seperti kasus Sam Munir.
1581812836971720705 2022-10-17 01:02:23 +0000 &lt;Popularitascom&gt; 43 anak meninggal dalam tragedi Kanjuruhan   #Arema #Kanjuruhan #malang #popularitascom  https://t.co/zwrsjSNVFD
1581812532188020736 2022-10-17 01:01:10 +0000 &lt;ilyas09770199&gt; Risma prioritaskan anak korban Tragedi Kanjuruhan dapat bansos #SemangatPerkuatNKRI  https://t.co/t1jyzWJrnZ
1581812468963102720 2022-10-17 01:00:55 +0000 &lt;kamidipus&gt; APPI dan 17 Klub Liga 1 Sumbang Rp 110 Juta untuk Korban Tragedi Kanjuruhan – Semua Halaman – Bolasport –  https://t.co/3WpR081yhZ – #Arenanews  -  https://t.co/h8RG733JSS
1581812411975503872 2022-10-17 01:00:42 +0000 &lt;Nasionalis88&gt; Risma prioritaskan anak korban tragedi kanjuruhan dapat bansos  #SemangatPerkuatNKRI  https://t.co/fw27TQZh3z
1581811941957197824 2022-10-17 00:58:50 +0000 &lt;detikcom&gt; Tim Gabungan Independen Pencari Fakta (TGIPF) merekomendasikan PSSI untuk menggelar Kongres Luar Biasa (KLB) buntut tragedi Kanjuruhan.  https://t.co/6yJNOgcdRv
1581811001594642433 2022-10-17 00:55:06 +0000 &lt;antaranews&gt; Kemarin, data anak dalam tragedi Kanjuruhan hingga banjir dan longsor  https://t.co/1MgLIIjWdU
1581810860431134720 2022-10-17 00:54:32 +0000 &lt;PolitikNarasi&gt; TERUNGKAP! Pasukan Brimob Polda Jatim di Tragedi Kanjuruhan  https://t.co/KmRTstVolU
1581810764071198721 2022-10-17 00:54:09 +0000 &lt;radaraktual&gt; Indikasi Judi di Balik Tragedi Kanjuruhan, Arteria Dahlan: Pertandingan Seri Saja Bandar Sudah Untung  https://t.co/wcZyTwsdub
1581810735440543744 2022-10-17 00:54:02 +0000 &lt;bb_sports_id&gt; Reformasi Sepak Bola Indonesia, Rasiman Bicara Waktu Kick Off, Mentalitas hingga Hillsborough  https://t.co/6qfS8Exms1 baca juga berita dari media lainnya di Indonesia di  https://t.co/GkwQxRUMd1   #persissolo #ligaindonesia #liga1 #rasiman #tragedikanjuruhan
1581809985989681152 2022-10-17 00:51:03 +0000 &lt;tukangrosok___&gt; Memang betul, yg bisa menyelamatkan Sepak Bola kita cuma RI 1 Bpk @jokowi . Terimakasih Pak @mohmahfudmd yg telah berperan membongkar kebobrokan @pssi, PANPEL LIB, serta Stasiun Broadcast atas Tragedi Stadion Kanjuruhan.  #UsutTuntasTragediKanjuruhan  https://t.co/SoGlKbpr7s
1581809809313370112 2022-10-17 00:50:21 +0000 &lt;WidyanaHilda&gt; 43 Anak Tewas dalam Tragedi Kanjuruhan, KPPPA: 33 Laki-Laki dan 10 Perempuan  https://t.co/ukySNBwPE3
1581808956594278404 2022-10-17 00:46:58 +0000 &lt;Kotakmi1&gt; APPI dan 17 Klub Liga 1 Sumbang Rp 110 Juta untuk Korban Tragedi Kanjuruhan – Semua Halaman – Bolasport –  https://t.co/wCqJglLzfN – #Arenanews  https://t.co/NIlDipTnjD
1581808424043810817 2022-10-17 00:44:51 +0000 &lt;madiunpunyakita&gt; Aksi Solidaritas Tragedi Kanjuruhan, Aliansi Suporter Sepak Bola Kabupaten Madiun Gelar Deklarasi Damai  https://t.co/HNHSPZ4pfd
1581808387196870656 2022-10-17 00:44:42 +0000 &lt;jatimpos_online&gt; Aksi Solidaritas Tragedi Kanjuruhan, Aliansi Suporter Sepak Bola Kabupaten Madiun Gelar Deklarasi Damai  https://t.co/B1nJBGZ58T
1581807325265788928 2022-10-17 00:40:29 +0000 &lt;Info_Nusantara2&gt; Wakil Ketua Komisi X DPR RI, Dede Yusuf, mendorong agar Presiden Joko Widodo menindaklanjuti rekomendasi dari Tim Gabungan Independen Pencari Fakta (TGIPF) Tragedi Kanjuruhan.   #ElClasico #AMAs  Senin  Alhamdulillah Kehilangan  Mo Salah  https://t.co/Er0OpdKraW
1581806821483827202 2022-10-17 00:38:29 +0000 &lt;fahmanet&gt; TGIPF Serahkan 124 Halaman Laporan, Ungkap Fakta Mengerikan Tragedi Kanjuruhan  https://t.co/q0EFxA55cE
1581806806380126208 2022-10-17 00:38:25 +0000 &lt;KasanMulyono&gt; Pertemuan Erick Thohir dan Presiden FIFA pasca tragedi Kanjuruhan: poin 4 lebih menarik  https://t.co/MXq5GCa80I
1581806751136903168 2022-10-17 00:38:12 +0000 &lt;BatamPos&gt; Anak Korban Tragedi Kanjuruhan Diprioritaskan Dapat Bansos  https://t.co/U8vibNaOcj
1581806136071639040 2022-10-17 00:35:46 +0000 &lt;Alamalika&gt; Berita di luar negeri ttg betapa biadabnya polisi Indonesia dlm tragedi Kanjuruhan  https://t.co/OjJBNdz3QD
1581805729672941569 2022-10-17 00:34:09 +0000 &lt;CarditoDewi&gt; Jokowi dan presiden FIFA dijadwalkan akan bertemu pada 18 Oktober membahas pembenahan sepakbola Indonesia sejak terjadinya Tragedi Kanjuruhan yang menewaskan 132 orang.  Pemalang | Senin | #lukasenembepenipu  https://t.co/Cwpt9GL70s
1581804844972576768 2022-10-17 00:30:38 +0000 &lt;redaksidetail&gt; Ngeri! Data Kementerian PPPA Sebut 43 Anak Meninggal Dalam Tragedi Kanjuruhan  https://t.co/iWYll2CJTD
1581803313452191745 2022-10-17 00:24:33 +0000 &lt;berita_hanif&gt; Belum usai ! Jokowi beri perintah Polri lanjutkan pendalaman temuan TGIPF terhadap tragedi Kanjuruhan.  isyana | #IndonesiaMemanggil | Senin  https://t.co/vOpHpzoiru
1581802757933400064 2022-10-17 00:22:20 +0000 &lt;putrisrikandi_&gt; Risma prioritaskan anak tragedi kanjuruhan dapat bansos  #SemangatPerkuatNKRI  https://t.co/fbg95FCxHw
1581802657324285953 2022-10-17 00:21:56 +0000 &lt;AristyoNoviana&gt; Buntut Tragedi Kanjuruhan, Jokowi instruksikan seluruh stadion di Indonesia di-upgrade menjadi lebih aman dan nyaman, demi keselamatan dan kenyamanan para penonton sepak bola.  #IndonesiaMemanggil | Senin | isyana  https://t.co/WYz9XKazQv
1581802515313483776 2022-10-17 00:21:22 +0000 &lt;kaypazza&gt; KPPPA: 43 anak tewas dalam tragedi Kanjuruhan - ANTARA News Bali  https://t.co/4uFYprc4Tw
1581800158546644992 2022-10-17 00:12:00 +0000 &lt;Zyanpatra&gt; Tragedi Kanjuruhan, Kementerian PPPA Sebut 43 Anak Meninggal Dunia  https://t.co/4culXWonna
1581798638799695874 2022-10-17 00:05:58 +0000 &lt;amelliaftz&gt; Risma Prioritaskan Anak Korban Tragedi Kanjuruhan Dapat Bansos #SemangatPerkuatNKRI  https://t.co/dVdpt9Z0rh
1581798468515135490 2022-10-17 00:05:17 +0000 &lt;arisputra1515&gt; Risma Prioritaskan Anak Korban Tragedi Kanjuruhan Dapat Bansos #SemangatPerkuatNKRI  https://t.co/yszX621wFm
1581798452975243264 2022-10-17 00:05:14 +0000 &lt;kontenislam_com&gt; Pelaku Utama Tragedi Kanjuruhan  https://t.co/NQJfgfwaWt
1581798214683922432 2022-10-17 00:04:17 +0000 &lt;_JinggaSaja_&gt; Risma prioritaskan anak korban tragedi kanjuruhan dapat bansos  #SemangatPerkuatNKRI  https://t.co/Wdonci3sLq
</pre></div>
</div>
</div>
</div>
</section>
<section id="id7">
<h4>Ambil Tweet<a class="headerlink" href="#id7" title="Permalink to this headline">#</a></h4>
<p>Setelah proses crawling didapatkan data tweeter diatas, pada data tersebut terdapat data yang tidak diperlukan. Untuk melakukan prepocessing hanya memerlukan data tweet dari user, maka dari itu buang data yang tidak diperlukan dan ambil data tweet yang akan digunakan dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Tweets_dfs</span> <span class="o">=</span> <span class="n">twint</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">panda</span><span class="o">.</span><span class="n">Tweets_df</span>
<span class="n">Tweets_dfs</span><span class="p">[</span><span class="s2">&quot;tweet&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     Pemerintah pastikan Piala Dunia U-20 tetap dig...
1     Pemerintah pastikan Piala Dunia U-20 tetap dig...
2     43 Anak Jadi Korban dalam Tragedi Kanjuruhan  ...
3     Saya percaya mas nya bukan orang sembarangan. ...
4     Janji Aremania Kawal Terus Tragedi Kanjuruhan ...
                            ...                        
95    Tragedi Kanjuruhan, Kementerian PPPA Sebut 43 ...
96    Risma Prioritaskan Anak Korban Tragedi Kanjuru...
97    Risma Prioritaskan Anak Korban Tragedi Kanjuru...
98    Pelaku Utama Tragedi Kanjuruhan  https://t.co/...
99    Risma prioritaskan anak korban tragedi kanjuru...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id8">
<h4>Upload Data Tweet<a class="headerlink" href="#id8" title="Permalink to this headline">#</a></h4>
<p>Setelah data tweet di dapatkan, simpan data tweet tersebut dalam bentuk csv, kemudian download dan upload ke github untuk nanti digunakan sebagai dataset dari proses prepocessing text.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Tweets_dfs</span><span class="p">[</span><span class="s2">&quot;tweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;kanjuruhan.csv&quot;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id9">
<h3>Prepocessing Text<a class="headerlink" href="#id9" title="Permalink to this headline">#</a></h3>
<p>Setelah proses crawling, selanjutnya dilakukan prepocessing text, yaitu sebuah proses mesin yang digunakan untuk menyeleksi data teks agar lebih terstruktur dengan melalui beberapa tahapan-tahapan yang meliputi tahapan case folding, tokenizing, filtering dan stemming.
Sebelum melakukan tahapan-tahapan tersebut, terlebih dahulu kita import data crawling yang diupload ke github tadi dengan menggunakan library pandas pada source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> 

<span class="n">tweets</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;kanjuruhan.csv&quot;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">tweets</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-7bdccee1-ffc5-43d3-9947-e59f7ff15ab3">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tweet</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Pemerintah pastikan Piala Dunia U-20 tetap dig...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Pemerintah pastikan Piala Dunia U-20 tetap dig...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>43 Anak Jadi Korban dalam Tragedi Kanjuruhan  ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Saya percaya mas nya bukan orang sembarangan. ...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Janji Aremania Kawal Terus Tragedi Kanjuruhan ...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>Tragedi Kanjuruhan, Kementerian PPPA Sebut 43 ...</td>
    </tr>
    <tr>
      <th>96</th>
      <td>Risma Prioritaskan Anak Korban Tragedi Kanjuru...</td>
    </tr>
    <tr>
      <th>97</th>
      <td>Risma Prioritaskan Anak Korban Tragedi Kanjuru...</td>
    </tr>
    <tr>
      <th>98</th>
      <td>Pelaku Utama Tragedi Kanjuruhan  https://t.co/...</td>
    </tr>
    <tr>
      <th>99</th>
      <td>Risma prioritaskan anak korban tragedi kanjuru...</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 1 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-7bdccee1-ffc5-43d3-9947-e59f7ff15ab3')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-7bdccee1-ffc5-43d3-9947-e59f7ff15ab3 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-7bdccee1-ffc5-43d3-9947-e59f7ff15ab3');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<p>Setelah data crawling berhasil di import, selanjutnya lakukan tahapan-tahapan prepocessing seperti berikut.</p>
<section id="id10">
<h4>Case Folding<a class="headerlink" href="#id10" title="Permalink to this headline">#</a></h4>
<p>Setelah berhassil mengambil dataset, selanjutnya ke proses prepocessing ke tahapan case folding yaitu tahapan pertama untuk melakukan prepocessing text dengan mengubah text menjadi huruf kecil semua dengan menghilangkan juga karakter spesial, angka, tanda baca, spasi serta huruf yang tidak penting.</p>
<section id="id11">
<h5>Merubah Huruf Kecil Semua<a class="headerlink" href="#id11" title="Permalink to this headline">#</a></h5>
<p>Tahapan case folding yang pertama yaitu merubah semua huruf menjadi huruf kecil semua menggunakan fungsi lower() dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>


<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     pemerintah pastikan piala dunia u-20 tetap dig...
1     pemerintah pastikan piala dunia u-20 tetap dig...
2     43 anak jadi korban dalam tragedi kanjuruhan  ...
3     saya percaya mas nya bukan orang sembarangan. ...
4     janji aremania kawal terus tragedi kanjuruhan ...
                            ...                        
95    tragedi kanjuruhan, kementerian pppa sebut 43 ...
96    risma prioritaskan anak korban tragedi kanjuru...
97    risma prioritaskan anak korban tragedi kanjuru...
98    pelaku utama tragedi kanjuruhan  https://t.co/...
99    risma prioritaskan anak korban tragedi kanjuru...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id12">
<h5>Menghapus Karakter Spesial<a class="headerlink" href="#id12" title="Permalink to this headline">#</a></h5>
<p>Tahapan case folding selanjutnya ialah menghapus karakter spesial dengan menggunakan library nltk, untuk menggunakan librarynya terlebih dahulu install dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#install library nltk</span>
<span class="o">!</span>pip install nltk
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)
Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)
Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)
Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)
Requirement already satisfied: regex&gt;=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)
</pre></div>
</div>
</div>
</div>
<p>Setelah library nltk terinstall kita import librarynya dan buat sebuah function untuk menghapus karakter spesial tersebut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">string</span> 
<span class="kn">import</span> <span class="nn">re</span> <span class="c1">#regex library</span>
<span class="c1"># import word_tokenize &amp; FreqDist from NLTK</span>

<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span> 
<span class="kn">from</span> <span class="nn">nltk.probability</span> <span class="kn">import</span> <span class="n">FreqDist</span>


<span class="k">def</span> <span class="nf">remove_special</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># remove tab, new line, ans back slice</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">t&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">n&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">u&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">f&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">r&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
    <span class="c1"># remove non ASCII (emoticon, chinese word, .etc)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;ascii&#39;</span><span class="p">,</span> <span class="s1">&#39;replace&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;ascii&#39;</span><span class="p">)</span>
    <span class="c1"># remove mention, link, hashtag</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;([@#][A-Za-z0-9]+)|(\w+:\/\/\S+)&quot;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
    <span class="c1"># remove incomplete URL</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;http://&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;https://&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
                
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_special</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     pemerintah pastikan piala dunia u-20 tetap dig...
1     pemerintah pastikan piala dunia u-20 tetap dig...
2          43 anak jadi korban dalam tragedi kanjuruhan
3     saya percaya mas nya bukan orang sembarangan. ...
4     janji aremania kawal terus tragedi kanjuruhan ...
                            ...                        
95    tragedi kanjuruhan, kementerian pppa sebut 43 ...
96    risma prioritaskan anak korban tragedi kanjuru...
97    risma prioritaskan anak korban tragedi kanjuru...
98                      pelaku utama tragedi kanjuruhan
99    risma prioritaskan anak korban tragedi kanjuru...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id13">
<h5>Menghapus Angka<a class="headerlink" href="#id13" title="Permalink to this headline">#</a></h5>
<p>Selanjutnya melakukan penghapusan angka, penghapusan angka disini fleksibel, jika angka ingin dijadikan fitur maka penghapusan angka tidak perlu dilakukan. Untuk data tweet ini saya tidak ingin menjadikan angka sebagai fitur, untuk itu dilakukan penghapusan angka dengan function berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#remove number</span>
<span class="k">def</span> <span class="nf">remove_number</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span>  <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\d+&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_number</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     pemerintah pastikan piala dunia u- tetap digel...
1     pemerintah pastikan piala dunia u- tetap digel...
2             anak jadi korban dalam tragedi kanjuruhan
3     saya percaya mas nya bukan orang sembarangan. ...
4     janji aremania kawal terus tragedi kanjuruhan ...
                            ...                        
95    tragedi kanjuruhan, kementerian pppa sebut  an...
96    risma prioritaskan anak korban tragedi kanjuru...
97    risma prioritaskan anak korban tragedi kanjuru...
98                      pelaku utama tragedi kanjuruhan
99    risma prioritaskan anak korban tragedi kanjuru...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id14">
<h5>Menghapus Tanda Baca<a class="headerlink" href="#id14" title="Permalink to this headline">#</a></h5>
<p>Selanjutnya penghapusan tanda baca yang tidak perlu yang dilakukan dengan function punctuation berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#remove punctuation</span>
<span class="k">def</span> <span class="nf">remove_punctuation</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="nb">str</span><span class="o">.</span><span class="n">maketrans</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">))</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_punctuation</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     pemerintah pastikan piala dunia u tetap digela...
1     pemerintah pastikan piala dunia u tetap digela...
2             anak jadi korban dalam tragedi kanjuruhan
3     saya percaya mas nya bukan orang sembarangan m...
4     janji aremania kawal terus tragedi kanjuruhan ...
                            ...                        
95    tragedi kanjuruhan kementerian pppa sebut  ana...
96    risma prioritaskan anak korban tragedi kanjuru...
97    risma prioritaskan anak korban tragedi kanjuru...
98                      pelaku utama tragedi kanjuruhan
99    risma prioritaskan anak korban tragedi kanjuru...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id15">
<h5>Menghapus Spasi<a class="headerlink" href="#id15" title="Permalink to this headline">#</a></h5>
<p>Selanjutnya melakukan penghapusan spasi dengab menggunakan function berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#remove whitespace leading &amp; trailing</span>
<span class="k">def</span> <span class="nf">remove_whitespace_LT</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_whitespace_LT</span><span class="p">)</span>


<span class="c1">#remove multiple whitespace into single whitespace</span>
<span class="k">def</span> <span class="nf">remove_whitespace_multiple</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span><span class="s1">&#39; &#39;</span><span class="p">,</span><span class="n">text</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_whitespace_multiple</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     pemerintah pastikan piala dunia u tetap digela...
1     pemerintah pastikan piala dunia u tetap digela...
2             anak jadi korban dalam tragedi kanjuruhan
3     saya percaya mas nya bukan orang sembarangan m...
4     janji aremania kawal terus tragedi kanjuruhan ...
                            ...                        
95    tragedi kanjuruhan kementerian pppa sebut anak...
96    risma prioritaskan anak korban tragedi kanjuru...
97    risma prioritaskan anak korban tragedi kanjuru...
98                      pelaku utama tragedi kanjuruhan
99    risma prioritaskan anak korban tragedi kanjuru...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id16">
<h5>Menghapus Huruf<a class="headerlink" href="#id16" title="Permalink to this headline">#</a></h5>
<p>Selanjutnya melakukan penghapusan huruf yang tidak bermakna dengan function berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># remove single char</span>
<span class="k">def</span> <span class="nf">remove_singl_char</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\b[a-zA-Z]\b&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_singl_char</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     pemerintah pastikan piala dunia   tetap digela...
1     pemerintah pastikan piala dunia   tetap digela...
2             anak jadi korban dalam tragedi kanjuruhan
3     saya percaya mas nya bukan orang sembarangan m...
4     janji aremania kawal terus tragedi kanjuruhan ...
                            ...                        
95    tragedi kanjuruhan kementerian pppa sebut anak...
96    risma prioritaskan anak korban tragedi kanjuru...
97    risma prioritaskan anak korban tragedi kanjuru...
98                      pelaku utama tragedi kanjuruhan
99    risma prioritaskan anak korban tragedi kanjuru...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id17">
<h4>Tokenizing<a class="headerlink" href="#id17" title="Permalink to this headline">#</a></h4>
<p>Setelah tahapan case folding selesai, selanjutnya masuk ke tahapan tokenizing yang merupakan tahapan prepocessing yang memecah kalimat dari text menjadi kata agar membedakan antara kata pemisah atau bukan. Untuk melakukan tokenizing dapat menggunakan dengan library nltk dan function berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span>
<span class="c1"># NLTK word Tokenize </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt.zip.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># NLTK word Tokenize </span>
<span class="k">def</span> <span class="nf">word_tokenize_wrapper</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">word_tokenize_wrapper</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     [pemerintah, pastikan, piala, dunia, tetap, di...
1     [pemerintah, pastikan, piala, dunia, tetap, di...
2      [anak, jadi, korban, dalam, tragedi, kanjuruhan]
3     [saya, percaya, mas, nya, bukan, orang, sembar...
4     [janji, aremania, kawal, terus, tragedi, kanju...
                            ...                        
95    [tragedi, kanjuruhan, kementerian, pppa, sebut...
96    [risma, prioritaskan, anak, korban, tragedi, k...
97    [risma, prioritaskan, anak, korban, tragedi, k...
98                 [pelaku, utama, tragedi, kanjuruhan]
99    [risma, prioritaskan, anak, korban, tragedi, k...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id18">
<h4>Filtering(Stopword)<a class="headerlink" href="#id18" title="Permalink to this headline">#</a></h4>
<p>Tahapan prepocessing selanjutnya ialah filtering atau disebut juga stopword yang merupakan lanjutan dari tahapan tokenizing yang digunakan untuk mengambil kata-kata penting dari hasil tokenizing tersebut dengan menghapus kata hubung yang tidak memiliki makna.</p>
<p>Proses stopword dapat dilakukan dengan mengimport library stopword dan function berikut untuk melakukan stopword.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;stopwords&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Unzipping corpora/stopwords.zip.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">list_stopwords</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;indonesian&#39;</span><span class="p">)</span>

<span class="c1"># append additional stopword</span>
<span class="n">list_stopwords</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s2">&quot;yg&quot;</span><span class="p">,</span> <span class="s2">&quot;dg&quot;</span><span class="p">,</span> <span class="s2">&quot;rt&quot;</span><span class="p">,</span> <span class="s2">&quot;dgn&quot;</span><span class="p">,</span> <span class="s2">&quot;ny&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="s1">&#39;klo&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;kalo&#39;</span><span class="p">,</span> <span class="s1">&#39;amp&#39;</span><span class="p">,</span> <span class="s1">&#39;biar&#39;</span><span class="p">,</span> <span class="s1">&#39;bikin&#39;</span><span class="p">,</span> <span class="s1">&#39;bilang&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;gak&#39;</span><span class="p">,</span> <span class="s1">&#39;ga&#39;</span><span class="p">,</span> <span class="s1">&#39;krn&#39;</span><span class="p">,</span> <span class="s1">&#39;nya&#39;</span><span class="p">,</span> <span class="s1">&#39;nih&#39;</span><span class="p">,</span> <span class="s1">&#39;sih&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;si&#39;</span><span class="p">,</span> <span class="s1">&#39;tau&#39;</span><span class="p">,</span> <span class="s1">&#39;tdk&#39;</span><span class="p">,</span> <span class="s1">&#39;tuh&#39;</span><span class="p">,</span> <span class="s1">&#39;utk&#39;</span><span class="p">,</span> <span class="s1">&#39;ya&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;jd&#39;</span><span class="p">,</span> <span class="s1">&#39;jgn&#39;</span><span class="p">,</span> <span class="s1">&#39;sdh&#39;</span><span class="p">,</span> <span class="s1">&#39;aja&#39;</span><span class="p">,</span> <span class="s1">&#39;n&#39;</span><span class="p">,</span> <span class="s1">&#39;t&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;nyg&#39;</span><span class="p">,</span> <span class="s1">&#39;hehe&#39;</span><span class="p">,</span> <span class="s1">&#39;pen&#39;</span><span class="p">,</span> <span class="s1">&#39;u&#39;</span><span class="p">,</span> <span class="s1">&#39;nan&#39;</span><span class="p">,</span> <span class="s1">&#39;loh&#39;</span><span class="p">,</span> <span class="s1">&#39;rt&#39;</span><span class="p">,</span>
                       <span class="s1">&#39;&amp;amp&#39;</span><span class="p">,</span> <span class="s1">&#39;yah&#39;</span><span class="p">])</span>

<span class="c1"># convert list to dictionary</span>
<span class="n">list_stopwords</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">list_stopwords</span><span class="p">)</span>

<span class="c1">#Menghapus Stopword dari list token</span>
<span class="k">def</span> <span class="nf">stopwords_removal</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">list_stopwords</span><span class="p">]</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">stopwords_removal</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     [pemerintah, pastikan, piala, dunia, digelar, ...
1     [pemerintah, pastikan, piala, dunia, digelar, ...
2                   [anak, korban, tragedi, kanjuruhan]
3     [percaya, mas, orang, sembarangan, mas, nggak,...
4     [janji, aremania, kawal, tragedi, kanjuruhan, ...
                            ...                        
95    [tragedi, kanjuruhan, kementerian, pppa, anak,...
96    [risma, prioritaskan, anak, korban, tragedi, k...
97    [risma, prioritaskan, anak, korban, tragedi, k...
98                 [pelaku, utama, tragedi, kanjuruhan]
99    [risma, prioritaskan, anak, korban, tragedi, k...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id19">
<h4>Stemming<a class="headerlink" href="#id19" title="Permalink to this headline">#</a></h4>
<p>Tahapan terakhir dari proses prepocessing ialah stemming yang merupakan penghapusan suffix maupun prefix pada text sehingga menjadi kata dasar. Proses ini dapat dilakukan dengan menggunakan library sastrawi dan swifter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install Sastrawi
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting Sastrawi
  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)
     |████████████████████████████████| 209 kB 4.8 MB/s 
?25hInstalling collected packages: Sastrawi
Successfully installed Sastrawi-1.0.1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install swifter
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting swifter
  Downloading swifter-1.3.4.tar.gz (830 kB)
     |████████████████████████████████| 830 kB 5.5 MB/s 
?25hRequirement already satisfied: pandas&gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (1.3.5)
Collecting psutil&gt;=5.6.6
  Downloading psutil-5.9.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)
     |████████████████████████████████| 281 kB 53.6 MB/s 
?25hRequirement already satisfied: dask[dataframe]&gt;=2.10.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (2022.2.0)
Requirement already satisfied: tqdm&gt;=4.33.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (4.64.1)
Requirement already satisfied: ipywidgets&gt;=7.0.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (7.7.1)
Requirement already satisfied: cloudpickle&gt;=0.2.2 in /usr/local/lib/python3.7/dist-packages (from swifter) (1.5.0)
Requirement already satisfied: parso&gt;0.4.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (0.8.3)
Requirement already satisfied: bleach&gt;=3.1.1 in /usr/local/lib/python3.7/dist-packages (from swifter) (5.0.1)
Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach&gt;=3.1.1-&gt;swifter) (0.5.1)
Requirement already satisfied: six&gt;=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bleach&gt;=3.1.1-&gt;swifter) (1.15.0)
Requirement already satisfied: toolz&gt;=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (0.12.0)
Requirement already satisfied: partd&gt;=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (1.3.0)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (21.3)
Requirement already satisfied: pyyaml&gt;=5.3.1 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (6.0)
Requirement already satisfied: fsspec&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (2022.8.2)
Requirement already satisfied: numpy&gt;=1.18 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (1.21.6)
Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (3.6.1)
Requirement already satisfied: traitlets&gt;=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (5.1.1)
Requirement already satisfied: ipython&gt;=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (7.9.0)
Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (0.2.0)
Requirement already satisfied: jupyterlab-widgets&gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (3.0.3)
Requirement already satisfied: ipykernel&gt;=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (5.3.4)
Requirement already satisfied: tornado&gt;=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.1.1)
Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (6.1.12)
Collecting jedi&gt;=0.10
  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)
     |████████████████████████████████| 1.6 MB 46.1 MB/s 
?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.6.1)
Requirement already satisfied: setuptools&gt;=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (57.4.0)
Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.2.0)
Requirement already satisfied: prompt-toolkit&lt;2.1.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.0.10)
Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.7.5)
Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.4.2)
Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.8.0)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging&gt;=20.0-&gt;dask[dataframe]&gt;=2.10.0-&gt;swifter) (3.0.9)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=1.0.0-&gt;swifter) (2022.4)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=1.0.0-&gt;swifter) (2.8.2)
Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd&gt;=0.3.10-&gt;dask[dataframe]&gt;=2.10.0-&gt;swifter) (1.0.0)
Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit&lt;2.1.0,&gt;=2.0.0-&gt;ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.2.5)
Requirement already satisfied: notebook&gt;=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.5.0)
Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.7.0)
Requirement already satisfied: jupyter-core&gt;=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.11.1)
Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (1.8.0)
Requirement already satisfied: pyzmq&gt;=17 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (23.2.1)
Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.6.1)
Requirement already satisfied: terminado&gt;=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.13.3)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.11.3)
Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado&gt;=0.8.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.7.0)
Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.0.1)
Requirement already satisfied: entrypoints&gt;=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.4)
Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.7.1)
Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.6.0)
Requirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.8.4)
Requirement already satisfied: pandocfilters&gt;=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (1.5.0)
Requirement already satisfied: importlib-metadata&gt;=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.0.0)
Requirement already satisfied: jsonschema&gt;=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.3.3)
Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.16.2)
Requirement already satisfied: typing-extensions&gt;=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=3.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.1.1)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=3.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (3.9.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.18.1)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (22.1.0)
Requirement already satisfied: importlib-resources&gt;=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.10.0)
Building wheels for collected packages: swifter
  Building wheel for swifter (setup.py) ... ?25l?25hdone
  Created wheel for swifter: filename=swifter-1.3.4-py3-none-any.whl size=16322 sha256=18314779abdf54e8f5fa7033a365627c12b1fb10d02d775b18cc51917ff97227
  Stored in directory: /root/.cache/pip/wheels/29/a7/0e/3a8f17ac69d759e1e93647114bc9bdc95957e5b0cbfd405205
Successfully built swifter
Installing collected packages: jedi, psutil, swifter
  Attempting uninstall: psutil
    Found existing installation: psutil 5.4.8
    Uninstalling psutil-5.4.8:
      Successfully uninstalled psutil-5.4.8
Successfully installed jedi-0.18.1 psutil-5.9.2 swifter-1.3.4
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">Sastrawi.Stemmer.StemmerFactory</span> <span class="kn">import</span> <span class="n">StemmerFactory</span>
<span class="kn">import</span> <span class="nn">swifter</span>


<span class="c1"># create stemmer</span>
<span class="n">factory</span> <span class="o">=</span> <span class="n">StemmerFactory</span><span class="p">()</span>
<span class="n">stemmer</span> <span class="o">=</span> <span class="n">factory</span><span class="o">.</span><span class="n">create_stemmer</span><span class="p">()</span>

<span class="c1"># stemmed</span>
<span class="k">def</span> <span class="nf">stemmed_wrapper</span><span class="p">(</span><span class="n">term</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">term</span><span class="p">)</span>

<span class="n">term_dict</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">document</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">term</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">term_dict</span><span class="p">:</span>
            <span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span>
            
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">term_dict</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">term_dict</span><span class="p">:</span>
    <span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">=</span> <span class="n">stemmed_wrapper</span><span class="p">(</span><span class="n">term</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">term</span><span class="p">,</span><span class="s2">&quot;:&quot;</span> <span class="p">,</span><span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">])</span>
    
<span class="nb">print</span><span class="p">(</span><span class="n">term_dict</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------&quot;</span><span class="p">)</span>


<span class="c1"># apply stemmed term to dataframe</span>
<span class="k">def</span> <span class="nf">get_stemmed_term</span><span class="p">(</span><span class="n">document</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">document</span><span class="p">]</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">swifter</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_stemmed_term</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>444
------------------------
pemerintah : perintah
pastikan : pasti
piala : piala
dunia : dunia
digelar : gelar
indonesia : indonesia
ketua : ketua
tim : tim
gabungan : gabung
independen : independen
pencari : cari
fakta : fakta
tgipf : tgipf
tragedi : tragedi
kanjuruhan : kanjuruhan
mahfud : mahfud
md : md
pemalang : malang
kehilangan : hilang
megapixel : megapixel
anak : anak
korban : korban
percaya : percaya
mas : mas
orang : orang
sembarangan : sembarang
nggak : nggak
detail : detail
wkt : wkt
kick : kick
off : off
selesai : selesai
janji : janji
aremania : aremania
kawal : kawal
raih : raih
keadilan : adil
jokowi : jokowi
perintah : perintah
polri : polri
lanjutkan : lanjut
pendalaman : dalam
temuan : temu
el : el
rumi : rumi
kate : kate
presiden : presiden
ambil : ambil
langkah : langkah
konkret : konkret
sikapi : sikap
rekomendasi : rekomendasi
ahy : ahy
pemimpin : pimpin
perubahan : ubah
dokumen : dokumen
nama : nama
bertanggung : tanggung
kabar : kabar
dr : dr
kelanjutan : lanjut
investigasi : investigasi
so : so
far : far
pribadi : pribadi
puas : puas
hasilnya : hasil
bs : bs
berbuat : buat
cm : cm
butuh : butuh
keluarga : keluarga
polisi : polisi
pssi : pssi
msh : msh
malu : malu
udahlah : udahlah
cepet : cepet
tanggung : tanggung
buntut : buntut
instruksikan : instruksi
stadion : stadion
diupgrade : diupgrade
aman : aman
nyaman : nyaman
keselamatan : selamat
kenyamanan : nyaman
penonton : tonton
sepak : sepak
bola : bola
simak : simak
edisi : edisi
terbaru : baru
klik : klik
baguss : baguss
kakk : kakk
posternya : poster
informatif : informatif
langsung : langsung
semangat : semangat
mengusut : usut
minggu : minggu
gelar : gelar
rekonstruksi : rekonstruksi
autopsi : autopsi
jenazah : jenazah
kahmi : kahmi
forum : forum
bahas : bahas
kemanusiaan : manusia
stadionkanjuruhan : stadionkanjuruhan
mbah : mbah
gimana : gimana
wali : wali
kota : kota
sutiaji : sutiaji
gala : gala
dinner : dinner
balaikota : balaikota
malang : malang
dihadiri : hadir
pemain : main
ofisial : ofisial
perangkat : perangkat
pertandingan : tanding
panitia : panitia
kesuksesan : sukses
turnamen : turnamen
suntikan : sunti
moril : moril
pasca : pasca
lukanya : luka
dirasakan : rasa
masyarakat : masyarakat
luas : luas
tanggapi : tanggap
klb : klb
umuh : umuh
muchtar : muchtar
alasannya : alas
baca : baca
berita : berita
media : media
tindakan : tindak
sangattdk : sangattdk
manusiawi : manusiawi
berani : berani
aparat : aparat
keamanan : aman
pergi : pergi
papua : papua
lawanlah : lawan
kelompok : kelompok
kriminal : kriminal
bersenjatakkbdisana : bersenjatakkbdisana
bertindaklah : tindak
wajar : wajar
rakyat : rakyat
karna : karna
rakyatlahkalian : rakyatlahkalian
hormati : hormat
terkait : kait
bupati : bupati
jember : jember
alhamdulillah : alhamdulillah
ditangani : tangan
denganbaik : denganbaik
periksa : periksa
saksi : saksi
tambahan : tambah
pegiat : giat
olahraga : olahraga
sepakbola : sepakbola
evaluasi : evaluasi
suporter : suporter
hormatiketertiban : hormatiketertiban
kementerian : menteri
pppa : pppa
meninggal : tinggal
komisi : komisi
hilang : hilang
tindak : tindak
kekerasan : keras
kontras : kontras
mendampingi : damping
tpf : tpf
menemukan : temu
intimidasi : intimidasi
selengkapnya : lengkap
gamblang : gamblang
bangsa : bangsa
kalah : kalah
kejadian : jadi
dijadikan : jadi
momentum : momentum
kebangkitan : bangkit
com : com
onlineindo : onlineindo
news : news
alvin : alvin
lim : lim
didalangi : dalang
konso : konso
kanjuruhansekarang : kanjuruhansekarang
tugas : tugas
publuk : publuk
mengawasi : awas
rekomendasirekomendasi : rekomendasirekomendasi
dijalankan : jalan
akmal : akmal
marhali : marhali
anggota : anggota
menjadwalkan : jadwal
rekontruksi : rekontruksi
ulang : ulang
dibutuhkan : butuh
rangka : rangka
proses : proses
pembuktian : bukti
cepat : cepat
ditemukan : temu
permulaan : mula
terungkap : ungkap
fifa : fifa
senin : senin
morninggg : morninggg
drake : drake
cairan : cair
haram : haram
dpt : dpt
mempersatukan : satu
bongdrun : bongdrun
mreka : mreka
spakat : spakat
pembantaian : bantai
smentara : smentara
takdir : takdir
diskriminasi : diskriminasi
dzolim : dzolim
aturan : atur
menolak : tolak
vaksin : vaksin
salah : salah
detiksport : detiksport
buruburu : buruburu
bubar : bubar
psm : psm
makassar : makassar
memilih : pilih
meliburkan : libur
kompetisi : kompetisi
liga : liga
kepastian : pasti
pascatragedi : pascatragedi
berpijak : pijak
kebenaran : benar
kebanyakan : banyak
faktafakta : faktafakta
diangkat : angkat
framingframing : framingframing
menghilangkan : hilang
lapangan : lapang
semestinya : mesti
dikritisi : kritisi
institusi : institusi
rombak : rombak
total : total
citra : citra
ujung : ujung
tanduk : tanduk
kegeraman : geram
publik : publik
sambo : sambo
muncul : muncul
irjen : irjen
teddy : teddy
minahasa : minahasa
kapolda : kapolda
jatim : jatim
terjerat : jerat
jual : jual
beli : beli
narkoba : narkoba
jualan : jual
risma : risma
prioritaskan : prioritas
bansos : bansos
hak : hak
luka : luka
lpsk : lpsk
dugaan : duga
pidana : pidana
kesimpulan : simpul
hasil : hasil
bertanggungjawab : bertanggungjawab
tragedikanjuruhan : tragedikanjuruhan
pelaku : laku
utama : utama
arema : arema
berdoa : doa
semoga : moga
lekas : lekas
bantuan : bantu
terealisasi : realisasi
khawatir : khawatir
benahi : benah
mendesak : desak
pengurus : urus
mengundurkan : undur
lib : lib
tandatangani : tandatangani
petisi : petisi
id : id
tolong : tolong
mawas : mawas
smuanya : smuanya
perkumpulan : kumpul
hajatan : hajat
seindonesia : indonesia
hatihati : hatihati
menahan : tahan
mengendalikan : kendali
emosi : emosi
jaga : jaga
kluarga : kluarga
ditunggu : tunggu
sikap : sikap
resmi : resmi
tewas : tewas
didu : didu
tuan : tuan
rumah : rumah
asia : asia
saingannya : saing
korsel : korsel
qatar : qatar
fasilitas : fasilitas
mendukung : dukung
udah : udah
masuk : masuk
politik : politik
agenda : agenda
padet : padet
appi : appi
klub : klub
sumbang : sumbang
rp : rp
juta : juta
halaman : halaman
bolasport : bolasport
kpppa : kpppa
pikir : pikir
diperiksa : periksa
ditetapkan : tetap
pelanggaran : langgar
ham : ham
berat : berat
penegak : tegak
hukum : hukum
ngeles : ngeles
gas : gas
air : air
mata : mata
menguap : uap
pelakunya : laku
bebas : bebas
sam : sam
munir : munir
merekomendasikan : rekomendasi
menggelar : gelar
kongres : kongres
kemarin : kemarin
data : data
banjir : banjir
longsor : longsor
pasukan : pasu
brimob : brimob
polda : polda
indikasi : indikasi
judi : judi
arteria : arteria
dahlan : dahlan
seri : seri
bandar : bandar
sudahuntung : sudahuntung
reformasi : reformasi
rasiman : rasiman
bicara : bicara
mentalitas : mentalitas
hillsborough : hillsborough
menyelamatkan : selamat
ri : ri
bpk : bpk
terimakasih : terimakasih
berperan : peran
membongkar : bongkar
kebobrokan : bobrok
panpel : panpel
stasiun : stasiun
broadcast : broadcast
lakilaki : lakilaki
perempuan : perempuan
aksi : aksi
solidaritas : solidaritas
aliansi : aliansi
kabupaten : kabupaten
madiun : madiun
deklarasi : deklarasi
damai : damai
wakil : wakil
dpr : dpr
dede : dede
yusuf : yusuf
mendorong : dorong
joko : joko
widodo : widodo
menindaklanjuti : menindaklanjuti
tgipftragedi : tgipftragedi
mo : mo
serahkan : serah
laporan : lapor
mengerikan : keri
pertemuan : temu
erick : erick
thohir : thohir
poin : poin
menarik : tarik
diprioritaskan : prioritas
dapatbansos : dapatbansos
negeri : negeri
ttg : ttg
betapa : betapa
biadabnya : biadab
dlm : dlm
dijadwalkan : jadwal
bertemu : temu
oktober : oktober
membahas : bahas
pembenahan : benah
menewaskan : tewas
ngeri : ngeri
isyana : isyana
bali : bal
meninggaldunia : meninggaldunia
{&#39;pemerintah&#39;: &#39;perintah&#39;, &#39;pastikan&#39;: &#39;pasti&#39;, &#39;piala&#39;: &#39;piala&#39;, &#39;dunia&#39;: &#39;dunia&#39;, &#39;digelar&#39;: &#39;gelar&#39;, &#39;indonesia&#39;: &#39;indonesia&#39;, &#39;ketua&#39;: &#39;ketua&#39;, &#39;tim&#39;: &#39;tim&#39;, &#39;gabungan&#39;: &#39;gabung&#39;, &#39;independen&#39;: &#39;independen&#39;, &#39;pencari&#39;: &#39;cari&#39;, &#39;fakta&#39;: &#39;fakta&#39;, &#39;tgipf&#39;: &#39;tgipf&#39;, &#39;tragedi&#39;: &#39;tragedi&#39;, &#39;kanjuruhan&#39;: &#39;kanjuruhan&#39;, &#39;mahfud&#39;: &#39;mahfud&#39;, &#39;md&#39;: &#39;md&#39;, &#39;pemalang&#39;: &#39;malang&#39;, &#39;kehilangan&#39;: &#39;hilang&#39;, &#39;megapixel&#39;: &#39;megapixel&#39;, &#39;anak&#39;: &#39;anak&#39;, &#39;korban&#39;: &#39;korban&#39;, &#39;percaya&#39;: &#39;percaya&#39;, &#39;mas&#39;: &#39;mas&#39;, &#39;orang&#39;: &#39;orang&#39;, &#39;sembarangan&#39;: &#39;sembarang&#39;, &#39;nggak&#39;: &#39;nggak&#39;, &#39;detail&#39;: &#39;detail&#39;, &#39;wkt&#39;: &#39;wkt&#39;, &#39;kick&#39;: &#39;kick&#39;, &#39;off&#39;: &#39;off&#39;, &#39;selesai&#39;: &#39;selesai&#39;, &#39;janji&#39;: &#39;janji&#39;, &#39;aremania&#39;: &#39;aremania&#39;, &#39;kawal&#39;: &#39;kawal&#39;, &#39;raih&#39;: &#39;raih&#39;, &#39;keadilan&#39;: &#39;adil&#39;, &#39;jokowi&#39;: &#39;jokowi&#39;, &#39;perintah&#39;: &#39;perintah&#39;, &#39;polri&#39;: &#39;polri&#39;, &#39;lanjutkan&#39;: &#39;lanjut&#39;, &#39;pendalaman&#39;: &#39;dalam&#39;, &#39;temuan&#39;: &#39;temu&#39;, &#39;el&#39;: &#39;el&#39;, &#39;rumi&#39;: &#39;rumi&#39;, &#39;kate&#39;: &#39;kate&#39;, &#39;presiden&#39;: &#39;presiden&#39;, &#39;ambil&#39;: &#39;ambil&#39;, &#39;langkah&#39;: &#39;langkah&#39;, &#39;konkret&#39;: &#39;konkret&#39;, &#39;sikapi&#39;: &#39;sikap&#39;, &#39;rekomendasi&#39;: &#39;rekomendasi&#39;, &#39;ahy&#39;: &#39;ahy&#39;, &#39;pemimpin&#39;: &#39;pimpin&#39;, &#39;perubahan&#39;: &#39;ubah&#39;, &#39;dokumen&#39;: &#39;dokumen&#39;, &#39;nama&#39;: &#39;nama&#39;, &#39;bertanggung&#39;: &#39;tanggung&#39;, &#39;kabar&#39;: &#39;kabar&#39;, &#39;dr&#39;: &#39;dr&#39;, &#39;kelanjutan&#39;: &#39;lanjut&#39;, &#39;investigasi&#39;: &#39;investigasi&#39;, &#39;so&#39;: &#39;so&#39;, &#39;far&#39;: &#39;far&#39;, &#39;pribadi&#39;: &#39;pribadi&#39;, &#39;puas&#39;: &#39;puas&#39;, &#39;hasilnya&#39;: &#39;hasil&#39;, &#39;bs&#39;: &#39;bs&#39;, &#39;berbuat&#39;: &#39;buat&#39;, &#39;cm&#39;: &#39;cm&#39;, &#39;butuh&#39;: &#39;butuh&#39;, &#39;keluarga&#39;: &#39;keluarga&#39;, &#39;polisi&#39;: &#39;polisi&#39;, &#39;pssi&#39;: &#39;pssi&#39;, &#39;msh&#39;: &#39;msh&#39;, &#39;malu&#39;: &#39;malu&#39;, &#39;udahlah&#39;: &#39;udahlah&#39;, &#39;cepet&#39;: &#39;cepet&#39;, &#39;tanggung&#39;: &#39;tanggung&#39;, &#39;buntut&#39;: &#39;buntut&#39;, &#39;instruksikan&#39;: &#39;instruksi&#39;, &#39;stadion&#39;: &#39;stadion&#39;, &#39;diupgrade&#39;: &#39;diupgrade&#39;, &#39;aman&#39;: &#39;aman&#39;, &#39;nyaman&#39;: &#39;nyaman&#39;, &#39;keselamatan&#39;: &#39;selamat&#39;, &#39;kenyamanan&#39;: &#39;nyaman&#39;, &#39;penonton&#39;: &#39;tonton&#39;, &#39;sepak&#39;: &#39;sepak&#39;, &#39;bola&#39;: &#39;bola&#39;, &#39;simak&#39;: &#39;simak&#39;, &#39;edisi&#39;: &#39;edisi&#39;, &#39;terbaru&#39;: &#39;baru&#39;, &#39;klik&#39;: &#39;klik&#39;, &#39;baguss&#39;: &#39;baguss&#39;, &#39;kakk&#39;: &#39;kakk&#39;, &#39;posternya&#39;: &#39;poster&#39;, &#39;informatif&#39;: &#39;informatif&#39;, &#39;langsung&#39;: &#39;langsung&#39;, &#39;semangat&#39;: &#39;semangat&#39;, &#39;mengusut&#39;: &#39;usut&#39;, &#39;minggu&#39;: &#39;minggu&#39;, &#39;gelar&#39;: &#39;gelar&#39;, &#39;rekonstruksi&#39;: &#39;rekonstruksi&#39;, &#39;autopsi&#39;: &#39;autopsi&#39;, &#39;jenazah&#39;: &#39;jenazah&#39;, &#39;kahmi&#39;: &#39;kahmi&#39;, &#39;forum&#39;: &#39;forum&#39;, &#39;bahas&#39;: &#39;bahas&#39;, &#39;kemanusiaan&#39;: &#39;manusia&#39;, &#39;stadionkanjuruhan&#39;: &#39;stadionkanjuruhan&#39;, &#39;mbah&#39;: &#39;mbah&#39;, &#39;gimana&#39;: &#39;gimana&#39;, &#39;wali&#39;: &#39;wali&#39;, &#39;kota&#39;: &#39;kota&#39;, &#39;sutiaji&#39;: &#39;sutiaji&#39;, &#39;gala&#39;: &#39;gala&#39;, &#39;dinner&#39;: &#39;dinner&#39;, &#39;balaikota&#39;: &#39;balaikota&#39;, &#39;malang&#39;: &#39;malang&#39;, &#39;dihadiri&#39;: &#39;hadir&#39;, &#39;pemain&#39;: &#39;main&#39;, &#39;ofisial&#39;: &#39;ofisial&#39;, &#39;perangkat&#39;: &#39;perangkat&#39;, &#39;pertandingan&#39;: &#39;tanding&#39;, &#39;panitia&#39;: &#39;panitia&#39;, &#39;kesuksesan&#39;: &#39;sukses&#39;, &#39;turnamen&#39;: &#39;turnamen&#39;, &#39;suntikan&#39;: &#39;sunti&#39;, &#39;moril&#39;: &#39;moril&#39;, &#39;pasca&#39;: &#39;pasca&#39;, &#39;lukanya&#39;: &#39;luka&#39;, &#39;dirasakan&#39;: &#39;rasa&#39;, &#39;masyarakat&#39;: &#39;masyarakat&#39;, &#39;luas&#39;: &#39;luas&#39;, &#39;tanggapi&#39;: &#39;tanggap&#39;, &#39;klb&#39;: &#39;klb&#39;, &#39;umuh&#39;: &#39;umuh&#39;, &#39;muchtar&#39;: &#39;muchtar&#39;, &#39;alasannya&#39;: &#39;alas&#39;, &#39;baca&#39;: &#39;baca&#39;, &#39;berita&#39;: &#39;berita&#39;, &#39;media&#39;: &#39;media&#39;, &#39;tindakan&#39;: &#39;tindak&#39;, &#39;sangattdk&#39;: &#39;sangattdk&#39;, &#39;manusiawi&#39;: &#39;manusiawi&#39;, &#39;berani&#39;: &#39;berani&#39;, &#39;aparat&#39;: &#39;aparat&#39;, &#39;keamanan&#39;: &#39;aman&#39;, &#39;pergi&#39;: &#39;pergi&#39;, &#39;papua&#39;: &#39;papua&#39;, &#39;lawanlah&#39;: &#39;lawan&#39;, &#39;kelompok&#39;: &#39;kelompok&#39;, &#39;kriminal&#39;: &#39;kriminal&#39;, &#39;bersenjatakkbdisana&#39;: &#39;bersenjatakkbdisana&#39;, &#39;bertindaklah&#39;: &#39;tindak&#39;, &#39;wajar&#39;: &#39;wajar&#39;, &#39;rakyat&#39;: &#39;rakyat&#39;, &#39;karna&#39;: &#39;karna&#39;, &#39;rakyatlahkalian&#39;: &#39;rakyatlahkalian&#39;, &#39;hormati&#39;: &#39;hormat&#39;, &#39;terkait&#39;: &#39;kait&#39;, &#39;bupati&#39;: &#39;bupati&#39;, &#39;jember&#39;: &#39;jember&#39;, &#39;alhamdulillah&#39;: &#39;alhamdulillah&#39;, &#39;ditangani&#39;: &#39;tangan&#39;, &#39;denganbaik&#39;: &#39;denganbaik&#39;, &#39;periksa&#39;: &#39;periksa&#39;, &#39;saksi&#39;: &#39;saksi&#39;, &#39;tambahan&#39;: &#39;tambah&#39;, &#39;pegiat&#39;: &#39;giat&#39;, &#39;olahraga&#39;: &#39;olahraga&#39;, &#39;sepakbola&#39;: &#39;sepakbola&#39;, &#39;evaluasi&#39;: &#39;evaluasi&#39;, &#39;suporter&#39;: &#39;suporter&#39;, &#39;hormatiketertiban&#39;: &#39;hormatiketertiban&#39;, &#39;kementerian&#39;: &#39;menteri&#39;, &#39;pppa&#39;: &#39;pppa&#39;, &#39;meninggal&#39;: &#39;tinggal&#39;, &#39;komisi&#39;: &#39;komisi&#39;, &#39;hilang&#39;: &#39;hilang&#39;, &#39;tindak&#39;: &#39;tindak&#39;, &#39;kekerasan&#39;: &#39;keras&#39;, &#39;kontras&#39;: &#39;kontras&#39;, &#39;mendampingi&#39;: &#39;damping&#39;, &#39;tpf&#39;: &#39;tpf&#39;, &#39;menemukan&#39;: &#39;temu&#39;, &#39;intimidasi&#39;: &#39;intimidasi&#39;, &#39;selengkapnya&#39;: &#39;lengkap&#39;, &#39;gamblang&#39;: &#39;gamblang&#39;, &#39;bangsa&#39;: &#39;bangsa&#39;, &#39;kalah&#39;: &#39;kalah&#39;, &#39;kejadian&#39;: &#39;jadi&#39;, &#39;dijadikan&#39;: &#39;jadi&#39;, &#39;momentum&#39;: &#39;momentum&#39;, &#39;kebangkitan&#39;: &#39;bangkit&#39;, &#39;com&#39;: &#39;com&#39;, &#39;onlineindo&#39;: &#39;onlineindo&#39;, &#39;news&#39;: &#39;news&#39;, &#39;alvin&#39;: &#39;alvin&#39;, &#39;lim&#39;: &#39;lim&#39;, &#39;didalangi&#39;: &#39;dalang&#39;, &#39;konso&#39;: &#39;konso&#39;, &#39;kanjuruhansekarang&#39;: &#39;kanjuruhansekarang&#39;, &#39;tugas&#39;: &#39;tugas&#39;, &#39;publuk&#39;: &#39;publuk&#39;, &#39;mengawasi&#39;: &#39;awas&#39;, &#39;rekomendasirekomendasi&#39;: &#39;rekomendasirekomendasi&#39;, &#39;dijalankan&#39;: &#39;jalan&#39;, &#39;akmal&#39;: &#39;akmal&#39;, &#39;marhali&#39;: &#39;marhali&#39;, &#39;anggota&#39;: &#39;anggota&#39;, &#39;menjadwalkan&#39;: &#39;jadwal&#39;, &#39;rekontruksi&#39;: &#39;rekontruksi&#39;, &#39;ulang&#39;: &#39;ulang&#39;, &#39;dibutuhkan&#39;: &#39;butuh&#39;, &#39;rangka&#39;: &#39;rangka&#39;, &#39;proses&#39;: &#39;proses&#39;, &#39;pembuktian&#39;: &#39;bukti&#39;, &#39;cepat&#39;: &#39;cepat&#39;, &#39;ditemukan&#39;: &#39;temu&#39;, &#39;permulaan&#39;: &#39;mula&#39;, &#39;terungkap&#39;: &#39;ungkap&#39;, &#39;fifa&#39;: &#39;fifa&#39;, &#39;senin&#39;: &#39;senin&#39;, &#39;morninggg&#39;: &#39;morninggg&#39;, &#39;drake&#39;: &#39;drake&#39;, &#39;cairan&#39;: &#39;cair&#39;, &#39;haram&#39;: &#39;haram&#39;, &#39;dpt&#39;: &#39;dpt&#39;, &#39;mempersatukan&#39;: &#39;satu&#39;, &#39;bongdrun&#39;: &#39;bongdrun&#39;, &#39;mreka&#39;: &#39;mreka&#39;, &#39;spakat&#39;: &#39;spakat&#39;, &#39;pembantaian&#39;: &#39;bantai&#39;, &#39;smentara&#39;: &#39;smentara&#39;, &#39;takdir&#39;: &#39;takdir&#39;, &#39;diskriminasi&#39;: &#39;diskriminasi&#39;, &#39;dzolim&#39;: &#39;dzolim&#39;, &#39;aturan&#39;: &#39;atur&#39;, &#39;menolak&#39;: &#39;tolak&#39;, &#39;vaksin&#39;: &#39;vaksin&#39;, &#39;salah&#39;: &#39;salah&#39;, &#39;detiksport&#39;: &#39;detiksport&#39;, &#39;buruburu&#39;: &#39;buruburu&#39;, &#39;bubar&#39;: &#39;bubar&#39;, &#39;psm&#39;: &#39;psm&#39;, &#39;makassar&#39;: &#39;makassar&#39;, &#39;memilih&#39;: &#39;pilih&#39;, &#39;meliburkan&#39;: &#39;libur&#39;, &#39;kompetisi&#39;: &#39;kompetisi&#39;, &#39;liga&#39;: &#39;liga&#39;, &#39;kepastian&#39;: &#39;pasti&#39;, &#39;pascatragedi&#39;: &#39;pascatragedi&#39;, &#39;berpijak&#39;: &#39;pijak&#39;, &#39;kebenaran&#39;: &#39;benar&#39;, &#39;kebanyakan&#39;: &#39;banyak&#39;, &#39;faktafakta&#39;: &#39;faktafakta&#39;, &#39;diangkat&#39;: &#39;angkat&#39;, &#39;framingframing&#39;: &#39;framingframing&#39;, &#39;menghilangkan&#39;: &#39;hilang&#39;, &#39;lapangan&#39;: &#39;lapang&#39;, &#39;semestinya&#39;: &#39;mesti&#39;, &#39;dikritisi&#39;: &#39;kritisi&#39;, &#39;institusi&#39;: &#39;institusi&#39;, &#39;rombak&#39;: &#39;rombak&#39;, &#39;total&#39;: &#39;total&#39;, &#39;citra&#39;: &#39;citra&#39;, &#39;ujung&#39;: &#39;ujung&#39;, &#39;tanduk&#39;: &#39;tanduk&#39;, &#39;kegeraman&#39;: &#39;geram&#39;, &#39;publik&#39;: &#39;publik&#39;, &#39;sambo&#39;: &#39;sambo&#39;, &#39;muncul&#39;: &#39;muncul&#39;, &#39;irjen&#39;: &#39;irjen&#39;, &#39;teddy&#39;: &#39;teddy&#39;, &#39;minahasa&#39;: &#39;minahasa&#39;, &#39;kapolda&#39;: &#39;kapolda&#39;, &#39;jatim&#39;: &#39;jatim&#39;, &#39;terjerat&#39;: &#39;jerat&#39;, &#39;jual&#39;: &#39;jual&#39;, &#39;beli&#39;: &#39;beli&#39;, &#39;narkoba&#39;: &#39;narkoba&#39;, &#39;jualan&#39;: &#39;jual&#39;, &#39;risma&#39;: &#39;risma&#39;, &#39;prioritaskan&#39;: &#39;prioritas&#39;, &#39;bansos&#39;: &#39;bansos&#39;, &#39;hak&#39;: &#39;hak&#39;, &#39;luka&#39;: &#39;luka&#39;, &#39;lpsk&#39;: &#39;lpsk&#39;, &#39;dugaan&#39;: &#39;duga&#39;, &#39;pidana&#39;: &#39;pidana&#39;, &#39;kesimpulan&#39;: &#39;simpul&#39;, &#39;hasil&#39;: &#39;hasil&#39;, &#39;bertanggungjawab&#39;: &#39;bertanggungjawab&#39;, &#39;tragedikanjuruhan&#39;: &#39;tragedikanjuruhan&#39;, &#39;pelaku&#39;: &#39;laku&#39;, &#39;utama&#39;: &#39;utama&#39;, &#39;arema&#39;: &#39;arema&#39;, &#39;berdoa&#39;: &#39;doa&#39;, &#39;semoga&#39;: &#39;moga&#39;, &#39;lekas&#39;: &#39;lekas&#39;, &#39;bantuan&#39;: &#39;bantu&#39;, &#39;terealisasi&#39;: &#39;realisasi&#39;, &#39;khawatir&#39;: &#39;khawatir&#39;, &#39;benahi&#39;: &#39;benah&#39;, &#39;mendesak&#39;: &#39;desak&#39;, &#39;pengurus&#39;: &#39;urus&#39;, &#39;mengundurkan&#39;: &#39;undur&#39;, &#39;lib&#39;: &#39;lib&#39;, &#39;tandatangani&#39;: &#39;tandatangani&#39;, &#39;petisi&#39;: &#39;petisi&#39;, &#39;id&#39;: &#39;id&#39;, &#39;tolong&#39;: &#39;tolong&#39;, &#39;mawas&#39;: &#39;mawas&#39;, &#39;smuanya&#39;: &#39;smuanya&#39;, &#39;perkumpulan&#39;: &#39;kumpul&#39;, &#39;hajatan&#39;: &#39;hajat&#39;, &#39;seindonesia&#39;: &#39;indonesia&#39;, &#39;hatihati&#39;: &#39;hatihati&#39;, &#39;menahan&#39;: &#39;tahan&#39;, &#39;mengendalikan&#39;: &#39;kendali&#39;, &#39;emosi&#39;: &#39;emosi&#39;, &#39;jaga&#39;: &#39;jaga&#39;, &#39;kluarga&#39;: &#39;kluarga&#39;, &#39;ditunggu&#39;: &#39;tunggu&#39;, &#39;sikap&#39;: &#39;sikap&#39;, &#39;resmi&#39;: &#39;resmi&#39;, &#39;tewas&#39;: &#39;tewas&#39;, &#39;didu&#39;: &#39;didu&#39;, &#39;tuan&#39;: &#39;tuan&#39;, &#39;rumah&#39;: &#39;rumah&#39;, &#39;asia&#39;: &#39;asia&#39;, &#39;saingannya&#39;: &#39;saing&#39;, &#39;korsel&#39;: &#39;korsel&#39;, &#39;qatar&#39;: &#39;qatar&#39;, &#39;fasilitas&#39;: &#39;fasilitas&#39;, &#39;mendukung&#39;: &#39;dukung&#39;, &#39;udah&#39;: &#39;udah&#39;, &#39;masuk&#39;: &#39;masuk&#39;, &#39;politik&#39;: &#39;politik&#39;, &#39;agenda&#39;: &#39;agenda&#39;, &#39;padet&#39;: &#39;padet&#39;, &#39;appi&#39;: &#39;appi&#39;, &#39;klub&#39;: &#39;klub&#39;, &#39;sumbang&#39;: &#39;sumbang&#39;, &#39;rp&#39;: &#39;rp&#39;, &#39;juta&#39;: &#39;juta&#39;, &#39;halaman&#39;: &#39;halaman&#39;, &#39;bolasport&#39;: &#39;bolasport&#39;, &#39;kpppa&#39;: &#39;kpppa&#39;, &#39;pikir&#39;: &#39;pikir&#39;, &#39;diperiksa&#39;: &#39;periksa&#39;, &#39;ditetapkan&#39;: &#39;tetap&#39;, &#39;pelanggaran&#39;: &#39;langgar&#39;, &#39;ham&#39;: &#39;ham&#39;, &#39;berat&#39;: &#39;berat&#39;, &#39;penegak&#39;: &#39;tegak&#39;, &#39;hukum&#39;: &#39;hukum&#39;, &#39;ngeles&#39;: &#39;ngeles&#39;, &#39;gas&#39;: &#39;gas&#39;, &#39;air&#39;: &#39;air&#39;, &#39;mata&#39;: &#39;mata&#39;, &#39;menguap&#39;: &#39;uap&#39;, &#39;pelakunya&#39;: &#39;laku&#39;, &#39;bebas&#39;: &#39;bebas&#39;, &#39;sam&#39;: &#39;sam&#39;, &#39;munir&#39;: &#39;munir&#39;, &#39;merekomendasikan&#39;: &#39;rekomendasi&#39;, &#39;menggelar&#39;: &#39;gelar&#39;, &#39;kongres&#39;: &#39;kongres&#39;, &#39;kemarin&#39;: &#39;kemarin&#39;, &#39;data&#39;: &#39;data&#39;, &#39;banjir&#39;: &#39;banjir&#39;, &#39;longsor&#39;: &#39;longsor&#39;, &#39;pasukan&#39;: &#39;pasu&#39;, &#39;brimob&#39;: &#39;brimob&#39;, &#39;polda&#39;: &#39;polda&#39;, &#39;indikasi&#39;: &#39;indikasi&#39;, &#39;judi&#39;: &#39;judi&#39;, &#39;arteria&#39;: &#39;arteria&#39;, &#39;dahlan&#39;: &#39;dahlan&#39;, &#39;seri&#39;: &#39;seri&#39;, &#39;bandar&#39;: &#39;bandar&#39;, &#39;sudahuntung&#39;: &#39;sudahuntung&#39;, &#39;reformasi&#39;: &#39;reformasi&#39;, &#39;rasiman&#39;: &#39;rasiman&#39;, &#39;bicara&#39;: &#39;bicara&#39;, &#39;mentalitas&#39;: &#39;mentalitas&#39;, &#39;hillsborough&#39;: &#39;hillsborough&#39;, &#39;menyelamatkan&#39;: &#39;selamat&#39;, &#39;ri&#39;: &#39;ri&#39;, &#39;bpk&#39;: &#39;bpk&#39;, &#39;terimakasih&#39;: &#39;terimakasih&#39;, &#39;berperan&#39;: &#39;peran&#39;, &#39;membongkar&#39;: &#39;bongkar&#39;, &#39;kebobrokan&#39;: &#39;bobrok&#39;, &#39;panpel&#39;: &#39;panpel&#39;, &#39;stasiun&#39;: &#39;stasiun&#39;, &#39;broadcast&#39;: &#39;broadcast&#39;, &#39;lakilaki&#39;: &#39;lakilaki&#39;, &#39;perempuan&#39;: &#39;perempuan&#39;, &#39;aksi&#39;: &#39;aksi&#39;, &#39;solidaritas&#39;: &#39;solidaritas&#39;, &#39;aliansi&#39;: &#39;aliansi&#39;, &#39;kabupaten&#39;: &#39;kabupaten&#39;, &#39;madiun&#39;: &#39;madiun&#39;, &#39;deklarasi&#39;: &#39;deklarasi&#39;, &#39;damai&#39;: &#39;damai&#39;, &#39;wakil&#39;: &#39;wakil&#39;, &#39;dpr&#39;: &#39;dpr&#39;, &#39;dede&#39;: &#39;dede&#39;, &#39;yusuf&#39;: &#39;yusuf&#39;, &#39;mendorong&#39;: &#39;dorong&#39;, &#39;joko&#39;: &#39;joko&#39;, &#39;widodo&#39;: &#39;widodo&#39;, &#39;menindaklanjuti&#39;: &#39;menindaklanjuti&#39;, &#39;tgipftragedi&#39;: &#39;tgipftragedi&#39;, &#39;mo&#39;: &#39;mo&#39;, &#39;serahkan&#39;: &#39;serah&#39;, &#39;laporan&#39;: &#39;lapor&#39;, &#39;mengerikan&#39;: &#39;keri&#39;, &#39;pertemuan&#39;: &#39;temu&#39;, &#39;erick&#39;: &#39;erick&#39;, &#39;thohir&#39;: &#39;thohir&#39;, &#39;poin&#39;: &#39;poin&#39;, &#39;menarik&#39;: &#39;tarik&#39;, &#39;diprioritaskan&#39;: &#39;prioritas&#39;, &#39;dapatbansos&#39;: &#39;dapatbansos&#39;, &#39;negeri&#39;: &#39;negeri&#39;, &#39;ttg&#39;: &#39;ttg&#39;, &#39;betapa&#39;: &#39;betapa&#39;, &#39;biadabnya&#39;: &#39;biadab&#39;, &#39;dlm&#39;: &#39;dlm&#39;, &#39;dijadwalkan&#39;: &#39;jadwal&#39;, &#39;bertemu&#39;: &#39;temu&#39;, &#39;oktober&#39;: &#39;oktober&#39;, &#39;membahas&#39;: &#39;bahas&#39;, &#39;pembenahan&#39;: &#39;benah&#39;, &#39;menewaskan&#39;: &#39;tewas&#39;, &#39;ngeri&#39;: &#39;ngeri&#39;, &#39;isyana&#39;: &#39;isyana&#39;, &#39;bali&#39;: &#39;bal&#39;, &#39;meninggaldunia&#39;: &#39;meninggaldunia&#39;}
------------------------
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "ae6804792f2143748e4301d7de98621c", "version_major": 2, "version_minor": 0}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     [perintah, pasti, piala, dunia, gelar, indones...
1     [perintah, pasti, piala, dunia, gelar, indones...
2                   [anak, korban, tragedi, kanjuruhan]
3     [percaya, mas, orang, sembarang, mas, nggak, d...
4     [janji, aremania, kawal, tragedi, kanjuruhan, ...
                            ...                        
95    [tragedi, kanjuruhan, menteri, pppa, anak, men...
96    [risma, prioritas, anak, korban, tragedi, kanj...
97    [risma, prioritas, anak, korban, tragedi, kanj...
98                   [laku, utama, tragedi, kanjuruhan]
99    [risma, prioritas, anak, korban, tragedi, kanj...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tweets</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;Prepocessing.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id20">
<h3>Term Frequncy(TF)<a class="headerlink" href="#id20" title="Permalink to this headline">#</a></h3>
<p>Term Frequency(TF) merupakan banyaknya jumlah kemunculan term pada suatu dokumen. Untuk menghitung nilai TF terdapat beberapa cara, cara yang paling sederhana ialah dengan menghitung banyaknya jumlah kemunculan kata dalam 1 dokumen.<br>
Sedangkan untuk menghitung nilai TF dengan menggunakan mesin dapat menggunakan library sklearn dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span><span class="p">,</span> <span class="n">TfidfVectorizer</span><span class="p">,</span> <span class="n">CountVectorizer</span>
<span class="c1">#Membuat Dataframe</span>
<span class="n">dataTextPre</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Prepocessing.csv&#39;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">bag</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">dataTextPre</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">])</span>
<span class="n">dataTextPre</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-a6b97a26-18c0-4416-b8b9-5e3e04a961ba">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tweet</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>['perintah', 'pasti', 'piala', 'dunia', 'gelar...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>['perintah', 'pasti', 'piala', 'dunia', 'gelar...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>['anak', 'korban', 'tragedi', 'kanjuruhan']</td>
    </tr>
    <tr>
      <th>3</th>
      <td>['percaya', 'mas', 'orang', 'sembarang', 'mas'...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>['janji', 'aremania', 'kawal', 'tragedi', 'kan...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>['tragedi', 'kanjuruhan', 'menteri', 'pppa', '...</td>
    </tr>
    <tr>
      <th>96</th>
      <td>['risma', 'prioritas', 'anak', 'korban', 'trag...</td>
    </tr>
    <tr>
      <th>97</th>
      <td>['risma', 'prioritas', 'anak', 'korban', 'trag...</td>
    </tr>
    <tr>
      <th>98</th>
      <td>['laku', 'utama', 'tragedi', 'kanjuruhan']</td>
    </tr>
    <tr>
      <th>99</th>
      <td>['risma', 'prioritas', 'anak', 'korban', 'trag...</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 1 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-a6b97a26-18c0-4416-b8b9-5e3e04a961ba')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-a6b97a26-18c0-4416-b8b9-5e3e04a961ba button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-a6b97a26-18c0-4416-b8b9-5e3e04a961ba');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<section id="id21">
<h4>Matrik VSM(Visual Space Model)<a class="headerlink" href="#id21" title="Permalink to this headline">#</a></h4>
<p>Sebelum menghitung nilai TF, terlebih dahulu buat matrik vsm untuk menentukan bobot nilai term pada dokumen dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">matrik_vsm</span> <span class="o">=</span> <span class="n">bag</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="c1">#print(matrik_vsm)</span>
<span class="n">matrik_vsm</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(100, 411)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">matrik_vsm</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
</pre></div>
</div>
</div>
</div>
<p>Untuk menampilkan nilai TF yang didapat menggunakan source code berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span><span class="o">=</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">matrik_vsm</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]))</span>
<span class="c1">#dfb =pd.DataFrame(data=matrik_vsm,index=df,columns=[a])</span>
<span class="n">dataTF</span> <span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">matrik_vsm</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">matrik_vsm</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">)),</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>
<span class="n">dataTF</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;TF.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dataTF</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100
</pre></div>
</div>
<div class="output text_html">
  <div id="df-53b3ef1f-d6fd-44da-b749-398eb94d2aa0">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>adil</th>
      <th>agenda</th>
      <th>ahy</th>
      <th>air</th>
      <th>akmal</th>
      <th>aksi</th>
      <th>alas</th>
      <th>alhamdulillah</th>
      <th>aliansi</th>
      <th>alvin</th>
      <th>...</th>
      <th>urus</th>
      <th>usut</th>
      <th>utama</th>
      <th>vaksin</th>
      <th>wajar</th>
      <th>wakil</th>
      <th>wali</th>
      <th>widodo</th>
      <th>wkt</th>
      <th>yusuf</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>96</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>97</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>98</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>99</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>100</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 411 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-53b3ef1f-d6fd-44da-b749-398eb94d2aa0')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-53b3ef1f-d6fd-44da-b749-398eb94d2aa0 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-53b3ef1f-d6fd-44da-b749-398eb94d2aa0');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
</section>
</section>
<section id="id22">
<h3>Klustering Data<a class="headerlink" href="#id22" title="Permalink to this headline">#</a></h3>
<p>Clustering adalah suatu kegiatan mengelompokkan dokumen berdasarkan pada karakteristik yang terkandung di dalamnya. Proses analisa clustering pada intinya terdapat dua tahapan :<br>
yang pertama mentransformasi document ke dalam bentuk quantitative data, dan<br>
yang kedua menganalisa dokumen dalam bentuk quantitative data tersebut dengan metode clustering yang ditentukan.<br>
Untuk proses tahapan kedua ada berbagai jenis metode clustering yang bisa digunakan. Diantara metode-metode tersebut ialah metode K-Means, mixture modelling atau tulisan-tulisan clustering lainnya.<br></p>
<p>Yang umumnya menjadi permasalahan dalam pelaksanaan clustering ini adalah bagaimana cara merepresentasikan dokumen ke dalam bentuk data quantitative. Ada beberapa cara yang umum digunakan, salah satunya adalah Vector Space Model(VSM) yang merepresentasikan dokumen ke dalam bentuk vector dari term yang muncul dalam dokumen yang dianalisa. Salah satu bentuk representasinya adalah term-frequency (TF) vector yang bisa dilambangkan dengan :<br>
$<span class="math notranslate nohighlight">\(dtf = (tf_1, tf_2, . . . , tf_m)\)</span><span class="math notranslate nohighlight">\(
dimana&lt;br&gt;
\)</span>tf_i$ : adalah frekuensi dari term ke-i di dalam suatu dokumen.<br>
Kemudian selanjutnya untuk menganalisa dokumen yang sudah dalam bentuk quantitative dengan menggunakan metode K-Means dijelaskan seperti berikut.</p>
<section id="id23">
<h4>K-Means Clustering<a class="headerlink" href="#id23" title="Permalink to this headline">#</a></h4>
<p>K-Means clustering adalah algoritma untuk membagi n pengamatan menjadi k kelompok sedemikian hingga tiap pengamatan termasuk ke dalam kelompok dengan rata-rata terdekat (titik tengah kelompok). Algoritma ini memiliki hubungan yang renggang dengan algoritma KNN, algoritma pemelajaran mesin yang cukup terkenal dan sering disalah artikan dengan K-Means karena kemiripan namanya.<br>
Algoritme pengklasteran k rata-rata adalah sebagai berikut.<br></p>
<ol class="simple">
<li><p>Pilih k buah titik tengah secara acak.<br></p></li>
<li><p>Kelompokkan data sehingga terbentuk k buah kelompok dengan titik tengah tiap kelompok merupakan titik tengah yang telah dipilih sebelumnya.<br></p></li>
<li><p>Perbarui nilai titik tengah tiap kelompok.<br></p></li>
<li><p>Ulangi langkah 2 dan 3 sampai titik tengah semua kelompok tidak lagi berubah.<br></p></li>
</ol>
<p>Proses pengklasteran data ke dalam suatu kelompok dapat dilakukan dengan cara menghitung jarak terdekat dari suatu data ke sebuah titik tengah. Perhitungan jarak Minkowski dapat digunakan untuk menghitung jarak antara 2 buah data.</p>
<p>Pembaruan titik tengah dapat dilakukan dengan rumus berikut:<br></p>
<div class="math notranslate nohighlight">
\[{\displaystyle \mu _{k}={\frac {1}{N_{k}}}\sum _{j=1}^{N_{k}}x_{j}}\]</div>
<p>dengan <span class="math notranslate nohighlight">\(µk\)</span> adalah titik tengah kelompok ke-k, <span class="math notranslate nohighlight">\(Nk\)</span> adalah banyak data dalam kelompok ke-k, dan <span class="math notranslate nohighlight">\(xj\)</span> adalah data ke-j dalam kelompok ke-k.<br>
Untuk melakukan clustering dengan menggunakan mesin dapat menggunakan library sklearn seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="n">Kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">Kmeans</span> <span class="o">=</span> <span class="n">Kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataTF</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">Kmeans</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dataTF</span><span class="p">)</span>
<span class="n">centroids</span> <span class="o">=</span> <span class="n">Kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Kmeans</span><span class="o">.</span><span class="n">labels_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([2, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,
       1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 1,
       0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1], dtype=int32)
</pre></div>
</div>
</div>
</div>
</section>
<section id="id24">
<h4>Hasil Clustering<a class="headerlink" href="#id24" title="Permalink to this headline">#</a></h4>
<p>Hasil kluster dengan menggunakan metode K-Means ialah sebagai berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataTF</span><span class="p">[</span><span class="s1">&#39;Cluster_Id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Kmeans</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">dataTF</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-a0b20e61-5be9-42f1-9dd1-753c508025dd">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>adil</th>
      <th>agenda</th>
      <th>ahy</th>
      <th>air</th>
      <th>akmal</th>
      <th>aksi</th>
      <th>alas</th>
      <th>alhamdulillah</th>
      <th>aliansi</th>
      <th>alvin</th>
      <th>...</th>
      <th>usut</th>
      <th>utama</th>
      <th>vaksin</th>
      <th>wajar</th>
      <th>wakil</th>
      <th>wali</th>
      <th>widodo</th>
      <th>wkt</th>
      <th>yusuf</th>
      <th>Cluster_Id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>96</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>97</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>98</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>99</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>100</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 412 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-a0b20e61-5be9-42f1-9dd1-753c508025dd')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-a0b20e61-5be9-42f1-9dd1-753c508025dd button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-a0b20e61-5be9-42f1-9dd1-753c508025dd');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<p>Jumlah dari masing-masing kluster dengan 3 kluster sebagai berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">unique</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">Kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">dict_data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unique</span><span class="p">,</span> <span class="n">counts</span><span class="p">))</span>
<span class="n">dict_data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{0: 61, 1: 34, 2: 5}
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id25">
<h3>Kesimpulan<a class="headerlink" href="#id25" title="Permalink to this headline">#</a></h3>
<p>Berdasar dari proses klustering data dengan menggunakan 3 kluster dari 100 data diperoleh 80 data berkluster dengan id = 0, dan 9 data berkluster dengan id = 1, serta 11 data berkluster dengan id = 2.</p>
</section>
</section>
<section id="ringkasan-berita-dengan-pagerank">
<h2><strong>2. Ringkasan Berita dengan PageRank</strong><a class="headerlink" href="#ringkasan-berita-dengan-pagerank" title="Permalink to this headline">#</a></h2>
<section id="id26">
<h3>Mengambil Dokumen<a class="headerlink" href="#id26" title="Permalink to this headline">#</a></h3>
<p>Langkah awal untuk melakukan ekstraksi ringkasan dokumen ialah dengan mengambil dokumen tersebut dengan mengcrawling data dokumen dengan menggunakan scrapy &amp; crochet seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">cd</span> /content
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/content
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install scrapy
<span class="o">!</span>pip install crochet
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting scrapy
  Downloading Scrapy-2.6.3-py2.py3-none-any.whl (264 kB)
     |████████████████████████████████| 264 kB 5.4 MB/s 
?25hCollecting cssselect&gt;=0.9.1
  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)
Collecting Twisted&gt;=18.9.0
  Downloading Twisted-22.8.0-py3-none-any.whl (3.1 MB)
     |████████████████████████████████| 3.1 MB 46.5 MB/s 
?25hCollecting service-identity&gt;=18.1.0
  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)
Collecting itemadapter&gt;=0.1.0
  Downloading itemadapter-0.7.0-py3-none-any.whl (10 kB)
Requirement already satisfied: lxml&gt;=3.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (4.9.1)
Collecting protego&gt;=0.1.15
  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)
Collecting pyOpenSSL&gt;=21.0.0
  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)
     |████████████████████████████████| 57 kB 4.3 MB/s 
?25hCollecting queuelib&gt;=1.4.2
  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)
Collecting w3lib&gt;=1.17.0
  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)
Collecting zope.interface&gt;=5.0.0
  Downloading zope.interface-5.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (254 kB)
     |████████████████████████████████| 254 kB 50.9 MB/s 
?25hCollecting PyDispatcher&gt;=2.0.5
  Downloading PyDispatcher-2.0.6.tar.gz (38 kB)
Collecting itemloaders&gt;=1.0.1
  Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)
Collecting cryptography&gt;=3.3
  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)
     |████████████████████████████████| 4.0 MB 35.4 MB/s 
?25hCollecting tldextract
  Downloading tldextract-3.4.0-py3-none-any.whl (93 kB)
     |████████████████████████████████| 93 kB 2.7 MB/s 
?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from scrapy) (57.4.0)
Collecting parsel&gt;=1.5.0
  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)
Requirement already satisfied: cffi&gt;=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography&gt;=3.3-&gt;scrapy) (1.15.1)
Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi&gt;=1.12-&gt;cryptography&gt;=3.3-&gt;scrapy) (2.21)
Collecting jmespath&gt;=0.9.5
  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)
Requirement already satisfied: six&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from parsel&gt;=1.5.0-&gt;scrapy) (1.15.0)
Requirement already satisfied: attrs&gt;=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity&gt;=18.1.0-&gt;scrapy) (22.1.0)
Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity&gt;=18.1.0-&gt;scrapy) (0.4.8)
Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity&gt;=18.1.0-&gt;scrapy) (0.2.8)
Collecting incremental&gt;=21.3.0
  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)
Collecting hyperlink&gt;=17.1.1
  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)
     |████████████████████████████████| 74 kB 3.4 MB/s 
?25hCollecting constantly&gt;=15.1
  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)
Requirement already satisfied: typing-extensions&gt;=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=18.9.0-&gt;scrapy) (4.1.1)
Collecting Automat&gt;=0.8.0
  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)
Requirement already satisfied: idna&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink&gt;=17.1.1-&gt;Twisted&gt;=18.9.0-&gt;scrapy) (2.10)
Requirement already satisfied: requests&gt;=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract-&gt;scrapy) (2.28.1)
Collecting requests-file&gt;=1.4
  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)
Requirement already satisfied: filelock&gt;=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract-&gt;scrapy) (3.8.0)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.1.0-&gt;tldextract-&gt;scrapy) (1.26.12)
Requirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.1.0-&gt;tldextract-&gt;scrapy) (2.1.1)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.1.0-&gt;tldextract-&gt;scrapy) (2022.9.24)
Building wheels for collected packages: PyDispatcher
  Building wheel for PyDispatcher (setup.py) ... ?25l?25hdone
  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.6-py3-none-any.whl size=11958 sha256=f24b4fb7bbc8a17a5c4ff7f1e287de9f21b58debb5934b5635eeb72b0ea2de94
  Stored in directory: /root/.cache/pip/wheels/c9/d6/6a/de198d890277cde60ca3dbebe7ae592d3b381c7d9bb2455f4d
Successfully built PyDispatcher
Installing collected packages: w3lib, cssselect, zope.interface, requests-file, parsel, jmespath, itemadapter, incremental, hyperlink, cryptography, constantly, Automat, Twisted, tldextract, service-identity, queuelib, pyOpenSSL, PyDispatcher, protego, itemloaders, scrapy
Successfully installed Automat-20.2.0 PyDispatcher-2.0.6 Twisted-22.8.0 constantly-15.1.0 cryptography-38.0.1 cssselect-1.1.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.7.0 itemloaders-1.0.6 jmespath-1.0.1 parsel-1.6.0 protego-0.2.1 pyOpenSSL-22.1.0 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.6.3 service-identity-21.1.0 tldextract-3.4.0 w3lib-2.0.1 zope.interface-5.5.0
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting crochet
  Downloading crochet-2.0.0-py3-none-any.whl (31 kB)
Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from crochet) (1.14.1)
Requirement already satisfied: Twisted&gt;=16.0 in /usr/local/lib/python3.7/dist-packages (from crochet) (22.8.0)
Requirement already satisfied: typing-extensions&gt;=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (4.1.1)
Requirement already satisfied: hyperlink&gt;=17.1.1 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (21.0.0)
Requirement already satisfied: zope.interface&gt;=4.4.2 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (5.5.0)
Requirement already satisfied: incremental&gt;=21.3.0 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (22.10.0)
Requirement already satisfied: Automat&gt;=0.8.0 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (20.2.0)
Requirement already satisfied: constantly&gt;=15.1 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (15.1.0)
Requirement already satisfied: attrs&gt;=19.2.0 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (22.1.0)
Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from Automat&gt;=0.8.0-&gt;Twisted&gt;=16.0-&gt;crochet) (1.15.0)
Requirement already satisfied: idna&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink&gt;=17.1.1-&gt;Twisted&gt;=16.0-&gt;crochet) (2.10)
Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface&gt;=4.4.2-&gt;Twisted&gt;=16.0-&gt;crochet) (57.4.0)
Installing collected packages: crochet
Successfully installed crochet-2.0.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">scrapy.crawler</span> <span class="kn">import</span> <span class="n">CrawlerRunner</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">crochet</span> <span class="kn">import</span> <span class="n">setup</span><span class="p">,</span> <span class="n">wait_for</span>
<span class="n">setup</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">QuotesToCsv</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;MJKQuotesToCsv&quot;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;https://tekno.tempo.co/read/1645474/makin-canggih-berikut-4-kelebihan-windows-11&#39;</span>
    <span class="p">]</span>
    <span class="n">custom_settings</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;ITEM_PIPELINES&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;__main__.ExtractFirstLine&#39;</span><span class="p">:</span> <span class="mi">1</span>
        <span class="p">},</span>
        <span class="s1">&#39;FEEDS&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;news.csv&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;format&#39;</span><span class="p">:</span> <span class="s1">&#39;csv&#39;</span><span class="p">,</span>
                <span class="s1">&#39;overwrite&#39;</span><span class="p">:</span> <span class="kc">True</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;parse data from urls&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;#isi &gt; p&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span><span class="s1">&#39;news&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">extract</span><span class="p">()}</span>


<span class="k">class</span> <span class="nc">ExtractFirstLine</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;text processing&quot;&quot;&quot;</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">item</span><span class="p">)[</span><span class="s2">&quot;news&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>
        <span class="n">first_line</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__remove_html_tags__</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;news&#39;</span><span class="p">:</span> <span class="n">first_line</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">__remove_html_tags__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;remove html tags from string&quot;&quot;&quot;</span>
        <span class="n">html_tags</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;&lt;.*?&gt;&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">html_tags</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

<span class="nd">@wait_for</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">run_spider</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;run spider with MJKQuotesToCsv&quot;&quot;&quot;</span>
    <span class="n">crawler</span> <span class="o">=</span> <span class="n">CrawlerRunner</span><span class="p">()</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">crawler</span><span class="o">.</span><span class="n">crawl</span><span class="p">(</span><span class="n">QuotesToCsv</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">run_spider</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id27">
<h3>Membaca Dokumen<a class="headerlink" href="#id27" title="Permalink to this headline">#</a></h3>
<p>Setelah tahapan mengambil dokumen selesai, selanjutnya membaca dokumen yang sudah didapatkan. Untuk membaca dokumen terlebih dahulu kita convert file csv kedalam bentuk pdf dengan menggunakan library pdfkit. Untuk itu install library pdfkit terlebih dahulu seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install pdfkit

<span class="o">!</span>wget https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-1/wkhtmltox_0.12.6-1.bionic_amd64.deb

<span class="o">!</span>cp wkhtmltox_0.12.6-1.bionic_amd64.deb /usr/bin

<span class="o">!</span>sudo apt install /usr/bin/wkhtmltox_0.12.6-1.bionic_amd64.deb
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting pdfkit
  Downloading pdfkit-1.0.0-py3-none-any.whl (12 kB)
Installing collected packages: pdfkit
Successfully installed pdfkit-1.0.0
--2022-10-17 03:23:53--  https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6-1/wkhtmltox_0.12.6-1.bionic_amd64.deb
Resolving github.com (github.com)... 140.82.114.3
Connecting to github.com (github.com)|140.82.114.3|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/131323182/b6d71780-ab7e-11ea-9b13-e2875e48ec6c?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221017%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20221017T032353Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=2e1f92bc341f075b15133c9a66581103112a944fdc3a17b94c08b0b3710a8e1f&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;key_id=0&amp;repo_id=131323182&amp;response-content-disposition=attachment%3B%20filename%3Dwkhtmltox_0.12.6-1.bionic_amd64.deb&amp;response-content-type=application%2Foctet-stream [following]
--2022-10-17 03:23:53--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/131323182/b6d71780-ab7e-11ea-9b13-e2875e48ec6c?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221017%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20221017T032353Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=2e1f92bc341f075b15133c9a66581103112a944fdc3a17b94c08b0b3710a8e1f&amp;X-Amz-SignedHeaders=host&amp;actor_id=0&amp;key_id=0&amp;repo_id=131323182&amp;response-content-disposition=attachment%3B%20filename%3Dwkhtmltox_0.12.6-1.bionic_amd64.deb&amp;response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 15729530 (15M) [application/octet-stream]
Saving to: ‘wkhtmltox_0.12.6-1.bionic_amd64.deb’

wkhtmltox_0.12.6-1. 100%[===================&gt;]  15.00M  --.-KB/s    in 0.1s    

2022-10-17 03:23:54 (123 MB/s) - ‘wkhtmltox_0.12.6-1.bionic_amd64.deb’ saved [15729530/15729530]

Reading package lists... Done
Building dependency tree       
Reading state information... Done
Note, selecting &#39;wkhtmltox&#39; instead of &#39;/usr/bin/wkhtmltox_0.12.6-1.bionic_amd64.deb&#39;
The following package was automatically installed and is no longer required:
  libnvidia-common-460
Use &#39;sudo apt autoremove&#39; to remove it.
The following additional packages will be installed:
  xfonts-75dpi xfonts-base xfonts-encodings xfonts-utils
Suggested packages:
  xfs | xserver
The following NEW packages will be installed:
  wkhtmltox xfonts-75dpi xfonts-base xfonts-encodings xfonts-utils
0 upgraded, 5 newly installed, 0 to remove and 12 not upgraded.
Need to get 9,947 kB/25.7 MB of archives.
After this operation, 152 MB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 xfonts-encodings all 1:1.0.4-2 [573 kB]
Get:2 /usr/bin/wkhtmltox_0.12.6-1.bionic_amd64.deb wkhtmltox amd64 1:0.12.6-1.bionic [15.7 MB]
Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 xfonts-utils amd64 1:7.7+6 [91.5 kB]
Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 xfonts-75dpi all 1:1.0.4+nmu1 [3,368 kB]
Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 xfonts-base all 1:1.0.4+nmu1 [5,914 kB]
Fetched 9,947 kB in 1s (6,638 kB/s)
debconf: unable to initialize frontend: Dialog
debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, &lt;&gt; line 5.)
debconf: falling back to frontend: Readline
debconf: unable to initialize frontend: Readline
debconf: (This frontend requires a controlling tty.)
debconf: falling back to frontend: Teletype
dpkg-preconfigure: unable to re-open stdin: 
Selecting previously unselected package xfonts-encodings.
(Reading database ... 123934 files and directories currently installed.)
Preparing to unpack .../xfonts-encodings_1%3a1.0.4-2_all.deb ...
Unpacking xfonts-encodings (1:1.0.4-2) ...
Selecting previously unselected package xfonts-utils.
Preparing to unpack .../xfonts-utils_1%3a7.7+6_amd64.deb ...
Unpacking xfonts-utils (1:7.7+6) ...
Selecting previously unselected package xfonts-75dpi.
Preparing to unpack .../xfonts-75dpi_1%3a1.0.4+nmu1_all.deb ...
Unpacking xfonts-75dpi (1:1.0.4+nmu1) ...
Selecting previously unselected package xfonts-base.
Preparing to unpack .../xfonts-base_1%3a1.0.4+nmu1_all.deb ...
Unpacking xfonts-base (1:1.0.4+nmu1) ...
Selecting previously unselected package wkhtmltox.
Preparing to unpack .../wkhtmltox_0.12.6-1.bionic_amd64.deb ...
Unpacking wkhtmltox (1:0.12.6-1.bionic) ...
Setting up xfonts-encodings (1:1.0.4-2) ...
Setting up xfonts-utils (1:7.7+6) ...
Setting up xfonts-75dpi (1:1.0.4+nmu1) ...
Setting up xfonts-base (1:1.0.4+nmu1) ...
Setting up wkhtmltox (1:0.12.6-1.bionic) ...
Processing triggers for fontconfig (2.12.6-0ubuntu2) ...
Processing triggers for man-db (2.8.3-2ubuntu0.1) ...
Processing triggers for libc-bin (2.27-3ubuntu1.6) ...
</pre></div>
</div>
</div>
</div>
<section id="id28">
<h4>Convert File CSV ke PDF<a class="headerlink" href="#id28" title="Permalink to this headline">#</a></h4>
<p>Setelah librari pdfkit berhasil diinstal, maka langsung kita import untuk mengconvert file csv yang di dapat ke dalam format pdf menggunakan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pdfkit</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">path_wkhtmltopdf</span> <span class="o">=</span> <span class="s2">&quot;/content/wkhtmltox_0.12.6-1.bionic_amd64.deb&quot;</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">pdfkit</span><span class="o">.</span><span class="n">configuration</span><span class="p">(</span><span class="n">wkhtmltopdf</span><span class="o">=</span><span class="n">path_wkhtmltopdf</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;news.csv&#39;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">html_string</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to_html</span><span class="p">()</span>
<span class="n">pdfkit</span><span class="o">.</span><span class="n">from_string</span><span class="p">(</span><span class="n">html_string</span><span class="p">,</span> <span class="s2">&quot;Dokumen.pdf&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>Setelah berhasil diconvert selanjutnya baca dokumen yang sudah diconvert tersebut dengan library PyPDF2 dan docx2txt, untuk itu kita install library tersebut terlebih dahulu dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install PyPDF2
<span class="o">!</span>pip install docx2txt
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting PyPDF2
  Downloading PyPDF2-2.11.1-py3-none-any.whl (220 kB)
     |████████████████████████████████| 220 kB 5.1 MB/s 
?25hRequirement already satisfied: typing-extensions&gt;=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from PyPDF2) (4.1.1)
Installing collected packages: PyPDF2
Successfully installed PyPDF2-2.11.1
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting docx2txt
  Downloading docx2txt-0.8.tar.gz (2.8 kB)
Building wheels for collected packages: docx2txt
  Building wheel for docx2txt (setup.py) ... ?25l?25hdone
  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=f1fbd5b4d44654843d8f23b4f31225f1b8e70f384d462309f914354586a9e620
  Stored in directory: /root/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8
Successfully built docx2txt
Installing collected packages: docx2txt
Successfully installed docx2txt-0.8
</pre></div>
</div>
</div>
</div>
</section>
<section id="id29">
<h4>Baca Dokumen<a class="headerlink" href="#id29" title="Permalink to this headline">#</a></h4>
<p>Setelah berhasil diinstal selanjutnya kita import library tersebut untuk membaca dokumen yang sudah convert ke bentuk pdf dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">PyPDF2</span>
<span class="kn">import</span> <span class="nn">docx2txt</span>
<span class="kn">import</span> <span class="nn">sys</span>
</pre></div>
</div>
</div>
</div>
<p>Setelah diimport kita panggil file dokumen tersebut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">name</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Masukkan nama file: &#39;</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Anda telah memanggil dokument  </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Setelah itu baca file dokumen tersebut dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pdfFileObj</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
<span class="n">pdfReader</span> <span class="o">=</span> <span class="n">PyPDF2</span><span class="o">.</span><span class="n">PdfFileReader</span><span class="p">(</span><span class="n">pdfFileObj</span><span class="p">)</span>
<span class="n">pageObj</span> <span class="o">=</span> <span class="n">pdfReader</span><span class="o">.</span><span class="n">getPage</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">pageObj</span><span class="o">.</span><span class="n">extractText</span><span class="p">()</span>
<span class="n">document</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id30">
<h3>Memecah Dokumen<a class="headerlink" href="#id30" title="Permalink to this headline">#</a></h3>
<p>Setelah berhasil membaca dokumen, selanjutnya pecah dokumen sehingga terdiri dari kalimat dan kata-kata dengan menggunakan library nltk. Maka dari itu terlebih dahulu import librarynya seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.tokenize.punkt</span> <span class="kn">import</span> <span class="n">PunktSentenceTokenizer</span>
</pre></div>
</div>
</div>
</div>
<section id="id31">
<h4>Memecah Kalimat<a class="headerlink" href="#id31" title="Permalink to this headline">#</a></h4>
<p>Setelah library yang dibutuhkan sudah di import selanjutnya pecah dokumen dalam beberapa kalimat dengan menggunakan function berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">):</span>
    <span class="c1"># Kita memecahnya menggunakan  PunktSentenceTokenizer</span>
    <span class="c1"># </span>
    <span class="n">doc_tokenizer</span> <span class="o">=</span> <span class="n">PunktSentenceTokenizer</span><span class="p">()</span>
    
    <span class="c1"># metode tokenize() memanggil dokument kita</span>
    <span class="c1"># sebagai input dan menghasilkan daftar kalimat dalam dokumen</span>
    
    <span class="c1"># sentences_list adalah daftar masing masing kalimat dari dokumen yang ada.</span>
    <span class="n">sentences_list</span> <span class="o">=</span> <span class="n">doc_tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sentences_list</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sentences_list</span> <span class="o">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Banyaknya kalimat = &quot;</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences_list</span><span class="p">)),</span><span class="s1">&#39;kalimat&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sentences_list</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----------------------------------------------------------------------------------------------------------------------&#39;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Kalimat&#39;</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----------------------------------------------------------------------------------------------------------------------&#39;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
  <span class="n">n</span> <span class="o">=</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----------------------------------------------------------------------------------------------------------------------&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id32">
<h4>Memecah Kata<a class="headerlink" href="#id32" title="Permalink to this headline">#</a></h4>
<p>Setelah dokumen terpecah menjadi beberapa kalimat, selanjutnya kita pecah lagi menjadi kata dengan library sklearn seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span><span class="p">,</span> <span class="n">CountVectorizer</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">cv_matrix</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">sentences_list</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Banyaknya kosa kata = &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">((</span><span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())),</span><span class="s1">&#39;kosa kata&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;kosa kata = &quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id33">
<h3>Membuat Matrik TF-IDF<a class="headerlink" href="#id33" title="Permalink to this headline">#</a></h3>
<p>Setelah memecah dokumen menjadi beberapa kalimat dan kata, selanjutnya buat sebuah matrik VSM untuk membuat TF-IDF seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">normal_matrix</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">normal_matrix</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id34">
<h3>Membuat Graph<a class="headerlink" href="#id34" title="Permalink to this headline">#</a></h3>
<p>Setelah matrik TF-IDF terbentuk, selanjutnya buat graph berdasarkan dari matrik tersebut dengan library networkx seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">normal_matrix</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">toarray</span><span class="p">)</span>
<span class="n">res_graph</span> <span class="o">=</span> <span class="n">normal_matrix</span> <span class="o">*</span> <span class="n">normal_matrix</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nx_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_scipy_sparse_matrix</span><span class="p">(</span><span class="n">res_graph</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nx</span><span class="o">.</span><span class="n">draw_circular</span><span class="p">(</span><span class="n">nx_graph</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Banyaknya sisi </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">number_of_edges</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">normal_matrix</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id35">
<h3>Menghitung PageRank<a class="headerlink" href="#id35" title="Permalink to this headline">#</a></h3>
<p>Setelah terbentuk graph, selanjutnya hitung nilai pagerank dari masing-masing kalimat dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ranks</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">pagerank</span><span class="p">(</span><span class="n">nx_graph</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">rangking</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">:</span>
  <span class="n">m</span> <span class="o">=</span> <span class="n">ranks</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="s1">&#39;Kalimat ke&#39;</span><span class="p">,</span><span class="n">n</span>
  <span class="n">rangking</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Kalimat&#39;</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="s1">&#39;:&#39;</span><span class="p">,</span><span class="n">ranks</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
  <span class="n">n</span> <span class="o">=</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<p>Setelah nilai pagerank didapatkan, selanjutnya kita rangking nilai pagerank tersebut dari nilai yang paling tinggi seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rangking</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">rangking</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id36">
<h3>Memilih Kalimat<a class="headerlink" href="#id36" title="Permalink to this headline">#</a></h3>
<p>Setelah didapatkan kalimat yang memiliki nilai pagerank tertinggi, selanjutnya pilih kalimat yang memiliki nilai pagerank tertinggi, dari data dapat dilihat bahwa kalimat ke-12,8,23,3,9 dan seterusnya memiliki nilai pagerank dari yang paling tinggi hingga rendah.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">sentences_list</span><span class="p">[</span><span class="mi">11</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sentences_list</span><span class="p">[</span><span class="mi">7</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sentences_list</span><span class="p">[</span><span class="mi">22</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sentences_list</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sentences_list</span><span class="p">[</span><span class="mi">8</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id37">
<h3>Kesimpulan<a class="headerlink" href="#id37" title="Permalink to this headline">#</a></h3>
<p>Berdasar dari tahapan-tahapan yang dilakukan dapat disimpulkan bahwa ringkasan atau simpulan dokumen yang didapat ialah “Windows 11 akan secara otomatis mendeteksi monitor yang didukung HDR dan meningkatkan warna game yang dibuat di DirectX 11 atau lebih tinggi dengan peningkatan jangkauan dinamis. Apakah Anda memilih untuk tetap menggunakan Windows 10 atau membuat lompatan ke Windows 11, sepertinya
waktu yang tepat untuk meningkatkan ke NVMe SSD untuk melihat manfaat DirectStorage. Namun akan lebih baik jika Anda memiliki lebih dari persyaratan minimum untuk membuat pengalaman bermain game yang lebih baik. Dilansir dari <a class="reference external" href="http://kingston.com">kingston.com</a>, berikut 4 kelebihan Windows 11: Secara harfiah, DirectStorage adalah pembaruan yang mengubah permainan, teknologi ini memungkinkan NVMe SSD untuk mentransfer data permainan langsung ke kartu grafis, melewati kemacetan CPU dan memberikan kecepatan tinggi untuk rendering, tanpa waktu muat yang lama. Dikombinasikan dengan peningkatan memori dan peningkatan kecepatan dan kapasitas penyimpanan perangkat Anda, peningkatan ini dapat menawarkan peluang untuk meningkatkan kinerja dan dengan demikian pengalaman bermain game Anda secara keseluruhan..” Ringkasan tersebut diperoleh dari 4 data kalimat yang memiliki nilai pagerank tertinggi.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="topik-modelling-dengan-latent-semantic-indexing-lsi-atau-latent-semantic-analysis-lsa-menggunakan-scikit-learn">
<h1>Topik Modelling Dengan Latent Semantic Indexing (LSI) atau Latent Semantic Analysis (LSA) menggunakan Scikit-Learn<a class="headerlink" href="#topik-modelling-dengan-latent-semantic-indexing-lsi-atau-latent-semantic-analysis-lsa-menggunakan-scikit-learn" title="Permalink to this headline">#</a></h1>
<p>Dalam pembahasan kali ini, kita akan fokus pada Latent Semantic Indexing (LSI) atau Latent Semantic Analysis (LSA) dan melakukan topik modelling menggunakan Scikit-learn.</p>
<section id="topik-modelling">
<h2><strong>Topik Modelling</strong><a class="headerlink" href="#topik-modelling" title="Permalink to this headline">#</a></h2>
<p>Topik Modelling ialah teknik tanpa pengawasan untuk menemukan tema dokumen yang diberikan. Ini mengekstrak kumpulan kata kunci yang terjadi bersama. Kata kunci yang muncul bersama ini mewakili sebuah topik. Misalnya, saham, pasar, ekuitas, reksa dana akan mewakili topik ‘investasi saham’.</p>
</section>
<section id="latent-semantic-indexing-lsi-atau-latent-semantic-analysis-lsa">
<h2><strong>Latent Semantic Indexing (LSI) atau Latent Semantic Analysis (LSA)</strong><a class="headerlink" href="#latent-semantic-indexing-lsi-atau-latent-semantic-analysis-lsa" title="Permalink to this headline">#</a></h2>
<p>Latent Semantic Indexing (LSI) atau Latent Semantic Analysis (LSA)  adalah teknik dalam natural language processing , khususnya  distributional semantics , yang menganalisis hubungan antara satu set dokumen dan istilah yang dikandungnya dengan menghasilkan satu set konsep yang terkait dengan dokumen dan istilah. LSA mengasumsikan bahwa kata-kata yang memiliki makna yang dekat akan muncul dalam potongan teks yang serupa (  distributional hypothesis ). Sebuah matriks yang berisi jumlah kata per dokumen (baris mewakili kata-kata unik dan kolom mewakili setiap dokumen) dibangun dari sepotong besar teks dan teknik matematika yang disebut Singular Value Decomposition (SVD) digunakan untuk mengurangi jumlah baris dengan tetap menjaga kesamaan struktur antar kolom. Dokumen kemudian dibandingkan dengan mengambil kosinus sudut antara dua vektor (atau produk titik antara normalisasi dua vektor) yang dibentuk oleh dua kolom. Nilai yang mendekati 1 menunjukkan dokumen yang sangat mirip sedangkan nilai yang mendekati 0 menunjukkan dokumen yang sangat berbeda.<br></p>
<center><img src='https://media.geeksforgeeks.org/wp-content/uploads/20210406165951/Screenshot20210406165933.png'></center><center>Gambar LSA</center> Untuk melakukan LSA dapat dilakukan dengan mengikuti tahapan tahapan berikut.</section>
<section id="id38">
<h2><strong>Mengambil Dokumen</strong><a class="headerlink" href="#id38" title="Permalink to this headline">#</a></h2>
<p>Langkah awal untuk melakukan Topik Modelling ialah dengan mengambil dokumen tersebut dengan mengcrawling data dokumen dengan menggunakan scrapy &amp; crochet seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install scrapy
<span class="o">!</span>pip install crochet
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting scrapy
  Downloading Scrapy-2.7.0-py2.py3-none-any.whl (270 kB)
     |████████████████████████████████| 270 kB 8.6 MB/s 
?25hCollecting queuelib&gt;=1.4.2
  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)
Collecting Twisted&gt;=18.9.0
  Downloading Twisted-22.8.0-py3-none-any.whl (3.1 MB)
     |████████████████████████████████| 3.1 MB 51.2 MB/s 
?25hCollecting service-identity&gt;=18.1.0
  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)
Collecting w3lib&gt;=1.17.0
  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)
Requirement already satisfied: lxml&gt;=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (4.9.1)
Collecting itemloaders&gt;=1.0.1
  Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from scrapy) (21.3)
Collecting cryptography&gt;=3.3
  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)
     |████████████████████████████████| 4.0 MB 51.9 MB/s 
?25hCollecting itemadapter&gt;=0.1.0
  Downloading itemadapter-0.7.0-py3-none-any.whl (10 kB)
Collecting tldextract
  Downloading tldextract-3.4.0-py3-none-any.whl (93 kB)
     |████████████████████████████████| 93 kB 3.2 MB/s 
?25hCollecting cssselect&gt;=0.9.1
  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)
Collecting pyOpenSSL&gt;=21.0.0
  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)
     |████████████████████████████████| 57 kB 5.5 MB/s 
?25hCollecting zope.interface&gt;=5.1.0
  Downloading zope.interface-5.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (254 kB)
     |████████████████████████████████| 254 kB 76.4 MB/s 
?25hCollecting PyDispatcher&gt;=2.0.5
  Downloading PyDispatcher-2.0.6.tar.gz (38 kB)
Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from scrapy) (57.4.0)
Collecting protego&gt;=0.1.15
  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)
Collecting parsel&gt;=1.5.0
  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)
Requirement already satisfied: cffi&gt;=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography&gt;=3.3-&gt;scrapy) (1.15.1)
Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi&gt;=1.12-&gt;cryptography&gt;=3.3-&gt;scrapy) (2.21)
Collecting jmespath&gt;=0.9.5
  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)
Requirement already satisfied: six&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from parsel&gt;=1.5.0-&gt;scrapy) (1.15.0)
Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity&gt;=18.1.0-&gt;scrapy) (0.2.8)
Requirement already satisfied: attrs&gt;=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity&gt;=18.1.0-&gt;scrapy) (22.1.0)
Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity&gt;=18.1.0-&gt;scrapy) (0.4.8)
Collecting incremental&gt;=21.3.0
  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)
Collecting Automat&gt;=0.8.0
  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)
Collecting constantly&gt;=15.1
  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)
Collecting hyperlink&gt;=17.1.1
  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)
     |████████████████████████████████| 74 kB 3.4 MB/s 
?25hRequirement already satisfied: typing-extensions&gt;=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=18.9.0-&gt;scrapy) (4.1.1)
Requirement already satisfied: idna&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink&gt;=17.1.1-&gt;Twisted&gt;=18.9.0-&gt;scrapy) (2.10)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;scrapy) (3.0.9)
Collecting requests-file&gt;=1.4
  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)
Requirement already satisfied: requests&gt;=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract-&gt;scrapy) (2.23.0)
Requirement already satisfied: filelock&gt;=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract-&gt;scrapy) (3.8.0)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.1.0-&gt;tldextract-&gt;scrapy) (1.24.3)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.1.0-&gt;tldextract-&gt;scrapy) (3.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.1.0-&gt;tldextract-&gt;scrapy) (2022.9.24)
Building wheels for collected packages: PyDispatcher
  Building wheel for PyDispatcher (setup.py) ... ?25l?25hdone
  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.6-py3-none-any.whl size=11958 sha256=c51d8f1db21b459dd2498a5580788eb8d2a48f6dbf90dc0ffdca4872c1660345
  Stored in directory: /root/.cache/pip/wheels/c9/d6/6a/de198d890277cde60ca3dbebe7ae592d3b381c7d9bb2455f4d
Successfully built PyDispatcher
Installing collected packages: w3lib, cssselect, zope.interface, requests-file, parsel, jmespath, itemadapter, incremental, hyperlink, cryptography, constantly, Automat, Twisted, tldextract, service-identity, queuelib, pyOpenSSL, PyDispatcher, protego, itemloaders, scrapy
Successfully installed Automat-20.2.0 PyDispatcher-2.0.6 Twisted-22.8.0 constantly-15.1.0 cryptography-38.0.1 cssselect-1.1.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.7.0 itemloaders-1.0.6 jmespath-1.0.1 parsel-1.6.0 protego-0.2.1 pyOpenSSL-22.1.0 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.7.0 service-identity-21.1.0 tldextract-3.4.0 w3lib-2.0.1 zope.interface-5.5.0
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting crochet
  Downloading crochet-2.0.0-py3-none-any.whl (31 kB)
Requirement already satisfied: Twisted&gt;=16.0 in /usr/local/lib/python3.7/dist-packages (from crochet) (22.8.0)
Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from crochet) (1.14.1)
Requirement already satisfied: zope.interface&gt;=4.4.2 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (5.5.0)
Requirement already satisfied: typing-extensions&gt;=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (4.1.1)
Requirement already satisfied: incremental&gt;=21.3.0 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (22.10.0)
Requirement already satisfied: constantly&gt;=15.1 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (15.1.0)
Requirement already satisfied: attrs&gt;=19.2.0 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (22.1.0)
Requirement already satisfied: Automat&gt;=0.8.0 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (20.2.0)
Requirement already satisfied: hyperlink&gt;=17.1.1 in /usr/local/lib/python3.7/dist-packages (from Twisted&gt;=16.0-&gt;crochet) (21.0.0)
Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from Automat&gt;=0.8.0-&gt;Twisted&gt;=16.0-&gt;crochet) (1.15.0)
Requirement already satisfied: idna&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink&gt;=17.1.1-&gt;Twisted&gt;=16.0-&gt;crochet) (2.10)
Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface&gt;=4.4.2-&gt;Twisted&gt;=16.0-&gt;crochet) (57.4.0)
Installing collected packages: crochet
Successfully installed crochet-2.0.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">scrapy.crawler</span> <span class="kn">import</span> <span class="n">CrawlerRunner</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">crochet</span> <span class="kn">import</span> <span class="n">setup</span><span class="p">,</span> <span class="n">wait_for</span>
<span class="n">setup</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">QuotesToCsv</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;MJKQuotesToCsv&quot;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;https://tekno.tempo.co/read/1580340/peran-penting-iptekin-terhadap-kemajuan-sebuah-bangsa&#39;</span>
    <span class="p">]</span>
    <span class="n">custom_settings</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;ITEM_PIPELINES&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;__main__.ExtractFirstLine&#39;</span><span class="p">:</span> <span class="mi">1</span>
        <span class="p">},</span>
        <span class="s1">&#39;FEEDS&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;news.csv&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;format&#39;</span><span class="p">:</span> <span class="s1">&#39;csv&#39;</span><span class="p">,</span>
                <span class="s1">&#39;overwrite&#39;</span><span class="p">:</span> <span class="kc">True</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;parse data from urls&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;#isi &gt; p&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span><span class="s1">&#39;news&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">extract</span><span class="p">()}</span>


<span class="k">class</span> <span class="nc">ExtractFirstLine</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;text processing&quot;&quot;&quot;</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">item</span><span class="p">)[</span><span class="s2">&quot;news&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>
        <span class="n">first_line</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__remove_html_tags__</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;news&#39;</span><span class="p">:</span> <span class="n">first_line</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">__remove_html_tags__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;remove html tags from string&quot;&quot;&quot;</span>
        <span class="n">html_tags</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;&lt;.*?&gt;&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">html_tags</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

<span class="nd">@wait_for</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">run_spider</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;run spider with MJKQuotesToCsv&quot;&quot;&quot;</span>
    <span class="n">crawler</span> <span class="o">=</span> <span class="n">CrawlerRunner</span><span class="p">()</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">crawler</span><span class="o">.</span><span class="n">crawl</span><span class="p">(</span><span class="n">QuotesToCsv</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">run_spider</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:twisted:/usr/local/lib/python3.7/dist-packages/scrapy/utils/request.py:231: scrapy.exceptions.ScrapyDeprecationWarning: &#39;2.6&#39; is a deprecated value for the &#39;REQUEST_FINGERPRINTER_IMPLEMENTATION&#39; setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the &#39;REQUEST_FINGERPRINTER_IMPLEMENTATION&#39; setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the &#39;REQUEST_FINGERPRINTER_IMPLEMENTATION&#39; setting for information on how to handle this deprecation.
</pre></div>
</div>
</div>
</div>
</section>
<section id="meload-dokumen">
<h2><strong>Meload Dokumen</strong><a class="headerlink" href="#meload-dokumen" title="Permalink to this headline">#</a></h2>
<p>Setelah tahapan mengambil dokumen selesai, selanjutnya meload dokumen yang sudah didapatkan. Untuk dapat meload dokumen kita gunakan library os dan pandas seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Load Dataset</span>
<span class="n">documents_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;news.csv&quot;</span><span class="p">)</span> <span class="p">,</span><span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fin</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">fin</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="n">documents_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="membuat-fitur-tf-idf">
<h2><strong>Membuat Fitur TF-IDF</strong><a class="headerlink" href="#membuat-fitur-tf-idf" title="Permalink to this headline">#</a></h2>
<p>Setelah berhasil meload dokumen langkah selanjutnya ialah mengenerate fitur TF-IDF pada dokumen. Pada proses ini juga dilakukan operasi prepocessing, yaitu case folding, stopword, dan tokenizing. Untuk melakukan proses ini dengan menggunakan RegexpTokenizer dari library nltk seperti source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">RegexpTokenizer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="c1"># Initialize regex tokenizer</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">RegexpTokenizer</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\w+&#39;</span><span class="p">)</span>

<span class="c1"># Vectorize document using TF-IDF</span>
<span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">lowercase</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">,</span>
                        <span class="n">ngram_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span>
                        <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">)</span>

<span class="c1"># Fit and Transform the documents</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">tfidf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">documents_list</span><span class="p">)</span>  
<span class="n">train_data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;12x236 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;
	with 412 stored elements in Compressed Sparse Row format&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section id="membuat-matrik-svd">
<h2><strong>Membuat Matrik SVD</strong><a class="headerlink" href="#membuat-matrik-svd" title="Permalink to this headline">#</a></h2>
<p>Matrik SVD adalah teknik dekomposisi matriks yang memfaktorkan matriks dalam produk matriks. Untuk dapat membuat matrik tersebut kita dapat menggunakan TruncatedSVD dari library sklearn seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">TruncatedSVD</span>
<span class="c1"># Define the number of topics or components</span>
<span class="n">num_components</span><span class="o">=</span><span class="mi">12</span>

<span class="c1"># Create SVD object</span>
<span class="n">lsa</span> <span class="o">=</span> <span class="n">TruncatedSVD</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">num_components</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Fit SVD model on data</span>
<span class="n">lsa</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>

<span class="c1"># Get Singular values and Components </span>
<span class="n">Sigma</span> <span class="o">=</span> <span class="n">lsa</span><span class="o">.</span><span class="n">singular_values_</span>  
<span class="n">V_transpose</span> <span class="o">=</span> <span class="n">lsa</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">T</span>
<span class="n">V_transpose</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 3.02366178e-02, -1.66382861e-02,  3.00062190e-02, ...,
         1.35817657e-01, -1.98807570e-03,  7.74902033e-03],
       [ 8.38985795e-02,  2.10631147e-01, -4.69070221e-02, ...,
         1.82148827e-02, -2.80810446e-02, -1.39858160e-01],
       [ 2.10849282e-02, -1.84815299e-02,  2.61033720e-03, ...,
        -3.35817930e-02, -4.12961820e-04, -4.39328074e-03],
       ...,
       [ 2.52767786e-02, -2.00135859e-02, -5.03940302e-02, ...,
        -3.07241369e-02,  1.88065252e-04, -2.37049787e-02],
       [ 1.58110182e-02, -2.27024106e-02,  5.80867655e-02, ...,
        -2.65079399e-02, -1.14091743e-02, -1.09058826e-02],
       [ 2.27840084e-01, -1.53073584e-01, -1.05864584e-03, ...,
        -4.25488190e-02, -4.07617741e-03,  7.17080829e-02]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="ekstrak-topik-dan-istilah">
<h2><strong>Ekstrak topik dan istilah</strong><a class="headerlink" href="#ekstrak-topik-dan-istilah" title="Permalink to this headline">#</a></h2>
<p>Setelah membuar matriks SVD, Selanjutnya kita perlu mengekstrak topik dari matriks komponen SVD dengan source code seperti berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print the topics with their terms</span>
<span class="n">terms</span> <span class="o">=</span> <span class="n">tfidf</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>

<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">component</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lsa</span><span class="o">.</span><span class="n">components_</span><span class="p">):</span>
    <span class="n">zipped</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">terms</span><span class="p">,</span> <span class="n">component</span><span class="p">)</span>
    <span class="n">top_terms_key</span><span class="o">=</span><span class="nb">sorted</span><span class="p">(</span><span class="n">zipped</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="mi">5</span><span class="p">]</span>
    <span class="n">top_terms_list</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">top_terms_key</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Topic &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">index</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;: &quot;</span><span class="p">,</span><span class="n">top_terms_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:twisted:/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: builtins.FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Topic 0:  [&#39;negara&#39;, &#39;dan&#39;, &#39;yang&#39;, &#39;di&#39;, &#39;dalam&#39;]
Topic 1:  [&#39;elemen&#39;, &#39;ilmu&#39;, &#39;kunci&#39;, &#39;pengetahuan&#39;, &#39;adalah&#39;]
Topic 2:  [&#39;kemudian&#39;, &#39;juga&#39;, &#39;pendekatan&#39;, &#39;disebut&#39;, &#39;berbagai&#39;]
Topic 3:  [&#39;news&#39;, &#39;akan&#39;, &#39;sistem&#39;, &#39;pendekatan&#39;, &#39;kemudian&#39;]
Topic 4:  [&#39;bahan&#39;, &#39;korea&#39;, &#39;sangat&#39;, &#39;selatan&#39;, &#39;taiwan&#39;]
Topic 5:  [&#39;hal&#39;, &#39;baik&#39;, &#39;ini&#39;, &#39;cendekiawan&#39;, &#39;diskursus&#39;]
Topic 6:  [&#39;seringkali&#39;, &#39;banyak&#39;, &#39;sektor&#39;, &#39;cendekiawan&#39;, &#39;diskursus&#39;]
Topic 7:  [&#39;dan&#39;, &#39;juga&#39;, &#39;nies&#39;, &#39;antaranya&#39;, &#39;kelembagaan&#39;]
Topic 8:  [&#39;dokumen&#39;, &#39;bahan&#39;, &#39;korea&#39;, &#39;sangat&#39;, &#39;selatan&#39;]
Topic 9:  [&#39;ekonomi&#39;, &#39;bagian&#39;, &#39;begitu&#39;, &#39;berupaya&#39;, &#39;catch&#39;]
Topic 10:  [&#39;halnya&#39;, &#39;indonesia&#39;, &#39;langsung&#39;, &#39;menerapkan&#39;, &#39;mengabsorbsi&#39;]
Topic 11:  [&#39;amerika&#39;, &#39;austria&#39;, &#39;bagi&#39;, &#39;bahasa&#39;, &#39;belanda&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="id39">
<h2><strong>Kesimpulan</strong><a class="headerlink" href="#id39" title="Permalink to this headline">#</a></h2>
<p>Hasil yang didapatkan dari topik modelling dengan Latent Semantic Indexing (LSI) atau Latent Semantic Analysis menggunakan library scikit-learn dengan mengambil 12 topik sebagai berikut.<br>
Topic 1:  [‘negara’, ‘dan’, ‘yang’, ‘di’, ‘dalam’]<br>
Topic 2:  [‘elemen’, ‘ilmu’, ‘kunci’, ‘pengetahuan’, ‘adalah’]<br>
Topic 3:  [‘kemudian’, ‘juga’, ‘pendekatan’, ‘disebut’, ‘berbagai’]<br>
Topic 4:  [‘news’, ‘akan’, ‘sistem’, ‘pendekatan’, ‘kemudian’]<br>
Topic 5:  [‘bahan’, ‘korea’, ‘sangat’, ‘selatan’, ‘taiwan’]<br>
Topic 6:  [‘hal’, ‘baik’, ‘ini’, ‘cendekiawan’, ‘diskursus’]<br>
Topic 7:  [‘seringkali’, ‘banyak’, ‘sektor’, ‘cendekiawan’, ‘diskursus’]<br>
Topic 8:  [‘dan’, ‘juga’, ‘nies’, ‘antaranya’, ‘kelembagaan’]<br>
Topic 9:  [‘dokumen’, ‘bahan’, ‘korea’, ‘sangat’, ‘selatan’]<br>
Topic 10:  [‘ekonomi’, ‘bagian’, ‘begitu’, ‘berupaya’, ‘catch’]<br>
Topic 12:  [‘halnya’, ‘indonesia’, ‘langsung’, ‘menerapkan’, ‘mengabsorbsi’]<br>
Topic 12:  [‘amerika’, ‘austria’, ‘bagi’, ‘bahasa’, ‘belanda’]</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="ensemble-learning-bagging-stacking-dan-random-forest-classification-dan-grid-search">
<h1>Ensemble Learning (Bagging, Stacking, dan Random Forest Classification) dan Grid Search<a class="headerlink" href="#ensemble-learning-bagging-stacking-dan-random-forest-classification-dan-grid-search" title="Permalink to this headline">#</a></h1>
<p>Ensemble Learning adalah algoritma dalam pembelajaran mesin (machine learning) dimana algoritma ini sebagai pencarian solusi prediksi terbaik dibandingkan dengan algoritma yang lain karena metode ensemble ini menggunakan beberapa algoritma pembelajaran untuk pencapaian solusi prediksi yang lebih baik daripada algoritma yang bisa diperoleh dari salah satu pembelajaran algoritma kosituen saja. Tidak seperti ansamble statistika didalam mekanika statistika biasanya selalu tak terbatas. Ansemble Pembelajaran hanya terdiri dari seperangkat model alternatif yang bersifat terbatas, namun biasanya memungkinkan untuk menjadi lebih banyak lagi struktur fleksibel yang ada diantara alternatif model itu sendiri.<br>
Evaluasi prediksi dari ensemble biasanya memerlukan banyak komputasi daripada evaluasi prediksi model tunggal (single model), jadi ensemble ini memungkinkan untuk mengimbangi poor learning algorithms oleh performasi lebih dari komputasi itu. Terdapat beberapa metode ensemble learning yaitu bagging, stacking dan random forest classification. Dan pada content kali ini akan membahas metode metode tersebut dengan melakukan tahapan-tahapan berikut.</p>
<section id="id40">
<h2><strong>Praprepocessing Text</strong><a class="headerlink" href="#id40" title="Permalink to this headline">#</a></h2>
<p>Proses ini merupakan proses awal sebelum melakukan proses prepocessing text, yaitu proses untuk mendapatkan dataset yang akan digunakan untuk proses prepocessing, yang mana dataset yang akan digunakan diambil dari website dengan melakukan crawling pada website.</p>
<section id="id41">
<h3>Crawling Tweeter<a class="headerlink" href="#id41" title="Permalink to this headline">#</a></h3>
<p>Crawling merupakan suatu proses pengambilan data dengan menggunakan mesin yang dilakukan secara online. Proses ini dilakukan untuk mengimpor data yang ditemukan kedalam file lokal komputer. Kemudian data yang telah di impor tersebut akan dilakukan tahap prepocessing text. Pada proses crawling kali ini dilakukan crawling data pada twitter dengan menggunakan tools Twint.</p>
<section id="id42">
<h4>Installasi Twint<a class="headerlink" href="#id42" title="Permalink to this headline">#</a></h4>
<p>Twint merupakan sebuah tools yang digunakan untuk dapat melakukan scraping data dari media sosial yaitu twitter dengan menggunakan bahasa pemrograman python. Twint dapat dijalankan tanpa harus menggunakan API twitter itu sendiri, namun kapasitas scrapingnya dibatasi sebanyak 3200 tweet.</p>
<p>Twint tidak hanya digunakan untuk mengambil data tweet, twint juga bisa digunakan untuk mengambil data user, follower, retweet, dan sejenisnya. Twint memanfaatkan operator pencarian twitter yang digunakan untuk memilih dan memilah informasi yang sensitif, termasuk email dan nomor telepon di dalamnya.</p>
<p>Proses installasi Twint dapat dilakukan dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>git clone --depth<span class="o">=</span><span class="m">1</span> https://github.com/twintproject/twint.git
<span class="o">%</span><span class="k">cd</span> twint
<span class="o">!</span>pip3 install . -r requirements.txt
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cloning into &#39;twint&#39;...
remote: Enumerating objects: 47, done.
remote: Counting objects: 100% (47/47), done.
remote: Compressing objects: 100% (44/44), done.
remote: Total 47 (delta 3), reused 14 (delta 0), pack-reused 0
Unpacking objects: 100% (47/47), done.
/content/twint
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Processing /content/twint
<span class=" -Color -Color-Yellow">  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.</span>
<span class=" -Color -Color-Yellow">   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.</span>
Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (3.8.3)
Collecting aiodns
  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)
Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (4.6.3)
Collecting cchardet
  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)
     |████████████████████████████████| 263 kB 7.0 MB/s 
?25hCollecting dataclasses
  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)
Collecting elasticsearch
  Downloading elasticsearch-8.5.0-py3-none-any.whl (385 kB)
     |████████████████████████████████| 385 kB 41.4 MB/s 
?25hRequirement already satisfied: pysocks in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.7.1)
Requirement already satisfied: pandas&gt;=0.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.3.5)
Collecting aiohttp_socks&lt;=0.4.1
  Downloading aiohttp_socks-0.4.1-py3-none-any.whl (17 kB)
Collecting schedule
  Downloading schedule-1.1.0-py2.py3-none-any.whl (10 kB)
Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.17.0)
Collecting fake-useragent
  Downloading fake_useragent-0.1.14-py3-none-any.whl (13 kB)
Collecting googletransx
  Downloading googletransx-2.4.2.tar.gz (13 kB)
Requirement already satisfied: numpy&gt;=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.23.0-&gt;-r requirements.txt (line 8)) (1.21.6)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.23.0-&gt;-r requirements.txt (line 8)) (2.8.2)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.23.0-&gt;-r requirements.txt (line 8)) (2022.6)
Requirement already satisfied: attrs&gt;=19.2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp_socks&lt;=0.4.1-&gt;-r requirements.txt (line 9)) (22.1.0)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (6.0.2)
Requirement already satisfied: charset-normalizer&lt;3.0,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (2.1.1)
Requirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (1.3.1)
Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (4.0.2)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (1.8.1)
Requirement already satisfied: typing-extensions&gt;=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (4.1.1)
Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (0.13.0)
Requirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;-r requirements.txt (line 1)) (1.3.3)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=0.23.0-&gt;-r requirements.txt (line 8)) (1.15.0)
Requirement already satisfied: idna&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp-&gt;-r requirements.txt (line 1)) (2.10)
Collecting pycares&gt;=4.0.0
  Downloading pycares-4.2.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)
     |████████████████████████████████| 288 kB 38.9 MB/s 
?25hRequirement already satisfied: cffi&gt;=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pycares&gt;=4.0.0-&gt;aiodns-&gt;-r requirements.txt (line 2)) (1.15.1)
Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi&gt;=1.5.0-&gt;pycares&gt;=4.0.0-&gt;aiodns-&gt;-r requirements.txt (line 2)) (2.21)
Collecting elastic-transport&lt;9,&gt;=8
  Downloading elastic_transport-8.4.0-py3-none-any.whl (59 kB)
     |████████████████████████████████| 59 kB 4.1 MB/s 
?25hCollecting urllib3&lt;2,&gt;=1.26.2
  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)
     |████████████████████████████████| 140 kB 55.5 MB/s 
?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elastic-transport&lt;9,&gt;=8-&gt;elasticsearch-&gt;-r requirements.txt (line 6)) (2022.9.24)
Requirement already satisfied: geographiclib&lt;2,&gt;=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy-&gt;-r requirements.txt (line 11)) (1.52)
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from googletransx-&gt;-r requirements.txt (line 13)) (2.23.0)
Collecting requests
  Downloading requests-2.28.1-py3-none-any.whl (62 kB)
     |████████████████████████████████| 62 kB 1.4 MB/s 
?25hBuilding wheels for collected packages: twint, googletransx
  Building wheel for twint (setup.py) ... ?25l?25hdone
  Created wheel for twint: filename=twint-2.1.21-py3-none-any.whl size=38871 sha256=7e92b75b75bda0d87bb045ea8e8c8475d1b649ecd34587562fee6730c8584fa3
  Stored in directory: /tmp/pip-ephem-wheel-cache-2kekm_44/wheels/f7/3e/11/2803f3c6890e87a9bec35bb8e37ef1ad0777a00f43e2441fb1
  Building wheel for googletransx (setup.py) ... ?25l?25hdone
  Created wheel for googletransx: filename=googletransx-2.4.2-py3-none-any.whl size=15968 sha256=71cfbef1bf3218395f57f216de9a5aca4c28c22b4d107740e17b489a4d94252a
  Stored in directory: /root/.cache/pip/wheels/66/d5/b1/31104b338f7fd45aa8f7d22587765db06773b13df48a89735f
Successfully built twint googletransx
Installing collected packages: urllib3, requests, pycares, elastic-transport, schedule, googletransx, fake-useragent, elasticsearch, dataclasses, cchardet, aiohttp-socks, aiodns, twint
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.3
    Uninstalling urllib3-1.24.3:
      Successfully uninstalled urllib3-1.24.3
  Attempting uninstall: requests
    Found existing installation: requests 2.23.0
    Uninstalling requests-2.23.0:
      Successfully uninstalled requests-2.23.0
Successfully installed aiodns-3.0.0 aiohttp-socks-0.4.1 cchardet-2.1.7 dataclasses-0.6 elastic-transport-8.4.0 elasticsearch-8.5.0 fake-useragent-0.1.14 googletransx-2.4.2 pycares-4.2.2 requests-2.28.1 schedule-1.1.0 twint-2.1.21 urllib3-1.26.12
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install nest-asyncio
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting nest-asyncio
  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)
Installing collected packages: nest-asyncio
Successfully installed nest-asyncio-1.5.6
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install <span class="nv">aiohttp</span><span class="o">==</span><span class="m">3</span>.7.0
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting aiohttp==3.7.0
  Downloading aiohttp-3.7.0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)
     |████████████████████████████████| 1.3 MB 8.0 MB/s 
?25hRequirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (6.0.2)
Collecting async-timeout&lt;4.0,&gt;=3.0
  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)
Requirement already satisfied: chardet&lt;4.0,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (3.0.4)
Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (22.1.0)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (1.8.1)
Requirement already satisfied: idna&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp==3.7.0) (2.10)
Requirement already satisfied: typing-extensions&gt;=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp==3.7.0) (4.1.1)
Installing collected packages: async-timeout, aiohttp
  Attempting uninstall: async-timeout
    Found existing installation: async-timeout 4.0.2
    Uninstalling async-timeout-4.0.2:
      Successfully uninstalled async-timeout-4.0.2
  Attempting uninstall: aiohttp
    Found existing installation: aiohttp 3.8.3
    Uninstalling aiohttp-3.8.3:
      Successfully uninstalled aiohttp-3.8.3
Successfully installed aiohttp-3.7.0 async-timeout-3.0.1
</pre></div>
</div>
</div>
</div>
</section>
<section id="id43">
<h4>Scraping Data Tweeter<a class="headerlink" href="#id43" title="Permalink to this headline">#</a></h4>
<p>Setelah proses installasi Twint berhasil selanjutnya lakukan scraping data tweeter. Scraping sendiri merupakan proses pengambilan data dari website. Untuk melakukan proses scraping data dari tweeter, tinggal import twint untuk melakukan scraping data tweeter dengan tweet yang mengandung kata “#rockygerung” dengan limit 100 menggunakan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nest_asyncio</span>
<span class="n">nest_asyncio</span><span class="o">.</span><span class="n">apply</span><span class="p">()</span> <span class="c1">#digunakan sekali untuk mengaktifkan tindakan serentak dalam notebook jupyter.</span>
<span class="kn">import</span> <span class="nn">twint</span> <span class="c1">#untuk import twint</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">twint</span><span class="o">.</span><span class="n">Config</span><span class="p">()</span>
<span class="n">c</span><span class="o">.</span><span class="n">Search</span> <span class="o">=</span> <span class="s1">&#39;#rockygerung&#39;</span>
<span class="n">c</span><span class="o">.</span><span class="n">Lang</span> <span class="o">=</span> <span class="s2">&quot;in&quot;</span>
<span class="n">c</span><span class="o">.</span><span class="n">Pandas</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">c</span><span class="o">.</span><span class="n">Limit</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">twint</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">Search</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1590933496121688064 2022-11-11 05:04:38 +0000 &lt;rockygerungcom&gt; Quote:  Negeri yang memburuk karena dikelola manajemen benda mati: kerja, kerja, kerja.  | #negeri | #rockygerungcom | #rockygerung
1590931427251539968 2022-11-11 04:56:24 +0000 &lt;fajaronline&gt; Ketum Projo Temui Prabowo Usai Jokowi Berikan Sinyal Dukungan, Rocky Gerung: Ngapain, Mestinya Bubar Aja  https://t.co/NUtPTVPwVJ #BudiArieSetiadi #PrabowoSubianto #Projo #RockyGerung
1590872156975804416 2022-11-11 01:00:53 +0000 &lt;fajaronline&gt; Puan dan Mega ke Itaewon, Tragedi Kanjuruhan Tak Pernah Dikunjungi, Rocky Gerung: Ini Soal Standar Pemimpin  https://t.co/38Dhy63g42 #Itaewon #Kanjuruhan #PuanMaharani #RockyGerung
1590652396832976897 2022-11-10 10:27:38 +0000 &lt;Rgtvchannel_id&gt; #RockyGerung #PoliticsAndBeyond #IndonesiaBerpikir #FasliJalal
1590636648638750720 2022-11-10 09:25:04 +0000 &lt;jpnncom&gt; Rocky Gerung mengusulkan Anies Baswedan menjadikan Gibran sebagai cawapres. Begini respons Gibran, putra Presiden Jokowi, itu. #RockyGerung  https://t.co/X2CFC9264Q
1590607905320935424 2022-11-10 07:30:51 +0000 &lt;Rgtvchannel_id&gt; 10 November. Ada yang harus dikenang, ada yang harus diingat.  Selamat Hari Pahlawan.  #RGTVChannelid #politicsandbeyond  #RockyGerung  https://t.co/PTAWnCqgiC
1590529183578750976 2022-11-10 02:18:02 +0000 &lt;terkinidotid&gt; Rocky Gerung Usulkan Luhut Pandjaitan Jadi Cawapres Anies Baswedan: Pengamat politik Rocky Gerung mengusulkan agar Menko Marves Luhut Pandjaitan menjadi Calon Wakil Presiden (Cawapres) Anies Baswedan pada…  https://t.co/flwt1HHZHf #News #rockygerung #rockygerungluhutpandjaitan
1590339773016997888 2022-11-09 13:45:23 +0000 &lt;Korantalknews&gt; Mantan Ajudan Mengubah Kesaksian di Sidang, Akui Takut Pada Sosok Ferdy Sambo   https://t.co/aQy01Ywtt9  #korantalk #korantalknew #ferdysambo #like #brigadirj #bandung #bali #jakarta #indonesia #jokowi #jokowidodo #rockygerung #bbm #bbmnaik #surabaya #cicaheumbandung #instagood  https://t.co/ZuYL8Ymfcc
1590295887766777862 2022-11-09 10:51:00 +0000 &lt;Rgtvchannel_id&gt; #RockyGerung #PoliticsAndBeyond #IndonesiaBerpikir
1590189864045379585 2022-11-09 03:49:42 +0000 &lt;rockygerungcom&gt; Quote:  Memaki boleh.  Tapi jangan cuma itu keahlianmu, Bong:)  | #memaki | #rockygerungcom | #rockygerung
1590137806428393472 2022-11-09 00:22:51 +0000 &lt;fajaronline&gt; Rocky Gerung Puji Buzzer Demokrat Pintar-pintar, Panca: Beda Sama Buzzer Coro, Nggak Aneh Ade Armando Ditelanjangi  https://t.co/BRnNrbR82X #Buzzer #CiptaPancaLaksana #PartaiDemokrat #RockyGerung
1589986615275188227 2022-11-08 14:22:04 +0000 &lt;Rgtvchannel_id&gt; Banyak kisah Rhoma Irama di masa lalu terbongkar ketika ngobrol seru bareng Rocky Gerung.  Saksikan Rabu besok (9/11/2022) hanya di Youtube RGTV Channel ID  #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir #RhomaIrama #Soneta #BisikanRhoma  https://t.co/NpYjeq5De3
1589972488498581505 2022-11-08 13:25:56 +0000 &lt;Rgtvchannel_id&gt; #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir #RhomaIrama #Soneta #BisikanRhoma
1589612333428768768 2022-11-07 13:34:48 +0000 &lt;Rgtvchannel_id&gt; Rhoma : &quot;Di dalam negara demokrasi itu harus ada oposisi. Kalau ada politisi yang mengatakan tak boleh ada oposisi, itu... &quot;  Rocky: &quot;Dungu!&quot; Rhoma: &quot;Iya... dungu.&quot;  #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir #RhomaIrama #Soneta #BisikanRhoma  https://t.co/C5ypnzNfTC
1589590967396749313 2022-11-07 12:09:54 +0000 &lt;Rgtvchannel_id&gt; Banyak jalan menuju Rhoma Bila engkau gagal di dalam satu cara Cari lagi cara lainnya  dari lirik lagu &quot;Banyak Jalan Menuju Roma&quot; cipt. Rhoma Irama  #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir #RhomaIrama #Soneta #BisikanRhoma  https://t.co/cT05glNCvO
1589526799637426178 2022-11-07 07:54:55 +0000 &lt;AgusKwadrat&gt; Politik Identitas adalah suatu gerakan politik yang dengan sengaja disebut sebagai pembodohan atau penipuan dan sering kali dihadapkan pada aksi massa dari suatu pihak yang memiliki kepentingan.  #AniesBaswedan  #SuryaPaloh  #Munarman  #NovelBamukmin  #RockyGerung  #NichoSilalahi
1589525707813957632 2022-11-07 07:50:35 +0000 &lt;AnakKedungBulus&gt; Populisme Agama adalah suatu pendekatan politik yang dengan sengaja disebut sebagai kepentingan &quot;umat&quot; dan sering kali dihadapkan pada kepentingan suatu kelompok yang disebut &quot;saudara seiman&quot;.  #AniesBaswedan  #SuryaPaloh  #Munarman  #NovelBamukmin  #RockyGerung  #NichoSilalahi
1589485967949561856 2022-11-07 05:12:40 +0000 &lt;Rgtvchannel_id&gt; #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir #RhomaIrama #Soneta #BisikanRhoma
1589414589674192896 2022-11-07 00:29:02 +0000 &lt;terkinidotid&gt; Rocky Gerung Sebut Ade Armando Memecah Belah Suara Ganjar: Pengamat politik Rocky Gerung memberikan pendapatnya terkait video Ade Armando yang membahas tentang Anies Baswedan dan penganut agama Kristen.  https://t.co/iPSg4WdRnV #News #rockygerung #rockygerungadearmando
1589258072891219969 2022-11-06 14:07:06 +0000 &lt;Rgtvchannel_id&gt; Di episode #BisikanRhoma #50 yang sudah tayang di channel Rhoma Irama Official, sang Raja kasih tiga pertanyaan berat buat saya sambil berulang kali bilang, &quot;I love you Rocky&quot;  I love you too bang Haji!  #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #RhomaIrama #Soneta  https://t.co/bw9qr6g5Ch
1589250517846601729 2022-11-06 13:37:04 +0000 &lt;terkinidotid&gt; Rocky Gerung Sebut Jokowi Lebih Nyaman Bertemu Pendukung Dibanding Aksi Demonstrasi!: Belum lama ini, melalui sebuah unggahan dikanal youtobe, Rocky Gerung soroti Presiden Jokowi.  https://t.co/4YRQ9y3kwg #News #rockygerung #jokowi #presidenjokowi #jokowidodo
1589248078254833664 2022-11-06 13:27:23 +0000 &lt;Rgtvchannel_id&gt; Rho-Ro Kolaborasi Dua Fenomena  Rocky Gerung bertemu Rhoma Irama di markas Soneta. Apa jadinya kalau dua sosok fenomenal berjumpa? No Rocky No Party!  #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir #RhomaIrama #Soneta #BisikanRhoma  https://t.co/6c7NXIZt08
1589198248153354242 2022-11-06 10:09:22 +0000 &lt;Rgtvchannel_id&gt; #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir
1589098485361836032 2022-11-06 03:32:57 +0000 &lt;rockygerungcom&gt; Quote:  “Kami mulai kedunguan di sini. Kami akan tetap di sini”.  ~prasasti di sebuah kolam  | #kolam | #rockygerung | #rockygerungcom
1588986143387062272 2022-11-05 20:06:33 +0000 &lt;muzaqi_moh&gt; @henrysubiakto @PartaiSocmed Guru besar tp otak kecil #RockyGerung
1588835400050946051 2022-11-05 10:07:33 +0000 &lt;Rgtvchannel_id&gt; Cari keringat di kaki Gunung Fuji.  Di waktu senggang saat memenuhi undangan diskusi di Jepang beberapa waktu lalu, saya sempatkan berolahraga di hutan Pinus di sana.  #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir  https://t.co/hPc21nXcnb
1588811967674068993 2022-11-05 08:34:26 +0000 &lt;Rgtvchannel_id&gt; Cinta dan pengabdian adalah Edelweiss itu sendiri  #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir  https://t.co/lBS67SOfcz
1588778651348533248 2022-11-05 06:22:03 +0000 &lt;terkinidotid&gt; Rocky Gerung Sindir Jokowi Kabur dari Istana Setiap Ada Demo: Sekali Lagi Kedunguan Namanya!: Rocky Gerung menyindir Presiden Joko Widodo (Jokowi) yang disebut kerap tak ada di Istana setiap kali…  https://t.co/7P45LatbUf #News #rockygerung #presidenjokowi #demojokowi #gnprdemo
1588765232788566016 2022-11-05 05:28:43 +0000 &lt;rockygerungcom&gt; Quote:  Membaca itu pake otak. Supaya bila ngamuk, tak terlihat dungu.  | #otak | #rockygerungcom | #rockygerung
1588729591786778624 2022-11-05 03:07:06 +0000 &lt;AnakKedungBulus&gt; Gus Staquf : &quot;Bermain Identitas Agama Berarti Menggiring Perpecahan&quot;   #AniesBawedan  #SlametMaarif #NovelBamukmin  #Munarman  #ReflyHarun  #RockyGerung
1588728817543434241 2022-11-05 03:04:01 +0000 &lt;DameRomadona&gt; Rocky Gerung Punya Jagoan Pendamping Anies di Pilpres 2024, Bukan Aher Apa Lagi AHY  https://t.co/HUGqtxfDiN  #rockygerung #AniesPresiden2024  #plipres2024 #PemiluSerentak2024 #Pemilu2024 #ahy #news #new #NewsUpdates #berita
1588509502206521344 2022-11-04 12:32:33 +0000 &lt;partaigeloraid&gt; Rocky Gerung: Kebijakan Second Home Visa Itu Konyol ↘️ Saksikan di #GeloraTV  https://t.co/CYDm6ExVfl  https://t.co/CYDm6ExVfl  https://t.co/CYDm6ExVfl #geloratalks #rockygerung #partaigelora #AyoMoveOn #arahbaruindonesia  https://t.co/wUp5l3M7mL
1588494814437597186 2022-11-04 11:34:11 +0000 &lt;Rgtvchannel_id&gt; #RockyGerung #RGTVChannelID #PoliticsAndBeyond #IndonesiaBerpikir #JJRizal #LaksaCibinong
1588448599075344386 2022-11-04 08:30:32 +0000 &lt;ZFazaa86&gt; Apa? Merendah untuk dipuji? Itu sama halnya dengan meninggi. #rockygerung
1588447113629032448 2022-11-04 08:24:38 +0000 &lt;Rgtvchannel_id&gt; Selain mie ayam saya juga nikmati ketoprak di kaki gunung Galunggung.  Ketoprak ini makanan kesukaan Prabu Siliwangi. Dulu namanya ketopras.  #Rockymendation #RockyGerung #RockyGerungOfficial #PoliticsAndBeyond #IndonesiaBerpikir  https://t.co/0GzvS7Ab2f
1588372858463391744 2022-11-04 03:29:34 +0000 &lt;Rgtvchannel_id&gt; #RockyGerung #RGTVChannelID #PoliticsAndBeyond #IndonesiaBerpikir #JJRizal #LaksaCibinong  https://t.co/DiRaQDfEeY
1588360504556208128 2022-11-04 02:40:29 +0000 &lt;fajaronline&gt; Partai Demokrat Pastikan Mundur Jika Anies Pilih Luhut sebagai Cawapres  https://t.co/xWUMhGSEor #AniesBaswedan #RockyGerung #YanHarahap
1588349415864950784 2022-11-04 01:56:25 +0000 &lt;fajaronline&gt; Rocky Gerung Sebut Luhut Pendamping Anies yang Memenuhi Kriteria, AHY dan Aher Kalah  https://t.co/XnzfBj3X5x #AhmadHeryawan #AHY #AniesBaswedan #RockyGerung
1588338446191382528 2022-11-04 01:12:50 +0000 &lt;fajaronline&gt; Rocky Gerung Bilang Anies Butuh Pendamping yang Bisa Membangun Indonesia dengan Gaya Teknokrat  https://t.co/WRlA51Q9lD #AniesBaswedan #CawapresAnies #Pilpres2024 #RockyGerung
1588110734784724993 2022-11-03 10:07:59 +0000 &lt;Rgtvchannel_id&gt; #RGTVCHANNELID mengajak #IndonesiaBerpikir  #RockyGerung #RGTVChannelID #PoliticsAndBeyond #IndonesiaBerpikir
1588019170343792640 2022-11-03 04:04:08 +0000 &lt;eramadanicom&gt; Selengkapnya ditautan berikut :  https://t.co/8ezXkYu8On  #apindo #fahrihamzah #rockygerung #mancanegara #partai #partaigelora #visa #secondhome  https://t.co/l6PbPzknyX
1587982514488242176 2022-11-03 01:38:29 +0000 &lt;only4yo27523847&gt; Bismillah   https://t.co/0R3ROGuv8b  #panggung #debat #roger roger roger #rockygerung #cacadberbangsa #muak muak muak...
1587808712424497153 2022-11-02 14:07:51 +0000 &lt;rockygerungcom&gt; Quote:  Kosong ide, modal fanatik, tapi ngotot pujian. Ajaib :))  | #fanatik | #rockygerungcom | #rockygerung
[!] No more data! Scraping will stop now.
found 0 deleted tweets in this search.
</pre></div>
</div>
</div>
</div>
</section>
<section id="id44">
<h4>Ambil Tweet<a class="headerlink" href="#id44" title="Permalink to this headline">#</a></h4>
<p>Setelah proses crawling didapatkan data tweeter diatas, pada data tersebut terdapat data yang tidak diperlukan. Untuk melakukan prepocessing hanya memerlukan data tweet dari user, maka dari itu buang data yang tidak diperlukan dan ambil data tweet yang akan digunakan dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Tweets_dfs</span> <span class="o">=</span> <span class="n">twint</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">panda</span><span class="o">.</span><span class="n">Tweets_df</span>
<span class="n">Tweets_dfs</span><span class="p">[</span><span class="s2">&quot;tweet&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     Quote:  Negeri yang memburuk karena dikelola m...
1     Ketum Projo Temui Prabowo Usai Jokowi Berikan ...
2     Puan dan Mega ke Itaewon, Tragedi Kanjuruhan T...
3     #RockyGerung #PoliticsAndBeyond #IndonesiaBerp...
4     Rocky Gerung mengusulkan Anies Baswedan menjad...
5     10 November. Ada yang harus dikenang, ada yang...
6     Rocky Gerung Usulkan Luhut Pandjaitan Jadi Caw...
7     Mantan Ajudan Mengubah Kesaksian di Sidang, Ak...
8     #RockyGerung #PoliticsAndBeyond #IndonesiaBerp...
9     Quote:  Memaki boleh.  Tapi jangan cuma itu ke...
10    Rocky Gerung Puji Buzzer Demokrat Pintar-pinta...
11    Banyak kisah Rhoma Irama di masa lalu terbongk...
12    #RockyGerung #RockyGerungOfficial #PoliticsAnd...
13    Rhoma : &quot;Di dalam negara demokrasi itu harus a...
14    Banyak jalan menuju Rhoma Bila engkau gagal di...
15    Politik Identitas adalah suatu gerakan politik...
16    Populisme Agama adalah suatu pendekatan politi...
17    #RockyGerung #RockyGerungOfficial #PoliticsAnd...
18    Rocky Gerung Sebut Ade Armando Memecah Belah S...
19    Di episode #BisikanRhoma #50 yang sudah tayang...
20    Rocky Gerung Sebut Jokowi Lebih Nyaman Bertemu...
21    Rho-Ro Kolaborasi Dua Fenomena  Rocky Gerung b...
22    #RockyGerung #RockyGerungOfficial #PoliticsAnd...
23    Quote:  “Kami mulai kedunguan di sini. Kami ak...
24    @henrysubiakto @PartaiSocmed Guru besar tp ota...
25    Cari keringat di kaki Gunung Fuji.  Di waktu s...
26    Cinta dan pengabdian adalah Edelweiss itu send...
27    Rocky Gerung Sindir Jokowi Kabur dari Istana S...
28    Quote:  Membaca itu pake otak. Supaya bila nga...
29    Gus Staquf : &quot;Bermain Identitas Agama Berarti ...
30    Rocky Gerung Punya Jagoan Pendamping Anies di ...
31    Rocky Gerung: Kebijakan Second Home Visa Itu K...
32    #RockyGerung #RGTVChannelID #PoliticsAndBeyond...
33    Apa? Merendah untuk dipuji? Itu sama halnya de...
34    Selain mie ayam saya juga nikmati ketoprak di ...
35    #RockyGerung #RGTVChannelID #PoliticsAndBeyond...
36    Partai Demokrat Pastikan Mundur Jika Anies Pil...
37    Rocky Gerung Sebut Luhut Pendamping Anies yang...
38    Rocky Gerung Bilang Anies Butuh Pendamping yan...
39    #RGTVCHANNELID mengajak #IndonesiaBerpikir  #R...
40    Selengkapnya ditautan berikut :  https://t.co/...
41    Bismillah   https://t.co/0R3ROGuv8b  #panggung...
42    Quote:  Kosong ide, modal fanatik, tapi ngotot...
Name: tweet, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id45">
<h3>Upload Data Tweet<a class="headerlink" href="#id45" title="Permalink to this headline">#</a></h3>
<p>Setelah data tweet di dapatkan, simpan data tweet tersebut dalam bentuk csv, kemudian download dan upload ke github untuk nanti digunakan sebagai dataset dari proses prepocessing text.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Tweets_dfs</span><span class="p">[</span><span class="s2">&quot;tweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;RG.csv&quot;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id46">
<h2><strong>Prepocessing Text</strong><a class="headerlink" href="#id46" title="Permalink to this headline">#</a></h2>
<p>Setelah proses crawling, selanjutnya dilakukan prepocessing text, yaitu sebuah proses mesin yang digunakan untuk menyeleksi data teks agar lebih terstruktur dengan melalui beberapa tahapan-tahapan yang meliputi tahapan case folding, tokenizing, filtering dan stemming.
Sebelum melakukan tahapan-tahapan tersebut, terlebih dahulu kita import data crawling yang diupload ke github tadi dengan menggunakan library pandas pada source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> 

<span class="n">tweets</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/Fahrur190125/Data/main/RG.csv&quot;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">tweets</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-f251aad2-e06e-4b89-8bf4-dffe79027949">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tweet</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Anies itu Penantang 👈👉 said #RockyGerung    ht...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>#RockyGerung #RGTVChannelid #PolitcsAndBeyond ...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>KODE DARI OPUNG LUHUT!!  Tidak mau jadi calon ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Rocky Gerung Bicara Soal Keberlangsungan Pemer...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>#RockyGerung #RGTVChannelid #PolitcsAndBeyond ...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>Jaman REZIM SKRG kaya bapa tiri di sinetron......</td>
    </tr>
    <tr>
      <th>96</th>
      <td>Sobat akal sehat nantikan video part 2 yang ak...</td>
    </tr>
    <tr>
      <th>97</th>
      <td>Menteri Koordinator bidang Kemaritiman dan Inv...</td>
    </tr>
    <tr>
      <th>98</th>
      <td>PEMBODOHAN YANG BERLANGSUNG DALAM KURIKULUM ET...</td>
    </tr>
    <tr>
      <th>99</th>
      <td>Setuju dengan Bung Rocky?!  Saksikan selengkap...</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 1 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-f251aad2-e06e-4b89-8bf4-dffe79027949')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-f251aad2-e06e-4b89-8bf4-dffe79027949 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-f251aad2-e06e-4b89-8bf4-dffe79027949');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<p>Setelah data crawling berhasil di import, selanjutnya lakukan tahapan-tahapan prepocessing seperti berikut.</p>
<section id="id47">
<h3>Case Folding<a class="headerlink" href="#id47" title="Permalink to this headline">#</a></h3>
<p>Setelah berhassil mengambil dataset, selanjutnya ke proses prepocessing ke tahapan case folding yaitu tahapan pertama untuk melakukan prepocessing text dengan mengubah text menjadi huruf kecil semua dengan menghilangkan juga karakter spesial, angka, tanda baca, spasi serta huruf yang tidak penting.</p>
<section id="id48">
<h4>Merubah Huruf Kecil Semua<a class="headerlink" href="#id48" title="Permalink to this headline">#</a></h4>
<p>Tahapan case folding yang pertama yaitu merubah semua huruf menjadi huruf kecil semua menggunakan fungsi lower() dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>


<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     anies itu penantang 👈👉 said #rockygerung    ht...
1     #rockygerung #rgtvchannelid #politcsandbeyond ...
2     kode dari opung luhut!!  tidak mau jadi calon ...
3     rocky gerung bicara soal keberlangsungan pemer...
4     #rockygerung #rgtvchannelid #politcsandbeyond ...
                            ...                        
95    jaman rezim skrg kaya bapa tiri di sinetron......
96    sobat akal sehat nantikan video part 2 yang ak...
97    menteri koordinator bidang kemaritiman dan inv...
98    pembodohan yang berlangsung dalam kurikulum et...
99    setuju dengan bung rocky?!  saksikan selengkap...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id49">
<h4>Menghapus Karakter Spesial<a class="headerlink" href="#id49" title="Permalink to this headline">#</a></h4>
<p>Tahapan case folding selanjutnya ialah menghapus karakter spesial dengan menggunakan library nltk, untuk menggunakan librarynya terlebih dahulu install dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#install library nltk</span>
<span class="o">!</span>pip install nltk
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)
Requirement already satisfied: regex&gt;=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)
Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)
Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)
Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)
</pre></div>
</div>
</div>
</div>
<p>Setelah library nltk terinstall kita import librarynya dan buat sebuah function untuk menghapus karakter spesial tersebut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">string</span> 
<span class="kn">import</span> <span class="nn">re</span> <span class="c1">#regex library</span>
<span class="c1"># import word_tokenize &amp; FreqDist from NLTK</span>

<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span> 
<span class="kn">from</span> <span class="nn">nltk.probability</span> <span class="kn">import</span> <span class="n">FreqDist</span>


<span class="k">def</span> <span class="nf">remove_special</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># remove tab, new line, ans back slice</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">t&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">n&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">u&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">f&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">r&#39;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
    <span class="c1"># remove non ASCII (emoticon, chinese word, .etc)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;ascii&#39;</span><span class="p">,</span> <span class="s1">&#39;replace&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;ascii&#39;</span><span class="p">)</span>
    <span class="c1"># remove mention, link, hashtag</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;([@#][A-Za-z0-9]+)|(\w+:\/\/\S+)&quot;</span><span class="p">,</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
    <span class="c1"># remove incomplete URL</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;http://&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;https://&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
                
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_special</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                           anies itu penantang ?? said
1                                                      
2     kode dari opung luhut!! tidak mau jadi calon p...
3     rocky gerung bicara soal keberlangsungan pemer...
4                                                      
                            ...                        
95    jaman rezim skrg kaya bapa tiri di sinetron......
96    sobat akal sehat nantikan video part 2 yang ak...
97    menteri koordinator bidang kemaritiman dan inv...
98    pembodohan yang berlangsung dalam kurikulum et...
99    setuju dengan bung rocky?! saksikan selengkapn...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id50">
<h4>Menghapus Angka<a class="headerlink" href="#id50" title="Permalink to this headline">#</a></h4>
<p>Selanjutnya melakukan penghapusan angka, penghapusan angka disini fleksibel, jika angka ingin dijadikan fitur maka penghapusan angka tidak perlu dilakukan. Untuk data tweet ini saya tidak ingin menjadikan angka sebagai fitur, untuk itu dilakukan penghapusan angka dengan function berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#remove number</span>
<span class="k">def</span> <span class="nf">remove_number</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span>  <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\d+&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_number</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                           anies itu penantang ?? said
1                                                      
2     kode dari opung luhut!! tidak mau jadi calon p...
3     rocky gerung bicara soal keberlangsungan pemer...
4                                                      
                            ...                        
95    jaman rezim skrg kaya bapa tiri di sinetron......
96    sobat akal sehat nantikan video part  yang aka...
97    menteri koordinator bidang kemaritiman dan inv...
98    pembodohan yang berlangsung dalam kurikulum et...
99    setuju dengan bung rocky?! saksikan selengkapn...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id51">
<h4>Menghapus Tanda Baca<a class="headerlink" href="#id51" title="Permalink to this headline">#</a></h4>
<p>Selanjutnya penghapusan tanda baca yang tidak perlu yang dilakukan dengan function punctuation berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#remove punctuation</span>
<span class="k">def</span> <span class="nf">remove_punctuation</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="nb">str</span><span class="o">.</span><span class="n">maketrans</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">,</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">))</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_punctuation</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                             anies itu penantang  said
1                                                      
2     kode dari opung luhut tidak mau jadi calon pre...
3     rocky gerung bicara soal keberlangsungan pemer...
4                                                      
                            ...                        
95    jaman rezim skrg kaya bapa tiri di sinetron di...
96    sobat akal sehat nantikan video part  yang aka...
97    menteri koordinator bidang kemaritiman dan inv...
98    pembodohan yang berlangsung dalam kurikulum et...
99    setuju dengan bung rocky saksikan selengkapnya...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id52">
<h4>Menghapus Spasi<a class="headerlink" href="#id52" title="Permalink to this headline">#</a></h4>
<p>Selanjutnya melakukan penghapusan spasi dengab menggunakan function berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#remove whitespace leading &amp; trailing</span>
<span class="k">def</span> <span class="nf">remove_whitespace_LT</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_whitespace_LT</span><span class="p">)</span>


<span class="c1">#remove multiple whitespace into single whitespace</span>
<span class="k">def</span> <span class="nf">remove_whitespace_multiple</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span><span class="s1">&#39; &#39;</span><span class="p">,</span><span class="n">text</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_whitespace_multiple</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                              anies itu penantang said
1                                                      
2     kode dari opung luhut tidak mau jadi calon pre...
3     rocky gerung bicara soal keberlangsungan pemer...
4                                                      
                            ...                        
95    jaman rezim skrg kaya bapa tiri di sinetron di...
96    sobat akal sehat nantikan video part yang akan...
97    menteri koordinator bidang kemaritiman dan inv...
98    pembodohan yang berlangsung dalam kurikulum et...
99    setuju dengan bung rocky saksikan selengkapnya...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id53">
<h4>Menghapus Huruf<a class="headerlink" href="#id53" title="Permalink to this headline">#</a></h4>
<p>Selanjutnya melakukan penghapusan huruf yang tidak bermakna dengan function berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># remove single char</span>
<span class="k">def</span> <span class="nf">remove_singl_char</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\b[a-zA-Z]\b&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">remove_singl_char</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                              anies itu penantang said
1                                                      
2     kode dari opung luhut tidak mau jadi calon pre...
3     rocky gerung bicara soal keberlangsungan pemer...
4                                                      
                            ...                        
95    jaman rezim skrg kaya bapa tiri di sinetron di...
96    sobat akal sehat nantikan video part yang akan...
97    menteri koordinator bidang kemaritiman dan inv...
98    pembodohan yang berlangsung dalam kurikulum et...
99    setuju dengan bung rocky saksikan selengkapnya...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id54">
<h3>Tokenizing<a class="headerlink" href="#id54" title="Permalink to this headline">#</a></h3>
<p>Setelah tahapan case folding selesai, selanjutnya masuk ke tahapan tokenizing yang merupakan tahapan prepocessing yang memecah kalimat dari text menjadi kata agar membedakan antara kata pemisah atau bukan. Untuk melakukan tokenizing dapat menggunakan dengan library nltk dan function berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span>
<span class="c1"># NLTK word Tokenize </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt.zip.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># NLTK word Tokenize </span>
<span class="k">def</span> <span class="nf">word_tokenize_wrapper</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">word_tokenize_wrapper</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                         [anies, itu, penantang, said]
1                                                    []
2     [kode, dari, opung, luhut, tidak, mau, jadi, c...
3     [rocky, gerung, bicara, soal, keberlangsungan,...
4                                                    []
                            ...                        
95    [jaman, rezim, skrg, kaya, bapa, tiri, di, sin...
96    [sobat, akal, sehat, nantikan, video, part, ya...
97    [menteri, koordinator, bidang, kemaritiman, da...
98    [pembodohan, yang, berlangsung, dalam, kurikul...
99    [setuju, dengan, bung, rocky, saksikan, seleng...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id55">
<h3>Filtering(Stopword)<a class="headerlink" href="#id55" title="Permalink to this headline">#</a></h3>
<p>Tahapan prepocessing selanjutnya ialah filtering atau disebut juga stopword yang merupakan lanjutan dari tahapan tokenizing yang digunakan untuk mengambil kata-kata penting dari hasil tokenizing tersebut dengan menghapus kata hubung yang tidak memiliki makna.</p>
<p>Proses stopword dapat dilakukan dengan mengimport library stopword dan function berikut untuk melakukan stopword.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;stopwords&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Unzipping corpora/stopwords.zip.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">list_stopwords</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;indonesian&#39;</span><span class="p">)</span>

<span class="c1"># append additional stopword</span>
<span class="n">list_stopwords</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s2">&quot;yg&quot;</span><span class="p">,</span> <span class="s2">&quot;dg&quot;</span><span class="p">,</span> <span class="s2">&quot;rt&quot;</span><span class="p">,</span> <span class="s2">&quot;dgn&quot;</span><span class="p">,</span> <span class="s2">&quot;ny&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="s1">&#39;klo&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;kalo&#39;</span><span class="p">,</span> <span class="s1">&#39;amp&#39;</span><span class="p">,</span> <span class="s1">&#39;biar&#39;</span><span class="p">,</span> <span class="s1">&#39;bikin&#39;</span><span class="p">,</span> <span class="s1">&#39;bilang&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;gak&#39;</span><span class="p">,</span> <span class="s1">&#39;ga&#39;</span><span class="p">,</span> <span class="s1">&#39;krn&#39;</span><span class="p">,</span> <span class="s1">&#39;nya&#39;</span><span class="p">,</span> <span class="s1">&#39;nih&#39;</span><span class="p">,</span> <span class="s1">&#39;sih&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;si&#39;</span><span class="p">,</span> <span class="s1">&#39;tau&#39;</span><span class="p">,</span> <span class="s1">&#39;tdk&#39;</span><span class="p">,</span> <span class="s1">&#39;tuh&#39;</span><span class="p">,</span> <span class="s1">&#39;utk&#39;</span><span class="p">,</span> <span class="s1">&#39;ya&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;jd&#39;</span><span class="p">,</span> <span class="s1">&#39;jgn&#39;</span><span class="p">,</span> <span class="s1">&#39;sdh&#39;</span><span class="p">,</span> <span class="s1">&#39;aja&#39;</span><span class="p">,</span> <span class="s1">&#39;n&#39;</span><span class="p">,</span> <span class="s1">&#39;t&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;nyg&#39;</span><span class="p">,</span> <span class="s1">&#39;hehe&#39;</span><span class="p">,</span> <span class="s1">&#39;pen&#39;</span><span class="p">,</span> <span class="s1">&#39;u&#39;</span><span class="p">,</span> <span class="s1">&#39;nan&#39;</span><span class="p">,</span> <span class="s1">&#39;loh&#39;</span><span class="p">,</span> <span class="s1">&#39;rt&#39;</span><span class="p">,</span>
                       <span class="s1">&#39;&amp;amp&#39;</span><span class="p">,</span> <span class="s1">&#39;yah&#39;</span><span class="p">])</span>

<span class="c1"># convert list to dictionary</span>
<span class="n">list_stopwords</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">list_stopwords</span><span class="p">)</span>

<span class="c1">#Menghapus Stopword dari list token</span>
<span class="k">def</span> <span class="nf">stopwords_removal</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">list_stopwords</span><span class="p">]</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">stopwords_removal</span><span class="p">)</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                              [anies, penantang, said]
1                                                    []
2     [kode, opung, luhut, calon, presiden, acara, k...
3     [rocky, gerung, bicara, keberlangsungan, pemer...
4                                                    []
                            ...                        
95    [jaman, rezim, skrg, kaya, bapa, tiri, sinetro...
96    [sobat, akal, sehat, nantikan, video, part, ta...
97    [menteri, koordinator, bidang, kemaritiman, in...
98        [pembodohan, kurikulum, etika, rocky, gerung]
99    [setuju, rocky, saksikan, selengkapnya, youtub...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="id56">
<h3>Stemming<a class="headerlink" href="#id56" title="Permalink to this headline">#</a></h3>
<p>Tahapan terakhir dari proses prepocessing ialah stemming yang merupakan penghapusan suffix maupun prefix pada text sehingga menjadi kata dasar. Proses ini dapat dilakukan dengan menggunakan library sastrawi dan swifter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install Sastrawi
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting Sastrawi
  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)
     |████████████████████████████████| 209 kB 8.7 MB/s 
?25hInstalling collected packages: Sastrawi
Successfully installed Sastrawi-1.0.1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install swifter
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting swifter
  Downloading swifter-1.3.4.tar.gz (830 kB)
     |████████████████████████████████| 830 kB 9.6 MB/s 
?25hRequirement already satisfied: pandas&gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (1.3.5)
Collecting psutil&gt;=5.6.6
  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)
     |████████████████████████████████| 280 kB 57.0 MB/s 
?25hRequirement already satisfied: dask[dataframe]&gt;=2.10.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (2022.2.0)
Requirement already satisfied: tqdm&gt;=4.33.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (4.64.1)
Requirement already satisfied: ipywidgets&gt;=7.0.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (7.7.1)
Requirement already satisfied: cloudpickle&gt;=0.2.2 in /usr/local/lib/python3.7/dist-packages (from swifter) (1.5.0)
Requirement already satisfied: parso&gt;0.4.0 in /usr/local/lib/python3.7/dist-packages (from swifter) (0.8.3)
Requirement already satisfied: bleach&gt;=3.1.1 in /usr/local/lib/python3.7/dist-packages (from swifter) (5.0.1)
Requirement already satisfied: six&gt;=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bleach&gt;=3.1.1-&gt;swifter) (1.15.0)
Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach&gt;=3.1.1-&gt;swifter) (0.5.1)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (21.3)
Requirement already satisfied: fsspec&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (2022.10.0)
Requirement already satisfied: toolz&gt;=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (0.12.0)
Requirement already satisfied: pyyaml&gt;=5.3.1 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (6.0)
Requirement already satisfied: partd&gt;=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (1.3.0)
Requirement already satisfied: numpy&gt;=1.18 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]&gt;=2.10.0-&gt;swifter) (1.21.6)
Requirement already satisfied: traitlets&gt;=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (5.1.1)
Requirement already satisfied: ipython&gt;=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (7.9.0)
Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (3.6.1)
Requirement already satisfied: ipykernel&gt;=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (5.3.4)
Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (0.2.0)
Requirement already satisfied: jupyterlab-widgets&gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets&gt;=7.0.0-&gt;swifter) (3.0.3)
Requirement already satisfied: tornado&gt;=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (6.0.4)
Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (6.1.12)
Requirement already satisfied: setuptools&gt;=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (57.4.0)
Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.8.0)
Requirement already satisfied: prompt-toolkit&lt;2.1.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.0.10)
Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.6.1)
Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.4.2)
Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.7.5)
Collecting jedi&gt;=0.10
  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)
     |████████████████████████████████| 1.6 MB 43.2 MB/s 
?25hRequirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.2.0)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging&gt;=20.0-&gt;dask[dataframe]&gt;=2.10.0-&gt;swifter) (3.0.9)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=1.0.0-&gt;swifter) (2022.6)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=1.0.0-&gt;swifter) (2.8.2)
Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd&gt;=0.3.10-&gt;dask[dataframe]&gt;=2.10.0-&gt;swifter) (1.0.0)
Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit&lt;2.1.0,&gt;=2.0.0-&gt;ipython&gt;=4.0.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.2.5)
Requirement already satisfied: notebook&gt;=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.7.16)
Requirement already satisfied: terminado&gt;=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.13.3)
Requirement already satisfied: jupyter-core&gt;=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.11.2)
Requirement already satisfied: nbconvert&lt;6.0 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.6.1)
Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.15.0)
Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (1.8.0)
Requirement already satisfied: jinja2&lt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.11.3)
Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.7.0)
Requirement already satisfied: pyzmq&gt;=17 in /usr/local/lib/python3.7/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (23.2.1)
Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2&lt;=3.0.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.0.1)
Requirement already satisfied: entrypoints&gt;=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert&lt;6.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.4)
Requirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert&lt;6.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.8.4)
Requirement already satisfied: pandocfilters&gt;=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert&lt;6.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (1.5.0)
Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert&lt;6.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.7.1)
Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert&lt;6.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.6.0)
Requirement already satisfied: jsonschema&gt;=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.3.3)
Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (2.16.2)
Requirement already satisfied: importlib-metadata&gt;=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.13.0)
Requirement already satisfied: typing-extensions&gt;=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=3.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (4.1.1)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=3.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (3.10.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.19.2)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (22.1.0)
Requirement already satisfied: importlib-resources&gt;=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (5.10.0)
Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado&gt;=0.8.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&gt;=7.0.0-&gt;swifter) (0.7.0)
Building wheels for collected packages: swifter
  Building wheel for swifter (setup.py) ... ?25l?25hdone
  Created wheel for swifter: filename=swifter-1.3.4-py3-none-any.whl size=16323 sha256=794e1c7f4d1b3691e5bb6967ef3705a7c909d2f135adeb78910fa817f6c4e083
  Stored in directory: /root/.cache/pip/wheels/29/a7/0e/3a8f17ac69d759e1e93647114bc9bdc95957e5b0cbfd405205
Successfully built swifter
Installing collected packages: jedi, psutil, swifter
  Attempting uninstall: psutil
    Found existing installation: psutil 5.4.8
    Uninstalling psutil-5.4.8:
      Successfully uninstalled psutil-5.4.8
Successfully installed jedi-0.18.1 psutil-5.9.4 swifter-1.3.4
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">Sastrawi.Stemmer.StemmerFactory</span> <span class="kn">import</span> <span class="n">StemmerFactory</span>
<span class="kn">import</span> <span class="nn">swifter</span>


<span class="c1"># create stemmer</span>
<span class="n">factory</span> <span class="o">=</span> <span class="n">StemmerFactory</span><span class="p">()</span>
<span class="n">stemmer</span> <span class="o">=</span> <span class="n">factory</span><span class="o">.</span><span class="n">create_stemmer</span><span class="p">()</span>

<span class="c1"># stemmed</span>
<span class="k">def</span> <span class="nf">stemmed_wrapper</span><span class="p">(</span><span class="n">term</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">term</span><span class="p">)</span>

<span class="n">term_dict</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">document</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">term</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">term_dict</span><span class="p">:</span>
            <span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span>
            
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">term_dict</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">term_dict</span><span class="p">:</span>
    <span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">=</span> <span class="n">stemmed_wrapper</span><span class="p">(</span><span class="n">term</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">term</span><span class="p">,</span><span class="s2">&quot;:&quot;</span> <span class="p">,</span><span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">])</span>
    
<span class="nb">print</span><span class="p">(</span><span class="n">term_dict</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------&quot;</span><span class="p">)</span>


<span class="c1"># apply stemmed term to dataframe</span>
<span class="k">def</span> <span class="nf">get_stemmed_term</span><span class="p">(</span><span class="n">document</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">document</span><span class="p">]</span>

<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">swifter</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_stemmed_term</span><span class="p">)</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>424
------------------------
anies : anies
penantang : tantang
said : said
kode : kode
opung : opung
luhut : luhut
calon : calon
presiden : presiden
acara : acara
kib : kib
pimpinan : pimpin
airlangga : airlangga
hartarto : hartarto
gimana : gimana
arti : arti
rocky : rocky
gerung : gerung
bicara : bicara
keberlangsungan : langsung
pemerintahan : perintah
jokowi : jokowi
pengamat : amat
politik : politik
pendapatnya : dapat
era : era
menurutnya : turut
rgtv : rgtv
channel : channel
id : id
mengajak : ajak
wali : wali
kota : kota
solo : solo
gibran : gibran
rakabuming : rakabuming
raka : raka
mengakui : aku
menerima : terima
kritikan : kritik
bertemu : temu
tweet : tweet
sekolah : sekolah
menandakan : tanda
pelajar : ajar
belom : bom
pemikir : pikir
quote : quote
kalangan : kalang
istana : istana
menelepon : telepon
pengen : ken
berkunjung : kunjung
silakan : sila
ucapkan : ucap
publik : publik
sisi : sisi
ekonomi : ekonomi
dikritik : kritik
habis : habis
sadar : sadar
belajar : ajar
otak : otak
kosong : kosong
dungu : dungu
mengaku : aku
bertandang : tandang
kediaman : diam
orang : orang
jenius : jenius
masukan : masuk
baca : baca
selengkapnya : lengkap
bahas : bahas
dungudunguan : dungudunguan
saksikan : saksi
youtube : youtube
temukan : temu
link : link
akui : aku
disemprot : semprot
dibahas : bahas
xi : xi
jinping : jinping
dikudeta : kudeta
dampaknya : dampak
indonesia : indonesia
tantang : tantang
juara : juara
kelas : kelas
terbang : terbang
one : one
pride : pride
mma : mma
dukung : dukung
bertarung : tarung
ring : ring
duel : duel
sengit : sengit
penyandang : sandang
menang : menang
awali : awal
harimu : hari
semangat : semangat
selamat : selamat
senin : senin
sobat : sobat
akal : akal
sehat : sehat
salam : salam
berguru : guru
reaksi : reaksi
disinggung : singgung
oligarki : oligarki
menceritakan : cerita
momen : momen
pertemuan : temu
putra : putra
aliansi : aliansi
serikat : serikat
buruh : buruh
bersatu : satu
berama : ama
quen : quen
of : of
longmarct : longmarct
bergerak : gerak
puncak : puncak
negara : negara
jakarta : jakarta
sep : sep
nggak : nggak
urusan : urus
unggahan : unggah
foto : foto
media : media
sosial : sosial
menuai : tuai
sorotan : sorot
lantaran : lantar
penjajagan : penjajagan
pasangan : pasang
mas : mas
bang : bang
manyambut : manyambut
pertarungan : tarung
tamu : tamu
tebak : tebak
clue : clue
pria : pria
kelahiran : lahir
magetan : magetan
jawa : jawa
timur : timur
hobi : hobi
muay : muay
thai : thai
berjualan : jual
bakso : bakso
heran : heran
disambangi : sambang
dibenci : benci
nicho : nicho
silalahi : silalahi
soroti : sorot
maksa : maksa
statemen : statemen
berbahaya : bahaya
pegiat : giat
aktivis : aktivis
menyoroti : sorot
pernyataan : nyata
pndah : pndah
dr : dr
jkt : jkt
beliau : beliau
cm : cm
pindah : pindah
merdeka : merdeka
selatan : selatan
utara : utara
bukabukaan : bukabukaan
obrolan : obrol
jam : jam
bareng : bareng
buzzerp : buzzerp
visible : visible
confusion : confusion
baswedan : baswedan
legitimasi : legitimasi
menilai : nilai
gubernur : gubernur
dki : dki
memiliki : milik
republik : republik
heboh : heboh
rumor : rumor
militer : militer
china : china
ditahan : tahan
rumah : rumah
tahanan : tahan
persaingan : saing
jenderal : jenderal
laporan : lapor
tentara : tentara
akrab : akrab
kekuasaan : kuasa
mendekat : dekat
rg : rg
didatangi : datang
diyakini : yakin
berkantor : kantor
medan : medan
kunjungi : kunjung
pastikan : pasti
cebongkampret : cebongkampret
pan : pan
berminat : minat
mengasuh : asuh
mending : mending
diasuh : asuh
partai : partai
amanat : amanat
nasional : nasional
peluang : peluang
selesai : selesai
jarangjarang : jarangjarang
lord : lord
menatap : tatap
pasca : pasca
via : via
part : part
tonton : tonton
ditakedown : ditakedown
klik : klik
kebebasan : bebas
freedom : freedom
natural : natural
right : right
konstitusi : konstitusi
tugas : tugas
pemerintah : perintah
melindungi : lindung
sambangi : sambang
pembahasannya : bahas
pesan : pesan
ramai : ramai
netizen : netizen
bersuara : suara
pertalite : pertalite
boros : boros
cepat : cepat
harganya : harga
coba : coba
simak : simak
videonya : video
terbagi : bagi
demo : demo
golput : golput
tempo : tempo
kritik : kritik
idolakan : idola
cuitan : cuit
viral : viral
menyebut : sebut
cebong : cebong
kampret : kampret
joko : joko
widodo : widodo
istilah : istilah
mengunjungi : unjung
masuk : masuk
angin : angin
temui : temu
om : om
pangeran : pangeran
ngobrol : ngobrol
tolong : tolong
cariin : cariin
cewe : cewe
doi : doi
grogi : grogi
ama : ama
cowo : cowo
kekekekkek : kekekekkek
ketemu : ketemu
lemes : lemes
saudara : saudara
rumahnya : rumah
kirakira : kirakira
prediksi : prediksi
gangguan : ganggu
terciptanya : cipta
hoax : hoax
kebodohan : bodoh
tim : tim
bocorkan : bocor
pembahasan : bahas
disangka : sangka
akun : akun
twitter : twitter
pribadinya : pribadi
menanggapi : tanggap
mementionnya : mementionnya
dll : dll
cemas : cemas
kadrun : kadrun
cemburu : cemburu
siapkan : siap
hadiah : hadiah
sepatu : sepatu
nasib : nasib
pensiun : pensiun
jabatannya : jabat
sinyal : sinyal
diganggu : ganggu
penguasa : kuasa
sprindik : sprindik
sowan : sowan
tegaskan : tegas
bapaknya : bapak
berkawan : kawan
botol : botol
minuman : minum
gagal : gagal
fokus : fokus
kabar : kabar
gembira : gembira
sayembara : sayembara
komentar : komentar
terlucu : lucu
hadiahnya : hadiah
tercengang : cengang
anak : anak
walikota : walikota
mengunggah : unggah
fotonya : foto
lei : lei
host : host
desain : desain
jelang : jelang
pilpres : pilpres
duga : duga
dipanggil : panggil
kpk : kpk
salah : salah
idola : idola
janjikan : janji
nawarin : nawarin
operasi : operasi
katarak : katarak
yaa : yaa
bhuehuehue : bhuehuehue
angkat : angkat
mengomentari : komentar
insiden : insiden
penembakan : tembak
brigadir : brigadir
dikepalai : palai
ferdy : ferdy
sambo : sambo
berita : berita
periode : periode
menko : menko
singgung : singgung
big : big
data : data
binsar : binsar
pandjaitan : pandjaitan
berbincang : bincang
contohi : contoh
amerika : amerika
usul : usul
sistem : sistem
pilkada : pilkada
dievalusi : dievalusi
tamparan : tampar
rakyat : rakyat
parpol : parpol
serang : serang
berebut : rebut
elektabilitas : elektabilitas
enak : enak
nontonnya : nontonnya
marves : marves
mustahil : mustahil
kalean : kalean
mesti : mesti
nonton : nonton
menteri : menteri
koordinator : koordinator
bidang : bidang
kemaritiman : maritim
investasi : investasi
usil : usil
bintang : bintang
podcast : podcast
jaman : jaman
rezim : rezim
skrg : skrg
kaya : kaya
bapa : bapa
tiri : tiri
sinetron : sinetron
kasih : kasih
makan : makan
bsu : bsu
blt : blt
anakrakyat : anakrakyat
udh : udh
kekenyangan : kenyang
trs : trs
pecutin : pecutin
nantikan : nanti
video : video
tayang : tayang
rabu : rabu
wib : wib
isu : isu
diperbincangkan : bincang
pembodohan : bodoh
kurikulum : kurikulum
etika : etika
setuju : tuju
{&#39;anies&#39;: &#39;anies&#39;, &#39;penantang&#39;: &#39;tantang&#39;, &#39;said&#39;: &#39;said&#39;, &#39;kode&#39;: &#39;kode&#39;, &#39;opung&#39;: &#39;opung&#39;, &#39;luhut&#39;: &#39;luhut&#39;, &#39;calon&#39;: &#39;calon&#39;, &#39;presiden&#39;: &#39;presiden&#39;, &#39;acara&#39;: &#39;acara&#39;, &#39;kib&#39;: &#39;kib&#39;, &#39;pimpinan&#39;: &#39;pimpin&#39;, &#39;airlangga&#39;: &#39;airlangga&#39;, &#39;hartarto&#39;: &#39;hartarto&#39;, &#39;gimana&#39;: &#39;gimana&#39;, &#39;arti&#39;: &#39;arti&#39;, &#39;rocky&#39;: &#39;rocky&#39;, &#39;gerung&#39;: &#39;gerung&#39;, &#39;bicara&#39;: &#39;bicara&#39;, &#39;keberlangsungan&#39;: &#39;langsung&#39;, &#39;pemerintahan&#39;: &#39;perintah&#39;, &#39;jokowi&#39;: &#39;jokowi&#39;, &#39;pengamat&#39;: &#39;amat&#39;, &#39;politik&#39;: &#39;politik&#39;, &#39;pendapatnya&#39;: &#39;dapat&#39;, &#39;era&#39;: &#39;era&#39;, &#39;menurutnya&#39;: &#39;turut&#39;, &#39;rgtv&#39;: &#39;rgtv&#39;, &#39;channel&#39;: &#39;channel&#39;, &#39;id&#39;: &#39;id&#39;, &#39;mengajak&#39;: &#39;ajak&#39;, &#39;wali&#39;: &#39;wali&#39;, &#39;kota&#39;: &#39;kota&#39;, &#39;solo&#39;: &#39;solo&#39;, &#39;gibran&#39;: &#39;gibran&#39;, &#39;rakabuming&#39;: &#39;rakabuming&#39;, &#39;raka&#39;: &#39;raka&#39;, &#39;mengakui&#39;: &#39;aku&#39;, &#39;menerima&#39;: &#39;terima&#39;, &#39;kritikan&#39;: &#39;kritik&#39;, &#39;bertemu&#39;: &#39;temu&#39;, &#39;tweet&#39;: &#39;tweet&#39;, &#39;sekolah&#39;: &#39;sekolah&#39;, &#39;menandakan&#39;: &#39;tanda&#39;, &#39;pelajar&#39;: &#39;ajar&#39;, &#39;belom&#39;: &#39;bom&#39;, &#39;pemikir&#39;: &#39;pikir&#39;, &#39;quote&#39;: &#39;quote&#39;, &#39;kalangan&#39;: &#39;kalang&#39;, &#39;istana&#39;: &#39;istana&#39;, &#39;menelepon&#39;: &#39;telepon&#39;, &#39;pengen&#39;: &#39;ken&#39;, &#39;berkunjung&#39;: &#39;kunjung&#39;, &#39;silakan&#39;: &#39;sila&#39;, &#39;ucapkan&#39;: &#39;ucap&#39;, &#39;publik&#39;: &#39;publik&#39;, &#39;sisi&#39;: &#39;sisi&#39;, &#39;ekonomi&#39;: &#39;ekonomi&#39;, &#39;dikritik&#39;: &#39;kritik&#39;, &#39;habis&#39;: &#39;habis&#39;, &#39;sadar&#39;: &#39;sadar&#39;, &#39;belajar&#39;: &#39;ajar&#39;, &#39;otak&#39;: &#39;otak&#39;, &#39;kosong&#39;: &#39;kosong&#39;, &#39;dungu&#39;: &#39;dungu&#39;, &#39;mengaku&#39;: &#39;aku&#39;, &#39;bertandang&#39;: &#39;tandang&#39;, &#39;kediaman&#39;: &#39;diam&#39;, &#39;orang&#39;: &#39;orang&#39;, &#39;jenius&#39;: &#39;jenius&#39;, &#39;masukan&#39;: &#39;masuk&#39;, &#39;baca&#39;: &#39;baca&#39;, &#39;selengkapnya&#39;: &#39;lengkap&#39;, &#39;bahas&#39;: &#39;bahas&#39;, &#39;dungudunguan&#39;: &#39;dungudunguan&#39;, &#39;saksikan&#39;: &#39;saksi&#39;, &#39;youtube&#39;: &#39;youtube&#39;, &#39;temukan&#39;: &#39;temu&#39;, &#39;link&#39;: &#39;link&#39;, &#39;akui&#39;: &#39;aku&#39;, &#39;disemprot&#39;: &#39;semprot&#39;, &#39;dibahas&#39;: &#39;bahas&#39;, &#39;xi&#39;: &#39;xi&#39;, &#39;jinping&#39;: &#39;jinping&#39;, &#39;dikudeta&#39;: &#39;kudeta&#39;, &#39;dampaknya&#39;: &#39;dampak&#39;, &#39;indonesia&#39;: &#39;indonesia&#39;, &#39;tantang&#39;: &#39;tantang&#39;, &#39;juara&#39;: &#39;juara&#39;, &#39;kelas&#39;: &#39;kelas&#39;, &#39;terbang&#39;: &#39;terbang&#39;, &#39;one&#39;: &#39;one&#39;, &#39;pride&#39;: &#39;pride&#39;, &#39;mma&#39;: &#39;mma&#39;, &#39;dukung&#39;: &#39;dukung&#39;, &#39;bertarung&#39;: &#39;tarung&#39;, &#39;ring&#39;: &#39;ring&#39;, &#39;duel&#39;: &#39;duel&#39;, &#39;sengit&#39;: &#39;sengit&#39;, &#39;penyandang&#39;: &#39;sandang&#39;, &#39;menang&#39;: &#39;menang&#39;, &#39;awali&#39;: &#39;awal&#39;, &#39;harimu&#39;: &#39;hari&#39;, &#39;semangat&#39;: &#39;semangat&#39;, &#39;selamat&#39;: &#39;selamat&#39;, &#39;senin&#39;: &#39;senin&#39;, &#39;sobat&#39;: &#39;sobat&#39;, &#39;akal&#39;: &#39;akal&#39;, &#39;sehat&#39;: &#39;sehat&#39;, &#39;salam&#39;: &#39;salam&#39;, &#39;berguru&#39;: &#39;guru&#39;, &#39;reaksi&#39;: &#39;reaksi&#39;, &#39;disinggung&#39;: &#39;singgung&#39;, &#39;oligarki&#39;: &#39;oligarki&#39;, &#39;menceritakan&#39;: &#39;cerita&#39;, &#39;momen&#39;: &#39;momen&#39;, &#39;pertemuan&#39;: &#39;temu&#39;, &#39;putra&#39;: &#39;putra&#39;, &#39;aliansi&#39;: &#39;aliansi&#39;, &#39;serikat&#39;: &#39;serikat&#39;, &#39;buruh&#39;: &#39;buruh&#39;, &#39;bersatu&#39;: &#39;satu&#39;, &#39;berama&#39;: &#39;ama&#39;, &#39;quen&#39;: &#39;quen&#39;, &#39;of&#39;: &#39;of&#39;, &#39;longmarct&#39;: &#39;longmarct&#39;, &#39;bergerak&#39;: &#39;gerak&#39;, &#39;puncak&#39;: &#39;puncak&#39;, &#39;negara&#39;: &#39;negara&#39;, &#39;jakarta&#39;: &#39;jakarta&#39;, &#39;sep&#39;: &#39;sep&#39;, &#39;nggak&#39;: &#39;nggak&#39;, &#39;urusan&#39;: &#39;urus&#39;, &#39;unggahan&#39;: &#39;unggah&#39;, &#39;foto&#39;: &#39;foto&#39;, &#39;media&#39;: &#39;media&#39;, &#39;sosial&#39;: &#39;sosial&#39;, &#39;menuai&#39;: &#39;tuai&#39;, &#39;sorotan&#39;: &#39;sorot&#39;, &#39;lantaran&#39;: &#39;lantar&#39;, &#39;penjajagan&#39;: &#39;penjajagan&#39;, &#39;pasangan&#39;: &#39;pasang&#39;, &#39;mas&#39;: &#39;mas&#39;, &#39;bang&#39;: &#39;bang&#39;, &#39;manyambut&#39;: &#39;manyambut&#39;, &#39;pertarungan&#39;: &#39;tarung&#39;, &#39;tamu&#39;: &#39;tamu&#39;, &#39;tebak&#39;: &#39;tebak&#39;, &#39;clue&#39;: &#39;clue&#39;, &#39;pria&#39;: &#39;pria&#39;, &#39;kelahiran&#39;: &#39;lahir&#39;, &#39;magetan&#39;: &#39;magetan&#39;, &#39;jawa&#39;: &#39;jawa&#39;, &#39;timur&#39;: &#39;timur&#39;, &#39;hobi&#39;: &#39;hobi&#39;, &#39;muay&#39;: &#39;muay&#39;, &#39;thai&#39;: &#39;thai&#39;, &#39;berjualan&#39;: &#39;jual&#39;, &#39;bakso&#39;: &#39;bakso&#39;, &#39;heran&#39;: &#39;heran&#39;, &#39;disambangi&#39;: &#39;sambang&#39;, &#39;dibenci&#39;: &#39;benci&#39;, &#39;nicho&#39;: &#39;nicho&#39;, &#39;silalahi&#39;: &#39;silalahi&#39;, &#39;soroti&#39;: &#39;sorot&#39;, &#39;maksa&#39;: &#39;maksa&#39;, &#39;statemen&#39;: &#39;statemen&#39;, &#39;berbahaya&#39;: &#39;bahaya&#39;, &#39;pegiat&#39;: &#39;giat&#39;, &#39;aktivis&#39;: &#39;aktivis&#39;, &#39;menyoroti&#39;: &#39;sorot&#39;, &#39;pernyataan&#39;: &#39;nyata&#39;, &#39;pndah&#39;: &#39;pndah&#39;, &#39;dr&#39;: &#39;dr&#39;, &#39;jkt&#39;: &#39;jkt&#39;, &#39;beliau&#39;: &#39;beliau&#39;, &#39;cm&#39;: &#39;cm&#39;, &#39;pindah&#39;: &#39;pindah&#39;, &#39;merdeka&#39;: &#39;merdeka&#39;, &#39;selatan&#39;: &#39;selatan&#39;, &#39;utara&#39;: &#39;utara&#39;, &#39;bukabukaan&#39;: &#39;bukabukaan&#39;, &#39;obrolan&#39;: &#39;obrol&#39;, &#39;jam&#39;: &#39;jam&#39;, &#39;bareng&#39;: &#39;bareng&#39;, &#39;buzzerp&#39;: &#39;buzzerp&#39;, &#39;visible&#39;: &#39;visible&#39;, &#39;confusion&#39;: &#39;confusion&#39;, &#39;baswedan&#39;: &#39;baswedan&#39;, &#39;legitimasi&#39;: &#39;legitimasi&#39;, &#39;menilai&#39;: &#39;nilai&#39;, &#39;gubernur&#39;: &#39;gubernur&#39;, &#39;dki&#39;: &#39;dki&#39;, &#39;memiliki&#39;: &#39;milik&#39;, &#39;republik&#39;: &#39;republik&#39;, &#39;heboh&#39;: &#39;heboh&#39;, &#39;rumor&#39;: &#39;rumor&#39;, &#39;militer&#39;: &#39;militer&#39;, &#39;china&#39;: &#39;china&#39;, &#39;ditahan&#39;: &#39;tahan&#39;, &#39;rumah&#39;: &#39;rumah&#39;, &#39;tahanan&#39;: &#39;tahan&#39;, &#39;persaingan&#39;: &#39;saing&#39;, &#39;jenderal&#39;: &#39;jenderal&#39;, &#39;laporan&#39;: &#39;lapor&#39;, &#39;tentara&#39;: &#39;tentara&#39;, &#39;akrab&#39;: &#39;akrab&#39;, &#39;kekuasaan&#39;: &#39;kuasa&#39;, &#39;mendekat&#39;: &#39;dekat&#39;, &#39;rg&#39;: &#39;rg&#39;, &#39;didatangi&#39;: &#39;datang&#39;, &#39;diyakini&#39;: &#39;yakin&#39;, &#39;berkantor&#39;: &#39;kantor&#39;, &#39;medan&#39;: &#39;medan&#39;, &#39;kunjungi&#39;: &#39;kunjung&#39;, &#39;pastikan&#39;: &#39;pasti&#39;, &#39;cebongkampret&#39;: &#39;cebongkampret&#39;, &#39;pan&#39;: &#39;pan&#39;, &#39;berminat&#39;: &#39;minat&#39;, &#39;mengasuh&#39;: &#39;asuh&#39;, &#39;mending&#39;: &#39;mending&#39;, &#39;diasuh&#39;: &#39;asuh&#39;, &#39;partai&#39;: &#39;partai&#39;, &#39;amanat&#39;: &#39;amanat&#39;, &#39;nasional&#39;: &#39;nasional&#39;, &#39;peluang&#39;: &#39;peluang&#39;, &#39;selesai&#39;: &#39;selesai&#39;, &#39;jarangjarang&#39;: &#39;jarangjarang&#39;, &#39;lord&#39;: &#39;lord&#39;, &#39;menatap&#39;: &#39;tatap&#39;, &#39;pasca&#39;: &#39;pasca&#39;, &#39;via&#39;: &#39;via&#39;, &#39;part&#39;: &#39;part&#39;, &#39;tonton&#39;: &#39;tonton&#39;, &#39;ditakedown&#39;: &#39;ditakedown&#39;, &#39;klik&#39;: &#39;klik&#39;, &#39;kebebasan&#39;: &#39;bebas&#39;, &#39;freedom&#39;: &#39;freedom&#39;, &#39;natural&#39;: &#39;natural&#39;, &#39;right&#39;: &#39;right&#39;, &#39;konstitusi&#39;: &#39;konstitusi&#39;, &#39;tugas&#39;: &#39;tugas&#39;, &#39;pemerintah&#39;: &#39;perintah&#39;, &#39;melindungi&#39;: &#39;lindung&#39;, &#39;sambangi&#39;: &#39;sambang&#39;, &#39;pembahasannya&#39;: &#39;bahas&#39;, &#39;pesan&#39;: &#39;pesan&#39;, &#39;ramai&#39;: &#39;ramai&#39;, &#39;netizen&#39;: &#39;netizen&#39;, &#39;bersuara&#39;: &#39;suara&#39;, &#39;pertalite&#39;: &#39;pertalite&#39;, &#39;boros&#39;: &#39;boros&#39;, &#39;cepat&#39;: &#39;cepat&#39;, &#39;harganya&#39;: &#39;harga&#39;, &#39;coba&#39;: &#39;coba&#39;, &#39;simak&#39;: &#39;simak&#39;, &#39;videonya&#39;: &#39;video&#39;, &#39;terbagi&#39;: &#39;bagi&#39;, &#39;demo&#39;: &#39;demo&#39;, &#39;golput&#39;: &#39;golput&#39;, &#39;tempo&#39;: &#39;tempo&#39;, &#39;kritik&#39;: &#39;kritik&#39;, &#39;idolakan&#39;: &#39;idola&#39;, &#39;cuitan&#39;: &#39;cuit&#39;, &#39;viral&#39;: &#39;viral&#39;, &#39;menyebut&#39;: &#39;sebut&#39;, &#39;cebong&#39;: &#39;cebong&#39;, &#39;kampret&#39;: &#39;kampret&#39;, &#39;joko&#39;: &#39;joko&#39;, &#39;widodo&#39;: &#39;widodo&#39;, &#39;istilah&#39;: &#39;istilah&#39;, &#39;mengunjungi&#39;: &#39;unjung&#39;, &#39;masuk&#39;: &#39;masuk&#39;, &#39;angin&#39;: &#39;angin&#39;, &#39;temui&#39;: &#39;temu&#39;, &#39;om&#39;: &#39;om&#39;, &#39;pangeran&#39;: &#39;pangeran&#39;, &#39;ngobrol&#39;: &#39;ngobrol&#39;, &#39;tolong&#39;: &#39;tolong&#39;, &#39;cariin&#39;: &#39;cariin&#39;, &#39;cewe&#39;: &#39;cewe&#39;, &#39;doi&#39;: &#39;doi&#39;, &#39;grogi&#39;: &#39;grogi&#39;, &#39;ama&#39;: &#39;ama&#39;, &#39;cowo&#39;: &#39;cowo&#39;, &#39;kekekekkek&#39;: &#39;kekekekkek&#39;, &#39;ketemu&#39;: &#39;ketemu&#39;, &#39;lemes&#39;: &#39;lemes&#39;, &#39;saudara&#39;: &#39;saudara&#39;, &#39;rumahnya&#39;: &#39;rumah&#39;, &#39;kirakira&#39;: &#39;kirakira&#39;, &#39;prediksi&#39;: &#39;prediksi&#39;, &#39;gangguan&#39;: &#39;ganggu&#39;, &#39;terciptanya&#39;: &#39;cipta&#39;, &#39;hoax&#39;: &#39;hoax&#39;, &#39;kebodohan&#39;: &#39;bodoh&#39;, &#39;tim&#39;: &#39;tim&#39;, &#39;bocorkan&#39;: &#39;bocor&#39;, &#39;pembahasan&#39;: &#39;bahas&#39;, &#39;disangka&#39;: &#39;sangka&#39;, &#39;akun&#39;: &#39;akun&#39;, &#39;twitter&#39;: &#39;twitter&#39;, &#39;pribadinya&#39;: &#39;pribadi&#39;, &#39;menanggapi&#39;: &#39;tanggap&#39;, &#39;mementionnya&#39;: &#39;mementionnya&#39;, &#39;dll&#39;: &#39;dll&#39;, &#39;cemas&#39;: &#39;cemas&#39;, &#39;kadrun&#39;: &#39;kadrun&#39;, &#39;cemburu&#39;: &#39;cemburu&#39;, &#39;siapkan&#39;: &#39;siap&#39;, &#39;hadiah&#39;: &#39;hadiah&#39;, &#39;sepatu&#39;: &#39;sepatu&#39;, &#39;nasib&#39;: &#39;nasib&#39;, &#39;pensiun&#39;: &#39;pensiun&#39;, &#39;jabatannya&#39;: &#39;jabat&#39;, &#39;sinyal&#39;: &#39;sinyal&#39;, &#39;diganggu&#39;: &#39;ganggu&#39;, &#39;penguasa&#39;: &#39;kuasa&#39;, &#39;sprindik&#39;: &#39;sprindik&#39;, &#39;sowan&#39;: &#39;sowan&#39;, &#39;tegaskan&#39;: &#39;tegas&#39;, &#39;bapaknya&#39;: &#39;bapak&#39;, &#39;berkawan&#39;: &#39;kawan&#39;, &#39;botol&#39;: &#39;botol&#39;, &#39;minuman&#39;: &#39;minum&#39;, &#39;gagal&#39;: &#39;gagal&#39;, &#39;fokus&#39;: &#39;fokus&#39;, &#39;kabar&#39;: &#39;kabar&#39;, &#39;gembira&#39;: &#39;gembira&#39;, &#39;sayembara&#39;: &#39;sayembara&#39;, &#39;komentar&#39;: &#39;komentar&#39;, &#39;terlucu&#39;: &#39;lucu&#39;, &#39;hadiahnya&#39;: &#39;hadiah&#39;, &#39;tercengang&#39;: &#39;cengang&#39;, &#39;anak&#39;: &#39;anak&#39;, &#39;walikota&#39;: &#39;walikota&#39;, &#39;mengunggah&#39;: &#39;unggah&#39;, &#39;fotonya&#39;: &#39;foto&#39;, &#39;lei&#39;: &#39;lei&#39;, &#39;host&#39;: &#39;host&#39;, &#39;desain&#39;: &#39;desain&#39;, &#39;jelang&#39;: &#39;jelang&#39;, &#39;pilpres&#39;: &#39;pilpres&#39;, &#39;duga&#39;: &#39;duga&#39;, &#39;dipanggil&#39;: &#39;panggil&#39;, &#39;kpk&#39;: &#39;kpk&#39;, &#39;salah&#39;: &#39;salah&#39;, &#39;idola&#39;: &#39;idola&#39;, &#39;janjikan&#39;: &#39;janji&#39;, &#39;nawarin&#39;: &#39;nawarin&#39;, &#39;operasi&#39;: &#39;operasi&#39;, &#39;katarak&#39;: &#39;katarak&#39;, &#39;yaa&#39;: &#39;yaa&#39;, &#39;bhuehuehue&#39;: &#39;bhuehuehue&#39;, &#39;angkat&#39;: &#39;angkat&#39;, &#39;mengomentari&#39;: &#39;komentar&#39;, &#39;insiden&#39;: &#39;insiden&#39;, &#39;penembakan&#39;: &#39;tembak&#39;, &#39;brigadir&#39;: &#39;brigadir&#39;, &#39;dikepalai&#39;: &#39;palai&#39;, &#39;ferdy&#39;: &#39;ferdy&#39;, &#39;sambo&#39;: &#39;sambo&#39;, &#39;berita&#39;: &#39;berita&#39;, &#39;periode&#39;: &#39;periode&#39;, &#39;menko&#39;: &#39;menko&#39;, &#39;singgung&#39;: &#39;singgung&#39;, &#39;big&#39;: &#39;big&#39;, &#39;data&#39;: &#39;data&#39;, &#39;binsar&#39;: &#39;binsar&#39;, &#39;pandjaitan&#39;: &#39;pandjaitan&#39;, &#39;berbincang&#39;: &#39;bincang&#39;, &#39;contohi&#39;: &#39;contoh&#39;, &#39;amerika&#39;: &#39;amerika&#39;, &#39;usul&#39;: &#39;usul&#39;, &#39;sistem&#39;: &#39;sistem&#39;, &#39;pilkada&#39;: &#39;pilkada&#39;, &#39;dievalusi&#39;: &#39;dievalusi&#39;, &#39;tamparan&#39;: &#39;tampar&#39;, &#39;rakyat&#39;: &#39;rakyat&#39;, &#39;parpol&#39;: &#39;parpol&#39;, &#39;serang&#39;: &#39;serang&#39;, &#39;berebut&#39;: &#39;rebut&#39;, &#39;elektabilitas&#39;: &#39;elektabilitas&#39;, &#39;enak&#39;: &#39;enak&#39;, &#39;nontonnya&#39;: &#39;nontonnya&#39;, &#39;marves&#39;: &#39;marves&#39;, &#39;mustahil&#39;: &#39;mustahil&#39;, &#39;kalean&#39;: &#39;kalean&#39;, &#39;mesti&#39;: &#39;mesti&#39;, &#39;nonton&#39;: &#39;nonton&#39;, &#39;menteri&#39;: &#39;menteri&#39;, &#39;koordinator&#39;: &#39;koordinator&#39;, &#39;bidang&#39;: &#39;bidang&#39;, &#39;kemaritiman&#39;: &#39;maritim&#39;, &#39;investasi&#39;: &#39;investasi&#39;, &#39;usil&#39;: &#39;usil&#39;, &#39;bintang&#39;: &#39;bintang&#39;, &#39;podcast&#39;: &#39;podcast&#39;, &#39;jaman&#39;: &#39;jaman&#39;, &#39;rezim&#39;: &#39;rezim&#39;, &#39;skrg&#39;: &#39;skrg&#39;, &#39;kaya&#39;: &#39;kaya&#39;, &#39;bapa&#39;: &#39;bapa&#39;, &#39;tiri&#39;: &#39;tiri&#39;, &#39;sinetron&#39;: &#39;sinetron&#39;, &#39;kasih&#39;: &#39;kasih&#39;, &#39;makan&#39;: &#39;makan&#39;, &#39;bsu&#39;: &#39;bsu&#39;, &#39;blt&#39;: &#39;blt&#39;, &#39;anakrakyat&#39;: &#39;anakrakyat&#39;, &#39;udh&#39;: &#39;udh&#39;, &#39;kekenyangan&#39;: &#39;kenyang&#39;, &#39;trs&#39;: &#39;trs&#39;, &#39;pecutin&#39;: &#39;pecutin&#39;, &#39;nantikan&#39;: &#39;nanti&#39;, &#39;video&#39;: &#39;video&#39;, &#39;tayang&#39;: &#39;tayang&#39;, &#39;rabu&#39;: &#39;rabu&#39;, &#39;wib&#39;: &#39;wib&#39;, &#39;isu&#39;: &#39;isu&#39;, &#39;diperbincangkan&#39;: &#39;bincang&#39;, &#39;pembodohan&#39;: &#39;bodoh&#39;, &#39;kurikulum&#39;: &#39;kurikulum&#39;, &#39;etika&#39;: &#39;etika&#39;, &#39;setuju&#39;: &#39;tuju&#39;}
------------------------
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "0c9940a7760b48cbb3055943574ec1fe"}
</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0                                [anies, tantang, said]
1                                                    []
2     [kode, opung, luhut, calon, presiden, acara, k...
3     [rocky, gerung, bicara, langsung, perintah, jo...
4                                                    []
                            ...                        
95    [jaman, rezim, skrg, kaya, bapa, tiri, sinetro...
96    [sobat, akal, sehat, nanti, video, part, tayan...
97    [menteri, koordinator, bidang, maritim, invest...
98             [bodoh, kurikulum, etika, rocky, gerung]
99    [tuju, rocky, saksi, lengkap, youtube, rgtv, c...
Name: tweet, Length: 100, dtype: object
</pre></div>
</div>
</div>
</div>
<p>Setelah tahap stemming proses prepocessing sudah selesai, namun pada dataset masih belum memiliki kelas atau label untuk itu akan dilakukan pemberian label atau kelas dengan menggunakan nilai polarity.</p>
</section>
</section>
<section id="id57">
<h2><strong>Labelling Dataset</strong><a class="headerlink" href="#id57" title="Permalink to this headline">#</a></h2>
<p>Setelah proses prepocesing selesai didapat sebuah dataset yang masih belum memiliki label, untuk itu pada tahapan ini dataset akan diberikan kelas atau label yang sesuai. Akan tetapi tahap pelabelan ini akan memerlukan waktu yang lama jika dilakukan secara manual. Untuk itu pada tahapan ini saya memberikan kelas atau label pada masing-masing data secara otomatis dengan menggunakan nilai polarity.</p>
<section id="id58">
<h3>Nilai Polarity<a class="headerlink" href="#id58" title="Permalink to this headline">#</a></h3>
<p>Nilai polarity merupakan nilai yang menunjukkan apakah kata tersebut bernilai negatif atau positif ataupun netral. Nilai polarity didapatkan dengan menjumlahkan nilai dari setiap kata dataset yang menunjukkan bahwa kata tersebut bernilai positif atau negatif ataupun netral.<br>
Didalam satu kalimat atau data,nilai dari kata-kata didalam satu kalimat tersebut akan dijumlah sehingga akan didapatkan nilai atau skor polarity. Nilai atau skor tersebutlah yang akan menentukan kalimat atau data tersebut berkelas positif(pro) atau negatif(kontra) ataupun netral.<br>
Jika nilai polarity yang didapat lebih dari 0 maka kalimat atau data tersebut diberi label atau kelas pro. Jika nilai polarity yang didapat kurang dari 0 maka kalimat atau data tersebut diberi label atau kelas kontra. Sedangkan jika nilai polarity sama dengan 0 maka kalimat atau data tersebut diberi label netral.</p>
</section>
<section id="id59">
<h3>Ambil Nilai Polarity<a class="headerlink" href="#id59" title="Permalink to this headline">#</a></h3>
<p>Sebelum melakukan pemberian label atau kelas dengan menggunakan nilai polarity, kita ambil nilai polarity dari setiap kata apakah positif atau negatif. Untuk itu saya mengambil nilai polarity dari github yang di dapat dari link github berikut <a class="reference external" href="https://github.com/fajri91/InSet">https://github.com/fajri91/InSet</a>
Nilai lexicon positif dan negatif yang didapat dari github tersebut saya download kemudian saya upload ke github saya dan kemudian saya ambil data lexicon positif dan negatif tersebut dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">positive</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/Fahrur190125/Data/main/positive.csv&quot;</span><span class="p">)</span>
<span class="n">positive</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;lexpos.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">negative</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/Fahrur190125/Data/main/negative.csv&quot;</span><span class="p">)</span>
<span class="n">negative</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;lexneg.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id60">
<h3>Menentukan Kelas/Label dengan Nilai Polarity<a class="headerlink" href="#id60" title="Permalink to this headline">#</a></h3>
<p>Setelah berhasil mengambil nilai polarity lexicon positif dan negatif selanjutnya kita tentukan kelas dari masing masing data dengan menjumlahkan nilai polarity yang didapat dengan ketentuan jika lebih dari 0 maka memiliki kelas pro, jika kurang dari 0 maka diberi kelas kontra, dan jika sama dengan 0 maka memiliki kelas netral, dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Determine sentiment polarity of tweets using indonesia sentiment lexicon (source : https://github.com/fajri91/InSet)</span>
<span class="c1"># Loads lexicon positive and negative data</span>
<span class="n">lexicon_positive</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;lexpos.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvfile</span><span class="p">:</span>
    <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">csvfile</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
        <span class="n">lexicon_positive</span><span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">lexicon_negative</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;lexneg.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvfile</span><span class="p">:</span>
    <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">csvfile</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
        <span class="n">lexicon_negative</span><span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        
<span class="c1"># Function to determine sentiment polarity of tweets        </span>
<span class="k">def</span> <span class="nf">sentiment_analysis_lexicon_indonesia</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1">#for word in text:</span>
    <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="n">lexicon_positive</span><span class="p">):</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">score</span> <span class="o">+</span> <span class="n">lexicon_positive</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="n">lexicon_negative</span><span class="p">):</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">score</span> <span class="o">+</span> <span class="n">lexicon_negative</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
    <span class="n">polarity</span><span class="o">=</span><span class="s1">&#39;&#39;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">score</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="n">polarity</span> <span class="o">=</span> <span class="s1">&#39;pro&#39;</span>
    <span class="k">elif</span> <span class="p">(</span><span class="n">score</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="n">polarity</span> <span class="o">=</span> <span class="s1">&#39;kontra&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">polarity</span> <span class="o">=</span> <span class="s1">&#39;netral&#39;</span>
    <span class="k">return</span> <span class="n">score</span><span class="p">,</span> <span class="n">polarity</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Results from determine sentiment polarity of tweets</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sentiment_analysis_lexicon_indonesia</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">results</span><span class="p">))</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;polarity_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>pro       41
kontra    40
netral    19
Name: label, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Setelah didapat dataset yang sudah memiliki label selanjutnya kita simpan dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Export to csv file</span>
<span class="n">tweets</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;Prepocessing_label.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">tweets</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-ef362c48-dcc2-4653-b9b7-784b7b6e32f0">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tweet</th>
      <th>polarity_score</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[anies, tantang, said]</td>
      <td>-4</td>
      <td>kontra</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[]</td>
      <td>0</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[kode, opung, luhut, calon, presiden, acara, k...</td>
      <td>-2</td>
      <td>kontra</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[rocky, gerung, bicara, langsung, perintah, jo...</td>
      <td>9</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[]</td>
      <td>0</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>[jaman, rezim, skrg, kaya, bapa, tiri, sinetro...</td>
      <td>3</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>96</th>
      <td>[sobat, akal, sehat, nanti, video, part, tayan...</td>
      <td>7</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>97</th>
      <td>[menteri, koordinator, bidang, maritim, invest...</td>
      <td>6</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>98</th>
      <td>[bodoh, kurikulum, etika, rocky, gerung]</td>
      <td>0</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>99</th>
      <td>[tuju, rocky, saksi, lengkap, youtube, rgtv, c...</td>
      <td>2</td>
      <td>pro</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 3 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-ef362c48-dcc2-4653-b9b7-784b7b6e32f0')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-ef362c48-dcc2-4653-b9b7-784b7b6e32f0 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-ef362c48-dcc2-4653-b9b7-784b7b6e32f0');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
</section>
</section>
<section id="id61">
<h2><strong>Term Frequncy(TF)</strong><a class="headerlink" href="#id61" title="Permalink to this headline">#</a></h2>
<p>Term Frequency(TF) merupakan banyaknya jumlah kemunculan term pada suatu dokumen. Untuk menghitung nilai TF terdapat beberapa cara, cara yang paling sederhana ialah dengan menghitung banyaknya jumlah kemunculan kata dalam 1 dokumen.<br>
Sedangkan untuk menghitung nilai TF dengan menggunakan mesin dapat menggunakan library sklearn dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span><span class="p">,</span> <span class="n">TfidfVectorizer</span><span class="p">,</span> <span class="n">CountVectorizer</span>
<span class="c1">#Membuat Dataframe</span>
<span class="n">dataTextPre</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Prepocessing_label.csv&#39;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dataTextPre</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;polarity_score&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">bag</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">dataTextPre</span><span class="p">[</span><span class="s1">&#39;tweet&#39;</span><span class="p">])</span>
<span class="n">dataTextPre</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-88006bf5-2456-4d00-b6e3-ba8ed5e61693">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tweet</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>['anies', 'tantang', 'said']</td>
      <td>kontra</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[]</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>2</th>
      <td>['kode', 'opung', 'luhut', 'calon', 'presiden'...</td>
      <td>kontra</td>
    </tr>
    <tr>
      <th>3</th>
      <td>['rocky', 'gerung', 'bicara', 'langsung', 'per...</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[]</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>['jaman', 'rezim', 'skrg', 'kaya', 'bapa', 'ti...</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>96</th>
      <td>['sobat', 'akal', 'sehat', 'nanti', 'video', '...</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>97</th>
      <td>['menteri', 'koordinator', 'bidang', 'maritim'...</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>98</th>
      <td>['bodoh', 'kurikulum', 'etika', 'rocky', 'geru...</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>99</th>
      <td>['tuju', 'rocky', 'saksi', 'lengkap', 'youtube...</td>
      <td>pro</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 2 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-88006bf5-2456-4d00-b6e3-ba8ed5e61693')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-88006bf5-2456-4d00-b6e3-ba8ed5e61693 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-88006bf5-2456-4d00-b6e3-ba8ed5e61693');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<section id="id62">
<h3>Matrik VSM(Visual Space Model)<a class="headerlink" href="#id62" title="Permalink to this headline">#</a></h3>
<p>Sebelum menghitung nilai TF, terlebih dahulu buat matrik vsm untuk menentukan bobot nilai term pada dokumen dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">matrik_vsm</span> <span class="o">=</span> <span class="n">bag</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="c1">#print(matrik_vsm)</span>
<span class="n">matrik_vsm</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(100, 390)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">matrik_vsm</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
</pre></div>
</div>
</div>
</div>
<p>Untuk menampilkan nilai TF yang didapat menggunakan source code berikut</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span><span class="o">=</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">matrik_vsm</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]))</span>
<span class="c1">#dfb =pd.DataFrame(data=matrik_vsm,index=df,columns=[a])</span>
<span class="n">dataTF</span> <span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">matrik_vsm</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">matrik_vsm</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">)),</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>
<span class="n">dataTF</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;TF.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dataTF</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100
</pre></div>
</div>
<div class="output text_html">
  <div id="df-2c3f445f-1b86-455b-a860-6e20c115cbb4">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>acara</th>
      <th>airlangga</th>
      <th>ajak</th>
      <th>ajar</th>
      <th>akal</th>
      <th>akrab</th>
      <th>aktivis</th>
      <th>aku</th>
      <th>akun</th>
      <th>aliansi</th>
      <th>...</th>
      <th>viral</th>
      <th>visible</th>
      <th>wali</th>
      <th>walikota</th>
      <th>wib</th>
      <th>widodo</th>
      <th>xi</th>
      <th>yaa</th>
      <th>yakin</th>
      <th>youtube</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>96</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>97</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>98</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>99</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>100</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 390 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-2c3f445f-1b86-455b-a860-6e20c115cbb4')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-2c3f445f-1b86-455b-a860-6e20c115cbb4 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-2c3f445f-1b86-455b-a860-6e20c115cbb4');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
</section>
<section id="id63">
<h3>Nilai Term Dokumen<a class="headerlink" href="#id63" title="Permalink to this headline">#</a></h3>
<p>Setelah didapat nilai matrik vsm, selanjutnya tentukan nilai term pada masing masing dokumen menggunakan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">datalabel</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Prepocessing_label.csv&#39;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">TF</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;TF.csv&#39;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dataJurnal</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">TF</span><span class="p">,</span> <span class="n">datalabel</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dataJurnal</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-32179969-56d7-4372-bfbe-f9249c6c892a">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>acara</th>
      <th>airlangga</th>
      <th>ajak</th>
      <th>ajar</th>
      <th>akal</th>
      <th>akrab</th>
      <th>aktivis</th>
      <th>aku</th>
      <th>akun</th>
      <th>aliansi</th>
      <th>...</th>
      <th>visible</th>
      <th>wali</th>
      <th>walikota</th>
      <th>wib</th>
      <th>widodo</th>
      <th>xi</th>
      <th>yaa</th>
      <th>yakin</th>
      <th>youtube</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>kontra</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>kontra</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>96</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>97</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>pro</td>
    </tr>
    <tr>
      <th>98</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>netral</td>
    </tr>
    <tr>
      <th>99</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>pro</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 391 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-32179969-56d7-4372-bfbe-f9249c6c892a')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-32179969-56d7-4372-bfbe-f9249c6c892a button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-32179969-56d7-4372-bfbe-f9249c6c892a');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
</section>
<section id="id64">
<h3>Mengambil Data label<a class="headerlink" href="#id64" title="Permalink to this headline">#</a></h3>
<p>Setelah didapat nilai term pada masing masing dokumen kita ambil data label pada masing masing dokumen.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataJurnal</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;kontra&#39;, &#39;netral&#39;, &#39;pro&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataJurnal</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 100 entries, 0 to 99
Columns: 391 entries, acara to label
dtypes: int64(390), object(1)
memory usage: 305.6+ KB
</pre></div>
</div>
</div>
</div>
</section>
<section id="id65">
<h3>Split Data<a class="headerlink" href="#id65" title="Permalink to this headline">#</a></h3>
<p>Selanjutnya kita split dataset menjadi data training dan testing dengan source code berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### Train test split to avoid overfitting</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="o">=</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">dataJurnal</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">dataJurnal</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">],</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="id66">
<h4>Data Training<a class="headerlink" href="#id66" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-98cef068-84d9-4fcd-916d-f390fa976528">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>acara</th>
      <th>airlangga</th>
      <th>ajak</th>
      <th>ajar</th>
      <th>akal</th>
      <th>akrab</th>
      <th>aktivis</th>
      <th>aku</th>
      <th>akun</th>
      <th>aliansi</th>
      <th>...</th>
      <th>viral</th>
      <th>visible</th>
      <th>wali</th>
      <th>walikota</th>
      <th>wib</th>
      <th>widodo</th>
      <th>xi</th>
      <th>yaa</th>
      <th>yakin</th>
      <th>youtube</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>30</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>33</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>96</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>67</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>64</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>47</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>44</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>85 rows × 390 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-98cef068-84d9-4fcd-916d-f390fa976528')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-98cef068-84d9-4fcd-916d-f390fa976528 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-98cef068-84d9-4fcd-916d-f390fa976528');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
</section>
<section id="id67">
<h4>Data Testing<a class="headerlink" href="#id67" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-34aa2580-b06f-417f-b020-a97adbb49c8f">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>acara</th>
      <th>airlangga</th>
      <th>ajak</th>
      <th>ajar</th>
      <th>akal</th>
      <th>akrab</th>
      <th>aktivis</th>
      <th>aku</th>
      <th>akun</th>
      <th>aliansi</th>
      <th>...</th>
      <th>viral</th>
      <th>visible</th>
      <th>wali</th>
      <th>walikota</th>
      <th>wib</th>
      <th>widodo</th>
      <th>xi</th>
      <th>yaa</th>
      <th>yakin</th>
      <th>youtube</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>26</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>86</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>55</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>75</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>93</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>73</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>54</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>95</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>53</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>92</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>15 rows × 390 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-34aa2580-b06f-417f-b020-a97adbb49c8f')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-34aa2580-b06f-417f-b020-a97adbb49c8f button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-34aa2580-b06f-417f-b020-a97adbb49c8f');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<p>Setelah didapat matrik VSM, selanjutnya lakukan metode Bagging, Stacking, dan Random Forest Clasification dengan grid search seperti berikut.</p>
</section>
</section>
</section>
<section id="bagging-classification">
<h2><strong>Bagging Classification</strong><a class="headerlink" href="#bagging-classification" title="Permalink to this headline">#</a></h2>
<p>Bagging merupakan metode yang dapat memperbaiki hasil dari algoritma klasifikasi machine learning dengan menggabungkan klasifikasi prediksi dari beberapa model. Hal ini digunakan untuk mengatasi ketidakstabilan pada model yang kompleks dengan kumpulan data yang relatif kecil. Bagging adalah salah satu algoritma berbasis ensemble yang paling awal dan paling sederhana, namun efektif. Bagging paling cocok untuk masalah dengan dataset pelatihan yang relatif kecil. Bagging mempunyai variasi yang disebut Pasting Small Votes. cara ini dirancang untuk masalah dengan dataset pelatihan yang besar, mengikuti pendekatan yang serupa, tetapi membagi dataset besar menjadi segmen yang lebih kecil. Penggolong individu dilatih dengan segmen ini, yang disebut bites, sebelum menggabungkannya melalui cara voting mayoritas.<br></p>
<center><img src="https://upload.wikimedia.org/wikipedia/commons/6/6b/Bagging.png"></center>
<center>Gambar Bagging</center><br>
Bagging mengadopsi distribusi bootstrap supaya menghasilkan base learner yang berbeda, untuk memperoleh data subset. sehingga melatih base learners. dan bagging juga mengadopsi strategi aggregasi output base leaner, yaitu metode voting untuk kasus klasifikasi dan averaging untuk kasus regresi. Untuk melakukan bagging pada data yang sudah di precocessing dengan menngunakan libary skikit learn seperti berikut.<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">model_selection</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
  
<span class="c1"># load the data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X_train</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">y_train</span>
  
<span class="n">seed</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1">#kfold = model_selection.KFold(n_splits = 3,random_state = seed)</span>
  
<span class="c1"># initialize the base classifier</span>
<span class="n">base_cls</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="c1">#Menyimpan Hasil Nilai Base Classifier</span>
<span class="n">base_classifier</span><span class="o">=</span><span class="p">[]</span>
<span class="n">hasilNilai_classifier</span><span class="o">=</span><span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="p">):</span>
  <span class="c1"># no. of base classifier</span>
  <span class="n">num_trees</span> <span class="o">=</span> <span class="n">i</span>
    
  <span class="c1"># bagging classifier</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">base_estimator</span> <span class="o">=</span> <span class="n">base_cls</span><span class="p">,</span>
                            <span class="n">n_estimators</span> <span class="o">=</span> <span class="n">num_trees</span><span class="p">,</span>
                            <span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>
    
  <span class="n">results</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

  <span class="c1">#Nilai base classifier dan hasil nilai classifier disimpan dan akan ditampilkan di grafik</span>
  <span class="n">base_classifier</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
  <span class="n">hasilNilai_classifier</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;accuracy :&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>accuracy :
0.4470588235294118
accuracy :
0.4235294117647059
accuracy :
0.5294117647058825
accuracy :
0.5294117647058824
accuracy :
0.5058823529411764
accuracy :
0.5764705882352942
accuracy :
0.5294117647058824
accuracy :
0.5058823529411764
accuracy :
0.49411764705882355
accuracy :
0.5176470588235295
accuracy :
0.49411764705882355
accuracy :
0.49411764705882355
accuracy :
0.5058823529411764
accuracy :
0.49411764705882355
accuracy :
0.5058823529411766
accuracy :
0.48235294117647065
accuracy :
0.49411764705882355
accuracy :
0.48235294117647065
accuracy :
0.49411764705882355
accuracy :
0.49411764705882355
accuracy :
0.49411764705882355
accuracy :
0.5058823529411766
accuracy :
0.49411764705882355
accuracy :
0.48235294117647065
accuracy :
0.48235294117647065
accuracy :
0.48235294117647065
accuracy :
0.48235294117647065
accuracy :
0.48235294117647065
accuracy :
0.5058823529411766
accuracy :
0.49411764705882355
accuracy :
0.5058823529411766
accuracy :
0.5058823529411766
accuracy :
0.5058823529411766
accuracy :
0.48235294117647065
accuracy :
0.49411764705882355
accuracy :
0.48235294117647065
accuracy :
0.49411764705882355
accuracy :
0.49411764705882355
accuracy :
0.49411764705882355
accuracy :
0.49411764705882355
accuracy :
0.48235294117647065
accuracy :
0.48235294117647065
accuracy :
0.45882352941176474
accuracy :
0.48235294117647065
accuracy :
0.47058823529411764
accuracy :
0.48235294117647065
accuracy :
0.48235294117647054
accuracy :
0.47058823529411764
accuracy :
0.5058823529411766
</pre></div>
</div>
</div>
</div>
<p>Menampilkan data hasil akurasi yang di dapat dari metode bagging dengan melakukan perulangan yang digrafikkan menggunakan Plot dari library python sebagai berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">base_classifier</span><span class="p">,</span> <span class="n">hasilNilai_classifier</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Hasil Nilai Bagging Classifier&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Nilai Estimator&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Hasil Akurasi&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/crawling_349_0.png" src="_images/crawling_349_0.png" />
</div>
</div>
</section>
<section id="stacking-classification">
<h2><strong>Stacking Classification</strong><a class="headerlink" href="#stacking-classification" title="Permalink to this headline">#</a></h2>
<p>Stacking merupakan cara untuk mengkombinasi beberapa model, dengan konsep meta learner. dipakai setelah bagging dan boosting. tidak seperti bagging dan boosting, stacking memungkinkan mengkombinasikan model dari tipe yang berbeda. Ide dasarnya adalah untuk train learner tingkat pertama menggunakan kumpulan data training asli, dan kemudian menghasilkan kumpulan data baru untuk melatih learner tingkat kedua, di mana output dari learner tingkat pertama dianggap sebagai fitur masukan sementara yang asli label masih dianggap sebagai label data training baru. Pembelajar tingkat pertama sering dihasilkan dengan menerapkan algoritma learning yang berbeda.</p>
<p>Dalam fase training pada stacking, satu set data baru perlu dihasilkan dari classifier tingkat pertama. Jika data yang tepat yang digunakan untuk melatih classifier tingkat pertama juga digunakan untuk menghasilkan kumpulan data baru untuk melatih classifier tingkat kedua. proses tersebut memiliki risiko yang tinggi yang akan mengakibatkan overfitting. sehingga disarankan bahwa contoh yang digunakan untuk menghasilkan kumpulan data baru dikeluarkan dari contoh data training untuk learner tingkat pertama, dan prosedur crossvalidasi.<br></p>
<center><img src="https://upload.wikimedia.org/wikipedia/commons/d/de/Stacking.png"></center><center>Gambar Stacking</center><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">StackingClassifier</span>

<span class="n">estimators</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span><span class="s1">&#39;rf1&#39;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;svr&#39;</span><span class="p">,</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)))</span>
<span class="p">]</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">(</span>
    <span class="n">estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span> <span class="n">final_estimator</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8
</pre></div>
</div>
</div>
</div>
</section>
<section id="random-forest-classification">
<h2><strong>Random Forest Classification</strong><a class="headerlink" href="#random-forest-classification" title="Permalink to this headline">#</a></h2>
<p>Random forest (RF) adalah suatu algoritma yang digunakan pada klasifikasi data dalam jumlah yang besar. Klasifikasi random forest dilakukan melalui penggabungan pohon (tree) dengan melakukan training pada sampel data yang dimiliki. Penggunaan pohon (tree) yang semakin banyak akan mempengaruhi akurasi yang akan didapatkan menjadi lebih baik. Penentuan klasifikasi dengan random forest diambil berdasarkan hasil voting dari tree yang terbentuk. Pemenang dari tree yang terbentuk ditentukan dengan vote terbanyak. Pembangunan pohon (tree) pada random forest sampai dengan mencapai ukuran maksimum dari pohon data. Akan tetapi,pembangunan pohon random forest tidak dilakukan pemangkasan (pruning) yang merupakan sebuah metode untuk mengurangi kompleksitas ruang. Pembangunan dilakukan dengan penerapan metode random feature selection untuk meminimalisir kesalahan. Pembentukan pohon (tree) dengan sample data menggunakan variable yang diambil secara acak dan menjalankan klasifikasi pada semua tree yang terbentuk. Random forest menggunakan Decision Tree untuk melakukan proses seleksi. Pohon yang dibangun dibagi secara rekursif dari data pada kelas yang sama. Pemecahan (split) digunakan untuk membagi data berdasarkan jenis atribut yang digunakan. Pembuatan decision tree pada saat penentuan klasifikasi,pohon yang buruk akan membuat prediksi acak yang saling bertentangan. Sehingga,beberapa decision tree akan menghasilkan jawaban yang baik. Random forest merupakan salah satu cara penerapan dari pendekatan diskriminasi stokastik pada klasifikasi. Proses Klasifikasi akan berjalan jika semua tree telah terbentuk.Pada saat proses klasifikasi selesai dilakukan, inisialisasi dilakukan dengan sebanyak data berdasarkan nilai akurasinya. Keuntungan penggunaan random forest yaitu mampu mengklasifiksi data yang memiliki atribut yang tidak lengkap,dapat digunakan untuk klasifikasi dan regresi akan tetapi tidak terlalu bagus untuk regresi, lebih cocok untuk pengklasifikasian data serta dapat digunakan untuk menangani data sampel yang banyak. Proses klasifikasi pada random forest berawal dari memecah data sampel yang ada kedalam decision tree secara acak. Setelah pohon terbentuk,maka akan dilakukan voting pada setiap kelas dari data sampel. Kemudian, mengkombinasikan vote dari setiap kelas kemudian diambil vote yang paling banyak.Dengan menggunakan random forest pada klasifikasi data maka, akan menghasilkan vote yang paling baik.<br></p>
<center><img src='https://upload.wikimedia.org/wikipedia/commons/7/76/Random_forest_diagram_complete.png'></center><center>Gambar Random Forest</center><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="c1">#Create a Gaussian Classifier</span>
<span class="n">clf</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1">#Train the model using the training sets y_pred=clf.predict(X_test)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1"># prediction on test set</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1">#Import scikit-learn metrics module for accuracy calculation</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="c1"># Model Accuracy, how often is the classifier correct?</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.6666666666666666
</pre></div>
</div>
</div>
</div>
</section>
<section id="grid-search">
<h2><strong>Grid Search</strong><a class="headerlink" href="#grid-search" title="Permalink to this headline">#</a></h2>
<p>Grid Search adalah sebuah function yang terdapat pada library Scikit-Learn. Function ini dapat membantu untuk mengulang melalui hyperparameter yang telah ditentukan dan menyesuaikan estimator (model) Anda pada data set pelatihan. Pada kali ini saya akan menggunakan Grid Search untuk membantu menemukan nilai estimator atau nilai yang terbaik sehingga nilai dari base classifier mendapatkan hasil akurasi yang terbaik pada metode Bagging dan Random Forest Classification.</p>
<section id="bagging-classification-dengan-menggunakan-grid-search">
<h3>Bagging Classification dengan menggunakan Grid Search<a class="headerlink" href="#bagging-classification-dengan-menggunakan-grid-search" title="Permalink to this headline">#</a></h3>
<p>Penggunaan Grid Search pada metode Bagging Classification untuk menemukan nilai estimator terbaik sehingga menghasilkan akurasi yang terbaik dapat dilakukan sebagai berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">model_selection</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;base_estimator__max_depth&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">X_train</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">y_train</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">DecisionTreeClassifier</span><span class="p">(),</span>
                                     <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">max_features</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">param_grid</span><span class="p">)</span>
 
<span class="n">results</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;accuracy :&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>accuracy :
0.5058823529411764
</pre></div>
</div>
</div>
</div>
</section>
<section id="random-forest-classification-dengan-menggunakan-grid-search">
<h3>Random Forest Classification dengan menggunakan Grid Search<a class="headerlink" href="#random-forest-classification-dengan-menggunakan-grid-search" title="Permalink to this headline">#</a></h3>
<p>Penggunaan Grid Search pada metode Random Forest Classification untuk menemukan nilai estimator terbaik sehingga menghasilkan akurasi yang terbaik dapat dilakukan sebagai berikut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">hyper_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
                <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>
                <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">400</span><span class="p">],</span>
                <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
                <span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Grid search</span>
<span class="n">model_cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(),</span>
                        <span class="n">param_grid</span><span class="o">=</span><span class="n">hyper_params</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 625 candidates, totalling 3125 fits
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=1,
             param_grid={&#39;max_depth&#39;: [3, 5, 10, 15, 20],
                         &#39;max_features&#39;: [3, 5, 7, 11, 15],
                         &#39;min_samples_leaf&#39;: [20, 50, 100, 200, 400],
                         &#39;n_estimators&#39;: [10, 25, 50, 80, 100]},
             return_train_score=True, verbose=1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">estimator</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(),</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
             <span class="n">param_grid</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
                         <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>
                         <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">400</span><span class="p">],</span>
                         <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">100</span><span class="p">]},</span>
             <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=1,
             param_grid={&#39;max_depth&#39;: [3, 5, 10, 15, 20],
                         &#39;max_features&#39;: [3, 5, 7, 11, 15],
                         &#39;min_samples_leaf&#39;: [20, 50, 100, 200, 400],
                         &#39;n_estimators&#39;: [10, 25, 50, 80, 100]},
             return_train_score=True, verbose=1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_cv</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.48235294117647054
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_cv</span><span class="o">.</span><span class="n">best_estimator_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RandomForestClassifier(max_depth=10, max_features=11, min_samples_leaf=20,
                       n_estimators=50)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Pengimplementasian best estimator hasil dari GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="c1">#Create a Gaussian Classifier</span>
<span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                       <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="c1">#Train the model using the training sets y_pred=clf.predict(X_test)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1"># prediction on test set</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1">#Import scikit-learn metrics module for accuracy calculation</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="c1"># Model Accuracy, how often is the classifier correct?</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.4666666666666667
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id68">
<h2><strong>Kesimpulan</strong><a class="headerlink" href="#id68" title="Permalink to this headline">#</a></h2>
<p>Berdasar dari hasil atau nilai akurasi yang di dapat dari semua metode ensemble learning, metode Stacking Classification menghasilkan nilai akurasi yang paling baik dengan nilai akurasi sebesar 80% dibandingkan dengan metode Random Forest Classification sebesar 66% dan metode Bagging Classification sebesar 57%. Dan dari hasil akurasi yang diperoleh dari metode Bagging dan Random Forest Classification dengan menggunakan Grid Search memperoleh hasil atau nilai akurasi yang lebih buruk dibandingkan tanpa menggunakan Grid Search. Sehingga dapat disimpulkan bahwa penggunaan Grid Searh pada metode Bagging dan Random Forest Classification pada data Twitteer dengan pencarian ‘#rockygerung’ menunjukkan bahwa penggunaan Grid Searh tidak dapat meningkatkan nilai akurasi yang diperoleh, akan tetapi membuat nilai akurasi yang di dapat semakin buruk. Oleh karena itu penggunaan Grid Search pada metode Bagging dan Random Forest Classification tidak begitu berpengaruh terhadap peningkatan akurasi yang diperoleh.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Welcome to your Jupyter Book</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="ekstraksi.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Ekstraksi Ringkasan Dokumen</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Jupyter Book Community<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>